30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   9%|▉         | 9/100 [00:06<01:07,  1.35pipeline/s]Optimization Progress:  89%|████████▉ | 89/100 [00:10<00:05,  1.88pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  1.88pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  2.34pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.34pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.34pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 100/100 [00:14<00:00,  2.34pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.34pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.34pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  2.34pipeline/s]Optimization Progress:  52%|█████▏    | 103/200 [00:16<01:06,  1.45pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 103/200 [00:16<01:06,  1.45pipeline/s]Optimization Progress:  52%|█████▎    | 105/200 [00:20<01:49,  1.16s/pipeline]Optimization Progress:  92%|█████████▎| 185/200 [00:45<00:13,  1.11pipeline/s]
Generation 1 - Current Pareto front scores:
-1	-357685369.898048	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-2	-256427570.41419634	SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=1), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 200/200 [00:47<00:00,  1.11pipeline/s]Optimization Progress: 100%|██████████| 200/200 [00:47<00:00,  1.49pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:47<00:00,  1.49pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:42:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:49<00:00,  1.49pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 [10:42:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:49<00:00,  1.49pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [00:49<00:00,  1.49pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:51<00:00,  1.49pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [00:52<00:00,  1.49pipeline/s]Optimization Progress:  67%|██████▋   | 201/300 [01:07<10:22,  6.29s/pipeline]Optimization Progress:  94%|█████████▎| 281/300 [02:01<01:27,  4.61s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-357685369.898048	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-2	-256427570.41419634	SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=1), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [02:02<00:00,  4.61s/pipeline]Optimization Progress: 100%|██████████| 300/300 [02:02<00:00,  3.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:43:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 300/300 [02:02<00:00,  3.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 300/300 [02:02<00:00,  3.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 300/300 [02:03<00:00,  3.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [02:03<00:00,  3.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [02:04<00:00,  3.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 300/300 [02:06<00:00,  3.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [02:07<00:00,  3.23s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [02:09<05:33,  3.41s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [02:20<05:33,  3.41s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [04:22<1:08:24, 42.32s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [04:36<08:24, 29.67s/pipeline]  
Generation 3 - Current Pareto front scores:
-1	-357397654.65250266	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25)
-2	-256427570.41419634	SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=1), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 400/400 [04:36<00:00, 29.67s/pipeline]Optimization Progress: 100%|██████████| 400/400 [04:36<00:00, 20.78s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:46:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 400/400 [04:38<00:00, 20.78s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [04:38<00:00, 20.78s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [04:39<00:00, 20.78s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [04:40<00:00, 20.78s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [04:40<00:00, 20.78s/pipeline]Optimization Progress:  80%|████████  | 401/500 [04:50<34:16, 20.78s/pipeline]Optimization Progress:  80%|████████  | 402/500 [05:13<32:47, 20.07s/pipeline]Optimization Progress:  96%|█████████▋| 482/500 [05:24<04:13, 14.09s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-357397654.65250266	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25)
-2	-256427570.41419634	SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=1), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:46:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 500/500 [05:24<00:00, 14.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:46:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 500/500 [05:26<00:00, 14.09s/pipeline]Optimization Progress: 100%|██████████| 500/500 [05:26<00:00,  9.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [05:26<00:00,  9.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 500/500 [05:28<00:00,  9.89s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [05:29<12:57,  7.85s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [06:02<25:17, 15.48s/pipeline]Optimization Progress:  97%|█████████▋| 582/600 [06:05<03:15, 10.85s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-354242772.9340952	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-248442216.90397066	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [06:05<00:00, 10.85s/pipeline]Optimization Progress: 100%|██████████| 600/600 [06:05<00:00,  7.60s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [06:07<00:00,  7.60s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [06:08<00:00,  7.60s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [06:09<00:00,  7.60s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 602/700 [06:09<12:24,  7.60s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 603/700 [06:09<12:16,  7.60s/pipeline]Optimization Progress:  86%|████████▋ | 604/700 [06:09<08:57,  5.60s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▋ | 604/700 [06:09<08:57,  5.60s/pipeline]Optimization Progress:  86%|████████▋ | 605/700 [06:20<08:52,  5.60s/pipeline]Optimization Progress:  87%|████████▋ | 606/700 [06:24<09:31,  6.08s/pipeline]Optimization Progress:  98%|█████████▊| 686/700 [06:25<00:59,  4.26s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-354242772.9340952	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-248442216.90397066	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [06:27<00:00,  4.26s/pipeline]Optimization Progress: 100%|██████████| 700/700 [06:27<00:00,  3.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:47:53] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 700/700 [06:27<00:00,  3.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 700/700 [06:28<00:00,  3.02s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [06:28<03:44,  2.29s/pipeline]Optimization Progress:  88%|████████▊ | 704/800 [06:33<03:42,  2.32s/pipeline]Optimization Progress:  98%|█████████▊| 783/800 [06:35<00:27,  1.63s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-354242772.9340952	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-248442216.90397066	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [06:36<00:00,  1.63s/pipeline]Optimization Progress: 100%|██████████| 800/800 [06:36<00:00,  1.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 800/800 [06:36<00:00,  1.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [06:37<00:00,  1.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:48:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 800/800 [06:38<00:00,  1.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 800/800 [06:38<00:00,  1.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 800/800 [06:38<00:00,  1.16s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [06:44<03:19,  2.03s/pipeline]Optimization Progress:  98%|█████████▊| 882/900 [06:46<00:25,  1.43s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-248442216.90397066	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [06:46<00:00,  1.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [06:46<00:00,  1.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:48:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 900/900 [06:46<00:00,  1.43s/pipeline]Optimization Progress: 100%|██████████| 900/900 [06:46<00:00,  1.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 900/900 [06:46<00:00,  1.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [10:48:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 900/900 [06:46<00:00,  1.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 900/900 [06:47<00:00,  1.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [06:48<00:00,  1.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 900/900 [06:48<00:00,  1.01s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 900/1000 [06:50<01:40,  1.01s/pipeline]Optimization Progress:  90%|█████████ | 903/1000 [06:55<02:33,  1.58s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [06:57<00:20,  1.12s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-248274882.3715229	LinearSVR(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-217722543.50187406	LinearSVR(Nystroem(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [06:58<00:00,  1.12s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [06:58<00:00,  1.26pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1000/1000 [06:59<00:00,  1.26pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [07:00<01:18,  1.26pipeline/s]Optimization Progress:  91%|█████████ | 1003/1100 [07:03<01:44,  1.08s/pipeline]Optimization Progress:  98%|█████████▊| 1083/1100 [07:05<00:13,  1.31pipeline/s]
Generation 10 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-248274882.3715229	LinearSVR(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-211432694.73746327	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=1), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 1100/1100 [07:05<00:00,  1.31pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:05<00:00,  1.31pipeline/s]Optimization Progress: 100%|██████████| 1100/1100 [07:05<00:00,  1.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:05<00:00,  1.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:48:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 1100/1100 [07:06<00:00,  1.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 1100/1100 [07:06<00:00,  1.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:07<00:00,  1.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 1100/1100 [07:07<00:00,  1.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:07<00:00,  1.85pipeline/s]Optimization Progress:  92%|█████████▏| 1105/1200 [07:12<01:11,  1.33pipeline/s]Optimization Progress:  99%|█████████▊| 1183/1200 [07:14<00:09,  1.87pipeline/s]
Generation 11 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-248274882.3715229	LinearSVR(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=sigmoid, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-211432694.73746327	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=1), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1200/1200 [07:14<00:00,  1.87pipeline/s]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1200/1200 [07:14<00:00,  1.87pipeline/s]Optimization Progress: 100%|██████████| 1200/1200 [07:14<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [07:14<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1200/1200 [07:14<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [07:15<00:00,  2.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1202/1300 [07:15<00:37,  2.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1203/1300 [07:15<00:36,  2.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1204/1300 [07:15<00:36,  2.65pipeline/s]Optimization Progress:  93%|█████████▎| 1205/1300 [07:15<00:32,  2.91pipeline/s]Optimization Progress:  93%|█████████▎| 1209/1300 [07:24<01:21,  1.12pipeline/s]Optimization Progress:  99%|█████████▉| 1286/1300 [07:27<00:08,  1.57pipeline/s]
Generation 12 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-236319856.42189234	SGDRegressor(Normalizer(input_matrix, Normalizer__norm=l2), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-3	-211090760.08721247	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:27<00:00,  1.57pipeline/s]Optimization Progress: 100%|██████████| 1300/1300 [07:27<00:00,  2.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1300/1300 [07:27<00:00,  2.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [07:27<00:00,  2.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:28<00:00,  2.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1300/1300 [07:28<00:00,  2.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1300/1300 [07:28<00:00,  2.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1300/1300 [07:28<00:00,  2.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 1300/1300 [07:29<00:00,  2.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1303/1400 [07:29<00:43,  2.23pipeline/s]Optimization Progress:  93%|█████████▎| 1304/1400 [07:29<00:44,  2.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1304/1400 [07:29<00:44,  2.15pipeline/s]Optimization Progress:  93%|█████████▎| 1307/1400 [07:34<01:15,  1.24pipeline/s]Optimization Progress:  99%|█████████▉| 1386/1400 [07:36<00:08,  1.74pipeline/s]
Generation 13 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-236319856.42189234	SGDRegressor(Normalizer(input_matrix, Normalizer__norm=l2), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-3	-211090760.08721247	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:49:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 1400/1400 [07:36<00:00,  1.74pipeline/s]Optimization Progress: 100%|██████████| 1400/1400 [07:36<00:00,  2.44pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1400/1400 [07:37<00:00,  2.44pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [07:37<00:00,  2.44pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:49:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 1400/1400 [07:38<00:00,  2.44pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [07:38<00:00,  2.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1400/1500 [07:39<00:40,  2.44pipeline/s]Optimization Progress:  94%|█████████▎| 1403/1500 [07:47<02:09,  1.34s/pipeline]Optimization Progress:  99%|█████████▉| 1482/1500 [07:49<00:17,  1.06pipeline/s]
Generation 14 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-236319856.42189234	SGDRegressor(Normalizer(input_matrix, Normalizer__norm=l2), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-3	-208864988.87212414	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [07:49<00:00,  1.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1500/1500 [07:50<00:00,  1.06pipeline/s]Optimization Progress: 100%|██████████| 1500/1500 [07:50<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1500/1500 [07:50<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [07:50<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00100.
Optimization Progress: 100%|██████████| 1500/1500 [07:50<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [07:50<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:49:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 1500/1500 [07:51<00:00,  1.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1501/1600 [07:51<01:05,  1.50pipeline/s]Optimization Progress:  94%|█████████▍| 1503/1600 [08:05<03:12,  1.98s/pipeline]Optimization Progress:  99%|█████████▉| 1583/1600 [08:07<00:23,  1.40s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-236317231.1829447	SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-3	-206792911.10972878	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.40s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [08:09<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [08:09<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1600/1600 [08:09<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 1600/1600 [08:09<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1600/1600 [08:10<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1600/1600 [08:10<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 1600/1600 [08:10<00:00,  1.01pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1600/1700 [08:10<01:38,  1.01pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1601/1700 [08:10<01:37,  1.01pipeline/s]Optimization Progress:  94%|█████████▍| 1602/1700 [08:10<01:38,  1.00s/pipeline]Optimization Progress:  94%|█████████▍| 1604/1700 [08:14<02:08,  1.34s/pipeline]Optimization Progress:  99%|█████████▉| 1683/1700 [08:18<00:16,  1.05pipeline/s]
Generation 16 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-217616270.1035974	LinearSVR(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=laplacian, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-206792911.10972878	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-4	-202602961.63259324	SGDRegressor(Nystroem(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [08:18<00:00,  1.05pipeline/s]Optimization Progress: 100%|██████████| 1700/1700 [08:18<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [08:18<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [08:18<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1700/1700 [08:19<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [08:19<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [08:19<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1700/1700 [08:19<00:00,  1.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1700/1700 [08:19<00:00,  1.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1703/1800 [08:20<01:04,  1.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1704/1800 [08:20<01:04,  1.50pipeline/s]Optimization Progress:  95%|█████████▍| 1705/1800 [08:20<00:55,  1.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1705/1800 [08:20<00:55,  1.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1706/1800 [08:20<00:55,  1.70pipeline/s]Optimization Progress:  95%|█████████▍| 1709/1800 [08:24<01:09,  1.30pipeline/s]Optimization Progress:  99%|█████████▉| 1788/1800 [08:27<00:06,  1.83pipeline/s]
Generation 17 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-217616270.1035974	LinearSVR(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=laplacian, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-206792911.10972878	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-4	-202602961.63259324	SGDRegressor(Nystroem(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1800/1800 [08:27<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [08:27<00:00,  1.83pipeline/s]Optimization Progress: 100%|██████████| 1800/1800 [08:27<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [08:27<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [08:27<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 1800/1800 [08:27<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00010.
Optimization Progress: 100%|██████████| 1800/1800 [08:27<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [08:28<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 1800/1800 [08:28<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [08:28<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [08:28<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [08:28<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00100.
Optimization Progress: 100%|██████████| 1800/1800 [08:29<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [08:29<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [08:29<00:00,  2.59pipeline/s]Optimization Progress:  95%|█████████▌| 1805/1900 [08:32<00:58,  1.63pipeline/s]Optimization Progress:  99%|█████████▉| 1883/1900 [08:35<00:07,  2.28pipeline/s]
Generation 18 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216291141.6580047	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-206792911.10972878	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-4	-202602961.63259324	SGDRegressor(Nystroem(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [08:35<00:00,  2.28pipeline/s]Optimization Progress: 100%|██████████| 1900/1900 [08:35<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [08:35<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [08:35<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [08:35<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [08:36<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [08:36<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [08:36<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [08:36<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [08:36<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [08:36<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 1900/1900 [08:36<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 1900/1900 [08:37<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1900/1900 [08:37<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 1900/1900 [08:37<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [08:37<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1900/1900 [08:37<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [08:37<00:00,  3.23pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [08:37<00:00,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1902/2000 [08:38<00:30,  3.23pipeline/s]Optimization Progress:  95%|█████████▌| 1905/2000 [08:44<01:09,  1.36pipeline/s]Optimization Progress:  99%|█████████▉| 1984/2000 [08:48<00:08,  1.89pipeline/s]
Generation 19 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216291141.6580047	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-206792911.10972878	SGDRegressor(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-4	-202602961.63259324	SGDRegressor(Nystroem(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2000/2000 [08:48<00:00,  1.89pipeline/s]Optimization Progress: 100%|██████████| 2000/2000 [08:48<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:50:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 2000/2000 [08:49<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [10:50:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 2000/2000 [08:49<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [08:49<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [08:49<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2000/2000 [08:49<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [08:49<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [08:50<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 2000/2000 [08:50<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [08:50<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [08:50<00:00,  2.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [08:50<00:00,  2.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2003/2100 [08:50<00:36,  2.65pipeline/s]Optimization Progress:  95%|█████████▌| 2004/2100 [08:50<00:39,  2.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2004/2100 [08:50<00:39,  2.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2005/2100 [08:50<00:39,  2.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2006/2100 [08:50<00:39,  2.40pipeline/s]Optimization Progress:  96%|█████████▌| 2008/2100 [09:03<01:55,  1.26s/pipeline]Optimization Progress:  99%|█████████▉| 2088/2100 [09:07<00:10,  1.12pipeline/s]
Generation 20 - Current Pareto front scores:
-1	-353751849.33210135	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=17, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216291141.6580047	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-189811740.20610192	LinearSVR(Nystroem(MaxAbsScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=laplacian, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-5	-188846094.06540826	SGDRegressor(PolynomialFeatures(Nystroem(ZeroCount(MaxAbsScaler(input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=chi2, Nystroem__n_components=4), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.12pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.12pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.12pipeline/s]Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [09:07<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [09:08<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 2100/2100 [09:08<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [09:08<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [09:08<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [09:08<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [09:08<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 2100/2100 [09:09<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 2100/2100 [09:09<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [09:09<00:00,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2100/2200 [09:09<01:03,  1.58pipeline/s]Optimization Progress:  96%|█████████▌| 2103/2200 [09:14<01:51,  1.15s/pipeline]Optimization Progress:  99%|█████████▉| 2182/2200 [09:17<00:14,  1.22pipeline/s]
Generation 21 - Current Pareto front scores:
-1	-353498107.5002518	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216291141.6580047	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-185905464.86910552	LinearSVR(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=laplacian, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.22pipeline/s]Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 2200/2200 [09:18<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2200/2200 [09:19<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [09:19<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [09:19<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2200/2200 [09:19<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [09:19<00:00,  1.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [09:19<00:00,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2201/2300 [09:20<00:57,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2202/2300 [09:20<00:56,  1.73pipeline/s]Optimization Progress:  96%|█████████▌| 2204/2300 [09:26<01:36,  1.00s/pipeline]Optimization Progress:  99%|█████████▉| 2284/2300 [09:30<00:11,  1.39pipeline/s]
Generation 22 - Current Pareto front scores:
-1	-353498107.5002518	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216291141.6580047	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-185905464.86910552	LinearSVR(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=laplacian, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2300/2300 [09:30<00:00,  1.39pipeline/s]Optimization Progress: 100%|██████████| 2300/2300 [09:30<00:00,  1.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [09:31<00:00,  1.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [09:31<00:00,  1.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [09:31<00:00,  1.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:50:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 2300/2300 [09:31<00:00,  1.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [09:32<00:00,  1.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 2300/2300 [09:32<00:00,  1.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2300/2300 [09:32<00:00,  1.97pipeline/s]Optimization Progress:  96%|█████████▌| 2306/2400 [09:33<00:45,  2.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2306/2400 [09:33<00:45,  2.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2307/2400 [09:33<00:45,  2.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2308/2400 [09:33<00:44,  2.07pipeline/s]Optimization Progress:  96%|█████████▋| 2310/2400 [09:38<01:02,  1.44pipeline/s]Optimization Progress: 100%|█████████▉| 2390/2400 [09:40<00:04,  2.02pipeline/s]
Generation 23 - Current Pareto front scores:
-1	-353498107.5002518	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216203376.09456983	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=4), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-185905464.86910552	LinearSVR(Nystroem(MaxAbsScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=laplacian, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2400/2400 [09:42<00:00,  2.02pipeline/s]Optimization Progress: 100%|██████████| 2400/2400 [09:42<00:00,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2401/2500 [09:42<00:39,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2402/2500 [09:42<00:39,  2.48pipeline/s]Optimization Progress:  96%|█████████▌| 2403/2500 [09:42<00:28,  3.37pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2403/2500 [09:42<00:28,  3.37pipeline/s]Optimization Progress:  96%|█████████▌| 2406/2500 [09:48<01:14,  1.26pipeline/s]Optimization Progress:  99%|█████████▉| 2485/2500 [09:50<00:08,  1.77pipeline/s]
Generation 24 - Current Pareto front scores:
-1	-353498107.5002518	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216203376.09456983	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=4), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177369453.05550367	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [09:50<00:00,  1.77pipeline/s]Optimization Progress: 100%|██████████| 2500/2500 [09:50<00:00,  2.46pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [09:51<00:00,  2.46pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2500/2500 [09:51<00:00,  2.46pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [09:52<00:00,  2.46pipeline/s]Optimization Progress:  96%|█████████▋| 2504/2600 [09:52<00:38,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2504/2600 [09:52<00:38,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2505/2600 [09:52<00:37,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2506/2600 [09:52<00:37,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2507/2600 [09:52<00:37,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2508/2600 [09:52<00:36,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2509/2600 [09:52<00:36,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2510/2600 [09:52<00:35,  2.51pipeline/s]Optimization Progress:  97%|█████████▋| 2512/2600 [09:55<00:34,  2.57pipeline/s]Optimization Progress: 100%|█████████▉| 2592/2600 [09:55<00:02,  3.66pipeline/s]
Generation 25 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216203376.09456983	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=4), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177350730.5002144	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:51:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 2600/2600 [09:56<00:00,  3.66pipeline/s]Optimization Progress: 100%|██████████| 2600/2600 [09:56<00:00,  4.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:51:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 2600/2600 [09:56<00:00,  4.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [09:58<00:00,  4.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [09:58<00:19,  4.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2603/2700 [09:58<00:19,  4.91pipeline/s]Optimization Progress:  97%|█████████▋| 2606/2700 [10:01<00:40,  2.33pipeline/s]Optimization Progress:  99%|█████████▉| 2685/2700 [10:04<00:04,  3.23pipeline/s]
Generation 26 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216203376.09456983	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=4), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177350730.5002144	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [10:04<00:00,  3.23pipeline/s]Optimization Progress: 100%|██████████| 2700/2700 [10:04<00:00,  4.49pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [10:05<00:00,  4.49pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [10:05<00:00,  4.49pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [10:05<00:00,  4.49pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 2700/2700 [10:05<00:00,  4.49pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [10:06<00:00,  4.49pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:51:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 2700/2700 [10:06<00:00,  4.49pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:51:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 2700/2700 [10:06<00:00,  4.49pipeline/s]Optimization Progress:  97%|█████████▋| 2706/2800 [10:06<00:24,  3.79pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2706/2800 [10:06<00:24,  3.79pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2707/2800 [10:06<00:24,  3.79pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2708/2800 [10:06<00:24,  3.79pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2709/2800 [10:06<00:24,  3.79pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2710/2800 [10:06<00:23,  3.79pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2711/2800 [10:06<00:23,  3.79pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2712/2800 [10:06<00:23,  3.79pipeline/s]Optimization Progress:  97%|█████████▋| 2714/2800 [10:10<00:28,  3.04pipeline/s]Optimization Progress: 100%|█████████▉| 2794/2800 [10:11<00:01,  4.26pipeline/s]
Generation 27 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-216032740.4891706	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177280445.9237676	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [10:12<00:00,  4.26pipeline/s]Optimization Progress: 100%|██████████| 2800/2800 [10:12<00:00,  5.57pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [10:12<00:00,  5.57pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 2800/2800 [10:12<00:00,  5.57pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2802/2900 [10:13<00:17,  5.57pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2803/2900 [10:13<00:17,  5.57pipeline/s]Optimization Progress:  97%|█████████▋| 2804/2900 [10:13<00:22,  4.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2804/2900 [10:13<00:22,  4.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2805/2900 [10:13<00:22,  4.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2806/2900 [10:13<00:21,  4.30pipeline/s]Optimization Progress:  97%|█████████▋| 2808/2900 [10:17<00:45,  2.03pipeline/s]Optimization Progress: 100%|█████████▉| 2888/2900 [10:20<00:04,  2.84pipeline/s]
Generation 28 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-215213781.59545088	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177280445.9237676	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-177074697.26576194	LinearSVR(Nystroem(GradientBoostingRegressor(MinMaxScaler(input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-177025369.69809172	LinearSVR(MaxAbsScaler(Nystroem(MaxAbsScaler(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=laplacian, Nystroem__n_components=5)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [10:20<00:00,  2.84pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [10:21<00:00,  2.84pipeline/s]Optimization Progress: 100%|██████████| 2900/2900 [10:21<00:00,  3.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [10:22<00:00,  3.47pipeline/s]Optimization Progress:  97%|█████████▋| 2902/3000 [10:22<00:38,  2.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2902/3000 [10:22<00:38,  2.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2903/3000 [10:22<00:38,  2.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2904/3000 [10:22<00:37,  2.53pipeline/s]Optimization Progress:  97%|█████████▋| 2906/3000 [10:25<00:47,  1.99pipeline/s]Optimization Progress: 100%|█████████▉| 2986/3000 [10:30<00:05,  2.71pipeline/s]
Generation 29 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-215213781.59545088	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177280445.9237676	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-174812093.94022673	LinearSVR(Nystroem(MinMaxScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [10:30<00:00,  2.71pipeline/s]Optimization Progress: 100%|██████████| 3000/3000 [10:30<00:00,  3.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [10:31<00:00,  3.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:51:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 3000/3000 [10:32<00:00,  3.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [10:32<00:00,  3.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [10:32<00:00,  3.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [10:32<00:00,  3.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:51:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 3000/3000 [10:33<00:00,  3.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 3000/3000 [10:33<00:00,  3.77pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3002/3100 [10:33<00:26,  3.77pipeline/s]Optimization Progress:  97%|█████████▋| 3003/3100 [10:33<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3003/3100 [10:33<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3004/3100 [10:33<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3005/3100 [10:33<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3006/3100 [10:33<00:43,  2.16pipeline/s]Optimization Progress:  97%|█████████▋| 3008/3100 [10:39<01:01,  1.50pipeline/s]Optimization Progress: 100%|█████████▉| 3088/3100 [10:41<00:05,  2.12pipeline/s]
Generation 30 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-215213781.59545088	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177280445.9237676	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-174812093.94022673	LinearSVR(Nystroem(MinMaxScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [10:41<00:00,  2.12pipeline/s]Optimization Progress: 100%|██████████| 3100/3100 [10:41<00:00,  2.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [10:43<00:35,  2.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3102/3200 [10:43<00:34,  2.82pipeline/s]Optimization Progress:  97%|█████████▋| 3103/3200 [10:43<00:42,  2.28pipeline/s]Optimization Progress:  97%|█████████▋| 3105/3200 [10:50<02:02,  1.29s/pipeline]Optimization Progress: 100%|█████████▉| 3184/3200 [10:53<00:14,  1.10pipeline/s]
Generation 31 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-215213781.59545088	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177280445.9237676	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-174812093.94022673	LinearSVR(Nystroem(MinMaxScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [10:53<00:00,  1.10pipeline/s]Optimization Progress: 100%|██████████| 3200/3200 [10:53<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [10:54<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [10:54<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 3200/3200 [10:54<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:52:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 3200/3200 [10:54<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [10:55<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3200/3200 [10:55<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:52:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 3200/3200 [10:56<00:00,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [10:56<01:02,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3203/3300 [10:56<01:02,  1.56pipeline/s]Optimization Progress:  97%|█████████▋| 3204/3300 [10:56<01:02,  1.55pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3204/3300 [10:56<01:02,  1.55pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3205/3300 [10:56<01:01,  1.55pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3206/3300 [10:56<01:00,  1.55pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3207/3300 [10:56<01:00,  1.55pipeline/s]Optimization Progress:  97%|█████████▋| 3209/3300 [10:59<00:58,  1.56pipeline/s]Optimization Progress: 100%|█████████▉| 3289/3300 [11:00<00:05,  2.20pipeline/s]
Generation 32 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-215213781.59545088	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.45, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-177280445.9237676	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-174812093.94022673	LinearSVR(Nystroem(MinMaxScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-168419565.164481	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(input_matrix)), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 3300/3300 [11:01<00:00,  2.20pipeline/s]Optimization Progress: 100%|██████████| 3300/3300 [11:01<00:00,  2.92pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3300/3300 [11:02<00:00,  2.92pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [11:02<00:00,  2.92pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [11:03<00:00,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3300/3400 [11:03<00:34,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3301/3400 [11:04<00:33,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3302/3400 [11:04<00:33,  2.92pipeline/s]Optimization Progress:  97%|█████████▋| 3303/3400 [11:04<00:43,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3303/3400 [11:04<00:43,  2.22pipeline/s]Optimization Progress:  97%|█████████▋| 3305/3400 [11:10<02:01,  1.28s/pipeline]Optimization Progress: 100%|█████████▉| 3385/3400 [11:12<00:13,  1.11pipeline/s]
Generation 33 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205654604.62535566	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-147859995.3652856	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [11:12<00:00,  1.11pipeline/s]Optimization Progress: 100%|██████████| 3400/3400 [11:12<00:00,  1.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:52:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 3400/3400 [11:14<00:00,  1.56pipeline/s]Optimization Progress:  97%|█████████▋| 3403/3500 [11:15<01:08,  1.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3403/3500 [11:15<01:08,  1.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3404/3500 [11:15<01:07,  1.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3405/3500 [11:15<01:07,  1.41pipeline/s]Optimization Progress:  97%|█████████▋| 3407/3500 [11:18<01:09,  1.35pipeline/s]Optimization Progress: 100%|█████████▉| 3487/3500 [11:21<00:06,  1.89pipeline/s]
Generation 34 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205654604.62535566	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-147859995.3652856	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [11:21<00:00,  1.89pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 3500/3500 [11:21<00:00,  1.89pipeline/s]Optimization Progress: 100%|██████████| 3500/3500 [11:21<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [11:22<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [11:23<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 3500/3500 [11:23<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 3500/3500 [11:23<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [11:24<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [11:24<00:00,  2.59pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:52:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 3500/3500 [11:24<00:00,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3500/3600 [11:25<00:38,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3501/3600 [11:25<00:38,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3502/3600 [11:25<00:37,  2.59pipeline/s]Optimization Progress:  97%|█████████▋| 3503/3600 [11:25<00:57,  1.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3503/3600 [11:25<00:57,  1.70pipeline/s]Optimization Progress:  97%|█████████▋| 3505/3600 [11:29<01:46,  1.12s/pipeline]Optimization Progress: 100%|█████████▉| 3585/3600 [11:30<00:11,  1.27pipeline/s]
Generation 35 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205654604.62535566	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-147859995.3652856	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 3600/3600 [11:31<00:00,  1.27pipeline/s]Optimization Progress: 100%|██████████| 3600/3600 [11:31<00:00,  1.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [11:32<00:00,  1.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3600/3600 [11:33<00:00,  1.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3600/3600 [11:33<00:00,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3600/3700 [11:33<00:56,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3601/3700 [11:33<00:56,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3602/3700 [11:33<00:55,  1.76pipeline/s]Optimization Progress:  97%|█████████▋| 3603/3700 [11:33<00:56,  1.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3603/3700 [11:33<00:56,  1.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3604/3700 [11:33<00:56,  1.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3605/3700 [11:33<00:55,  1.70pipeline/s]Optimization Progress:  97%|█████████▋| 3607/3700 [11:36<01:00,  1.53pipeline/s]Optimization Progress: 100%|█████████▉| 3687/3700 [11:40<00:06,  2.12pipeline/s]
Generation 36 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205654604.62535566	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-147859995.3652856	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [11:41<00:00,  2.12pipeline/s]Optimization Progress: 100%|██████████| 3700/3700 [11:41<00:00,  2.96pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3700/3700 [11:42<00:00,  2.96pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 3700/3700 [11:43<00:00,  2.96pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:53:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 3700/3700 [11:43<00:00,  2.96pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3700/3800 [11:44<00:33,  2.96pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3701/3800 [11:44<00:33,  2.96pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3702/3800 [11:44<00:33,  2.96pipeline/s]Optimization Progress:  97%|█████████▋| 3703/3800 [11:44<00:51,  1.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3703/3800 [11:44<00:51,  1.87pipeline/s]Optimization Progress:  98%|█████████▊| 3705/3800 [11:48<01:43,  1.09s/pipeline]Optimization Progress: 100%|█████████▉| 3785/3800 [11:50<00:11,  1.30pipeline/s]
Generation 37 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205654604.62535566	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-147859995.3652856	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-147076122.92724627	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [11:50<00:00,  1.30pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 3800/3800 [11:51<00:00,  1.30pipeline/s]Optimization Progress: 100%|██████████| 3800/3800 [11:51<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3800/3800 [11:51<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [11:52<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [11:52<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [11:52<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 3800/3800 [11:52<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [11:53<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 3800/3800 [11:53<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3800/3800 [11:53<00:00,  1.81pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3801/3900 [11:53<00:54,  1.81pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [11:53<00:54,  1.81pipeline/s]Optimization Progress:  98%|█████████▊| 3803/3900 [11:53<01:03,  1.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3803/3900 [11:53<01:03,  1.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3804/3900 [11:53<01:02,  1.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3805/3900 [11:53<01:02,  1.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3806/3900 [11:53<01:01,  1.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3807/3900 [11:53<01:00,  1.53pipeline/s]Optimization Progress:  98%|█████████▊| 3809/3900 [11:57<00:56,  1.62pipeline/s]Optimization Progress: 100%|█████████▉| 3889/3900 [12:01<00:04,  2.22pipeline/s]
Generation 38 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-147859995.3652856	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-147076122.92724627	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 3900/3900 [12:02<00:00,  2.22pipeline/s]Optimization Progress: 100%|██████████| 3900/3900 [12:02<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [12:02<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [12:03<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3900/3900 [12:03<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [12:04<00:00,  3.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3901/4000 [12:04<00:32,  3.06pipeline/s]Optimization Progress:  98%|█████████▊| 3902/4000 [12:04<00:59,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [12:04<00:59,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3903/4000 [12:04<00:59,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3904/4000 [12:04<00:58,  1.64pipeline/s]Optimization Progress:  98%|█████████▊| 3906/4000 [12:08<01:03,  1.47pipeline/s]Optimization Progress: 100%|█████████▉| 3986/4000 [12:09<00:06,  2.08pipeline/s]
Generation 39 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-144758946.03771064	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [12:09<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:53:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 4000/4000 [12:09<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [12:10<00:00,  2.08pipeline/s]Optimization Progress: 100%|██████████| 4000/4000 [12:10<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 4000/4000 [12:10<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [12:11<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [12:11<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [12:12<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 4000/4000 [12:12<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [12:12<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [12:12<00:00,  2.88pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [12:12<00:00,  2.88pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4001/4100 [12:12<00:34,  2.88pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4002/4100 [12:12<00:34,  2.88pipeline/s]Optimization Progress:  98%|█████████▊| 4003/4100 [12:12<00:46,  2.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4003/4100 [12:12<00:46,  2.09pipeline/s]Optimization Progress:  98%|█████████▊| 4005/4100 [12:15<01:10,  1.35pipeline/s]Optimization Progress: 100%|█████████▉| 4085/4100 [12:16<00:07,  1.91pipeline/s]
Generation 40 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-144758946.03771064	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [12:16<00:00,  1.91pipeline/s]Optimization Progress: 100%|██████████| 4100/4100 [12:16<00:00,  2.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [12:16<00:00,  2.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 4100/4100 [12:17<00:00,  2.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [12:18<00:00,  2.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 4100/4100 [12:18<00:00,  2.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 4100/4100 [12:18<00:00,  2.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 4100/4100 [12:20<00:00,  2.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [12:20<00:00,  2.69pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4100/4200 [12:20<00:37,  2.69pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4101/4200 [12:20<00:36,  2.69pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4102/4200 [12:20<00:36,  2.69pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4103/4200 [12:20<00:36,  2.69pipeline/s]Optimization Progress:  98%|█████████▊| 4104/4200 [12:20<00:49,  1.93pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4104/4200 [12:20<00:49,  1.93pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4105/4200 [12:20<00:49,  1.93pipeline/s]Optimization Progress:  98%|█████████▊| 4107/4200 [12:24<01:16,  1.21pipeline/s]Optimization Progress: 100%|█████████▉| 4187/4200 [12:25<00:07,  1.72pipeline/s]
Generation 41 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-144758946.03771064	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-143293700.3498882	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:53:53] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 4200/4200 [12:27<00:00,  1.72pipeline/s]Optimization Progress: 100%|██████████| 4200/4200 [12:27<00:00,  2.24pipeline/s]Optimization Progress:  98%|█████████▊| 4203/4300 [12:28<00:43,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [12:28<00:43,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4204/4300 [12:28<00:43,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4205/4300 [12:28<00:42,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4206/4300 [12:28<00:42,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4207/4300 [12:28<00:41,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4208/4300 [12:28<00:41,  2.22pipeline/s]Optimization Progress:  98%|█████████▊| 4210/4300 [12:32<00:42,  2.14pipeline/s]Optimization Progress: 100%|█████████▉| 4290/4300 [12:36<00:03,  2.92pipeline/s]
Generation 42 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-144758946.03771064	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-143293700.3498882	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=10)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:54:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 4300/4300 [12:37<00:00,  2.92pipeline/s]Optimization Progress: 100%|██████████| 4300/4300 [12:37<00:00,  3.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 4300/4300 [12:37<00:00,  3.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [12:37<00:00,  3.85pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [12:38<00:00,  3.85pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4301/4400 [12:39<00:25,  3.85pipeline/s]Optimization Progress:  98%|█████████▊| 4302/4400 [12:39<00:45,  2.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4302/4400 [12:39<00:45,  2.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4303/4400 [12:39<00:44,  2.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4304/4400 [12:39<00:44,  2.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4305/4400 [12:39<00:43,  2.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4306/4400 [12:39<00:43,  2.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4307/4400 [12:39<00:42,  2.17pipeline/s]Optimization Progress:  98%|█████████▊| 4309/4400 [12:42<00:44,  2.05pipeline/s]Optimization Progress: 100%|█████████▉| 4389/4400 [12:43<00:03,  2.91pipeline/s]
Generation 43 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-144042925.5012135	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [12:43<00:00,  2.91pipeline/s]Optimization Progress: 100%|██████████| 4400/4400 [12:43<00:00,  3.99pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [12:43<00:00,  3.99pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [12:43<00:00,  3.99pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4400/4400 [12:44<00:00,  3.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4404/4500 [12:45<00:24,  3.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4405/4500 [12:45<00:23,  3.99pipeline/s]Optimization Progress:  98%|█████████▊| 4406/4500 [12:45<00:23,  3.97pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4406/4500 [12:45<00:23,  3.97pipeline/s]Optimization Progress:  98%|█████████▊| 4410/4500 [12:50<00:48,  1.84pipeline/s]Optimization Progress: 100%|█████████▉| 4488/4500 [12:52<00:04,  2.58pipeline/s]
Generation 44 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-174889552.7119221	LinearSVR(Nystroem(MinMaxScaler(input_matrix), Nystroem__gamma=0.9500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-4	-144042925.5012135	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [12:53<00:00,  2.58pipeline/s]Optimization Progress: 100%|██████████| 4500/4500 [12:53<00:00,  3.37pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4500/4500 [12:53<00:00,  3.37pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [12:53<00:00,  3.37pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [12:53<00:00,  3.37pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [12:54<00:00,  3.37pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4502/4600 [12:54<00:29,  3.37pipeline/s]Optimization Progress:  98%|█████████▊| 4503/4600 [12:54<00:33,  2.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4503/4600 [12:54<00:33,  2.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4504/4600 [12:54<00:33,  2.90pipeline/s]Optimization Progress:  98%|█████████▊| 4506/4600 [12:58<00:56,  1.65pipeline/s]Optimization Progress: 100%|█████████▉| 4586/4600 [13:00<00:06,  2.31pipeline/s]
Generation 45 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171285903.11882442	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-143884004.14022163	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4600/4600 [13:01<00:00,  2.31pipeline/s]Optimization Progress: 100%|██████████| 4600/4600 [13:01<00:00,  3.12pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 4600/4600 [13:01<00:00,  3.12pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4600/4700 [13:03<00:32,  3.12pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4601/4700 [13:03<00:31,  3.12pipeline/s]Optimization Progress:  98%|█████████▊| 4602/4700 [13:03<00:46,  2.10pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4602/4700 [13:03<00:46,  2.10pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4603/4700 [13:03<00:46,  2.10pipeline/s]Optimization Progress:  98%|█████████▊| 4605/4700 [13:06<00:58,  1.63pipeline/s]Optimization Progress: 100%|█████████▉| 4685/4700 [13:08<00:06,  2.29pipeline/s]
Generation 46 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171285903.11882442	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-143884004.14022163	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4700/4700 [13:09<00:00,  2.29pipeline/s]Optimization Progress: 100%|██████████| 4700/4700 [13:09<00:00,  3.00pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4700/4700 [13:10<00:00,  3.00pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4701/4800 [13:11<00:33,  3.00pipeline/s]Optimization Progress:  98%|█████████▊| 4702/4800 [13:11<00:45,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4702/4800 [13:11<00:45,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4703/4800 [13:11<00:45,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4704/4800 [13:11<00:44,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4705/4800 [13:11<00:44,  2.14pipeline/s]Optimization Progress:  98%|█████████▊| 4707/4800 [13:15<00:54,  1.69pipeline/s]Optimization Progress: 100%|█████████▉| 4787/4800 [13:17<00:05,  2.38pipeline/s]
Generation 47 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171285903.11882442	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-143884004.14022163	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:54:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 4800/4800 [13:17<00:00,  2.38pipeline/s]Optimization Progress: 100%|██████████| 4800/4800 [13:17<00:00,  3.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:54:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 4800/4800 [13:17<00:00,  3.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4800/4800 [13:18<00:00,  3.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4800/4800 [13:18<00:00,  3.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 4800/4800 [13:18<00:00,  3.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4800/4800 [13:19<00:00,  3.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4800/4900 [13:20<00:30,  3.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4801/4900 [13:20<00:29,  3.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4802/4900 [13:20<00:29,  3.32pipeline/s]Optimization Progress:  98%|█████████▊| 4803/4900 [13:20<00:44,  2.19pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4803/4900 [13:20<00:44,  2.19pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4804/4900 [13:20<00:43,  2.19pipeline/s]Optimization Progress:  98%|█████████▊| 4806/4900 [13:23<00:58,  1.61pipeline/s]Optimization Progress: 100%|█████████▉| 4886/4900 [13:24<00:06,  2.29pipeline/s]
Generation 48 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171285903.11882442	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-143884004.14022163	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [13:25<00:00,  2.29pipeline/s]Optimization Progress: 100%|██████████| 4900/4900 [13:25<00:00,  2.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:54:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 4900/4900 [13:25<00:00,  2.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [13:25<00:00,  2.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [13:26<00:00,  2.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:54:53] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 4900/4900 [13:26<00:00,  2.97pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4902/5000 [13:26<00:32,  2.97pipeline/s]Optimization Progress:  98%|█████████▊| 4903/5000 [13:26<00:34,  2.81pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4903/5000 [13:26<00:34,  2.81pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4904/5000 [13:26<00:34,  2.81pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4905/5000 [13:26<00:33,  2.81pipeline/s]Optimization Progress:  98%|█████████▊| 4907/5000 [13:30<00:48,  1.92pipeline/s]Optimization Progress: 100%|█████████▉| 4987/5000 [13:32<00:04,  2.67pipeline/s]
Generation 49 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171285903.11882442	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-143884004.14022163	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 5000/5000 [13:33<00:00,  2.67pipeline/s]Optimization Progress: 100%|██████████| 5000/5000 [13:33<00:00,  3.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [10:54:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5000/5000 [13:33<00:00,  3.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 5000/5000 [13:33<00:00,  3.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 5000/5000 [13:34<00:00,  3.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5000/5000 [13:35<00:00,  3.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5000/5000 [13:35<00:00,  3.69pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5001/5100 [13:36<00:26,  3.69pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5002/5100 [13:36<00:26,  3.69pipeline/s]Optimization Progress:  98%|█████████▊| 5003/5100 [13:36<00:46,  2.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5003/5100 [13:36<00:46,  2.07pipeline/s]Optimization Progress:  98%|█████████▊| 5005/5100 [13:39<01:15,  1.25pipeline/s]Optimization Progress: 100%|█████████▉| 5085/5100 [13:40<00:08,  1.77pipeline/s]
Generation 50 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171285903.11882442	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-143884004.14022163	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [13:41<00:00,  1.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 5100/5100 [13:41<00:00,  1.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5100/5100 [13:41<00:00,  1.77pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5100/5100 [13:41<00:00,  1.77pipeline/s]Optimization Progress: 100%|██████████| 5100/5100 [13:41<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:55:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5100/5100 [13:41<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:55:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5100/5100 [13:41<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 5100/5100 [13:42<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [13:42<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [13:42<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 5100/5100 [13:42<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [13:43<00:00,  2.48pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 5100/5100 [13:44<00:00,  2.48pipeline/s]Optimization Progress:  98%|█████████▊| 5103/5200 [13:44<00:55,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5103/5200 [13:44<00:55,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5104/5200 [13:44<00:54,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5105/5200 [13:44<00:53,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5106/5200 [13:44<00:53,  1.76pipeline/s]Optimization Progress:  98%|█████████▊| 5108/5200 [13:48<00:58,  1.57pipeline/s]Optimization Progress: 100%|█████████▉| 5188/5200 [13:51<00:05,  2.17pipeline/s]
Generation 51 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171232856.68098632	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=10), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-143884004.14022163	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(input_matrix, input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5200/5200 [13:53<00:00,  2.17pipeline/s]Optimization Progress: 100%|██████████| 5200/5200 [13:53<00:00,  2.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [13:53<00:00,  2.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 5200/5200 [13:53<00:00,  2.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5200/5200 [13:53<00:00,  2.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [13:54<00:00,  2.76pipeline/s]Optimization Progress:  98%|█████████▊| 5202/5300 [13:54<00:45,  2.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5202/5300 [13:54<00:45,  2.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5203/5300 [13:54<00:45,  2.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5204/5300 [13:54<00:44,  2.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5205/5300 [13:54<00:44,  2.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5206/5300 [13:54<00:43,  2.15pipeline/s]Optimization Progress:  98%|█████████▊| 5207/5300 [14:10<00:43,  2.15pipeline/s]Optimization Progress:  98%|█████████▊| 5208/5300 [14:12<01:50,  1.20s/pipeline]Optimization Progress: 100%|█████████▉| 5288/5300 [14:13<00:10,  1.18pipeline/s]
Generation 52 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-141690545.8126123	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(CombineDFs(input_matrix, input_matrix), input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:55:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5300/5300 [14:14<00:00,  1.18pipeline/s]Optimization Progress: 100%|██████████| 5300/5300 [14:14<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5300/5300 [14:14<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5300/5300 [14:14<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [14:15<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 5300/5300 [14:15<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5300/5300 [14:15<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:55:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5300/5300 [14:16<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5300/5300 [14:16<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5300/5300 [14:17<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5300/5300 [14:17<00:00,  1.66pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5301/5400 [14:17<00:59,  1.66pipeline/s]Optimization Progress:  98%|█████████▊| 5302/5400 [14:17<01:29,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5302/5400 [14:17<01:29,  1.09pipeline/s]Optimization Progress:  98%|█████████▊| 5304/5400 [14:21<01:56,  1.21s/pipeline]Optimization Progress: 100%|█████████▉| 5384/5400 [14:23<00:13,  1.17pipeline/s]
Generation 53 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-141690545.8126123	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(CombineDFs(input_matrix, input_matrix), input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [14:23<00:00,  1.17pipeline/s]Optimization Progress: 100%|██████████| 5400/5400 [14:23<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5400/5400 [14:23<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [14:23<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:55:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5400/5400 [14:24<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5400/5400 [14:25<00:00,  1.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [14:25<00:00,  1.66pipeline/s]Optimization Progress:  98%|█████████▊| 5403/5500 [14:25<01:02,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5403/5500 [14:25<01:02,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5404/5500 [14:25<01:01,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5405/5500 [14:25<01:01,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5406/5500 [14:25<01:00,  1.56pipeline/s]Optimization Progress:  98%|█████████▊| 5408/5500 [14:28<00:57,  1.60pipeline/s]Optimization Progress: 100%|█████████▉| 5488/5500 [14:30<00:05,  2.25pipeline/s]
Generation 54 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-141690545.8126123	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(CombineDFs(CombineDFs(input_matrix, input_matrix), input_matrix)), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [14:30<00:00,  2.25pipeline/s]Optimization Progress: 100%|██████████| 5500/5500 [14:30<00:00,  3.16pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 5500/5500 [14:31<00:00,  3.16pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5500/5500 [14:31<00:00,  3.16pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [14:31<00:00,  3.16pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:55:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5500/5500 [14:32<00:00,  3.16pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:55:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5500/5500 [14:32<00:00,  3.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5503/5600 [14:32<00:30,  3.16pipeline/s]Optimization Progress:  98%|█████████▊| 5504/5600 [14:32<00:36,  2.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5504/5600 [14:32<00:36,  2.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5505/5600 [14:32<00:36,  2.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5506/5600 [14:32<00:35,  2.63pipeline/s]Optimization Progress:  98%|█████████▊| 5508/5600 [14:36<00:52,  1.74pipeline/s]Optimization Progress: 100%|█████████▉| 5588/5600 [14:40<00:04,  2.41pipeline/s]
Generation 55 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-131730194.63614008	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:56:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5600/5600 [14:40<00:00,  2.41pipeline/s]Optimization Progress: 100%|██████████| 5600/5600 [14:40<00:00,  3.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 5600/5600 [14:41<00:00,  3.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [14:41<00:00,  3.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [14:41<00:00,  3.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [14:41<00:00,  3.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [14:42<00:00,  3.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 5600/5600 [14:43<00:00,  3.28pipeline/s]Optimization Progress:  98%|█████████▊| 5603/5700 [14:43<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5603/5700 [14:43<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5604/5700 [14:43<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5605/5700 [14:43<00:44,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5606/5700 [14:43<00:43,  2.16pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5607/5700 [14:43<00:43,  2.16pipeline/s]Optimization Progress:  98%|█████████▊| 5609/5700 [14:46<00:45,  2.00pipeline/s]Optimization Progress: 100%|█████████▉| 5689/5700 [14:49<00:03,  2.77pipeline/s]
Generation 56 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-131730194.63614008	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-6	-123184479.50513163	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:56:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 5700/5700 [14:49<00:00,  2.77pipeline/s]Optimization Progress: 100%|██████████| 5700/5700 [14:49<00:00,  3.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [14:50<00:00,  3.78pipeline/s]Optimization Progress:  98%|█████████▊| 5705/5800 [14:51<00:29,  3.27pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5705/5800 [14:51<00:29,  3.27pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5706/5800 [14:51<00:28,  3.27pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5707/5800 [14:51<00:28,  3.27pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5708/5800 [14:51<00:28,  3.27pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5709/5800 [14:51<00:27,  3.27pipeline/s]Optimization Progress:  98%|█████████▊| 5711/5800 [14:54<00:31,  2.82pipeline/s]Optimization Progress: 100%|█████████▉| 5791/5800 [14:55<00:02,  3.99pipeline/s]
Generation 57 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-131730194.63614008	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-6	-123184479.50513163	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [14:55<00:00,  3.99pipeline/s]Optimization Progress: 100%|██████████| 5800/5800 [14:55<00:00,  5.15pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5800/5800 [14:56<00:00,  5.15pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5800/5800 [14:57<00:00,  5.15pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 5800/5800 [14:57<00:00,  5.15pipeline/s]Optimization Progress:  98%|█████████▊| 5804/5900 [15:01<00:54,  1.77pipeline/s]Optimization Progress: 100%|█████████▉| 5881/5900 [15:06<00:07,  2.42pipeline/s]
Generation 58 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-131730194.63614008	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 5900/5900 [15:06<00:00,  2.42pipeline/s]Optimization Progress: 100%|██████████| 5900/5900 [15:06<00:00,  3.37pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 5900/5900 [15:08<00:00,  3.37pipeline/s]Optimization Progress:  98%|█████████▊| 5905/6000 [15:09<00:33,  2.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5905/6000 [15:09<00:33,  2.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5906/6000 [15:09<00:32,  2.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5907/6000 [15:09<00:32,  2.86pipeline/s]Optimization Progress:  98%|█████████▊| 5909/6000 [15:12<00:47,  1.92pipeline/s]Optimization Progress: 100%|█████████▉| 5989/6000 [15:15<00:04,  2.68pipeline/s]
Generation 59 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-131730194.63614008	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6000/6000 [15:15<00:00,  2.68pipeline/s]Optimization Progress: 100%|██████████| 6000/6000 [15:15<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [15:15<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [15:15<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [15:15<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6000/6000 [15:15<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 6000/6000 [15:15<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 6000/6000 [15:17<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6000/6000 [15:17<00:00,  3.76pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [15:18<00:00,  3.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6003/6100 [15:18<00:25,  3.76pipeline/s]Optimization Progress:  98%|█████████▊| 6004/6100 [15:18<00:39,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6004/6100 [15:18<00:39,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6005/6100 [15:18<00:39,  2.41pipeline/s]Optimization Progress:  98%|█████████▊| 6007/6100 [15:24<01:21,  1.14pipeline/s]Optimization Progress: 100%|█████████▉| 6087/6100 [15:25<00:08,  1.62pipeline/s]
Generation 60 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-126626459.6875784	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.6000000000000001, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-125396696.83476622	LinearSVR(MaxAbsScaler(Nystroem(MinMaxScaler(StandardScaler(CombineDFs(input_matrix, input_matrix))), Nystroem__gamma=1.0, Nystroem__kernel=rbf, Nystroem__n_components=9)), LinearSVR__C=15.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 6100/6100 [15:25<00:00,  1.62pipeline/s]Optimization Progress: 100%|██████████| 6100/6100 [15:25<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [15:25<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 6100/6100 [15:26<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [15:28<00:00,  2.29pipeline/s]Optimization Progress:  98%|█████████▊| 6106/6200 [15:28<00:43,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6106/6200 [15:28<00:43,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6107/6200 [15:28<00:43,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6108/6200 [15:28<00:42,  2.14pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6109/6200 [15:28<00:42,  2.14pipeline/s]Optimization Progress:  99%|█████████▊| 6111/6200 [15:35<01:03,  1.40pipeline/s]Optimization Progress: 100%|█████████▉| 6191/6200 [15:39<00:04,  1.94pipeline/s]
Generation 61 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [15:39<00:00,  1.94pipeline/s]Optimization Progress: 100%|██████████| 6200/6200 [15:39<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 6200/6200 [15:40<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 6200/6200 [15:40<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [15:40<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [15:40<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [15:40<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [15:40<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 6200/6200 [15:40<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [15:41<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:57:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6200/6200 [15:41<00:00,  2.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:57:08] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6200/6200 [15:41<00:00,  2.74pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6202/6300 [15:41<00:35,  2.74pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6203/6300 [15:41<00:35,  2.74pipeline/s]Optimization Progress:  98%|█████████▊| 6204/6300 [15:41<00:42,  2.25pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6204/6300 [15:41<00:42,  2.25pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6205/6300 [15:41<00:42,  2.25pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6206/6300 [15:41<00:41,  2.25pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6207/6300 [15:41<00:41,  2.25pipeline/s]Optimization Progress:  99%|█████████▊| 6209/6300 [15:51<01:17,  1.17pipeline/s]Optimization Progress: 100%|█████████▉| 6289/6300 [15:52<00:06,  1.65pipeline/s]
Generation 62 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [15:53<00:00,  1.65pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [15:53<00:00,  1.65pipeline/s]Optimization Progress: 100%|██████████| 6300/6300 [15:53<00:00,  2.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [15:53<00:00,  2.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [15:54<00:00,  2.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [15:54<00:00,  2.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:57:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6300/6300 [15:54<00:00,  2.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6300/6300 [15:56<00:00,  2.27pipeline/s]Optimization Progress:  99%|█████████▊| 6305/6400 [15:56<00:46,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6305/6400 [15:56<00:46,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6306/6400 [15:56<00:46,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6307/6400 [15:56<00:45,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6308/6400 [15:56<00:45,  2.03pipeline/s]Optimization Progress:  99%|█████████▊| 6310/6400 [16:00<00:50,  1.77pipeline/s]Optimization Progress: 100%|█████████▉| 6390/6400 [16:01<00:03,  2.51pipeline/s]
Generation 63 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205468451.92384255	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=rbf, Nystroem__n_components=1), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-171212342.4650476	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6400/6400 [16:01<00:00,  2.51pipeline/s]Optimization Progress: 100%|██████████| 6400/6400 [16:01<00:00,  3.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 6400/6400 [16:01<00:00,  3.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 6400/6400 [16:01<00:00,  3.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 6400/6400 [16:02<00:00,  3.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:57:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6400/6400 [16:02<00:00,  3.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [16:03<00:00,  3.35pipeline/s]Optimization Progress:  99%|█████████▊| 6404/6500 [16:04<00:40,  2.36pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6404/6500 [16:04<00:40,  2.36pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6405/6500 [16:04<00:40,  2.36pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6406/6500 [16:04<00:39,  2.36pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6407/6500 [16:04<00:39,  2.36pipeline/s]Optimization Progress:  99%|█████████▊| 6409/6500 [16:10<00:59,  1.53pipeline/s]Optimization Progress: 100%|█████████▉| 6489/6500 [16:14<00:05,  2.12pipeline/s]
Generation 64 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170770672.49410418	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [16:14<00:00,  2.12pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [10:57:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6500/6500 [16:14<00:00,  2.12pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 6500/6500 [16:14<00:00,  2.12pipeline/s]Optimization Progress: 100%|██████████| 6500/6500 [16:14<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 6500/6500 [16:14<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [16:14<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [16:14<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 6500/6500 [16:15<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [16:15<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 6500/6500 [16:16<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [16:16<00:00,  2.91pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [16:16<00:00,  2.91pipeline/s]Optimization Progress:  99%|█████████▊| 6503/6600 [16:17<00:48,  2.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6503/6600 [16:17<00:48,  2.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6504/6600 [16:17<00:47,  2.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6505/6600 [16:17<00:47,  2.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6506/6600 [16:17<00:46,  2.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6507/6600 [16:17<00:46,  2.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6508/6600 [16:17<00:45,  2.02pipeline/s]Optimization Progress:  99%|█████████▊| 6510/6600 [16:20<00:43,  2.08pipeline/s]Optimization Progress: 100%|█████████▉| 6590/6600 [16:22<00:03,  2.90pipeline/s]
Generation 65 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170770672.49410418	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6600/6600 [16:22<00:00,  2.90pipeline/s]Optimization Progress: 100%|██████████| 6600/6600 [16:22<00:00,  3.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6600/6600 [16:22<00:00,  3.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:57:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6600/6600 [16:25<00:00,  3.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 6600/6600 [16:25<00:00,  3.97pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 6600/6600 [16:25<00:00,  3.97pipeline/s]Optimization Progress:  99%|█████████▊| 6605/6700 [16:25<00:33,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6605/6700 [16:25<00:33,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6606/6700 [16:25<00:32,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6607/6700 [16:25<00:32,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6608/6700 [16:25<00:32,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6609/6700 [16:25<00:31,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6610/6700 [16:25<00:31,  2.87pipeline/s]Optimization Progress:  99%|█████████▊| 6612/6700 [16:29<00:36,  2.39pipeline/s]Optimization Progress: 100%|█████████▉| 6692/6700 [16:32<00:02,  3.31pipeline/s]
Generation 66 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170770672.49410418	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [16:32<00:00,  3.31pipeline/s]Optimization Progress: 100%|██████████| 6700/6700 [16:32<00:00,  4.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6700/6700 [16:33<00:00,  4.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6700/6700 [16:33<00:00,  4.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6700/6700 [16:34<00:00,  4.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 6700/6700 [16:34<00:00,  4.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6700/6700 [16:35<00:00,  4.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [16:35<00:00,  4.36pipeline/s]Optimization Progress:  99%|█████████▊| 6704/6800 [16:35<00:37,  2.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6704/6800 [16:35<00:37,  2.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6705/6800 [16:35<00:37,  2.56pipeline/s]Optimization Progress:  99%|█████████▊| 6707/6800 [16:47<02:13,  1.44s/pipeline]Optimization Progress: 100%|█████████▉| 6787/6800 [16:50<00:13,  1.02s/pipeline]
Generation 67 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170770672.49410418	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [16:50<00:00,  1.02s/pipeline]Optimization Progress: 100%|██████████| 6800/6800 [16:50<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 6800/6800 [16:50<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [16:50<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [16:51<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 6800/6800 [16:51<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 6800/6800 [16:52<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [16:52<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6800/6800 [16:52<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [16:52<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 [10:58:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6800/6800 [16:52<00:00,  1.40pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [16:52<00:00,  1.40pipeline/s]Optimization Progress:  99%|█████████▊| 6804/6900 [16:53<01:08,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6804/6900 [16:53<01:08,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6805/6900 [16:53<01:07,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6806/6900 [16:53<01:07,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6807/6900 [16:53<01:06,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6808/6900 [16:53<01:05,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6809/6900 [16:53<01:04,  1.40pipeline/s]Optimization Progress:  99%|█████████▊| 6811/6900 [16:57<00:59,  1.48pipeline/s]Optimization Progress: 100%|█████████▉| 6891/6900 [17:01<00:04,  2.06pipeline/s]
Generation 68 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6900/6900 [17:01<00:00,  2.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6900/6900 [17:01<00:00,  2.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6900/6900 [17:01<00:00,  2.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [17:01<00:00,  2.06pipeline/s]Optimization Progress: 100%|██████████| 6900/6900 [17:01<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6900/6900 [17:01<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6900/6900 [17:01<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6900/6900 [17:02<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6900/6900 [17:02<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6900/6900 [17:02<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6900/6900 [17:02<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [10:58:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6900/6900 [17:02<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [17:03<00:00,  2.78pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 6900/6900 [17:04<00:00,  2.78pipeline/s]Optimization Progress:  99%|█████████▊| 6902/7000 [17:04<01:01,  1.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6902/7000 [17:04<01:01,  1.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6903/7000 [17:04<01:00,  1.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6904/7000 [17:04<01:00,  1.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6905/7000 [17:04<00:59,  1.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6906/7000 [17:04<00:59,  1.59pipeline/s]Optimization Progress:  99%|█████████▊| 6908/7000 [17:07<00:56,  1.63pipeline/s]Optimization Progress: 100%|█████████▉| 6988/7000 [17:08<00:05,  2.30pipeline/s]
Generation 69 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 7000/7000 [17:09<00:00,  2.30pipeline/s]Optimization Progress: 100%|██████████| 7000/7000 [17:09<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [17:09<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 7000/7000 [17:10<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [17:10<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 7000/7000 [17:11<00:00,  3.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [17:11<00:00,  3.06pipeline/s]Optimization Progress:  99%|█████████▊| 7005/7100 [17:11<00:35,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7005/7100 [17:11<00:35,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7006/7100 [17:11<00:34,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7007/7100 [17:11<00:34,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7008/7100 [17:12<00:33,  2.71pipeline/s]Optimization Progress:  99%|█████████▊| 7010/7100 [17:16<00:46,  1.95pipeline/s]Optimization Progress: 100%|█████████▉| 7090/7100 [17:16<00:03,  2.76pipeline/s]
Generation 70 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 7100/7100 [17:17<00:00,  2.76pipeline/s]Optimization Progress: 100%|██████████| 7100/7100 [17:17<00:00,  3.84pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [17:17<00:00,  3.84pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7100/7100 [17:19<00:00,  3.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7100/7200 [17:20<00:26,  3.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7101/7200 [17:20<00:25,  3.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7102/7200 [17:20<00:25,  3.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7103/7200 [17:20<00:25,  3.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7104/7200 [17:20<00:24,  3.84pipeline/s]Optimization Progress:  99%|█████████▊| 7105/7200 [17:20<00:36,  2.57pipeline/s]Optimization Progress:  99%|█████████▊| 7109/7200 [17:24<00:50,  1.80pipeline/s]Optimization Progress: 100%|█████████▉| 7186/7200 [17:26<00:05,  2.53pipeline/s]
Generation 71 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 7200/7200 [17:26<00:00,  2.53pipeline/s]Optimization Progress: 100%|██████████| 7200/7200 [17:26<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 7200/7200 [17:26<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [10:58:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7200/7200 [17:26<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [17:26<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [10:58:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7200/7200 [17:26<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [17:27<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 7200/7200 [17:27<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [17:27<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [17:27<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 7200/7200 [17:27<00:00,  3.56pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:58:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7200/7200 [17:28<00:00,  3.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7201/7300 [17:29<00:27,  3.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7202/7300 [17:29<00:27,  3.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7203/7300 [17:29<00:27,  3.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7204/7300 [17:29<00:26,  3.56pipeline/s]Optimization Progress:  99%|█████████▊| 7205/7300 [17:29<00:35,  2.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7205/7300 [17:29<00:35,  2.70pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7206/7300 [17:29<00:34,  2.70pipeline/s]Optimization Progress:  99%|█████████▉| 7209/7300 [17:32<00:45,  2.00pipeline/s]Optimization Progress: 100%|█████████▉| 7288/7300 [17:33<00:04,  2.82pipeline/s]
Generation 72 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7300/7300 [17:35<00:00,  2.82pipeline/s]Optimization Progress: 100%|██████████| 7300/7300 [17:35<00:00,  3.57pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7300/7300 [17:35<00:00,  3.57pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7300/7300 [17:36<00:00,  3.57pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [17:37<00:00,  3.57pipeline/s]Optimization Progress:  99%|█████████▊| 7303/7400 [17:37<00:38,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7303/7400 [17:37<00:38,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7304/7400 [17:37<00:38,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7305/7400 [17:37<00:37,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7306/7400 [17:37<00:37,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7307/7400 [17:37<00:36,  2.52pipeline/s]Optimization Progress:  99%|█████████▉| 7309/7400 [17:41<00:43,  2.08pipeline/s]Optimization Progress: 100%|█████████▉| 7389/7400 [17:43<00:03,  2.90pipeline/s]
Generation 73 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [17:43<00:00,  2.90pipeline/s]Optimization Progress: 100%|██████████| 7400/7400 [17:43<00:00,  4.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [17:44<00:00,  4.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 7400/7400 [17:45<00:00,  4.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [17:46<00:00,  4.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7400/7400 [17:46<00:00,  4.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 7400/7400 [17:46<00:00,  4.06pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 7400/7400 [17:46<00:00,  4.06pipeline/s]Optimization Progress:  99%|█████████▊| 7404/7500 [17:46<00:37,  2.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7404/7500 [17:46<00:37,  2.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7405/7500 [17:46<00:37,  2.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7406/7500 [17:46<00:36,  2.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7407/7500 [17:46<00:36,  2.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7408/7500 [17:46<00:35,  2.56pipeline/s]Optimization Progress:  99%|█████████▉| 7410/7500 [17:50<00:40,  2.22pipeline/s]Optimization Progress: 100%|█████████▉| 7490/7500 [17:52<00:03,  3.08pipeline/s]
Generation 74 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7500/7500 [17:52<00:00,  3.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 7500/7500 [17:53<00:00,  3.08pipeline/s]Optimization Progress: 100%|██████████| 7500/7500 [17:53<00:00,  4.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 7500/7500 [17:53<00:00,  4.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7500/7500 [17:53<00:00,  4.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7500/7500 [17:55<00:00,  4.01pipeline/s]Optimization Progress:  99%|█████████▉| 7506/7600 [17:55<00:26,  3.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7506/7600 [17:55<00:26,  3.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7507/7600 [17:55<00:26,  3.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7508/7600 [17:55<00:26,  3.51pipeline/s]Optimization Progress:  99%|█████████▉| 7510/7600 [17:59<00:44,  2.04pipeline/s]Optimization Progress: 100%|█████████▉| 7590/7600 [18:02<00:03,  2.82pipeline/s]
Generation 75 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7600/7600 [18:03<00:00,  2.82pipeline/s]Optimization Progress: 100%|██████████| 7600/7600 [18:03<00:00,  3.61pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [18:03<00:00,  3.61pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7600/7600 [18:03<00:00,  3.61pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [18:03<00:00,  3.61pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7600/7600 [18:03<00:00,  3.61pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 7600/7600 [18:04<00:00,  3.61pipeline/s]Optimization Progress:  99%|█████████▊| 7603/7700 [18:04<00:33,  2.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7603/7700 [18:04<00:33,  2.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7604/7700 [18:04<00:33,  2.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7605/7700 [18:04<00:32,  2.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7606/7700 [18:04<00:32,  2.90pipeline/s]Optimization Progress:  99%|█████████▉| 7608/7700 [18:07<00:39,  2.31pipeline/s]Optimization Progress: 100%|█████████▉| 7688/7700 [18:13<00:03,  3.10pipeline/s]
Generation 76 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [18:13<00:00,  3.10pipeline/s]Optimization Progress: 100%|██████████| 7700/7700 [18:13<00:00,  4.07pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 7700/7700 [18:13<00:00,  4.07pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [18:13<00:00,  4.07pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7700/7700 [18:14<00:00,  4.07pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [18:14<00:00,  4.07pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [18:15<00:00,  4.07pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7700/7700 [18:16<00:00,  4.07pipeline/s]Optimization Progress:  99%|█████████▉| 7706/7800 [18:16<00:26,  3.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7706/7800 [18:16<00:26,  3.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7707/7800 [18:16<00:26,  3.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7708/7800 [18:16<00:26,  3.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7709/7800 [18:16<00:25,  3.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7710/7800 [18:16<00:25,  3.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7711/7800 [18:16<00:25,  3.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7712/7800 [18:16<00:24,  3.53pipeline/s]Optimization Progress:  99%|█████████▉| 7714/7800 [18:20<00:31,  2.74pipeline/s]Optimization Progress: 100%|█████████▉| 7794/7800 [18:21<00:01,  3.85pipeline/s]
Generation 77 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [18:22<00:00,  3.85pipeline/s]Optimization Progress: 100%|██████████| 7800/7800 [18:22<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 7800/7800 [18:22<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [18:22<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 7800/7800 [18:23<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7800/7800 [18:24<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7800/7800 [18:24<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7800/7800 [18:24<00:00,  4.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7800/7900 [18:25<00:22,  4.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7801/7900 [18:25<00:22,  4.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7802/7900 [18:25<00:21,  4.47pipeline/s]Optimization Progress:  99%|█████████▉| 7803/7900 [18:25<00:42,  2.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7803/7900 [18:25<00:42,  2.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7804/7900 [18:25<00:41,  2.30pipeline/s]Optimization Progress:  99%|█████████▉| 7806/7900 [18:29<01:05,  1.43pipeline/s]Optimization Progress: 100%|█████████▉| 7886/7900 [18:32<00:07,  2.00pipeline/s]
Generation 78 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [10:59:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 7900/7900 [18:33<00:00,  2.00pipeline/s]Optimization Progress: 100%|██████████| 7900/7900 [18:33<00:00,  2.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 7900/7900 [18:33<00:00,  2.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 7900/7900 [18:34<00:00,  2.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7900/7900 [18:34<00:00,  2.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [18:35<00:00,  2.66pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7900/7900 [18:35<00:00,  2.66pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7901/8000 [18:36<00:37,  2.66pipeline/s]Optimization Progress:  99%|█████████▉| 7902/8000 [18:36<00:59,  1.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7902/8000 [18:36<00:59,  1.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7903/8000 [18:36<00:58,  1.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7904/8000 [18:36<00:58,  1.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7905/8000 [18:36<00:57,  1.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7906/8000 [18:36<00:57,  1.65pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7907/8000 [18:36<00:56,  1.65pipeline/s]Optimization Progress:  99%|█████████▉| 7909/8000 [18:40<00:54,  1.67pipeline/s]Optimization Progress: 100%|█████████▉| 7989/8000 [18:45<00:04,  2.28pipeline/s]
Generation 79 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170758351.47101054	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=8), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [18:45<00:00,  2.28pipeline/s]Optimization Progress: 100%|██████████| 8000/8000 [18:45<00:00,  3.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8000/8000 [18:46<00:00,  3.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [18:46<00:00,  3.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [11:00:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8000/8000 [18:46<00:00,  3.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 8000/8000 [18:47<00:00,  3.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 8000/8000 [18:47<00:00,  3.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8000/8000 [18:47<00:00,  3.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:00:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8000/8000 [18:48<00:00,  3.01pipeline/s]Optimization Progress:  99%|█████████▉| 8002/8100 [18:48<01:03,  1.54pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8002/8100 [18:48<01:03,  1.54pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8003/8100 [18:48<01:03,  1.54pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8004/8100 [18:48<01:02,  1.54pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8005/8100 [18:48<01:01,  1.54pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8006/8100 [18:48<01:01,  1.54pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8007/8100 [18:48<01:00,  1.54pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8008/8100 [18:48<00:59,  1.54pipeline/s]Optimization Progress:  99%|█████████▉| 8010/8100 [18:52<00:53,  1.70pipeline/s]Optimization Progress: 100%|█████████▉| 8090/8100 [18:54<00:04,  2.37pipeline/s]
Generation 80 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 8100/8100 [18:55<00:00,  2.37pipeline/s]Optimization Progress: 100%|██████████| 8100/8100 [18:55<00:00,  3.04pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [18:56<00:00,  3.04pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [18:56<00:00,  3.04pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8100/8100 [18:57<00:00,  3.04pipeline/s]Optimization Progress:  99%|█████████▉| 8102/8200 [18:57<00:47,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8102/8200 [18:57<00:47,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8103/8200 [18:57<00:47,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8104/8200 [18:57<00:46,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8105/8200 [18:57<00:46,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8106/8200 [18:57<00:45,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8107/8200 [18:57<00:45,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8108/8200 [18:57<00:44,  2.05pipeline/s]Optimization Progress:  99%|█████████▉| 8110/8200 [19:03<00:49,  1.81pipeline/s]Optimization Progress: 100%|█████████▉| 8190/8200 [19:08<00:04,  2.47pipeline/s]
Generation 81 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [19:09<00:00,  2.47pipeline/s]Optimization Progress: 100%|██████████| 8200/8200 [19:09<00:00,  3.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8200/8200 [19:09<00:00,  3.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [19:10<00:00,  3.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [19:10<00:00,  3.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 8200/8200 [19:11<00:00,  3.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8200/8200 [19:11<00:00,  3.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [11:00:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8200/8200 [19:11<00:00,  3.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8200/8200 [19:11<00:00,  3.24pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8201/8300 [19:11<00:30,  3.24pipeline/s]Optimization Progress:  99%|█████████▉| 8202/8300 [19:11<01:01,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8202/8300 [19:11<01:01,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8203/8300 [19:11<01:00,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8204/8300 [19:11<01:00,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8205/8300 [19:11<00:59,  1.60pipeline/s]Optimization Progress:  99%|█████████▉| 8207/8300 [19:15<01:01,  1.50pipeline/s]Optimization Progress: 100%|█████████▉| 8287/8300 [19:18<00:06,  2.10pipeline/s]
Generation 82 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8300/8300 [19:18<00:00,  2.10pipeline/s]Optimization Progress: 100%|██████████| 8300/8300 [19:18<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [19:19<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [19:19<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:00:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8300/8300 [19:19<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8300/8300 [19:20<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8300/8300 [19:20<00:00,  2.86pipeline/s]Optimization Progress:  99%|█████████▉| 8304/8400 [19:20<00:38,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8304/8400 [19:21<00:38,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8305/8400 [19:21<00:38,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8306/8400 [19:21<00:38,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8307/8400 [19:21<00:37,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8308/8400 [19:21<00:37,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8309/8400 [19:21<00:36,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8310/8400 [19:21<00:36,  2.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8311/8400 [19:21<00:36,  2.47pipeline/s]Optimization Progress:  99%|█████████▉| 8313/8400 [19:26<00:40,  2.13pipeline/s]Optimization Progress: 100%|█████████▉| 8393/8400 [19:28<00:02,  2.99pipeline/s]
Generation 83 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8400/8400 [19:29<00:00,  2.99pipeline/s]Optimization Progress: 100%|██████████| 8400/8400 [19:29<00:00,  3.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [19:29<00:00,  3.50pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [19:31<00:00,  3.50pipeline/s]Optimization Progress:  99%|█████████▉| 8403/8500 [19:31<00:41,  2.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8403/8500 [19:31<00:41,  2.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8404/8500 [19:31<00:41,  2.32pipeline/s]Optimization Progress:  99%|█████████▉| 8406/8500 [19:37<01:19,  1.18pipeline/s]Optimization Progress: 100%|█████████▉| 8486/8500 [19:38<00:08,  1.68pipeline/s]
Generation 84 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8500/8500 [19:39<00:00,  1.68pipeline/s]Optimization Progress: 100%|██████████| 8500/8500 [19:39<00:00,  2.33pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 8500/8500 [19:39<00:00,  2.33pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8500/8500 [19:40<00:00,  2.33pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [19:40<00:00,  2.33pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8500/8500 [19:41<00:00,  2.33pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [19:41<00:00,  2.33pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [19:41<00:00,  2.33pipeline/s]Optimization Progress:  99%|█████████▉| 8507/8600 [19:41<00:38,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8507/8600 [19:41<00:38,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8508/8600 [19:41<00:38,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8509/8600 [19:41<00:37,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8510/8600 [19:41<00:37,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8511/8600 [19:41<00:36,  2.41pipeline/s]Optimization Progress:  99%|█████████▉| 8513/8600 [19:46<00:46,  1.87pipeline/s]Optimization Progress: 100%|█████████▉| 8593/8600 [19:47<00:02,  2.64pipeline/s]
Generation 85 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8600/8600 [19:48<00:00,  2.64pipeline/s]Optimization Progress: 100%|██████████| 8600/8600 [19:48<00:00,  3.38pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 8600/8600 [19:49<00:00,  3.38pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [19:49<00:00,  3.38pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8600/8600 [19:49<00:00,  3.38pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8600/8600 [19:50<00:00,  3.38pipeline/s]Optimization Progress:  99%|█████████▉| 8605/8700 [19:51<00:36,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8605/8700 [19:51<00:36,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8606/8700 [19:51<00:36,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8607/8700 [19:51<00:35,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8608/8700 [19:51<00:35,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8609/8700 [19:51<00:35,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8610/8700 [19:51<00:34,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8611/8700 [19:51<00:34,  2.59pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8612/8700 [19:51<00:33,  2.59pipeline/s]Optimization Progress:  99%|█████████▉| 8614/8700 [19:59<00:45,  1.89pipeline/s]Optimization Progress: 100%|█████████▉| 8694/8700 [19:59<00:02,  2.69pipeline/s]
Generation 86 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 8700/8700 [20:00<00:00,  2.69pipeline/s]Optimization Progress: 100%|██████████| 8700/8700 [20:00<00:00,  3.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8700/8700 [20:00<00:00,  3.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8700/8700 [20:01<00:00,  3.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [20:01<00:00,  3.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8700/8700 [20:01<00:00,  3.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8700/8700 [20:02<00:00,  3.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8700/8700 [20:02<00:00,  3.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8702/8800 [20:02<00:28,  3.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8703/8800 [20:02<00:27,  3.47pipeline/s]Optimization Progress:  99%|█████████▉| 8704/8800 [20:02<00:38,  2.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8704/8800 [20:02<00:38,  2.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8705/8800 [20:02<00:38,  2.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8706/8800 [20:02<00:37,  2.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8707/8800 [20:02<00:37,  2.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8708/8800 [20:02<00:36,  2.49pipeline/s]Optimization Progress:  99%|█████████▉| 8710/8800 [20:07<00:43,  2.05pipeline/s]Optimization Progress: 100%|█████████▉| 8790/8800 [20:09<00:03,  2.85pipeline/s]
Generation 87 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8800/8800 [20:10<00:00,  2.85pipeline/s]Optimization Progress: 100%|██████████| 8800/8800 [20:10<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8800/8800 [20:10<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [20:10<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8800/8800 [20:10<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8800/8800 [20:11<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [20:11<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8800/8800 [20:11<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8800/8800 [20:11<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8800/8800 [20:11<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8800/8800 [20:11<00:00,  3.98pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [20:13<00:00,  3.98pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8800/8900 [20:13<00:25,  3.98pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8801/8900 [20:13<00:24,  3.98pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8802/8900 [20:13<00:24,  3.98pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8803/8900 [20:13<00:24,  3.98pipeline/s]Optimization Progress:  99%|█████████▉| 8804/8900 [20:13<00:39,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8804/8900 [20:13<00:39,  2.41pipeline/s]Optimization Progress:  99%|█████████▉| 8807/8900 [20:17<01:03,  1.47pipeline/s]Optimization Progress: 100%|█████████▉| 8886/8900 [20:21<00:06,  2.04pipeline/s]
Generation 88 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8900/8900 [20:21<00:00,  2.04pipeline/s]Optimization Progress: 100%|██████████| 8900/8900 [20:21<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 8900/8900 [20:21<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8900/8900 [20:22<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8900/8900 [20:23<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 8900/8900 [20:23<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 8900/8900 [20:24<00:00,  2.86pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [20:25<00:00,  2.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8900/9000 [20:25<00:34,  2.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8901/9000 [20:25<00:34,  2.86pipeline/s]Optimization Progress:  99%|█████████▉| 8903/9000 [20:30<01:45,  1.09s/pipeline]Optimization Progress: 100%|█████████▉| 8983/9000 [20:32<00:13,  1.30pipeline/s]
Generation 89 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170748092.05777413	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=7), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9000/9000 [20:32<00:00,  1.30pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9000/9000 [20:32<00:00,  1.30pipeline/s]Optimization Progress: 100%|██████████| 9000/9000 [20:32<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 9000/9000 [20:32<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 9000/9000 [20:33<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9000/9000 [20:33<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:01:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9000/9000 [20:33<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 9000/9000 [20:33<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9000/9000 [20:34<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 9000/9000 [20:34<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9000/9000 [20:34<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9000/9000 [20:34<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 9000/9000 [20:34<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 9000/9000 [20:35<00:00,  1.83pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9000/9000 [20:35<00:00,  1.83pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9002/9100 [20:35<00:53,  1.83pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9003/9100 [20:35<00:52,  1.83pipeline/s]Optimization Progress:  99%|█████████▉| 9004/9100 [20:35<00:58,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9004/9100 [20:35<00:58,  1.64pipeline/s]Optimization Progress:  99%|█████████▉| 9005/9100 [20:50<00:58,  1.64pipeline/s]Optimization Progress:  99%|█████████▉| 9006/9100 [20:50<04:03,  2.59s/pipeline]Optimization Progress: 100%|█████████▉| 9086/9100 [20:51<00:25,  1.82s/pipeline]
Generation 90 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170627005.65319428	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:02:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9100/9100 [20:52<00:00,  1.82s/pipeline]Optimization Progress: 100%|██████████| 9100/9100 [20:52<00:00,  1.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 9100/9100 [20:52<00:00,  1.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [20:53<00:00,  1.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9100/9100 [20:54<00:00,  1.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [11:02:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9100/9100 [20:54<00:00,  1.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 9100/9100 [20:54<00:00,  1.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9100/9100 [20:55<00:00,  1.30s/pipeline]Optimization Progress:  99%|█████████▉| 9103/9200 [20:55<02:02,  1.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9103/9200 [20:55<02:02,  1.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9104/9200 [20:55<02:00,  1.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9105/9200 [20:55<01:59,  1.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9106/9200 [20:55<01:58,  1.26s/pipeline]Optimization Progress:  99%|█████████▉| 9108/9200 [20:59<01:43,  1.13s/pipeline]Optimization Progress: 100%|█████████▉| 9188/9200 [21:03<00:09,  1.25pipeline/s]
Generation 91 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170627005.65319428	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:02:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9200/9200 [21:03<00:00,  1.25pipeline/s]Optimization Progress: 100%|██████████| 9200/9200 [21:03<00:00,  1.72pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [21:03<00:00,  1.72pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:02:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9200/9200 [21:03<00:00,  1.72pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 9200/9200 [21:03<00:00,  1.72pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [21:04<00:00,  1.72pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 9200/9200 [21:04<00:00,  1.72pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9201/9300 [21:06<00:57,  1.72pipeline/s]Optimization Progress:  99%|█████████▉| 9202/9300 [21:06<01:15,  1.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9202/9300 [21:06<01:15,  1.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9203/9300 [21:06<01:14,  1.30pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9204/9300 [21:06<01:13,  1.30pipeline/s]Optimization Progress:  99%|█████████▉| 9206/9300 [21:10<01:19,  1.18pipeline/s]Optimization Progress: 100%|█████████▉| 9286/9300 [21:11<00:08,  1.67pipeline/s]
Generation 92 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170627005.65319428	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 9300/9300 [21:12<00:00,  1.67pipeline/s]Optimization Progress: 100%|██████████| 9300/9300 [21:12<00:00,  2.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [21:12<00:00,  2.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 9300/9300 [21:12<00:00,  2.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 9300/9300 [21:13<00:00,  2.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 9300/9300 [21:13<00:00,  2.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [21:13<00:00,  2.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 9300/9300 [21:14<00:00,  2.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [21:14<00:00,  2.35pipeline/s]Optimization Progress:  99%|█████████▉| 9306/9400 [21:14<00:40,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9306/9400 [21:14<00:40,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9307/9400 [21:14<00:39,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9308/9400 [21:14<00:39,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9309/9400 [21:14<00:39,  2.33pipeline/s]Optimization Progress:  99%|█████████▉| 9311/9400 [21:19<00:49,  1.81pipeline/s]Optimization Progress: 100%|█████████▉| 9391/9400 [21:20<00:03,  2.55pipeline/s]
Generation 93 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9400/9400 [21:20<00:00,  2.55pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [21:20<00:00,  2.55pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:02:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9400/9400 [21:21<00:00,  2.55pipeline/s]Optimization Progress: 100%|██████████| 9400/9400 [21:21<00:00,  3.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9400/9400 [21:21<00:00,  3.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9400/9400 [21:23<00:00,  3.29pipeline/s]Optimization Progress:  99%|█████████▉| 9405/9500 [21:24<00:36,  2.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9405/9500 [21:24<00:36,  2.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9406/9500 [21:24<00:35,  2.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9407/9500 [21:24<00:35,  2.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9408/9500 [21:24<00:34,  2.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9409/9500 [21:24<00:34,  2.64pipeline/s]Optimization Progress:  99%|█████████▉| 9411/9500 [21:29<00:47,  1.88pipeline/s]Optimization Progress: 100%|█████████▉| 9491/9500 [21:32<00:03,  2.61pipeline/s]
Generation 94 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9500/9500 [21:32<00:00,  2.61pipeline/s]Optimization Progress: 100%|██████████| 9500/9500 [21:32<00:00,  3.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [21:32<00:00,  3.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9500/9500 [21:33<00:00,  3.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [21:33<00:00,  3.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9500/9500 [21:34<00:00,  3.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9500/9500 [21:34<00:00,  3.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 9500/9500 [21:35<00:00,  3.58pipeline/s]Optimization Progress:  99%|█████████▉| 9504/9600 [21:35<00:38,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9504/9600 [21:35<00:38,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9505/9600 [21:35<00:37,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9506/9600 [21:35<00:37,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9507/9600 [21:35<00:36,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9508/9600 [21:35<00:36,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9509/9600 [21:35<00:36,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9510/9600 [21:35<00:35,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9511/9600 [21:35<00:35,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9512/9600 [21:35<00:34,  2.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9513/9600 [21:35<00:34,  2.52pipeline/s]Optimization Progress:  99%|█████████▉| 9515/9600 [21:40<00:35,  2.37pipeline/s]Optimization Progress: 100%|█████████▉| 9595/9600 [21:43<00:01,  3.26pipeline/s]
Generation 95 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [21:43<00:00,  3.26pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9600/9600 [21:44<00:00,  3.26pipeline/s]Optimization Progress: 100%|██████████| 9600/9600 [21:44<00:00,  4.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9600/9600 [21:44<00:00,  4.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [21:44<00:00,  4.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9600/9600 [21:44<00:00,  4.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9600/9600 [21:45<00:00,  4.35pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 9600/9600 [21:45<00:00,  4.35pipeline/s]Optimization Progress:  99%|█████████▉| 9609/9700 [21:47<00:26,  3.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9609/9700 [21:47<00:26,  3.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9610/9700 [21:47<00:26,  3.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9611/9700 [21:47<00:25,  3.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9612/9700 [21:47<00:25,  3.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9613/9700 [21:47<00:25,  3.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9614/9700 [21:47<00:25,  3.44pipeline/s]Optimization Progress:  99%|█████████▉| 9616/9700 [21:52<00:31,  2.65pipeline/s]Optimization Progress: 100%|█████████▉| 9696/9700 [21:53<00:01,  3.73pipeline/s]
Generation 96 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9700/9700 [21:53<00:00,  3.73pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9700/9700 [21:53<00:00,  3.73pipeline/s]Optimization Progress: 100%|██████████| 9700/9700 [21:53<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9700/9700 [21:53<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9700/9700 [21:54<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [21:54<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 9700/9700 [21:54<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9700/9700 [21:55<00:00,  4.47pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9700/9700 [21:55<00:00,  4.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9701/9800 [21:56<00:22,  4.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9702/9800 [21:56<00:21,  4.47pipeline/s]Optimization Progress:  99%|█████████▉| 9703/9800 [21:56<00:47,  2.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9703/9800 [21:56<00:47,  2.05pipeline/s]Optimization Progress:  99%|█████████▉| 9705/9800 [22:02<01:45,  1.11s/pipeline]Optimization Progress: 100%|█████████▉| 9785/9800 [22:05<00:11,  1.26pipeline/s]
Generation 97 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 9800/9800 [22:06<00:00,  1.26pipeline/s]Optimization Progress: 100%|██████████| 9800/9800 [22:06<00:00,  1.75pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9800/9800 [22:06<00:00,  1.75pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9800/9800 [22:06<00:00,  1.75pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9800/9800 [22:09<00:00,  1.75pipeline/s]Optimization Progress:  99%|█████████▉| 9808/9900 [22:09<00:47,  1.95pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9808/9900 [22:09<00:47,  1.95pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9809/9900 [22:09<00:46,  1.95pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9810/9900 [22:09<00:46,  1.95pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9811/9900 [22:09<00:45,  1.95pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9812/9900 [22:09<00:45,  1.95pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9813/9900 [22:09<00:44,  1.95pipeline/s]Optimization Progress:  99%|█████████▉| 9814/9900 [22:20<00:44,  1.95pipeline/s]Optimization Progress:  99%|█████████▉| 9815/9900 [22:20<01:13,  1.16pipeline/s]Optimization Progress: 100%|█████████▉| 9895/9900 [22:23<00:03,  1.63pipeline/s]
Generation 98 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9900/9900 [22:24<00:00,  1.63pipeline/s]Optimization Progress: 100%|██████████| 9900/9900 [22:24<00:00,  2.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9900/9900 [22:24<00:00,  2.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [22:26<00:00,  2.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9900/9900 [22:26<00:00,  2.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [11:03:53] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 9900/9900 [22:26<00:00,  2.18pipeline/s]Optimization Progress:  99%|█████████▉| 9905/10000 [22:27<00:48,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9905/10000 [22:27<00:48,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9906/10000 [22:27<00:48,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9907/10000 [22:27<00:47,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9908/10000 [22:27<00:47,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9909/10000 [22:27<00:46,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9910/10000 [22:27<00:46,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9911/10000 [22:27<00:45,  1.95pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9912/10000 [22:27<00:45,  1.95pipeline/s]Optimization Progress:  99%|█████████▉| 9914/10000 [22:35<00:53,  1.62pipeline/s]Optimization Progress: 100%|█████████▉| 9994/10000 [22:37<00:02,  2.27pipeline/s]
Generation 99 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                 _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [22:37<00:00,  2.27pipeline/s]Optimization Progress: 100%|██████████| 10000/10000 [22:37<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10000/10000 [22:37<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [22:38<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10000/10000 [22:38<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10000/10000 [22:38<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10000/10000 [22:38<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 [11:04:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10000/10000 [22:38<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [22:39<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [22:40<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10000/10000 [22:40<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10000/10000 [22:40<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10000/10000 [22:40<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 10000/10000 [22:41<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10000/10000 [22:41<00:00,  3.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:04:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10000/10000 [22:41<00:00,  3.14pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10001/10100 [22:41<00:31,  3.14pipeline/s]Optimization Progress:  99%|█████████▉| 10002/10100 [22:41<01:20,  1.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10002/10100 [22:41<01:20,  1.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10003/10100 [22:41<01:19,  1.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10004/10100 [22:41<01:18,  1.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10005/10100 [22:41<01:17,  1.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10006/10100 [22:41<01:16,  1.22pipeline/s]Optimization Progress:  99%|█████████▉| 10008/10100 [22:46<01:13,  1.25pipeline/s]Optimization Progress: 100%|█████████▉| 10088/10100 [22:49<00:06,  1.74pipeline/s]
Generation 100 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [22:50<00:00,  1.74pipeline/s]Optimization Progress: 100%|██████████| 10100/10100 [22:50<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [22:50<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10100/10100 [22:50<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10100/10100 [22:51<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10100/10100 [22:51<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [22:52<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10100/10100 [22:52<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [22:52<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10100/10100 [22:52<00:00,  2.36pipeline/s]Optimization Progress:  99%|█████████▉| 10105/10200 [22:53<00:43,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10105/10200 [22:53<00:43,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10106/10200 [22:53<00:42,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10107/10200 [22:53<00:42,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10108/10200 [22:53<00:41,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10109/10200 [22:53<00:41,  2.19pipeline/s]Optimization Progress:  99%|█████████▉| 10111/10200 [22:56<00:44,  1.99pipeline/s]Optimization Progress: 100%|█████████▉| 10191/10200 [22:58<00:03,  2.81pipeline/s]
Generation 101 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [22:58<00:00,  2.81pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [22:58<00:00,  2.81pipeline/s]Optimization Progress: 100%|██████████| 10200/10200 [22:58<00:00,  3.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 10200/10200 [22:59<00:00,  3.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 10200/10200 [22:59<00:00,  3.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10200/10200 [22:59<00:00,  3.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [23:00<00:00,  3.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 10200/10200 [23:01<00:00,  3.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10200/10200 [23:01<00:00,  3.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [23:01<00:00,  3.94pipeline/s]Optimization Progress:  99%|█████████▉| 10204/10300 [23:01<00:42,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10204/10300 [23:01<00:42,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10205/10300 [23:01<00:41,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10206/10300 [23:01<00:41,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10207/10300 [23:01<00:40,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10208/10300 [23:01<00:40,  2.27pipeline/s]Optimization Progress:  99%|█████████▉| 10210/10300 [23:05<00:44,  2.01pipeline/s]Optimization Progress: 100%|█████████▉| 10290/10300 [23:07<00:03,  2.80pipeline/s]
Generation 102 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10300/10300 [23:08<00:00,  2.80pipeline/s]Optimization Progress: 100%|██████████| 10300/10300 [23:08<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10300/10300 [23:08<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10300/10300 [23:09<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10300/10300 [23:09<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10300/10300 [23:09<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [23:10<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10300/10300 [23:10<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [23:10<00:00,  3.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 10300/10300 [23:10<00:00,  3.74pipeline/s]Optimization Progress:  99%|█████████▉| 10305/10400 [23:11<00:34,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10305/10400 [23:11<00:34,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10306/10400 [23:11<00:33,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10307/10400 [23:11<00:33,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10308/10400 [23:11<00:33,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10309/10400 [23:11<00:32,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10310/10400 [23:11<00:32,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10311/10400 [23:11<00:32,  2.78pipeline/s]Optimization Progress:  99%|█████████▉| 10313/10400 [23:23<01:02,  1.40pipeline/s]Optimization Progress: 100%|█████████▉| 10393/10400 [23:25<00:03,  1.97pipeline/s]
Generation 103 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [23:25<00:00,  1.97pipeline/s]Optimization Progress: 100%|██████████| 10400/10400 [23:25<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:04:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10400/10400 [23:26<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [23:28<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 10400/10400 [23:28<00:00,  2.72pipeline/s]Optimization Progress:  99%|█████████▉| 10404/10500 [23:28<00:44,  2.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10404/10500 [23:28<00:44,  2.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10405/10500 [23:28<00:43,  2.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10406/10500 [23:28<00:43,  2.17pipeline/s]Optimization Progress:  99%|█████████▉| 10408/10500 [23:38<01:38,  1.07s/pipeline]Optimization Progress: 100%|█████████▉| 10488/10500 [23:41<00:09,  1.31pipeline/s]
Generation 104 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 10500/10500 [23:41<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [23:41<00:00,  1.31pipeline/s]Optimization Progress: 100%|██████████| 10500/10500 [23:41<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10500/10500 [23:41<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10500/10500 [23:41<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [23:42<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 10500/10500 [23:42<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10500/10500 [23:42<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 10500/10500 [23:42<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10500/10500 [23:43<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10500/10500 [23:43<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10500/10500 [23:43<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [23:43<00:00,  1.84pipeline/s]Optimization Progress:  99%|█████████▉| 10503/10600 [23:44<01:02,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10503/10600 [23:44<01:02,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10504/10600 [23:44<01:01,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10505/10600 [23:44<01:01,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10506/10600 [23:44<01:00,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10507/10600 [23:44<00:59,  1.56pipeline/s]Optimization Progress:  99%|█████████▉| 10509/10600 [23:55<01:32,  1.02s/pipeline]Optimization Progress: 100%|█████████▉| 10589/10600 [23:57<00:07,  1.39pipeline/s]
Generation 105 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 10600/10600 [23:58<00:00,  1.39pipeline/s]Optimization Progress: 100%|██████████| 10600/10600 [23:58<00:00,  1.92pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10600/10600 [23:58<00:00,  1.92pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 10600/10600 [23:58<00:00,  1.92pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [23:59<00:00,  1.92pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10600/10600 [23:59<00:00,  1.92pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10600/10600 [24:00<00:00,  1.92pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [24:00<00:00,  1.92pipeline/s]Optimization Progress:  99%|█████████▉| 10603/10700 [24:01<01:04,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10603/10700 [24:01<01:04,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10604/10700 [24:01<01:03,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10605/10700 [24:01<01:02,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10606/10700 [24:01<01:02,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10607/10700 [24:01<01:01,  1.52pipeline/s]Optimization Progress:  99%|█████████▉| 10609/10700 [24:11<01:30,  1.00pipeline/s]Optimization Progress: 100%|█████████▉| 10689/10700 [24:13<00:07,  1.42pipeline/s]
Generation 106 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10700/10700 [24:13<00:00,  1.42pipeline/s]Optimization Progress: 100%|██████████| 10700/10700 [24:13<00:00,  2.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 10700/10700 [24:14<00:00,  2.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10700/10700 [24:14<00:00,  2.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [24:15<00:00,  2.02pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10701/10800 [24:16<00:49,  2.02pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10702/10800 [24:16<00:48,  2.02pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10703/10800 [24:16<00:48,  2.02pipeline/s]Optimization Progress:  99%|█████████▉| 10704/10800 [24:16<00:53,  1.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10704/10800 [24:16<00:53,  1.80pipeline/s]Optimization Progress:  99%|█████████▉| 10707/10800 [24:20<01:18,  1.19pipeline/s]Optimization Progress: 100%|█████████▉| 10786/10800 [24:22<00:08,  1.67pipeline/s]
Generation 107 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [24:22<00:00,  1.67pipeline/s]Optimization Progress: 100%|██████████| 10800/10800 [24:22<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 10800/10800 [24:23<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10800/10800 [24:23<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 10800/10800 [24:23<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 10800/10800 [24:24<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10800/10800 [24:24<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [24:25<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10800/10800 [24:25<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [24:26<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10800/10800 [24:26<00:00,  2.38pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:05:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 10800/10800 [24:26<00:00,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10801/10900 [24:27<00:41,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10802/10900 [24:27<00:41,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10803/10900 [24:27<00:40,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10804/10900 [24:27<00:40,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10805/10900 [24:27<00:39,  2.38pipeline/s]Optimization Progress:  99%|█████████▉| 10806/10900 [24:27<00:47,  1.97pipeline/s]Optimization Progress:  99%|█████████▉| 10811/10900 [24:32<00:58,  1.51pipeline/s]Optimization Progress: 100%|█████████▉| 10887/10900 [24:34<00:06,  2.12pipeline/s]
Generation 108 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10900/10900 [24:35<00:00,  2.12pipeline/s]Optimization Progress: 100%|██████████| 10900/10900 [24:35<00:00,  2.91pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10900/10900 [24:35<00:00,  2.91pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [24:35<00:00,  2.91pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 10900/10900 [24:36<00:00,  2.91pipeline/s]Optimization Progress:  99%|█████████▉| 10903/11000 [24:38<00:53,  1.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10903/11000 [24:38<00:53,  1.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10904/11000 [24:38<00:53,  1.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10905/11000 [24:38<00:52,  1.80pipeline/s]Optimization Progress:  99%|█████████▉| 10907/11000 [24:44<01:20,  1.16pipeline/s]Optimization Progress: 100%|█████████▉| 10987/11000 [24:47<00:08,  1.62pipeline/s]
Generation 109 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 11000/11000 [24:48<00:00,  1.62pipeline/s]Optimization Progress: 100%|██████████| 11000/11000 [24:48<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:06:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11000/11000 [24:48<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [24:48<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [24:49<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:06:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11000/11000 [24:50<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:06:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11000/11000 [24:51<00:00,  2.29pipeline/s]Optimization Progress:  99%|█████████▉| 11003/11100 [24:51<01:05,  1.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11003/11100 [24:51<01:05,  1.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11004/11100 [24:51<01:04,  1.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11005/11100 [24:51<01:03,  1.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11006/11100 [24:51<01:03,  1.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11007/11100 [24:51<01:02,  1.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11008/11100 [24:51<01:01,  1.49pipeline/s]Optimization Progress:  99%|█████████▉| 11010/11100 [24:57<01:04,  1.39pipeline/s]Optimization Progress: 100%|█████████▉| 11090/11100 [24:59<00:05,  1.95pipeline/s]
Generation 110 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:06:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11100/11100 [25:00<00:00,  1.95pipeline/s]Optimization Progress: 100%|██████████| 11100/11100 [25:00<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [25:01<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 11100/11100 [25:01<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [25:02<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [25:02<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [25:02<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 11100/11100 [25:03<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:06:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11100/11100 [25:03<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 11100/11100 [25:03<00:00,  2.68pipeline/s]Optimization Progress:  99%|█████████▉| 11108/11200 [25:03<00:34,  2.64pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11108/11200 [25:03<00:34,  2.64pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11109/11200 [25:03<00:34,  2.64pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11110/11200 [25:03<00:34,  2.64pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11111/11200 [25:03<00:33,  2.64pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11112/11200 [25:03<00:33,  2.64pipeline/s]Optimization Progress:  99%|█████████▉| 11114/11200 [25:08<00:44,  1.92pipeline/s]Optimization Progress: 100%|█████████▉| 11194/11200 [25:09<00:02,  2.71pipeline/s]
Generation 111 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 11200/11200 [25:10<00:00,  2.71pipeline/s]Optimization Progress: 100%|██████████| 11200/11200 [25:10<00:00,  3.46pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:06:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11200/11200 [25:11<00:00,  3.46pipeline/s]Optimization Progress:  99%|█████████▉| 11204/11300 [25:12<00:37,  2.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11204/11300 [25:12<00:37,  2.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11205/11300 [25:12<00:37,  2.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11206/11300 [25:12<00:36,  2.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11207/11300 [25:13<00:36,  2.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11208/11300 [25:13<00:36,  2.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11209/11300 [25:13<00:35,  2.54pipeline/s]Optimization Progress:  99%|█████████▉| 11211/11300 [25:17<00:41,  2.16pipeline/s]Optimization Progress: 100%|█████████▉| 11291/11300 [25:20<00:03,  2.97pipeline/s]
Generation 112 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 11300/11300 [25:21<00:00,  2.97pipeline/s]Optimization Progress: 100%|██████████| 11300/11300 [25:21<00:00,  3.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11300/11300 [25:22<00:00,  3.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11300/11300 [25:22<00:00,  3.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11300/11300 [25:23<00:00,  3.82pipeline/s]Optimization Progress:  99%|█████████▉| 11303/11400 [25:23<00:35,  2.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11303/11400 [25:23<00:35,  2.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11304/11400 [25:23<00:35,  2.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11305/11400 [25:23<00:35,  2.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11306/11400 [25:23<00:34,  2.71pipeline/s]Optimization Progress:  99%|█████████▉| 11308/11400 [25:31<01:07,  1.37pipeline/s]Optimization Progress: 100%|█████████▉| 11388/11400 [25:32<00:06,  1.94pipeline/s]
Generation 113 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 11400/11400 [25:32<00:00,  1.94pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:06:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11400/11400 [25:33<00:00,  1.94pipeline/s]Optimization Progress: 100%|██████████| 11400/11400 [25:33<00:00,  2.63pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11400/11400 [25:34<00:00,  2.63pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11400/11400 [25:35<00:00,  2.63pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11400/11400 [25:36<00:00,  2.63pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11402/11500 [25:37<00:37,  2.63pipeline/s]Optimization Progress:  99%|█████████▉| 11403/11500 [25:37<01:03,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11403/11500 [25:37<01:03,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11404/11500 [25:37<01:03,  1.52pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11405/11500 [25:37<01:02,  1.52pipeline/s]Optimization Progress:  99%|█████████▉| 11407/11500 [25:41<01:14,  1.25pipeline/s]Optimization Progress: 100%|█████████▉| 11487/11500 [25:44<00:07,  1.74pipeline/s]
Generation 114 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 11500/11500 [25:44<00:00,  1.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 11500/11500 [25:45<00:00,  1.74pipeline/s]Optimization Progress: 100%|██████████| 11500/11500 [25:45<00:00,  2.40pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11500/11500 [25:45<00:00,  2.40pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11500/11500 [25:45<00:00,  2.40pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11500/11500 [25:46<00:00,  2.40pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 11500/11500 [25:47<00:00,  2.40pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11500/11500 [25:47<00:00,  2.40pipeline/s]Optimization Progress:  99%|█████████▉| 11505/11600 [25:48<00:42,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11505/11600 [25:48<00:42,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11506/11600 [25:48<00:42,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11507/11600 [25:48<00:41,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11508/11600 [25:48<00:41,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11509/11600 [25:48<00:40,  2.22pipeline/s]Optimization Progress:  99%|█████████▉| 11511/11600 [25:51<00:44,  1.98pipeline/s]Optimization Progress: 100%|█████████▉| 11591/11600 [25:53<00:03,  2.77pipeline/s]
Generation 115 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11600/11600 [25:54<00:00,  2.77pipeline/s]Optimization Progress: 100%|██████████| 11600/11600 [25:54<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11600/11600 [25:54<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 11600/11600 [25:55<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11600/11600 [25:55<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11600/11600 [25:55<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11600/11600 [25:55<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 11600/11600 [25:56<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11600/11600 [25:56<00:00,  3.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 11600/11600 [25:57<00:00,  3.80pipeline/s]Optimization Progress:  99%|█████████▉| 11603/11700 [25:57<00:50,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11603/11700 [25:57<00:50,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11604/11700 [25:57<00:50,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11605/11700 [25:57<00:49,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11606/11700 [25:57<00:49,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11607/11700 [25:57<00:48,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11608/11700 [25:57<00:47,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11609/11700 [25:57<00:47,  1.92pipeline/s]Optimization Progress:  99%|█████████▉| 11611/11700 [26:04<00:55,  1.59pipeline/s]Optimization Progress: 100%|█████████▉| 11691/11700 [26:05<00:03,  2.26pipeline/s]
Generation 116 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11700/11700 [26:06<00:00,  2.26pipeline/s]Optimization Progress: 100%|██████████| 11700/11700 [26:06<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 11700/11700 [26:06<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 11700/11700 [26:06<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11700/11700 [26:06<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11700/11700 [26:06<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11700/11700 [26:07<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11700/11700 [26:08<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 11700/11700 [26:09<00:00,  2.88pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11700/11700 [26:09<00:00,  2.88pipeline/s]Optimization Progress:  99%|█████████▉| 11706/11800 [26:09<00:36,  2.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11706/11800 [26:09<00:36,  2.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11707/11800 [26:09<00:35,  2.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11708/11800 [26:09<00:35,  2.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11709/11800 [26:09<00:34,  2.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11710/11800 [26:09<00:34,  2.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11711/11800 [26:09<00:34,  2.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11712/11800 [26:09<00:33,  2.61pipeline/s]Optimization Progress:  99%|█████████▉| 11714/11800 [26:15<00:41,  2.08pipeline/s]Optimization Progress: 100%|█████████▉| 11794/11800 [26:17<00:02,  2.90pipeline/s]
Generation 117 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11800/11800 [26:18<00:00,  2.90pipeline/s]Optimization Progress: 100%|██████████| 11800/11800 [26:18<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 11800/11800 [26:19<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 11800/11800 [26:19<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 11800/11800 [26:20<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11800/11800 [26:20<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 11800/11800 [26:20<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11800/11800 [26:20<00:00,  3.31pipeline/s]Optimization Progress:  99%|█████████▉| 11803/11900 [26:21<00:42,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11803/11900 [26:21<00:42,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11804/11900 [26:21<00:42,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11805/11900 [26:21<00:41,  2.27pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11806/11900 [26:21<00:41,  2.27pipeline/s]Optimization Progress:  99%|█████████▉| 11808/11900 [26:24<00:45,  2.02pipeline/s]Optimization Progress: 100%|█████████▉| 11888/11900 [26:26<00:04,  2.81pipeline/s]
Generation 118 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 11900/11900 [26:27<00:00,  2.81pipeline/s]Optimization Progress: 100%|██████████| 11900/11900 [26:27<00:00,  3.85pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11900/11900 [26:28<00:00,  3.85pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11900/11900 [26:29<00:00,  3.85pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 11900/11900 [26:29<00:00,  3.85pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11900/11900 [26:29<00:00,  3.85pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:07:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 11900/11900 [26:30<00:00,  3.85pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 11900/11900 [26:30<00:00,  3.85pipeline/s]Optimization Progress:  99%|█████████▉| 11904/12000 [26:30<00:40,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11904/12000 [26:30<00:40,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11905/12000 [26:30<00:39,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11906/12000 [26:30<00:39,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11907/12000 [26:30<00:39,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11908/12000 [26:30<00:38,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11909/12000 [26:30<00:38,  2.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11910/12000 [26:30<00:37,  2.38pipeline/s]Optimization Progress:  99%|█████████▉| 11912/12000 [26:33<00:38,  2.31pipeline/s]Optimization Progress: 100%|█████████▉| 11992/12000 [26:36<00:02,  3.21pipeline/s]
Generation 119 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12000/12000 [26:36<00:00,  3.21pipeline/s]Optimization Progress: 100%|██████████| 12000/12000 [26:36<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12000/12000 [26:36<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 12000/12000 [26:36<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12000/12000 [26:37<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12000/12000 [26:37<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12000/12000 [26:38<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 12000/12000 [26:38<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12000/12000 [26:38<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12000/12000 [26:39<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12000/12000 [26:40<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12000/12000 [26:40<00:00,  4.44pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 12000/12000 [26:41<00:00,  4.44pipeline/s]Optimization Progress:  99%|█████████▉| 12006/12100 [26:41<00:37,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12006/12100 [26:41<00:37,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12007/12100 [26:41<00:37,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12008/12100 [26:41<00:36,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12009/12100 [26:41<00:36,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12010/12100 [26:41<00:36,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12011/12100 [26:41<00:35,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12012/12100 [26:41<00:35,  2.49pipeline/s]Optimization Progress:  99%|█████████▉| 12014/12100 [26:47<00:42,  2.02pipeline/s]Optimization Progress: 100%|█████████▉| 12094/12100 [26:48<00:02,  2.84pipeline/s]
Generation 120 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12100/12100 [26:48<00:00,  2.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12100/12100 [26:49<00:00,  2.84pipeline/s]Optimization Progress: 100%|██████████| 12100/12100 [26:49<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:08:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12100/12100 [26:49<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12100/12100 [26:49<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 12100/12100 [26:50<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12100/12100 [26:50<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 12100/12100 [26:51<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12100/12100 [26:51<00:00,  3.75pipeline/s]Optimization Progress:  99%|█████████▉| 12104/12200 [26:51<00:37,  2.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12104/12200 [26:51<00:37,  2.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12105/12200 [26:51<00:37,  2.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12106/12200 [26:51<00:36,  2.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12107/12200 [26:51<00:36,  2.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12108/12200 [26:51<00:36,  2.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12109/12200 [26:51<00:35,  2.55pipeline/s]Optimization Progress:  99%|█████████▉| 12111/12200 [26:56<00:42,  2.11pipeline/s]Optimization Progress: 100%|█████████▉| 12191/12200 [26:57<00:03,  2.98pipeline/s]
Generation 121 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12200/12200 [26:57<00:00,  2.98pipeline/s]Optimization Progress: 100%|██████████| 12200/12200 [26:57<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 12200/12200 [26:58<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 12200/12200 [26:58<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12200/12200 [26:58<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12200/12200 [26:58<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:08:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12200/12200 [26:59<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12200/12200 [27:00<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12200/12200 [27:00<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12200/12200 [27:00<00:00,  4.16pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 12200/12200 [27:00<00:00,  4.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12203/12300 [27:00<00:23,  4.16pipeline/s]Optimization Progress:  99%|█████████▉| 12204/12300 [27:00<00:39,  2.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12204/12300 [27:01<00:39,  2.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12205/12300 [27:01<00:39,  2.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12206/12300 [27:01<00:39,  2.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12207/12300 [27:01<00:38,  2.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12208/12300 [27:01<00:38,  2.41pipeline/s]Optimization Progress:  99%|█████████▉| 12210/12300 [27:05<00:47,  1.88pipeline/s]Optimization Progress: 100%|█████████▉| 12290/12300 [27:06<00:03,  2.67pipeline/s]
Generation 122 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12300/12300 [27:06<00:00,  2.67pipeline/s]Optimization Progress: 100%|██████████| 12300/12300 [27:06<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 12300/12300 [27:07<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 12300/12300 [27:07<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 12300/12300 [27:07<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12300/12300 [27:09<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12300/12300 [27:09<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12300/12300 [27:09<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 12300/12300 [27:10<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:08:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12300/12300 [27:10<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 12300/12300 [27:10<00:00,  3.66pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12300/12300 [27:10<00:00,  3.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12302/12400 [27:10<00:26,  3.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12303/12400 [27:10<00:26,  3.66pipeline/s]Optimization Progress:  99%|█████████▉| 12304/12400 [27:10<00:43,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12304/12400 [27:10<00:43,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12305/12400 [27:10<00:42,  2.22pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12306/12400 [27:10<00:42,  2.22pipeline/s]Optimization Progress:  99%|█████████▉| 12308/12400 [27:18<01:25,  1.07pipeline/s]Optimization Progress: 100%|█████████▉| 12388/12400 [27:19<00:07,  1.52pipeline/s]
Generation 123 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12400/12400 [27:20<00:00,  1.52pipeline/s]Optimization Progress: 100%|██████████| 12400/12400 [27:20<00:00,  2.10pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 12400/12400 [27:20<00:00,  2.10pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:08:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12400/12400 [27:21<00:00,  2.10pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 12400/12400 [27:21<00:00,  2.10pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12400/12400 [27:23<00:00,  2.10pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12400/12400 [27:23<00:00,  2.10pipeline/s]Optimization Progress:  99%|█████████▉| 12407/12500 [27:23<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12407/12500 [27:23<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12408/12500 [27:23<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12409/12500 [27:23<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12410/12500 [27:23<00:41,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12411/12500 [27:23<00:41,  2.16pipeline/s]Optimization Progress:  99%|█████████▉| 12413/12500 [27:30<00:59,  1.47pipeline/s]Optimization Progress: 100%|█████████▉| 12493/12500 [27:35<00:03,  2.03pipeline/s]
Generation 124 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 12500/12500 [27:36<00:00,  2.03pipeline/s]Optimization Progress: 100%|██████████| 12500/12500 [27:36<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12500/12500 [27:38<00:00,  2.57pipeline/s]Optimization Progress:  99%|█████████▉| 12508/12600 [27:39<00:35,  2.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12508/12600 [27:39<00:35,  2.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12509/12600 [27:39<00:35,  2.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12510/12600 [27:39<00:34,  2.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12511/12600 [27:39<00:34,  2.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12512/12600 [27:39<00:33,  2.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12513/12600 [27:39<00:33,  2.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12514/12600 [27:39<00:33,  2.59pipeline/s]Optimization Progress:  99%|█████████▉| 12516/12600 [27:43<00:35,  2.36pipeline/s]Optimization Progress: 100%|█████████▉| 12596/12600 [27:44<00:01,  3.33pipeline/s]
Generation 125 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 12600/12600 [27:44<00:00,  3.33pipeline/s]Optimization Progress: 100%|██████████| 12600/12600 [27:44<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 12600/12600 [27:45<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12600/12600 [27:46<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 12600/12600 [27:47<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:09:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12600/12600 [27:47<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12600/12600 [27:47<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 12600/12600 [27:47<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 12600/12600 [27:47<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12600/12600 [27:48<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 12600/12600 [27:48<00:00,  4.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 12600/12600 [27:48<00:00,  4.32pipeline/s]Optimization Progress:  99%|█████████▉| 12609/12700 [27:48<00:25,  3.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12609/12700 [27:48<00:25,  3.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12610/12700 [27:48<00:25,  3.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12611/12700 [27:48<00:25,  3.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12612/12700 [27:48<00:25,  3.50pipeline/s]Optimization Progress:  99%|█████████▉| 12614/12700 [27:52<00:38,  2.25pipeline/s]Optimization Progress: 100%|█████████▉| 12694/12700 [27:53<00:01,  3.16pipeline/s]
Generation 126 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 12700/12700 [27:54<00:00,  3.16pipeline/s]Optimization Progress: 100%|██████████| 12700/12700 [27:54<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12700/12700 [27:55<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 12700/12700 [27:56<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12700/12700 [27:57<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:09:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12700/12700 [27:57<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:09:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12700/12700 [27:57<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 12700/12700 [27:57<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 12700/12700 [27:57<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 12700/12700 [27:57<00:00,  4.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:09:24] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12700/12700 [27:58<00:00,  4.00pipeline/s]Optimization Progress:  99%|█████████▉| 12706/12800 [27:58<00:33,  2.84pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12706/12800 [27:58<00:33,  2.84pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12707/12800 [27:58<00:32,  2.84pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12708/12800 [27:58<00:32,  2.84pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12709/12800 [27:58<00:32,  2.84pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12710/12800 [27:58<00:31,  2.84pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12711/12800 [27:58<00:31,  2.84pipeline/s]Optimization Progress:  99%|█████████▉| 12713/12800 [28:02<00:36,  2.40pipeline/s]Optimization Progress: 100%|█████████▉| 12793/12800 [28:03<00:02,  3.36pipeline/s]
Generation 127 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:09:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12800/12800 [28:04<00:00,  3.36pipeline/s]Optimization Progress: 100%|██████████| 12800/12800 [28:04<00:00,  4.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:09:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12800/12800 [28:04<00:00,  4.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12800/12800 [28:05<00:00,  4.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:09:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12800/12800 [28:07<00:00,  4.45pipeline/s]Optimization Progress:  99%|█████████▉| 12805/12900 [28:08<00:38,  2.47pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12805/12900 [28:08<00:38,  2.47pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12806/12900 [28:08<00:37,  2.47pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12807/12900 [28:08<00:37,  2.47pipeline/s]Optimization Progress:  99%|█████████▉| 12809/12900 [28:17<01:30,  1.00pipeline/s]Optimization Progress: 100%|█████████▉| 12889/12900 [28:21<00:07,  1.41pipeline/s]
Generation 128 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12900/12900 [28:21<00:00,  1.41pipeline/s]Optimization Progress: 100%|██████████| 12900/12900 [28:21<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 12900/12900 [28:21<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12900/12900 [28:22<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12900/12900 [28:22<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12900/12900 [28:22<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 12900/12900 [28:22<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 12900/12900 [28:23<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12900/12900 [28:23<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12900/12900 [28:23<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12900/12900 [28:23<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:09:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 12900/12900 [28:23<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 12900/12900 [28:24<00:00,  2.00pipeline/s]Optimization Progress:  99%|█████████▉| 12906/13000 [28:24<00:49,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12906/13000 [28:24<00:49,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12907/13000 [28:24<00:48,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12908/13000 [28:24<00:48,  1.92pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12909/13000 [28:24<00:47,  1.92pipeline/s]Optimization Progress:  99%|█████████▉| 12911/13000 [28:32<01:14,  1.19pipeline/s]Optimization Progress: 100%|█████████▉| 12991/13000 [28:37<00:05,  1.64pipeline/s]
Generation 129 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 13000/13000 [28:37<00:00,  1.64pipeline/s]Optimization Progress: 100%|██████████| 13000/13000 [28:37<00:00,  2.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 13000/13000 [28:37<00:00,  2.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13000/13000 [28:38<00:00,  2.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13000/13000 [28:38<00:00,  2.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13000/13000 [28:39<00:00,  2.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13000/13000 [28:39<00:00,  2.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 13000/13000 [28:39<00:00,  2.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13000/13000 [28:41<00:00,  2.31pipeline/s]Optimization Progress:  99%|█████████▉| 13007/13100 [28:41<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13007/13100 [28:41<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13008/13100 [28:41<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13009/13100 [28:41<00:42,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13010/13100 [28:41<00:41,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13011/13100 [28:41<00:41,  2.16pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13012/13100 [28:41<00:40,  2.16pipeline/s]Optimization Progress:  99%|█████████▉| 13014/13100 [28:49<00:55,  1.56pipeline/s]Optimization Progress: 100%|█████████▉| 13094/13100 [28:50<00:02,  2.20pipeline/s]
Generation 130 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 13100/13100 [28:50<00:00,  2.20pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 13100/13100 [28:50<00:00,  2.20pipeline/s]Optimization Progress: 100%|██████████| 13100/13100 [28:50<00:00,  2.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13100/13100 [28:52<00:00,  2.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13100/13100 [28:53<00:00,  2.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13100/13100 [28:53<00:00,  2.93pipeline/s]Optimization Progress:  99%|█████████▉| 13107/13200 [28:53<00:34,  2.72pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13107/13200 [28:53<00:34,  2.72pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13108/13200 [28:53<00:33,  2.72pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13109/13200 [28:53<00:33,  2.72pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13110/13200 [28:53<00:33,  2.72pipeline/s]Optimization Progress:  99%|█████████▉| 13112/13200 [28:57<00:43,  2.04pipeline/s]Optimization Progress: 100%|█████████▉| 13192/13200 [29:00<00:02,  2.83pipeline/s]
Generation 131 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 13200/13200 [29:00<00:00,  2.83pipeline/s]Optimization Progress: 100%|██████████| 13200/13200 [29:00<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13200/13200 [29:00<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13200/13200 [29:01<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 13200/13200 [29:01<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13200/13200 [29:01<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13200/13200 [29:01<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 13200/13200 [29:02<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13200/13200 [29:03<00:00,  3.75pipeline/s]Optimization Progress:  99%|█████████▉| 13203/13300 [29:03<00:45,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13203/13300 [29:03<00:45,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13204/13300 [29:03<00:44,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13205/13300 [29:03<00:44,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13206/13300 [29:03<00:43,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13207/13300 [29:03<00:43,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13208/13300 [29:03<00:42,  2.15pipeline/s]Optimization Progress:  99%|█████████▉| 13210/13300 [29:09<00:53,  1.70pipeline/s]Optimization Progress: 100%|█████████▉| 13290/13300 [29:12<00:04,  2.36pipeline/s]
Generation 132 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13300/13300 [29:12<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13300/13300 [29:12<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 13300/13300 [29:12<00:00,  2.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13300/13300 [29:12<00:00,  2.36pipeline/s]Optimization Progress: 100%|██████████| 13300/13300 [29:12<00:00,  3.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13300/13300 [29:13<00:00,  3.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13300/13300 [29:13<00:00,  3.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13300/13300 [29:13<00:00,  3.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13300/13300 [29:15<00:00,  3.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13300/13300 [29:15<00:00,  3.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13300/13300 [29:15<00:00,  3.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:42] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13300/13300 [29:15<00:00,  3.30pipeline/s]Optimization Progress:  99%|█████████▉| 13306/13400 [29:16<00:35,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13306/13400 [29:16<00:35,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13307/13400 [29:16<00:34,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13308/13400 [29:16<00:34,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13309/13400 [29:16<00:34,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13310/13400 [29:16<00:33,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13311/13400 [29:16<00:33,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13312/13400 [29:16<00:32,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13313/13400 [29:16<00:32,  2.67pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13314/13400 [29:16<00:32,  2.67pipeline/s]Optimization Progress:  99%|█████████▉| 13316/13400 [29:20<00:32,  2.57pipeline/s]Optimization Progress: 100%|█████████▉| 13396/13400 [29:21<00:01,  3.64pipeline/s]
Generation 133 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 13400/13400 [29:21<00:00,  3.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13400/13400 [29:21<00:00,  3.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13400/13400 [29:22<00:00,  3.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13400/13400 [29:22<00:00,  3.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13400/13400 [29:23<00:00,  3.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13400/13400 [29:24<00:00,  3.64pipeline/s]Optimization Progress:  99%|█████████▉| 13404/13500 [29:24<00:29,  3.24pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13404/13500 [29:24<00:29,  3.24pipeline/s]Optimization Progress:  99%|█████████▉| 13408/13500 [29:29<00:52,  1.74pipeline/s]Optimization Progress: 100%|█████████▉| 13486/13500 [29:31<00:05,  2.43pipeline/s]
Generation 134 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13500/13500 [29:31<00:00,  2.43pipeline/s]Optimization Progress: 100%|██████████| 13500/13500 [29:31<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13500/13500 [29:31<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13500/13500 [29:31<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13500/13500 [29:33<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 13500/13500 [29:33<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:10:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13500/13500 [29:33<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13500/13500 [29:34<00:00,  3.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13500/13500 [29:34<00:00,  3.31pipeline/s]Optimization Progress:  99%|█████████▉| 13504/13600 [29:34<00:42,  2.28pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13504/13600 [29:34<00:42,  2.28pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13505/13600 [29:34<00:41,  2.28pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13506/13600 [29:34<00:41,  2.28pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13507/13600 [29:34<00:40,  2.28pipeline/s]Optimization Progress:  99%|█████████▉| 13509/13600 [29:40<00:58,  1.55pipeline/s]Optimization Progress: 100%|█████████▉| 13589/13600 [29:42<00:05,  2.18pipeline/s]
Generation 135 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 13600/13600 [29:42<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13600/13600 [29:42<00:00,  2.18pipeline/s]Optimization Progress: 100%|██████████| 13600/13600 [29:42<00:00,  3.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13600/13600 [29:42<00:00,  3.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13600/13600 [29:43<00:00,  3.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13600/13600 [29:43<00:00,  3.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13600/13600 [29:44<00:00,  3.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:11] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13600/13600 [29:45<00:00,  3.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13600/13600 [29:46<00:00,  3.02pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 13600/13600 [29:46<00:00,  3.02pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13602/13700 [29:46<00:32,  3.02pipeline/s]Optimization Progress:  99%|█████████▉| 13603/13700 [29:46<00:57,  1.69pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13603/13700 [29:46<00:57,  1.69pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13604/13700 [29:46<00:56,  1.69pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13605/13700 [29:46<00:56,  1.69pipeline/s]Optimization Progress:  99%|█████████▉| 13607/13700 [29:53<01:31,  1.02pipeline/s]Optimization Progress: 100%|█████████▉| 13687/13700 [29:56<00:09,  1.44pipeline/s]
Generation 136 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 13700/13700 [29:57<00:00,  1.44pipeline/s]Optimization Progress: 100%|██████████| 13700/13700 [29:57<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:24] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13700/13700 [29:58<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13700/13700 [29:58<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 13700/13700 [29:59<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13700/13700 [29:59<00:00,  1.97pipeline/s]Optimization Progress:  99%|█████████▉| 13702/13800 [29:59<01:08,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13702/13800 [29:59<01:08,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13703/13800 [29:59<01:08,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13704/13800 [29:59<01:07,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13705/13800 [29:59<01:06,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13706/13800 [29:59<01:06,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13707/13800 [30:00<01:05,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13708/13800 [30:00<01:04,  1.42pipeline/s]Optimization Progress:  99%|█████████▉| 13710/13800 [30:04<01:00,  1.50pipeline/s]Optimization Progress: 100%|█████████▉| 13790/13800 [30:06<00:04,  2.11pipeline/s]
Generation 137 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 13800/13800 [30:06<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13800/13800 [30:07<00:00,  2.11pipeline/s]Optimization Progress: 100%|██████████| 13800/13800 [30:07<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13800/13800 [30:07<00:00,  2.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 13800/13800 [30:08<00:00,  2.68pipeline/s]Optimization Progress:  99%|█████████▉| 13811/13900 [30:08<00:26,  3.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13811/13900 [30:08<00:26,  3.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13812/13900 [30:08<00:25,  3.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13813/13900 [30:08<00:25,  3.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13814/13900 [30:08<00:25,  3.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13815/13900 [30:08<00:24,  3.41pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13816/13900 [30:08<00:24,  3.41pipeline/s]Optimization Progress:  99%|█████████▉| 13818/13900 [30:12<00:28,  2.83pipeline/s]Optimization Progress: 100%|█████████▉| 13898/13900 [30:12<00:00,  4.01pipeline/s]
Generation 138 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 13900/13900 [30:13<00:00,  4.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 13900/13900 [30:14<00:00,  4.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 13900/13900 [30:15<00:00,  4.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 13900/13900 [30:15<00:00,  4.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 13900/13900 [30:16<00:00,  4.01pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13903/14000 [30:16<00:24,  4.01pipeline/s]Optimization Progress:  99%|█████████▉| 13904/14000 [30:16<00:34,  2.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13904/14000 [30:16<00:34,  2.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13905/14000 [30:16<00:33,  2.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13906/14000 [30:16<00:33,  2.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13907/14000 [30:16<00:33,  2.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13908/14000 [30:16<00:32,  2.80pipeline/s]Optimization Progress:  99%|█████████▉| 13910/14000 [30:20<00:40,  2.21pipeline/s]Optimization Progress: 100%|█████████▉| 13990/14000 [30:23<00:03,  3.06pipeline/s]
Generation 139 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 14000/14000 [30:23<00:00,  3.06pipeline/s]Optimization Progress: 100%|██████████| 14000/14000 [30:23<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:11:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14000/14000 [30:24<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 14000/14000 [30:24<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 14000/14000 [30:24<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 14000/14000 [30:24<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14000/14000 [30:25<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14000/14000 [30:25<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14000/14000 [30:25<00:00,  4.24pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14000/14000 [30:26<00:00,  4.24pipeline/s]Optimization Progress:  99%|█████████▉| 14006/14100 [30:26<00:28,  3.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14006/14100 [30:26<00:28,  3.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14007/14100 [30:26<00:27,  3.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14008/14100 [30:26<00:27,  3.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14009/14100 [30:26<00:27,  3.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14010/14100 [30:26<00:27,  3.32pipeline/s]Optimization Progress:  99%|█████████▉| 14012/14100 [30:31<00:42,  2.08pipeline/s]Optimization Progress: 100%|█████████▉| 14092/14100 [30:33<00:02,  2.93pipeline/s]
Generation 140 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 14100/14100 [30:33<00:00,  2.93pipeline/s]Optimization Progress: 100%|██████████| 14100/14100 [30:33<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14100/14100 [30:34<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:12:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14100/14100 [30:34<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 14100/14100 [30:34<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 14100/14100 [30:34<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14100/14100 [30:35<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:12:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14100/14100 [30:35<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14100/14100 [30:35<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 14100/14100 [30:36<00:00,  3.75pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14102/14200 [30:36<00:26,  3.75pipeline/s]Optimization Progress:  99%|█████████▉| 14103/14200 [30:36<00:44,  2.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14103/14200 [30:36<00:44,  2.17pipeline/s]Optimization Progress:  99%|█████████▉| 14105/14200 [30:40<01:31,  1.04pipeline/s]Optimization Progress: 100%|█████████▉| 14185/14200 [30:42<00:10,  1.47pipeline/s]
Generation 141 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14200/14200 [30:42<00:00,  1.47pipeline/s]Optimization Progress: 100%|██████████| 14200/14200 [30:42<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14200/14200 [30:42<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14200/14200 [30:43<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 14200/14200 [30:43<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 14200/14200 [30:43<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:12:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14200/14200 [30:43<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14200/14200 [30:45<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 14200/14200 [30:45<00:00,  2.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14201/14300 [30:45<00:47,  2.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14202/14300 [30:45<00:47,  2.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14203/14300 [30:45<00:46,  2.08pipeline/s]Optimization Progress:  99%|█████████▉| 14204/14300 [30:45<00:55,  1.73pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14204/14300 [30:45<00:55,  1.73pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14205/14300 [30:45<00:54,  1.73pipeline/s]Optimization Progress:  99%|█████████▉| 14207/14300 [30:50<01:22,  1.12pipeline/s]Optimization Progress: 100%|█████████▉| 14287/14300 [30:54<00:08,  1.57pipeline/s]
Generation 142 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:12:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14300/14300 [30:54<00:00,  1.57pipeline/s]Optimization Progress: 100%|██████████| 14300/14300 [30:54<00:00,  2.19pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14300/14300 [30:56<00:00,  2.19pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14300/14300 [30:56<00:00,  2.19pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14300/14300 [30:57<00:00,  2.19pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 14300/14300 [30:57<00:00,  2.19pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14300/14300 [30:58<00:00,  2.19pipeline/s]Optimization Progress:  99%|█████████▉| 14305/14400 [30:58<00:48,  1.96pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14305/14400 [30:58<00:48,  1.96pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14306/14400 [30:58<00:47,  1.96pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14307/14400 [30:58<00:47,  1.96pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14308/14400 [30:58<00:46,  1.96pipeline/s]Optimization Progress:  99%|█████████▉| 14310/14400 [31:03<01:02,  1.44pipeline/s]Optimization Progress: 100%|█████████▉| 14390/14400 [31:06<00:04,  2.01pipeline/s]
Generation 143 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14400/14400 [31:06<00:00,  2.01pipeline/s]Optimization Progress: 100%|██████████| 14400/14400 [31:06<00:00,  2.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14400/14400 [31:07<00:00,  2.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:12:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14400/14400 [31:08<00:00,  2.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 14400/14400 [31:08<00:00,  2.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 14400/14400 [31:08<00:00,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14400/14500 [31:10<00:35,  2.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14401/14500 [31:10<00:35,  2.78pipeline/s]Optimization Progress:  99%|█████████▉| 14402/14500 [31:10<01:17,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14402/14500 [31:10<01:17,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14403/14500 [31:10<01:17,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14404/14500 [31:10<01:16,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14405/14500 [31:10<01:15,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14406/14500 [31:10<01:14,  1.26pipeline/s]Optimization Progress:  99%|█████████▉| 14408/14500 [31:18<01:28,  1.04pipeline/s]Optimization Progress: 100%|█████████▉| 14488/14500 [31:21<00:08,  1.47pipeline/s]
Generation 144 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14500/14500 [31:21<00:00,  1.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 14500/14500 [31:23<00:00,  1.47pipeline/s]Optimization Progress: 100%|██████████| 14500/14500 [31:23<00:00,  1.91pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 14500/14500 [31:23<00:00,  1.91pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:12:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14500/14500 [31:23<00:00,  1.91pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 14500/14500 [31:23<00:00,  1.91pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 14500/14500 [31:23<00:00,  1.91pipeline/s]Optimization Progress:  99%|█████████▉| 14504/14600 [31:24<00:43,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14504/14600 [31:24<00:43,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14505/14600 [31:24<00:43,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14506/14600 [31:24<00:42,  2.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14507/14600 [31:24<00:42,  2.19pipeline/s]Optimization Progress:  99%|█████████▉| 14509/14600 [31:28<00:48,  1.86pipeline/s]Optimization Progress: 100%|█████████▉| 14589/14600 [31:30<00:04,  2.59pipeline/s]
Generation 145 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14600/14600 [31:31<00:00,  2.59pipeline/s]Optimization Progress: 100%|██████████| 14600/14600 [31:31<00:00,  3.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14600/14600 [31:31<00:00,  3.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 14600/14600 [31:31<00:00,  3.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 14600/14600 [31:32<00:00,  3.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 14600/14600 [31:32<00:00,  3.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 14600/14600 [31:32<00:00,  3.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 14600/14600 [31:34<00:00,  3.49pipeline/s]Optimization Progress:  99%|█████████▉| 14604/14700 [31:34<00:41,  2.30pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14604/14700 [31:34<00:41,  2.30pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14605/14700 [31:34<00:41,  2.30pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14606/14700 [31:34<00:40,  2.30pipeline/s]Optimization Progress:  99%|█████████▉| 14608/14700 [31:40<01:11,  1.29pipeline/s]Optimization Progress: 100%|█████████▉| 14688/14700 [31:42<00:06,  1.81pipeline/s]
Generation 146 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14700/14700 [31:42<00:00,  1.81pipeline/s]Optimization Progress: 100%|██████████| 14700/14700 [31:42<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 14700/14700 [31:43<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 14700/14700 [31:43<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 14700/14700 [31:43<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14700/14700 [31:44<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 14700/14700 [31:46<00:00,  2.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14704/14800 [31:46<00:37,  2.57pipeline/s]Optimization Progress:  99%|█████████▉| 14705/14800 [31:46<00:47,  1.98pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14705/14800 [31:46<00:47,  1.98pipeline/s]Optimization Progress:  99%|█████████▉| 14706/14800 [32:00<00:47,  1.98pipeline/s]Optimization Progress:  99%|█████████▉| 14707/14800 [32:01<03:54,  2.52s/pipeline]Optimization Progress: 100%|█████████▉| 14787/14800 [32:03<00:23,  1.78s/pipeline]
Generation 147 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14800/14800 [32:04<00:00,  1.78s/pipeline]Optimization Progress: 100%|██████████| 14800/14800 [32:04<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:13:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14800/14800 [32:04<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 14800/14800 [32:06<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:13:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 14800/14800 [32:06<00:00,  1.27s/pipeline]Optimization Progress:  99%|█████████▉| 14803/14900 [32:07<01:52,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14803/14900 [32:07<01:52,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14804/14900 [32:07<01:51,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14805/14900 [32:07<01:50,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14806/14900 [32:07<01:49,  1.16s/pipeline]Optimization Progress:  99%|█████████▉| 14808/14900 [32:12<01:43,  1.12s/pipeline]Optimization Progress: 100%|█████████▉| 14888/14900 [32:15<00:09,  1.26pipeline/s]
Generation 148 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 14900/14900 [32:15<00:00,  1.26pipeline/s]Optimization Progress: 100%|██████████| 14900/14900 [32:15<00:00,  1.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 14900/14900 [32:17<00:00,  1.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14900/14900 [32:18<00:00,  1.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 14900/14900 [32:18<00:00,  1.74pipeline/s]Optimization Progress:  99%|█████████▉| 14904/15000 [32:19<01:01,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14904/15000 [32:19<01:01,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14905/15000 [32:19<01:00,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14906/15000 [32:19<00:59,  1.57pipeline/s]Optimization Progress:  99%|█████████▉| 14908/15000 [32:22<01:07,  1.36pipeline/s]Optimization Progress: 100%|█████████▉| 14988/15000 [32:26<00:06,  1.89pipeline/s]
Generation 149 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15000/15000 [32:27<00:00,  1.89pipeline/s]Optimization Progress: 100%|██████████| 15000/15000 [32:27<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 15000/15000 [32:27<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15000/15000 [32:27<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:13:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15000/15000 [32:28<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15000/15000 [32:28<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:13:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15000/15000 [32:28<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15000/15000 [32:28<00:00,  2.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15000/15100 [32:30<00:39,  2.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15001/15100 [32:30<00:38,  2.56pipeline/s]Optimization Progress:  99%|█████████▉| 15002/15100 [32:30<01:13,  1.34pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15002/15100 [32:30<01:13,  1.34pipeline/s]Optimization Progress:  99%|█████████▉| 15004/15100 [32:37<02:29,  1.55s/pipeline]Optimization Progress: 100%|█████████▉| 15084/15100 [32:40<00:17,  1.10s/pipeline]
Generation 150 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15100/15100 [32:40<00:00,  1.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15100/15100 [32:40<00:00,  1.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:14:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15100/15100 [32:40<00:00,  1.10s/pipeline]Optimization Progress: 100%|██████████| 15100/15100 [32:40<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15100/15100 [32:40<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 15100/15100 [32:41<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 15100/15100 [32:42<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:14:08] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15100/15100 [32:42<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 15100/15100 [32:42<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15100/15100 [32:43<00:00,  1.28pipeline/s]Optimization Progress:  99%|█████████▉| 15103/15200 [32:43<01:19,  1.23pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15103/15200 [32:43<01:19,  1.23pipeline/s]Optimization Progress:  99%|█████████▉| 15105/15200 [32:52<03:06,  1.96s/pipeline]Optimization Progress: 100%|█████████▉| 15185/15200 [32:54<00:20,  1.38s/pipeline]
Generation 151 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15200/15200 [32:54<00:00,  1.38s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 15200/15200 [32:54<00:00,  1.38s/pipeline]Optimization Progress: 100%|██████████| 15200/15200 [32:54<00:00,  1.03pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15200/15200 [32:54<00:00,  1.03pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:14:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15200/15200 [32:55<00:00,  1.03pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:14:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15200/15200 [32:55<00:00,  1.03pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15200/15200 [32:55<00:00,  1.03pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15200/15200 [32:56<00:00,  1.03pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15200/15200 [32:56<00:00,  1.03pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15203/15300 [32:57<01:33,  1.03pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15204/15300 [32:57<01:32,  1.03pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15205/15300 [32:57<01:31,  1.03pipeline/s]Optimization Progress:  99%|█████████▉| 15206/15300 [32:57<01:21,  1.16pipeline/s]Optimization Progress:  99%|█████████▉| 15210/15300 [33:01<01:22,  1.10pipeline/s]Optimization Progress: 100%|█████████▉| 15287/15300 [33:04<00:08,  1.54pipeline/s]
Generation 152 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 15300/15300 [33:05<00:00,  1.54pipeline/s]Optimization Progress: 100%|██████████| 15300/15300 [33:05<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 15300/15300 [33:05<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15300/15300 [33:05<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:14:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15300/15300 [33:05<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 15300/15300 [33:06<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15300/15300 [33:06<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 15300/15300 [33:06<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:14:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15300/15300 [33:07<00:00,  2.11pipeline/s]Optimization Progress:  99%|█████████▉| 15303/15400 [33:07<00:51,  1.88pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15303/15400 [33:07<00:51,  1.88pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15304/15400 [33:07<00:50,  1.88pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15305/15400 [33:07<00:50,  1.88pipeline/s]Optimization Progress:  99%|█████████▉| 15307/15400 [33:11<01:02,  1.49pipeline/s]Optimization Progress: 100%|█████████▉| 15387/15400 [33:13<00:06,  2.09pipeline/s]
Generation 153 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 15400/15400 [33:13<00:00,  2.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 15400/15400 [33:15<00:00,  2.09pipeline/s]Optimization Progress: 100%|██████████| 15400/15400 [33:15<00:00,  2.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15400/15400 [33:15<00:00,  2.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:14:42] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15400/15400 [33:16<00:00,  2.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15400/15400 [33:16<00:00,  2.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 15400/15400 [33:17<00:00,  2.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 15400/15400 [33:17<00:00,  2.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 15400/15400 [33:17<00:00,  2.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15400/15400 [33:17<00:00,  2.58pipeline/s]Optimization Progress:  99%|█████████▉| 15404/15500 [33:17<00:39,  2.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15404/15500 [33:17<00:39,  2.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15405/15500 [33:17<00:39,  2.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15406/15500 [33:17<00:39,  2.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15407/15500 [33:17<00:38,  2.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15408/15500 [33:17<00:38,  2.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15409/15500 [33:17<00:37,  2.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15410/15500 [33:17<00:37,  2.40pipeline/s]Optimization Progress:  99%|█████████▉| 15411/15500 [33:30<00:37,  2.40pipeline/s]Optimization Progress:  99%|█████████▉| 15412/15500 [33:38<01:33,  1.06s/pipeline]Optimization Progress: 100%|█████████▉| 15492/15500 [33:40<00:05,  1.33pipeline/s]
Generation 154 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 15500/15500 [33:40<00:00,  1.33pipeline/s]Optimization Progress: 100%|██████████| 15500/15500 [33:40<00:00,  1.86pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 15500/15500 [33:41<00:00,  1.86pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:08] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15500/15500 [33:42<00:00,  1.86pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:08] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15500/15500 [33:42<00:00,  1.86pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 15500/15500 [33:42<00:00,  1.86pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15500/15500 [33:43<00:00,  1.86pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15500/15500 [33:43<00:00,  1.86pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15501/15600 [33:44<00:53,  1.86pipeline/s]Optimization Progress:  99%|█████████▉| 15502/15600 [33:44<01:23,  1.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15502/15600 [33:44<01:23,  1.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15503/15600 [33:44<01:23,  1.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15504/15600 [33:44<01:22,  1.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15505/15600 [33:44<01:21,  1.17pipeline/s]Optimization Progress:  99%|█████████▉| 15507/15600 [33:52<01:40,  1.08s/pipeline]Optimization Progress: 100%|█████████▉| 15587/15600 [33:55<00:09,  1.30pipeline/s]
Generation 155 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15600/15600 [33:55<00:00,  1.30pipeline/s]Optimization Progress: 100%|██████████| 15600/15600 [33:55<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15600/15600 [33:55<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15600/15600 [33:55<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15600/15600 [33:55<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 15600/15600 [33:56<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15600/15600 [33:56<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 15600/15600 [33:57<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15600/15600 [33:58<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15600/15600 [33:59<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 15600/15600 [33:59<00:00,  1.82pipeline/s]Optimization Progress:  99%|█████████▉| 15602/15700 [33:59<01:31,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15602/15700 [33:59<01:31,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15603/15700 [33:59<01:30,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15604/15700 [33:59<01:29,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15605/15700 [33:59<01:29,  1.07pipeline/s]Optimization Progress:  99%|█████████▉| 15607/15700 [34:09<01:57,  1.27s/pipeline]Optimization Progress: 100%|█████████▉| 15687/15700 [34:11<00:11,  1.12pipeline/s]
Generation 156 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 15700/15700 [34:12<00:00,  1.12pipeline/s]Optimization Progress: 100%|██████████| 15700/15700 [34:12<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15700/15700 [34:12<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15700/15700 [34:13<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 15700/15700 [34:13<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 15700/15700 [34:13<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15700/15700 [34:13<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 15700/15700 [34:13<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15700/15700 [34:14<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 15700/15700 [34:14<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 15700/15700 [34:14<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15700/15700 [34:14<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15700/15700 [34:14<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15700/15700 [34:14<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15700/15700 [34:15<00:00,  1.58pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15700/15700 [34:15<00:00,  1.58pipeline/s]Optimization Progress:  99%|█████████▉| 15703/15800 [34:15<01:15,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15703/15800 [34:15<01:15,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15704/15800 [34:15<01:14,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15705/15800 [34:15<01:13,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15706/15800 [34:15<01:13,  1.29pipeline/s]Optimization Progress:  99%|█████████▉| 15708/15800 [34:19<01:13,  1.24pipeline/s]Optimization Progress: 100%|█████████▉| 15788/15800 [34:22<00:06,  1.75pipeline/s]
Generation 157 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 15800/15800 [34:22<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15800/15800 [34:22<00:00,  1.75pipeline/s]Optimization Progress: 100%|██████████| 15800/15800 [34:22<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15800/15800 [34:22<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15800/15800 [34:22<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15800/15800 [34:22<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15800/15800 [34:23<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 15800/15800 [34:23<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 15800/15800 [34:24<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15800/15800 [34:24<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:15:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15800/15800 [34:24<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 15800/15800 [34:24<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 15800/15800 [34:25<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15800/15800 [34:25<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:15:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15800/15800 [34:25<00:00,  2.42pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15800/15800 [34:26<00:00,  2.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15802/15900 [34:26<00:40,  2.42pipeline/s]Optimization Progress:  99%|█████████▉| 15803/15900 [34:26<01:05,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15803/15900 [34:26<01:05,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15804/15900 [34:26<01:04,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15805/15900 [34:26<01:04,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15806/15900 [34:26<01:03,  1.48pipeline/s]Optimization Progress:  99%|█████████▉| 15808/15900 [34:31<01:11,  1.29pipeline/s]Optimization Progress: 100%|█████████▉| 15888/15900 [34:36<00:06,  1.78pipeline/s]
Generation 158 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 15900/15900 [34:36<00:00,  1.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15900/15900 [34:36<00:00,  1.78pipeline/s]Optimization Progress: 100%|██████████| 15900/15900 [34:36<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 15900/15900 [34:37<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:16:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 15900/15900 [34:37<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 15900/15900 [34:38<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15900/15900 [34:38<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 15900/15900 [34:38<00:00,  2.49pipeline/s]Optimization Progress:  99%|█████████▉| 15903/16000 [34:39<00:51,  1.87pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15903/16000 [34:39<00:51,  1.87pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15904/16000 [34:39<00:51,  1.87pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15905/16000 [34:39<00:50,  1.87pipeline/s]Optimization Progress:  99%|█████████▉| 15907/16000 [34:43<01:01,  1.52pipeline/s]Optimization Progress: 100%|█████████▉| 15987/16000 [34:46<00:06,  2.11pipeline/s]
Generation 159 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-170344760.48344162	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16000/16000 [34:46<00:00,  2.11pipeline/s]Optimization Progress: 100%|██████████| 16000/16000 [34:46<00:00,  2.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 16000/16000 [34:47<00:00,  2.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16000/16000 [34:47<00:00,  2.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 16000/16000 [34:47<00:00,  2.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16000/16000 [34:47<00:00,  2.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 16000/16000 [34:48<00:00,  2.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:16:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16000/16000 [34:48<00:00,  2.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16000/16000 [34:49<00:00,  2.95pipeline/s]Optimization Progress:  99%|█████████▉| 16006/16100 [34:49<00:34,  2.70pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16006/16100 [34:49<00:34,  2.70pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16007/16100 [34:49<00:34,  2.70pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16008/16100 [34:49<00:34,  2.70pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16009/16100 [34:49<00:33,  2.70pipeline/s]Optimization Progress:  99%|█████████▉| 16011/16100 [34:52<00:41,  2.13pipeline/s]Optimization Progress: 100%|█████████▉| 16091/16100 [34:53<00:02,  3.02pipeline/s]
Generation 160 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16100/16100 [34:54<00:00,  3.02pipeline/s]Optimization Progress: 100%|██████████| 16100/16100 [34:54<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:16:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16100/16100 [34:54<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:16:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16100/16100 [34:54<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16100/16100 [34:54<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16100/16100 [34:55<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:16:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16100/16100 [34:55<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16100/16100 [34:55<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16100/16100 [34:56<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:16:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16100/16100 [34:57<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16100/16100 [34:57<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 [11:16:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16100/16100 [34:57<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16100/16100 [34:57<00:00,  3.95pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16100/16100 [34:57<00:00,  3.95pipeline/s]Optimization Progress:  99%|█████████▉| 16103/16200 [34:58<00:55,  1.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16103/16200 [34:58<00:55,  1.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16104/16200 [34:58<00:54,  1.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16105/16200 [34:58<00:53,  1.76pipeline/s]Optimization Progress:  99%|█████████▉| 16107/16200 [35:03<01:12,  1.28pipeline/s]Optimization Progress: 100%|█████████▉| 16187/16200 [35:07<00:07,  1.79pipeline/s]
Generation 161 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16200/16200 [35:07<00:00,  1.79pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 16200/16200 [35:08<00:00,  1.79pipeline/s]Optimization Progress: 100%|██████████| 16200/16200 [35:08<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16200/16200 [35:09<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16200/16200 [35:09<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:16:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16200/16200 [35:09<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16200/16200 [35:10<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 16200/16200 [35:10<00:00,  2.43pipeline/s]Optimization Progress:  99%|█████████▉| 16203/16300 [35:10<00:50,  1.94pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16203/16300 [35:10<00:50,  1.94pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16204/16300 [35:10<00:49,  1.94pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16205/16300 [35:10<00:48,  1.94pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16206/16300 [35:10<00:48,  1.94pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16207/16300 [35:10<00:47,  1.94pipeline/s]Optimization Progress:  99%|█████████▉| 16209/16300 [35:17<01:06,  1.38pipeline/s]Optimization Progress: 100%|█████████▉| 16289/16300 [35:20<00:05,  1.93pipeline/s]
Generation 162 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:16:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16300/16300 [35:21<00:00,  1.93pipeline/s]Optimization Progress: 100%|██████████| 16300/16300 [35:21<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 16300/16300 [35:21<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 16300/16300 [35:22<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16300/16300 [35:22<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 16300/16300 [35:22<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 16300/16300 [35:22<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16300/16300 [35:24<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16300/16300 [35:24<00:00,  2.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16301/16400 [35:24<00:38,  2.56pipeline/s]Optimization Progress:  99%|█████████▉| 16302/16400 [35:24<01:14,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16302/16400 [35:24<01:14,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16303/16400 [35:24<01:13,  1.31pipeline/s]Optimization Progress:  99%|█████████▉| 16305/16400 [35:30<01:47,  1.13s/pipeline]Optimization Progress: 100%|█████████▉| 16385/16400 [35:32<00:11,  1.25pipeline/s]
Generation 163 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 16400/16400 [35:33<00:00,  1.25pipeline/s]Optimization Progress: 100%|██████████| 16400/16400 [35:33<00:00,  1.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 16400/16400 [35:33<00:00,  1.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 16400/16400 [35:33<00:00,  1.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16400/16400 [35:34<00:00,  1.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16400/16400 [35:35<00:00,  1.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 16400/16400 [35:35<00:00,  1.78pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 16400/16400 [35:35<00:00,  1.78pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16401/16500 [35:36<00:55,  1.78pipeline/s]Optimization Progress:  99%|█████████▉| 16402/16500 [35:50<00:55,  1.78pipeline/s]Optimization Progress:  99%|█████████▉| 16403/16500 [35:50<03:24,  2.11s/pipeline]Optimization Progress: 100%|█████████▉| 16483/16500 [35:53<00:25,  1.49s/pipeline]
Generation 164 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16500/16500 [35:53<00:00,  1.49s/pipeline]Optimization Progress: 100%|██████████| 16500/16500 [35:53<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16500/16500 [35:54<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:17:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16500/16500 [35:54<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16500/16500 [35:54<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16500/16500 [35:55<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16500/16500 [35:56<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 16500/16500 [35:56<00:00,  1.05s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16500/16600 [35:56<01:45,  1.05s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16501/16600 [35:56<01:44,  1.05s/pipeline]Optimization Progress:  99%|█████████▉| 16502/16600 [35:56<02:02,  1.25s/pipeline]Optimization Progress:  99%|█████████▉| 16504/16600 [36:03<02:56,  1.84s/pipeline]Optimization Progress: 100%|█████████▉| 16583/16600 [36:12<00:22,  1.32s/pipeline]
Generation 165 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 16600/16600 [36:13<00:00,  1.32s/pipeline]Optimization Progress: 100%|██████████| 16600/16600 [36:13<00:00,  1.06pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 16600/16600 [36:14<00:00,  1.06pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16600/16600 [36:14<00:00,  1.06pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 16600/16600 [36:15<00:00,  1.06pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 16600/16600 [36:15<00:00,  1.06pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 16600/16600 [36:15<00:00,  1.06pipeline/s]Optimization Progress:  99%|█████████▉| 16603/16700 [36:16<01:30,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16603/16700 [36:16<01:30,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16604/16700 [36:16<01:29,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16605/16700 [36:16<01:28,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16606/16700 [36:16<01:27,  1.07pipeline/s]Optimization Progress:  99%|█████████▉| 16608/16700 [36:22<01:34,  1.03s/pipeline]Optimization Progress: 100%|█████████▉| 16688/16700 [36:24<00:08,  1.37pipeline/s]
Generation 166 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 16700/16700 [36:24<00:00,  1.37pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16700/16700 [36:25<00:00,  1.37pipeline/s]Optimization Progress: 100%|██████████| 16700/16700 [36:25<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 16700/16700 [36:25<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16700/16700 [36:25<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16700/16700 [36:25<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16700/16700 [36:26<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 16700/16700 [36:26<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16700/16700 [36:26<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16700/16700 [36:26<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:17:53] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16700/16700 [36:26<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 16700/16700 [36:27<00:00,  1.93pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 16700/16700 [36:27<00:00,  1.93pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16701/16800 [36:28<00:51,  1.93pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16702/16800 [36:28<00:50,  1.93pipeline/s]Optimization Progress:  99%|█████████▉| 16703/16800 [36:28<01:07,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16703/16800 [36:28<01:07,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16704/16800 [36:28<01:06,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16705/16800 [36:28<01:05,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16706/16800 [36:28<01:05,  1.45pipeline/s]Optimization Progress:  99%|█████████▉| 16708/16800 [36:32<01:09,  1.32pipeline/s]Optimization Progress: 100%|█████████▉| 16788/16800 [36:35<00:06,  1.86pipeline/s]
Generation 167 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16800/16800 [36:35<00:00,  1.86pipeline/s]Optimization Progress: 100%|██████████| 16800/16800 [36:35<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16800/16800 [36:36<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16800/16800 [36:37<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16800/16800 [36:38<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 16800/16800 [36:38<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 16800/16800 [36:38<00:00,  2.60pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16802/16900 [36:39<00:37,  2.60pipeline/s]Optimization Progress:  99%|█████████▉| 16803/16900 [36:39<00:57,  1.70pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16803/16900 [36:39<00:57,  1.70pipeline/s]Optimization Progress:  99%|█████████▉| 16805/16900 [36:42<01:34,  1.00pipeline/s]Optimization Progress: 100%|█████████▉| 16885/16900 [36:46<00:10,  1.41pipeline/s]
Generation 168 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 16900/16900 [36:46<00:00,  1.41pipeline/s]Optimization Progress: 100%|██████████| 16900/16900 [36:46<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16900/16900 [36:46<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16900/16900 [36:46<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16900/16900 [36:47<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 16900/16900 [36:47<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16900/16900 [36:48<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:18:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 16900/16900 [36:48<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 16900/16900 [36:49<00:00,  1.99pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16900/17000 [36:49<00:50,  1.99pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16901/17000 [36:49<00:49,  1.99pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16902/17000 [36:49<00:49,  1.99pipeline/s]Optimization Progress:  99%|█████████▉| 16903/17000 [36:49<01:05,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16903/17000 [36:49<01:05,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16904/17000 [36:49<01:04,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16905/17000 [36:49<01:04,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16906/17000 [36:49<01:03,  1.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16907/17000 [36:49<01:02,  1.48pipeline/s]Optimization Progress:  99%|█████████▉| 16909/17000 [36:54<01:06,  1.37pipeline/s]Optimization Progress: 100%|█████████▉| 16989/17000 [36:57<00:05,  1.92pipeline/s]
Generation 169 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 17000/17000 [36:58<00:00,  1.92pipeline/s]Optimization Progress: 100%|██████████| 17000/17000 [36:58<00:00,  2.65pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 17000/17000 [36:58<00:00,  2.65pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:18:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17000/17000 [37:00<00:00,  2.65pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17000/17000 [37:00<00:00,  2.65pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17000/17000 [37:00<00:00,  2.65pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:18:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17000/17000 [37:00<00:00,  2.65pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 17000/17000 [37:00<00:00,  2.65pipeline/s]Optimization Progress:  99%|█████████▉| 17002/17100 [37:00<01:00,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17002/17100 [37:00<01:00,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17003/17100 [37:00<01:00,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17004/17100 [37:00<00:59,  1.61pipeline/s]Optimization Progress:  99%|█████████▉| 17006/17100 [37:04<01:05,  1.43pipeline/s]Optimization Progress: 100%|█████████▉| 17086/17100 [37:06<00:07,  2.00pipeline/s]
Generation 170 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 17100/17100 [37:07<00:00,  2.00pipeline/s]Optimization Progress: 100%|██████████| 17100/17100 [37:07<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 17100/17100 [37:07<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17100/17100 [37:07<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:18:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17100/17100 [37:07<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17100/17100 [37:07<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:18:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17100/17100 [37:07<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17100/17100 [37:08<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 17100/17100 [37:08<00:00,  2.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:18:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17100/17100 [37:09<00:00,  2.83pipeline/s]Optimization Progress:  99%|█████████▉| 17104/17200 [37:09<00:44,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17104/17200 [37:09<00:44,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17105/17200 [37:09<00:44,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17106/17200 [37:09<00:43,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17107/17200 [37:09<00:43,  2.15pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17108/17200 [37:09<00:42,  2.15pipeline/s]Optimization Progress:  99%|█████████▉| 17110/17200 [37:17<01:02,  1.43pipeline/s]Optimization Progress: 100%|█████████▉| 17190/17200 [37:20<00:05,  1.99pipeline/s]
Generation 171 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17200/17200 [37:20<00:00,  1.99pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:18:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17200/17200 [37:21<00:00,  1.99pipeline/s]Optimization Progress: 100%|██████████| 17200/17200 [37:21<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17200/17200 [37:22<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17200/17200 [37:22<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17200/17200 [37:22<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17200/17200 [37:22<00:00,  2.72pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17200/17200 [37:23<00:00,  2.72pipeline/s]Optimization Progress:  99%|█████████▉| 17207/17300 [37:23<00:33,  2.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17207/17300 [37:23<00:33,  2.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17208/17300 [37:23<00:33,  2.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17209/17300 [37:23<00:33,  2.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17210/17300 [37:23<00:32,  2.76pipeline/s]Optimization Progress:  99%|█████████▉| 17212/17300 [37:32<01:10,  1.25pipeline/s]Optimization Progress: 100%|█████████▉| 17292/17300 [37:34<00:04,  1.76pipeline/s]
Generation 172 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 17300/17300 [37:35<00:00,  1.76pipeline/s]Optimization Progress: 100%|██████████| 17300/17300 [37:35<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17300/17300 [37:36<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 17300/17300 [37:36<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 17300/17300 [37:37<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17300/17300 [37:37<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:19:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17300/17300 [37:37<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17300/17300 [37:37<00:00,  2.28pipeline/s]Optimization Progress:  99%|█████████▉| 17306/17400 [37:38<00:41,  2.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17306/17400 [37:38<00:41,  2.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17307/17400 [37:38<00:41,  2.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17308/17400 [37:38<00:40,  2.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17309/17400 [37:38<00:40,  2.25pipeline/s]Optimization Progress:  99%|█████████▉| 17311/17400 [37:46<01:06,  1.33pipeline/s]Optimization Progress: 100%|█████████▉| 17391/17400 [37:47<00:04,  1.87pipeline/s]
Generation 173 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17400/17400 [37:48<00:00,  1.87pipeline/s]Optimization Progress: 100%|██████████| 17400/17400 [37:48<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 17400/17400 [37:48<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17400/17400 [37:48<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 17400/17400 [37:48<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 17400/17400 [37:50<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17400/17400 [37:50<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17400/17400 [37:50<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 17400/17400 [37:51<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17400/17400 [37:51<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17400/17400 [37:51<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 17400/17400 [37:52<00:00,  2.64pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 17400/17400 [37:52<00:00,  2.64pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17403/17500 [37:53<00:36,  2.64pipeline/s]Optimization Progress:  99%|█████████▉| 17404/17500 [37:53<01:00,  1.58pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17404/17500 [37:53<01:00,  1.58pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17405/17500 [37:53<01:00,  1.58pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17406/17500 [37:53<00:59,  1.58pipeline/s]Optimization Progress:  99%|█████████▉| 17408/17500 [37:57<01:10,  1.31pipeline/s]Optimization Progress: 100%|█████████▉| 17488/17500 [38:00<00:06,  1.83pipeline/s]
Generation 174 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17500/17500 [38:00<00:00,  1.83pipeline/s]Optimization Progress: 100%|██████████| 17500/17500 [38:00<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 17500/17500 [38:00<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17500/17500 [38:01<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 17500/17500 [38:01<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:19:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17500/17500 [38:02<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17500/17500 [38:02<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 17500/17500 [38:03<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:19:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17500/17500 [38:04<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17500/17500 [38:04<00:00,  2.54pipeline/s]Optimization Progress:  99%|█████████▉| 17505/17600 [38:04<00:50,  1.88pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17505/17600 [38:04<00:50,  1.88pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17506/17600 [38:04<00:49,  1.88pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17507/17600 [38:04<00:49,  1.88pipeline/s]Optimization Progress:  99%|█████████▉| 17508/17600 [38:20<00:48,  1.88pipeline/s]Optimization Progress:  99%|█████████▉| 17509/17600 [38:24<02:45,  1.82s/pipeline]Optimization Progress: 100%|█████████▉| 17589/17600 [38:25<00:14,  1.28s/pipeline]
Generation 175 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 17600/17600 [38:26<00:00,  1.28s/pipeline]Optimization Progress: 100%|██████████| 17600/17600 [38:26<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17600/17600 [38:26<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17600/17600 [38:26<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17600/17600 [38:26<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:19:53] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17600/17600 [38:26<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:19:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17600/17600 [38:28<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 17600/17600 [38:28<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17600/17600 [38:28<00:00,  1.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 17600/17600 [38:28<00:00,  1.09pipeline/s]Optimization Progress:  99%|█████████▉| 17610/17700 [38:29<01:05,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17610/17700 [38:29<01:05,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17611/17700 [38:29<01:04,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 17612/17700 [38:29<01:03,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 17613/17700 [38:29<01:03,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 17614/17700 [38:29<01:02,  1.38pipeline/s]Optimization Progress: 100%|█████████▉| 17616/17700 [38:33<01:02,  1.35pipeline/s]Optimization Progress: 100%|█████████▉| 17696/17700 [38:35<00:02,  1.91pipeline/s]
Generation 176 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17700/17700 [38:35<00:00,  1.91pipeline/s]Optimization Progress: 100%|██████████| 17700/17700 [38:35<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17700/17700 [38:37<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 17700/17700 [38:37<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17700/17700 [38:38<00:00,  2.56pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:20:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17700/17700 [38:38<00:00,  2.56pipeline/s]Optimization Progress:  99%|█████████▉| 17703/17800 [38:38<00:57,  1.69pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17703/17800 [38:38<00:57,  1.69pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17704/17800 [38:38<00:56,  1.69pipeline/s]Optimization Progress:  99%|█████████▉| 17706/17800 [38:45<01:42,  1.09s/pipeline]Optimization Progress: 100%|█████████▉| 17786/17800 [38:46<00:10,  1.31pipeline/s]
Generation 177 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:20:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17800/17800 [38:47<00:00,  1.31pipeline/s]Optimization Progress: 100%|██████████| 17800/17800 [38:47<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 17800/17800 [38:47<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 17800/17800 [38:47<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 17800/17800 [38:49<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 17800/17800 [38:49<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17800/17800 [38:49<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 17800/17800 [38:49<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:20:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 17800/17800 [38:50<00:00,  1.83pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17801/17900 [38:50<00:54,  1.83pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17802/17900 [38:50<00:53,  1.83pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17803/17900 [38:50<00:52,  1.83pipeline/s]Optimization Progress:  99%|█████████▉| 17804/17900 [38:50<01:01,  1.57pipeline/s]Optimization Progress:  99%|█████████▉| 17807/17900 [38:54<01:18,  1.19pipeline/s]Optimization Progress: 100%|█████████▉| 17885/17900 [38:57<00:09,  1.67pipeline/s]
Generation 178 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17900/17900 [38:58<00:00,  1.67pipeline/s]Optimization Progress: 100%|██████████| 17900/17900 [38:58<00:00,  2.26pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17900/17900 [38:58<00:00,  2.26pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17900/17900 [38:58<00:00,  2.26pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 17900/17900 [38:59<00:00,  2.26pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 17900/17900 [38:59<00:00,  2.26pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 17900/17900 [39:00<00:00,  2.26pipeline/s]Optimization Progress:  99%|█████████▉| 17904/18000 [39:01<00:49,  1.95pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17904/18000 [39:01<00:49,  1.95pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17905/18000 [39:01<00:48,  1.95pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17906/18000 [39:01<00:48,  1.95pipeline/s]Optimization Progress:  99%|█████████▉| 17908/18000 [39:04<00:55,  1.65pipeline/s]Optimization Progress: 100%|█████████▉| 17988/18000 [39:07<00:05,  2.30pipeline/s]
Generation 179 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18000/18000 [39:07<00:00,  2.30pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 18000/18000 [39:07<00:00,  2.30pipeline/s]Optimization Progress: 100%|██████████| 18000/18000 [39:07<00:00,  3.22pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 18000/18000 [39:07<00:00,  3.22pipeline/s]Optimization Progress:  99%|█████████▉| 18004/18100 [39:10<00:46,  2.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18004/18100 [39:10<00:46,  2.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18005/18100 [39:10<00:46,  2.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18006/18100 [39:10<00:45,  2.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18007/18100 [39:10<00:45,  2.05pipeline/s]Optimization Progress:  99%|█████████▉| 18009/18100 [39:24<01:45,  1.16s/pipeline]Optimization Progress: 100%|█████████▉| 18089/18100 [39:28<00:09,  1.21pipeline/s]
Generation 180 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 18100/18100 [39:28<00:00,  1.21pipeline/s]Optimization Progress: 100%|██████████| 18100/18100 [39:28<00:00,  1.71pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 18100/18100 [39:28<00:00,  1.71pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18100/18100 [39:29<00:00,  1.71pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18100/18100 [39:29<00:00,  1.71pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 18100/18100 [39:29<00:00,  1.71pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 18100/18100 [39:30<00:00,  1.71pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:20:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18100/18100 [39:30<00:00,  1.71pipeline/s]Optimization Progress:  99%|█████████▉| 18107/18200 [39:31<00:49,  1.89pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18107/18200 [39:31<00:49,  1.89pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18108/18200 [39:31<00:48,  1.89pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18109/18200 [39:31<00:48,  1.89pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18110/18200 [39:31<00:47,  1.89pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18111/18200 [39:31<00:47,  1.89pipeline/s]Optimization Progress: 100%|█████████▉| 18113/18200 [39:36<00:55,  1.56pipeline/s]Optimization Progress: 100%|█████████▉| 18193/18200 [39:38<00:03,  2.20pipeline/s]
Generation 181 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18200/18200 [39:39<00:00,  2.20pipeline/s]Optimization Progress: 100%|██████████| 18200/18200 [39:39<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18200/18200 [39:39<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18200/18200 [39:39<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18200/18200 [39:39<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18200/18200 [39:39<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18200/18200 [39:39<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18200/18200 [39:40<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 18200/18200 [39:40<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18200/18200 [39:40<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18200/18200 [39:40<00:00,  2.90pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18200/18200 [39:41<00:00,  2.90pipeline/s]Optimization Progress:  99%|█████████▉| 18205/18300 [39:41<00:38,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18205/18300 [39:41<00:38,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18206/18300 [39:41<00:37,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18207/18300 [39:41<00:37,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18208/18300 [39:41<00:37,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18209/18300 [39:41<00:36,  2.48pipeline/s]Optimization Progress: 100%|█████████▉| 18211/18300 [39:46<00:47,  1.89pipeline/s]Optimization Progress: 100%|█████████▉| 18291/18300 [39:47<00:03,  2.68pipeline/s]
Generation 182 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 18300/18300 [39:47<00:00,  2.68pipeline/s]Optimization Progress: 100%|██████████| 18300/18300 [39:47<00:00,  3.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 18300/18300 [39:48<00:00,  3.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18300/18300 [39:48<00:00,  3.60pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18301/18400 [39:50<00:27,  3.60pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18302/18400 [39:50<00:27,  3.60pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18303/18400 [39:50<00:26,  3.60pipeline/s]Optimization Progress:  99%|█████████▉| 18304/18400 [39:50<00:37,  2.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18304/18400 [39:50<00:37,  2.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18305/18400 [39:50<00:37,  2.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18306/18400 [39:50<00:36,  2.56pipeline/s]Optimization Progress: 100%|█████████▉| 18308/18400 [39:54<00:50,  1.83pipeline/s]Optimization Progress: 100%|█████████▉| 18388/18400 [39:57<00:04,  2.54pipeline/s]
Generation 183 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 18400/18400 [39:57<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18400/18400 [39:57<00:00,  2.54pipeline/s]Optimization Progress: 100%|██████████| 18400/18400 [39:57<00:00,  3.55pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18400/18400 [39:57<00:00,  3.55pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 18400/18400 [39:59<00:00,  3.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18400/18500 [40:00<00:28,  3.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18401/18500 [40:00<00:27,  3.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18402/18500 [40:00<00:27,  3.55pipeline/s]Optimization Progress:  99%|█████████▉| 18403/18500 [40:00<00:49,  1.97pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18403/18500 [40:00<00:49,  1.97pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18404/18500 [40:00<00:48,  1.97pipeline/s]Optimization Progress:  99%|█████████▉| 18406/18500 [40:05<01:21,  1.16pipeline/s]Optimization Progress: 100%|█████████▉| 18486/18500 [40:07<00:08,  1.63pipeline/s]
Generation 184 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18500/18500 [40:07<00:00,  1.63pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 18500/18500 [40:08<00:00,  1.63pipeline/s]Optimization Progress: 100%|██████████| 18500/18500 [40:08<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18500/18500 [40:10<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18500/18500 [40:11<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18500/18500 [40:11<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 18500/18500 [40:11<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18500/18500 [40:11<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18500/18500 [40:11<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18500/18500 [40:11<00:00,  2.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 18500/18500 [40:11<00:00,  2.28pipeline/s]Optimization Progress:  99%|█████████▉| 18506/18600 [40:12<00:46,  2.02pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18506/18600 [40:12<00:46,  2.02pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18507/18600 [40:12<00:45,  2.02pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18508/18600 [40:12<00:45,  2.02pipeline/s]Optimization Progress: 100%|█████████▉| 18510/18600 [40:17<01:09,  1.30pipeline/s]Optimization Progress: 100%|█████████▉| 18590/18600 [40:19<00:05,  1.83pipeline/s]
Generation 185 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18600/18600 [40:19<00:00,  1.83pipeline/s]Optimization Progress: 100%|██████████| 18600/18600 [40:19<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18600/18600 [40:20<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18600/18600 [40:20<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 18600/18600 [40:20<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18600/18600 [40:20<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18600/18600 [40:21<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18600/18600 [40:21<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 18600/18600 [40:21<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18600/18600 [40:21<00:00,  2.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18600/18600 [40:22<00:00,  2.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18601/18700 [40:23<00:38,  2.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18602/18700 [40:23<00:38,  2.57pipeline/s]Optimization Progress:  99%|█████████▉| 18603/18700 [40:23<00:57,  1.69pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18603/18700 [40:23<00:57,  1.69pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18604/18700 [40:23<00:56,  1.69pipeline/s]Optimization Progress:  99%|█████████▉| 18606/18700 [40:26<01:06,  1.41pipeline/s]Optimization Progress: 100%|█████████▉| 18686/18700 [40:28<00:07,  1.97pipeline/s]
Generation 186 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18700/18700 [40:28<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18700/18700 [40:28<00:00,  1.97pipeline/s]Optimization Progress: 100%|██████████| 18700/18700 [40:28<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18700/18700 [40:28<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18700/18700 [40:29<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18700/18700 [40:29<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 18700/18700 [40:29<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:21:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18700/18700 [40:29<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18700/18700 [40:30<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18700/18700 [40:30<00:00,  2.80pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18704/18800 [40:32<00:34,  2.80pipeline/s]Optimization Progress:  99%|█████████▉| 18705/18800 [40:32<00:47,  2.00pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18705/18800 [40:32<00:47,  2.00pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18706/18800 [40:32<00:46,  2.00pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18707/18800 [40:32<00:46,  2.00pipeline/s]Optimization Progress: 100%|█████████▉| 18709/18800 [40:44<01:48,  1.19s/pipeline]Optimization Progress: 100%|█████████▉| 18789/18800 [40:46<00:09,  1.19pipeline/s]
Generation 187 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:22:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18800/18800 [40:46<00:00,  1.19pipeline/s]Optimization Progress: 100%|██████████| 18800/18800 [40:46<00:00,  1.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18800/18800 [40:47<00:00,  1.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 18800/18800 [40:47<00:00,  1.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18800/18800 [40:47<00:00,  1.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18800/18800 [40:48<00:00,  1.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 18800/18800 [40:49<00:00,  1.68pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 18800/18800 [40:49<00:00,  1.68pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18801/18900 [40:49<00:58,  1.68pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18802/18900 [40:49<00:58,  1.68pipeline/s]Optimization Progress:  99%|█████████▉| 18803/18900 [40:49<01:10,  1.37pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18803/18900 [40:49<01:10,  1.37pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18804/18900 [40:49<01:10,  1.37pipeline/s]Optimization Progress: 100%|█████████▉| 18806/18900 [40:54<01:35,  1.02s/pipeline]Optimization Progress: 100%|█████████▉| 18886/18900 [40:57<00:10,  1.38pipeline/s]
Generation 188 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 18900/18900 [40:59<00:00,  1.38pipeline/s]Optimization Progress: 100%|██████████| 18900/18900 [40:59<00:00,  1.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18900/18900 [40:59<00:00,  1.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 18900/18900 [40:59<00:00,  1.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 18900/18900 [40:59<00:00,  1.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:22:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 18900/18900 [40:59<00:00,  1.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 18900/18900 [40:59<00:00,  1.80pipeline/s]Optimization Progress:  99%|█████████▉| 18903/19000 [41:01<00:54,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18903/19000 [41:01<00:54,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18904/19000 [41:01<00:54,  1.77pipeline/s]Optimization Progress: 100%|█████████▉| 18906/19000 [41:05<01:13,  1.27pipeline/s]Optimization Progress: 100%|█████████▉| 18986/19000 [41:07<00:07,  1.79pipeline/s]
Generation 189 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:22:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19000/19000 [41:07<00:00,  1.79pipeline/s]Optimization Progress: 100%|██████████| 19000/19000 [41:07<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 19000/19000 [41:07<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19000/19000 [41:07<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 19000/19000 [41:08<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19000/19000 [41:08<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:22:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19000/19000 [41:08<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 19000/19000 [41:09<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:22:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19000/19000 [41:09<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 19000/19000 [41:09<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:22:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19000/19000 [41:09<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 19000/19000 [41:09<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:22:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19000/19000 [41:10<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19000/19000 [41:10<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 19000/19000 [41:10<00:00,  2.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19002/19100 [41:11<00:38,  2.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19003/19100 [41:11<00:38,  2.53pipeline/s]Optimization Progress:  99%|█████████▉| 19004/19100 [41:11<00:52,  1.83pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19004/19100 [41:11<00:52,  1.83pipeline/s]Optimization Progress: 100%|█████████▉| 19005/19100 [41:30<00:51,  1.83pipeline/s]Optimization Progress: 100%|█████████▉| 19006/19100 [41:36<06:36,  4.22s/pipeline]Optimization Progress: 100%|█████████▉| 19086/19100 [41:47<00:41,  3.00s/pipeline]
Generation 190 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 19100/19100 [41:47<00:00,  3.00s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19100/19100 [41:48<00:00,  3.00s/pipeline]Optimization Progress: 100%|██████████| 19100/19100 [41:48<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19100/19100 [41:48<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 19100/19100 [41:48<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19100/19100 [41:48<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19100/19100 [41:49<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19100/19100 [41:49<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 19100/19100 [41:50<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19100/19100 [41:51<00:00,  2.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19100/19100 [41:51<00:00,  2.10s/pipeline]Optimization Progress: 100%|█████████▉| 19106/19200 [41:52<02:36,  1.66s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19106/19200 [41:52<02:36,  1.66s/pipeline]Optimization Progress: 100%|█████████▉| 19108/19200 [41:56<02:50,  1.85s/pipeline]Optimization Progress: 100%|█████████▉| 19188/19200 [41:58<00:15,  1.30s/pipeline]
Generation 191 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19200/19200 [41:58<00:00,  1.30s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19200/19200 [41:59<00:00,  1.30s/pipeline]Optimization Progress: 100%|██████████| 19200/19200 [41:59<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 19200/19200 [41:59<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19200/19200 [42:00<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 19200/19200 [42:00<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 19200/19200 [42:00<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19200/19200 [42:00<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 19200/19200 [42:01<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 19200/19200 [42:01<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19200/19200 [42:01<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19200/19200 [42:01<00:00,  1.08pipeline/s]Optimization Progress:  99%|█████████▉| 19203/19300 [42:02<01:32,  1.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19203/19300 [42:02<01:32,  1.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19204/19300 [42:02<01:31,  1.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19205/19300 [42:02<01:30,  1.05pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19206/19300 [42:02<01:29,  1.05pipeline/s]Optimization Progress: 100%|█████████▉| 19208/19300 [42:06<01:23,  1.10pipeline/s]Optimization Progress: 100%|█████████▉| 19288/19300 [42:08<00:07,  1.55pipeline/s]
Generation 192 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19300/19300 [42:09<00:00,  1.55pipeline/s]Optimization Progress: 100%|██████████| 19300/19300 [42:09<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19300/19300 [42:10<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19300/19300 [42:10<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19300/19300 [42:10<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 19300/19300 [42:11<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19300/19300 [42:11<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19300/19300 [42:11<00:00,  2.18pipeline/s]Optimization Progress: 100%|█████████▉| 19304/19400 [42:12<00:53,  1.81pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19304/19400 [42:12<00:53,  1.81pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19305/19400 [42:12<00:52,  1.81pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19306/19400 [42:12<00:52,  1.81pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19307/19400 [42:12<00:51,  1.81pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19308/19400 [42:12<00:50,  1.81pipeline/s]Optimization Progress: 100%|█████████▉| 19310/19400 [42:17<01:00,  1.49pipeline/s]Optimization Progress: 100%|█████████▉| 19390/19400 [42:19<00:04,  2.12pipeline/s]
Generation 193 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19400/19400 [42:20<00:00,  2.12pipeline/s]Optimization Progress: 100%|██████████| 19400/19400 [42:20<00:00,  2.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 19400/19400 [42:21<00:00,  2.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 19400/19400 [42:21<00:00,  2.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19400/19400 [42:22<00:00,  2.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 19400/19400 [42:22<00:00,  2.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19400/19400 [42:22<00:00,  2.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 19400/19400 [42:22<00:00,  2.74pipeline/s]Optimization Progress: 100%|█████████▉| 19406/19500 [42:23<00:38,  2.44pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19406/19500 [42:23<00:38,  2.44pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19407/19500 [42:23<00:38,  2.44pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19408/19500 [42:23<00:37,  2.44pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19409/19500 [42:23<00:37,  2.44pipeline/s]Optimization Progress: 100%|█████████▉| 19411/19500 [42:29<01:00,  1.47pipeline/s]Optimization Progress: 100%|█████████▉| 19491/19500 [42:32<00:04,  2.06pipeline/s]
Generation 194 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19500/19500 [42:32<00:00,  2.06pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19500/19500 [42:32<00:00,  2.06pipeline/s]Optimization Progress: 100%|██████████| 19500/19500 [42:32<00:00,  2.76pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 19500/19500 [42:32<00:00,  2.76pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:23:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19500/19500 [42:33<00:00,  2.76pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19500/19500 [42:33<00:00,  2.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19500/19600 [42:34<00:36,  2.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19501/19600 [42:34<00:35,  2.76pipeline/s]Optimization Progress: 100%|█████████▉| 19502/19600 [42:34<00:56,  1.73pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19502/19600 [42:34<00:56,  1.73pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19503/19600 [42:34<00:55,  1.73pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19504/19600 [42:34<00:55,  1.73pipeline/s]Optimization Progress: 100%|█████████▉| 19506/19600 [42:39<01:12,  1.29pipeline/s]Optimization Progress: 100%|█████████▉| 19586/19600 [42:46<00:07,  1.77pipeline/s]
Generation 195 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19600/19600 [42:46<00:00,  1.77pipeline/s]Optimization Progress: 100%|██████████| 19600/19600 [42:46<00:00,  2.46pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19600/19600 [42:46<00:00,  2.46pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19600/19600 [42:47<00:00,  2.46pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 19600/19600 [42:48<00:00,  2.46pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 19600/19600 [42:48<00:00,  2.46pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19600/19600 [42:48<00:00,  2.46pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 19600/19600 [42:49<00:00,  2.46pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19601/19700 [42:50<00:40,  2.46pipeline/s]Optimization Progress: 100%|█████████▉| 19602/19700 [42:50<01:20,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19602/19700 [42:50<01:20,  1.21pipeline/s]Optimization Progress: 100%|█████████▉| 19604/19700 [42:55<02:07,  1.33s/pipeline]Optimization Progress: 100%|█████████▉| 19684/19700 [42:59<00:15,  1.06pipeline/s]
Generation 196 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 19700/19700 [43:00<00:00,  1.06pipeline/s]Optimization Progress: 100%|██████████| 19700/19700 [43:00<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:24:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19700/19700 [43:00<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 19700/19700 [43:00<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:24:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19700/19700 [43:00<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 19700/19700 [43:00<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19700/19700 [43:01<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 19700/19700 [43:02<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 19700/19700 [43:02<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:24:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19700/19700 [43:03<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 19700/19700 [43:03<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19700/19700 [43:03<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19700/19700 [43:03<00:00,  1.49pipeline/s]Optimization Progress: 100%|█████████▉| 19703/19800 [43:03<01:21,  1.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19703/19800 [43:03<01:21,  1.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19704/19800 [43:03<01:20,  1.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19705/19800 [43:03<01:19,  1.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19706/19800 [43:03<01:18,  1.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19707/19800 [43:03<01:17,  1.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19708/19800 [43:03<01:16,  1.20pipeline/s]Optimization Progress: 100%|█████████▉| 19710/19800 [43:09<01:16,  1.18pipeline/s]Optimization Progress: 100%|█████████▉| 19790/19800 [43:13<00:06,  1.65pipeline/s]
Generation 197 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19800/19800 [43:13<00:00,  1.65pipeline/s]Optimization Progress: 100%|██████████| 19800/19800 [43:13<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 19800/19800 [43:14<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19800/19800 [43:14<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 19800/19800 [43:14<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19800/19800 [43:14<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 19800/19800 [43:15<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:24:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19800/19800 [43:15<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 19800/19800 [43:16<00:00,  2.29pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:24:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19800/19800 [43:17<00:00,  2.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19801/19900 [43:17<00:43,  2.29pipeline/s]Optimization Progress: 100%|█████████▉| 19802/19900 [43:17<01:22,  1.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19802/19900 [43:17<01:22,  1.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19803/19900 [43:17<01:21,  1.19pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19804/19900 [43:17<01:20,  1.19pipeline/s]Optimization Progress: 100%|█████████▉| 19806/19900 [43:21<01:25,  1.10pipeline/s]Optimization Progress: 100%|█████████▉| 19886/19900 [43:24<00:09,  1.55pipeline/s]
Generation 198 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:24:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19900/19900 [43:25<00:00,  1.55pipeline/s]Optimization Progress: 100%|██████████| 19900/19900 [43:25<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 19900/19900 [43:25<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:24:53] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 19900/19900 [43:26<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 19900/19900 [43:27<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 19900/19900 [43:27<00:00,  2.17pipeline/s]Optimization Progress: 100%|█████████▉| 19903/20000 [43:28<01:01,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19903/20000 [43:28<01:01,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19904/20000 [43:28<01:01,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19905/20000 [43:28<01:00,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19906/20000 [43:28<00:59,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19907/20000 [43:28<00:59,  1.57pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19908/20000 [43:28<00:58,  1.57pipeline/s]Optimization Progress: 100%|█████████▉| 19910/20000 [43:37<01:16,  1.17pipeline/s]Optimization Progress: 100%|█████████▉| 19990/20000 [43:40<00:06,  1.64pipeline/s]
Generation 199 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:25:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20000/20000 [43:41<00:00,  1.64pipeline/s]Optimization Progress: 100%|██████████| 20000/20000 [43:41<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 20000/20000 [43:43<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20000/20000 [43:43<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 20000/20000 [43:43<00:00,  2.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20001/20100 [43:44<00:44,  2.25pipeline/s]Optimization Progress: 100%|█████████▉| 20002/20100 [43:44<01:12,  1.35pipeline/s]Optimization Progress: 100%|█████████▉| 20004/20100 [43:49<02:06,  1.31s/pipeline]Optimization Progress: 100%|█████████▉| 20083/20100 [44:03<00:16,  1.03pipeline/s]
Generation 200 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 20100/20100 [44:03<00:00,  1.03pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 20100/20100 [44:03<00:00,  1.03pipeline/s]Optimization Progress: 100%|██████████| 20100/20100 [44:03<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20100/20100 [44:04<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 20100/20100 [44:04<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20100/20100 [44:05<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 20100/20100 [44:05<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 20100/20100 [44:05<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:25:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20100/20100 [44:05<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20100/20100 [44:05<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20100/20100 [44:06<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20100/20100 [44:06<00:00,  1.45pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20100/20100 [44:06<00:00,  1.45pipeline/s]Optimization Progress: 100%|█████████▉| 20103/20200 [44:06<01:12,  1.33pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20103/20200 [44:06<01:12,  1.33pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20104/20200 [44:06<01:12,  1.33pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20105/20200 [44:06<01:11,  1.33pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20106/20200 [44:06<01:10,  1.33pipeline/s]Optimization Progress: 100%|█████████▉| 20108/20200 [44:10<01:10,  1.31pipeline/s]Optimization Progress: 100%|█████████▉| 20188/20200 [44:13<00:06,  1.84pipeline/s]
Generation 201 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 20200/20200 [44:14<00:00,  1.84pipeline/s]Optimization Progress: 100%|██████████| 20200/20200 [44:14<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 20200/20200 [44:14<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 20200/20200 [44:14<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:25:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20200/20200 [44:14<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 20200/20200 [44:14<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:25:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20200/20200 [44:15<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float64')..
Optimization Progress: 100%|██████████| 20200/20200 [44:15<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20200/20200 [44:15<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20200/20200 [44:15<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20200/20200 [44:15<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:25:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20200/20200 [44:15<00:00,  2.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 20200/20200 [44:15<00:00,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20200/20300 [44:16<00:40,  2.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20201/20300 [44:16<00:39,  2.49pipeline/s]Optimization Progress: 100%|█████████▉| 20202/20300 [44:16<01:05,  1.49pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20202/20300 [44:16<01:05,  1.49pipeline/s]Optimization Progress: 100%|█████████▉| 20203/20300 [44:30<01:04,  1.49pipeline/s]Optimization Progress: 100%|█████████▉| 20204/20300 [44:30<04:08,  2.59s/pipeline]Optimization Progress: 100%|█████████▉| 20284/20300 [44:33<00:29,  1.82s/pipeline]
Generation 202 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20300/20300 [44:33<00:00,  1.82s/pipeline]Optimization Progress: 100%|██████████| 20300/20300 [44:33<00:00,  1.28s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20300/20300 [44:33<00:00,  1.28s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:26:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20300/20300 [44:35<00:00,  1.28s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 20300/20300 [44:35<00:00,  1.28s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20302/20400 [44:36<02:05,  1.28s/pipeline]Optimization Progress: 100%|█████████▉| 20303/20400 [44:36<01:52,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20303/20400 [44:36<01:52,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20304/20400 [44:36<01:51,  1.16s/pipeline]Optimization Progress: 100%|█████████▉| 20306/20400 [44:45<02:47,  1.78s/pipeline]Optimization Progress: 100%|█████████▉| 20386/20400 [44:49<00:17,  1.26s/pipeline]
Generation 203 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20400/20400 [44:49<00:00,  1.26s/pipeline]Optimization Progress: 100%|██████████| 20400/20400 [44:49<00:00,  1.12pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 20400/20400 [44:49<00:00,  1.12pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 20400/20400 [44:50<00:00,  1.12pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:26:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20400/20400 [44:51<00:00,  1.12pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 20400/20400 [44:52<00:00,  1.12pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 20400/20400 [44:52<00:00,  1.12pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20400/20500 [44:52<01:29,  1.12pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20401/20500 [44:52<01:28,  1.12pipeline/s]Optimization Progress: 100%|█████████▉| 20402/20500 [44:52<01:47,  1.10s/pipeline]Optimization Progress: 100%|█████████▉| 20404/20500 [44:58<02:27,  1.54s/pipeline]Optimization Progress: 100%|█████████▉| 20483/20500 [45:02<00:18,  1.10s/pipeline]
Generation 204 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 20500/20500 [45:02<00:00,  1.10s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20500/20500 [45:03<00:00,  1.10s/pipeline]Optimization Progress: 100%|██████████| 20500/20500 [45:03<00:00,  1.27pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20500/20500 [45:04<00:00,  1.27pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 20500/20500 [45:04<00:00,  1.27pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20500/20500 [45:04<00:00,  1.27pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 20500/20500 [45:04<00:00,  1.27pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20500/20500 [45:05<00:00,  1.27pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 20500/20500 [45:05<00:00,  1.27pipeline/s]Optimization Progress: 100%|█████████▉| 20506/20600 [45:05<01:02,  1.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20506/20600 [45:05<01:02,  1.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20507/20600 [45:05<01:01,  1.50pipeline/s]Optimization Progress: 100%|█████████▉| 20509/20600 [45:11<01:35,  1.05s/pipeline]Optimization Progress: 100%|█████████▉| 20589/20600 [45:14<00:08,  1.34pipeline/s]
Generation 205 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20600/20600 [45:15<00:00,  1.34pipeline/s]Optimization Progress: 100%|██████████| 20600/20600 [45:15<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20600/20600 [45:15<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20600/20600 [45:15<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 20600/20600 [45:15<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20600/20600 [45:16<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20600/20600 [45:16<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20600/20600 [45:17<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20600/20600 [45:17<00:00,  1.89pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:26:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20600/20600 [45:17<00:00,  1.89pipeline/s]Optimization Progress: 100%|█████████▉| 20603/20700 [45:18<01:04,  1.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20603/20700 [45:18<01:04,  1.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20604/20700 [45:18<01:04,  1.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20605/20700 [45:18<01:03,  1.50pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20606/20700 [45:18<01:02,  1.50pipeline/s]Optimization Progress: 100%|█████████▉| 20608/20700 [45:27<01:36,  1.04s/pipeline]Optimization Progress: 100%|█████████▉| 20688/20700 [45:29<00:08,  1.35pipeline/s]
Generation 206 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20700/20700 [45:30<00:00,  1.35pipeline/s]Optimization Progress: 100%|██████████| 20700/20700 [45:30<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20700/20700 [45:32<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20700/20700 [45:32<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 20700/20700 [45:32<00:00,  1.84pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 20700/20700 [45:32<00:00,  1.84pipeline/s]Optimization Progress: 100%|█████████▉| 20707/20800 [45:33<00:45,  2.04pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20707/20800 [45:33<00:45,  2.04pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20708/20800 [45:33<00:45,  2.04pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20709/20800 [45:33<00:44,  2.04pipeline/s]Optimization Progress: 100%|█████████▉| 20710/20800 [45:50<00:44,  2.04pipeline/s]Optimization Progress: 100%|█████████▉| 20711/20800 [45:55<02:56,  1.99s/pipeline]Optimization Progress: 100%|█████████▉| 20791/20800 [45:57<00:12,  1.40s/pipeline]
Generation 207 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 20800/20800 [45:58<00:00,  1.40s/pipeline]Optimization Progress: 100%|██████████| 20800/20800 [45:58<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20800/20800 [45:58<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 20800/20800 [45:58<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 20800/20800 [45:58<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 20800/20800 [46:00<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 20800/20800 [46:01<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 20800/20800 [46:01<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:27:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 20800/20800 [46:01<00:00,  1.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 20800/20800 [46:01<00:00,  1.00pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20801/20900 [46:01<01:38,  1.00pipeline/s]Optimization Progress: 100%|█████████▉| 20802/20900 [46:01<01:58,  1.21s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20802/20900 [46:01<01:58,  1.21s/pipeline]Optimization Progress: 100%|█████████▉| 20804/20900 [46:08<02:51,  1.79s/pipeline]Optimization Progress: 100%|█████████▉| 20884/20900 [46:10<00:20,  1.26s/pipeline]
Generation 208 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 20900/20900 [46:13<00:00,  1.26s/pipeline]Optimization Progress: 100%|██████████| 20900/20900 [46:13<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 20900/20900 [46:13<00:00,  1.08pipeline/s]Optimization Progress: 100%|█████████▉| 20903/21000 [46:14<01:13,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20903/21000 [46:14<01:13,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20904/21000 [46:14<01:13,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20905/21000 [46:14<01:12,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20906/21000 [46:14<01:11,  1.31pipeline/s]Optimization Progress: 100%|█████████▉| 20908/21000 [46:25<01:49,  1.20s/pipeline]Optimization Progress: 100%|█████████▉| 20988/21000 [46:27<00:10,  1.18pipeline/s]
Generation 209 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21000/21000 [46:29<00:00,  1.18pipeline/s]Optimization Progress: 100%|██████████| 21000/21000 [46:29<00:00,  1.59pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21000/21000 [46:29<00:00,  1.59pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 21000/21000 [46:30<00:00,  1.59pipeline/s]Optimization Progress: 100%|█████████▉| 21002/21100 [46:30<01:09,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21002/21100 [46:31<01:09,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21003/21100 [46:31<01:08,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21004/21100 [46:31<01:07,  1.42pipeline/s]Optimization Progress: 100%|█████████▉| 21006/21100 [46:35<01:15,  1.25pipeline/s]Optimization Progress: 100%|█████████▉| 21086/21100 [46:38<00:08,  1.74pipeline/s]
Generation 210 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21100/21100 [46:38<00:00,  1.74pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 21100/21100 [46:38<00:00,  1.74pipeline/s]Optimization Progress: 100%|██████████| 21100/21100 [46:38<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:28:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21100/21100 [46:38<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 21100/21100 [46:39<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:28:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21100/21100 [46:39<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 21100/21100 [46:39<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 21100/21100 [46:39<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21100/21100 [46:39<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 21100/21100 [46:39<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21100/21100 [46:40<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21100/21100 [46:40<00:00,  2.47pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:28:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21100/21100 [46:41<00:00,  2.47pipeline/s]Optimization Progress: 100%|█████████▉| 21104/21200 [46:41<00:48,  1.99pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21104/21200 [46:41<00:48,  1.99pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21105/21200 [46:41<00:47,  1.99pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21106/21200 [46:41<00:47,  1.99pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21107/21200 [46:41<00:46,  1.99pipeline/s]Optimization Progress: 100%|█████████▉| 21109/21200 [46:52<01:29,  1.02pipeline/s]Optimization Progress: 100%|█████████▉| 21189/21200 [46:54<00:07,  1.44pipeline/s]
Generation 211 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:28:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21200/21200 [46:54<00:00,  1.44pipeline/s]Optimization Progress: 100%|██████████| 21200/21200 [46:54<00:00,  2.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:28:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21200/21200 [46:54<00:00,  2.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:28:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21200/21200 [46:55<00:00,  2.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21200/21200 [46:55<00:00,  2.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21200/21200 [46:56<00:00,  2.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 21200/21200 [46:56<00:00,  2.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21200/21200 [46:57<00:00,  2.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 21200/21200 [46:57<00:00,  2.01pipeline/s]Optimization Progress: 100%|█████████▉| 21203/21300 [46:58<01:06,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21203/21300 [46:58<01:06,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21204/21300 [46:58<01:05,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21205/21300 [46:58<01:05,  1.45pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21206/21300 [46:58<01:04,  1.45pipeline/s]Optimization Progress: 100%|█████████▉| 21208/21300 [47:02<01:09,  1.33pipeline/s]Optimization Progress: 100%|█████████▉| 21288/21300 [47:05<00:06,  1.87pipeline/s]
Generation 212 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 21300/21300 [47:05<00:00,  1.87pipeline/s]Optimization Progress: 100%|██████████| 21300/21300 [47:05<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21300/21300 [47:06<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 21300/21300 [47:07<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 21300/21300 [47:07<00:00,  2.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21300/21300 [47:07<00:00,  2.54pipeline/s]Optimization Progress: 100%|█████████▉| 21303/21400 [47:09<01:00,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21303/21400 [47:09<01:00,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21304/21400 [47:09<00:59,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21305/21400 [47:09<00:58,  1.61pipeline/s]Optimization Progress: 100%|█████████▉| 21307/21400 [47:20<01:55,  1.24s/pipeline]Optimization Progress: 100%|█████████▉| 21387/21400 [47:24<00:11,  1.13pipeline/s]
Generation 213 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 21400/21400 [47:25<00:00,  1.13pipeline/s]Optimization Progress: 100%|██████████| 21400/21400 [47:25<00:00,  1.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 21400/21400 [47:25<00:00,  1.54pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21400/21400 [47:27<00:00,  1.54pipeline/s]Optimization Progress: 100%|█████████▉| 21402/21500 [47:27<01:14,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21402/21500 [47:27<01:14,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21403/21500 [47:27<01:13,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21404/21500 [47:27<01:13,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21405/21500 [47:27<01:12,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21406/21500 [47:27<01:11,  1.31pipeline/s]Optimization Progress: 100%|█████████▉| 21408/21500 [47:35<01:26,  1.06pipeline/s]Optimization Progress: 100%|█████████▉| 21488/21500 [47:38<00:07,  1.50pipeline/s]
Generation 214 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 21500/21500 [47:38<00:00,  1.50pipeline/s]Optimization Progress: 100%|██████████| 21500/21500 [47:38<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 21500/21500 [47:38<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 21500/21500 [47:39<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21500/21500 [47:39<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21500/21500 [47:39<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21500/21500 [47:41<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21500/21500 [47:41<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21500/21500 [47:41<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 21500/21500 [47:41<00:00,  2.11pipeline/s]Optimization Progress: 100%|█████████▉| 21504/21600 [47:41<00:54,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21504/21600 [47:41<00:54,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21505/21600 [47:41<00:53,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21506/21600 [47:41<00:53,  1.77pipeline/s]Optimization Progress: 100%|█████████▉| 21507/21600 [48:00<00:52,  1.77pipeline/s]Optimization Progress: 100%|█████████▉| 21508/21600 [48:13<04:16,  2.78s/pipeline]Optimization Progress: 100%|█████████▉| 21588/21600 [48:15<00:23,  1.95s/pipeline]
Generation 215 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 21600/21600 [48:15<00:00,  1.95s/pipeline]Optimization Progress: 100%|██████████| 21600/21600 [48:15<00:00,  1.39s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 21600/21600 [48:15<00:00,  1.39s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 21600/21600 [48:15<00:00,  1.39s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 21600/21600 [48:17<00:00,  1.39s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21600/21600 [48:18<00:00,  1.39s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21600/21600 [48:18<00:00,  1.39s/pipeline]Optimization Progress: 100%|█████████▉| 21602/21700 [48:18<02:20,  1.43s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21602/21700 [48:18<02:20,  1.43s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21603/21700 [48:18<02:18,  1.43s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21604/21700 [48:18<02:17,  1.43s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21605/21700 [48:18<02:15,  1.43s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21606/21700 [48:18<02:14,  1.43s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21607/21700 [48:18<02:13,  1.43s/pipeline]Optimization Progress: 100%|█████████▉| 21609/21700 [48:26<01:59,  1.31s/pipeline]Optimization Progress: 100%|█████████▉| 21689/21700 [48:26<00:10,  1.09pipeline/s]
Generation 216 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:29:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21700/21700 [48:28<00:00,  1.09pipeline/s]Optimization Progress: 100%|██████████| 21700/21700 [48:28<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21700/21700 [48:28<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21700/21700 [48:28<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:29:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21700/21700 [48:28<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:29:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21700/21700 [48:29<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:29:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21700/21700 [48:30<00:00,  1.49pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 21700/21700 [48:30<00:00,  1.49pipeline/s]Optimization Progress: 100%|█████████▉| 21705/21800 [48:30<00:59,  1.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21705/21800 [48:30<00:59,  1.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21706/21800 [48:30<00:59,  1.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21707/21800 [48:30<00:58,  1.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21708/21800 [48:30<00:57,  1.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21709/21800 [48:30<00:57,  1.59pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21710/21800 [48:30<00:56,  1.59pipeline/s]Optimization Progress: 100%|█████████▉| 21712/21800 [48:35<00:58,  1.50pipeline/s]Optimization Progress: 100%|█████████▉| 21792/21800 [48:43<00:03,  2.02pipeline/s]
Generation 217 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21800/21800 [48:44<00:00,  2.02pipeline/s]Optimization Progress: 100%|██████████| 21800/21800 [48:44<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 21800/21800 [48:44<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21800/21800 [48:45<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21800/21800 [48:45<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21800/21800 [48:45<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 21800/21800 [48:46<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 21800/21800 [48:47<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 21800/21800 [48:47<00:00,  2.80pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:30:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21800/21800 [48:47<00:00,  2.80pipeline/s]Optimization Progress: 100%|█████████▉| 21805/21900 [48:47<00:44,  2.14pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21805/21900 [48:47<00:44,  2.14pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21806/21900 [48:47<00:43,  2.14pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21807/21900 [48:47<00:43,  2.14pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21808/21900 [48:47<00:42,  2.14pipeline/s]Optimization Progress: 100%|█████████▉| 21809/21900 [49:00<00:42,  2.14pipeline/s]Optimization Progress: 100%|█████████▉| 21810/21900 [49:19<03:17,  2.20s/pipeline]Optimization Progress: 100%|█████████▉| 21890/21900 [49:20<00:15,  1.54s/pipeline]
Generation 218 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 21900/21900 [49:21<00:00,  1.54s/pipeline]Optimization Progress: 100%|██████████| 21900/21900 [49:21<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:30:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 21900/21900 [49:21<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21900/21900 [49:22<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 21900/21900 [49:22<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 21900/21900 [49:22<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 21900/21900 [49:22<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 21900/21900 [49:22<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 21900/21900 [49:22<00:00,  1.11s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 21900/21900 [49:22<00:00,  1.11s/pipeline]Optimization Progress: 100%|█████████▉| 21902/22000 [49:23<01:43,  1.06s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21902/22000 [49:23<01:43,  1.06s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21903/22000 [49:23<01:42,  1.06s/pipeline]Optimization Progress: 100%|█████████▉| 21905/22000 [49:27<01:47,  1.13s/pipeline]Optimization Progress: 100%|█████████▉| 21985/22000 [49:30<00:12,  1.25pipeline/s]
Generation 219 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22000/22000 [49:31<00:00,  1.25pipeline/s]Optimization Progress: 100%|██████████| 22000/22000 [49:31<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 22000/22000 [49:31<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:30:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22000/22000 [49:31<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22000/22000 [49:31<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:30:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22000/22000 [49:31<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22000/22000 [49:32<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 22000/22000 [49:32<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22000/22000 [49:33<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 22000/22000 [49:33<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22000/22000 [49:34<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22000/22000 [49:34<00:00,  1.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 22000/22000 [49:34<00:00,  1.75pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22001/22100 [49:34<00:56,  1.75pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22002/22100 [49:34<00:55,  1.75pipeline/s]Optimization Progress: 100%|█████████▉| 22003/22100 [49:34<01:12,  1.33pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22003/22100 [49:34<01:12,  1.33pipeline/s]Optimization Progress: 100%|█████████▉| 22005/22100 [49:44<03:14,  2.05s/pipeline]Optimization Progress: 100%|█████████▉| 22085/22100 [49:54<00:22,  1.47s/pipeline]
Generation 220 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 22100/22100 [49:54<00:00,  1.47s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22100/22100 [49:55<00:00,  1.47s/pipeline]Optimization Progress: 100%|██████████| 22100/22100 [49:55<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22100/22100 [49:55<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22100/22100 [49:56<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22100/22100 [49:56<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 22100/22100 [49:57<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22100/22100 [49:57<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 22100/22100 [49:57<00:00,  1.04s/pipeline]Optimization Progress: 100%|█████████▉| 22102/22200 [49:58<02:01,  1.24s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22102/22200 [49:58<02:01,  1.24s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22103/22200 [49:58<02:00,  1.24s/pipeline]Optimization Progress: 100%|█████████▉| 22104/22200 [49:58<01:25,  1.13pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22104/22200 [49:58<01:25,  1.13pipeline/s]Optimization Progress: 100%|█████████▉| 22106/22200 [50:08<03:07,  2.00s/pipeline]Optimization Progress: 100%|█████████▉| 22186/22200 [50:12<00:19,  1.42s/pipeline]
Generation 221 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22200/22200 [50:14<00:00,  1.42s/pipeline]Optimization Progress: 100%|██████████| 22200/22200 [50:14<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22200/22200 [50:15<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22200/22200 [50:16<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22200/22200 [50:16<00:00,  1.05s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22200/22200 [50:16<00:00,  1.05s/pipeline]Optimization Progress: 100%|█████████▉| 22204/22300 [50:16<01:19,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22204/22300 [50:16<01:19,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22205/22300 [50:16<01:18,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22206/22300 [50:16<01:17,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22207/22300 [50:16<01:17,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22208/22300 [50:16<01:16,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22209/22300 [50:16<01:15,  1.21pipeline/s]Optimization Progress: 100%|█████████▉| 22211/22300 [50:24<01:23,  1.06pipeline/s]Optimization Progress: 100%|█████████▉| 22291/22300 [50:33<00:06,  1.45pipeline/s]
Generation 222 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22300/22300 [50:33<00:00,  1.45pipeline/s]Optimization Progress: 100%|██████████| 22300/22300 [50:33<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22300/22300 [50:33<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:32:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22300/22300 [50:34<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22300/22300 [50:35<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:32:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22300/22300 [50:36<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:32:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22300/22300 [50:36<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 22300/22300 [50:36<00:00,  2.00pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 22300/22300 [50:36<00:00,  2.00pipeline/s]Optimization Progress: 100%|█████████▉| 22304/22400 [50:37<00:57,  1.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22304/22400 [50:37<00:57,  1.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22305/22400 [50:37<00:57,  1.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22306/22400 [50:37<00:56,  1.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22307/22400 [50:37<00:56,  1.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22308/22400 [50:37<00:55,  1.66pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22309/22400 [50:37<00:54,  1.66pipeline/s]Optimization Progress: 100%|█████████▉| 22311/22400 [50:41<00:53,  1.67pipeline/s]Optimization Progress: 100%|█████████▉| 22391/22400 [50:44<00:03,  2.33pipeline/s]
Generation 223 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 22400/22400 [50:44<00:00,  2.33pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22400/22400 [50:44<00:00,  2.33pipeline/s]Optimization Progress: 100%|██████████| 22400/22400 [50:44<00:00,  3.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22400/22400 [50:45<00:00,  3.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:32:11] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22400/22400 [50:45<00:00,  3.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22400/22400 [50:46<00:00,  3.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22400/22400 [50:46<00:00,  3.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 22400/22400 [50:46<00:00,  3.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22400/22400 [50:47<00:00,  3.09pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:32:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22400/22400 [50:47<00:00,  3.09pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22401/22500 [50:48<00:32,  3.09pipeline/s]Optimization Progress: 100%|█████████▉| 22402/22500 [50:48<01:06,  1.47pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22402/22500 [50:48<01:06,  1.47pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22403/22500 [50:48<01:06,  1.47pipeline/s]Optimization Progress: 100%|█████████▉| 22405/22500 [51:02<03:02,  1.92s/pipeline]Optimization Progress: 100%|█████████▉| 22485/22500 [51:06<00:20,  1.36s/pipeline]
Generation 224 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 22500/22500 [51:06<00:00,  1.36s/pipeline]Optimization Progress: 100%|██████████| 22500/22500 [51:06<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:32:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22500/22500 [51:08<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 22500/22500 [51:08<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 22500/22500 [51:08<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:32:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22500/22500 [51:08<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22500/22500 [51:08<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22500/22500 [51:08<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:32:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22500/22500 [51:08<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22500/22500 [51:09<00:00,  1.04pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 22500/22500 [51:09<00:00,  1.04pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22500/22600 [51:10<01:35,  1.04pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22501/22600 [51:10<01:34,  1.04pipeline/s]Optimization Progress: 100%|█████████▉| 22502/22600 [51:10<01:54,  1.17s/pipeline]Optimization Progress: 100%|█████████▉| 22504/22600 [51:13<02:06,  1.32s/pipeline]Optimization Progress: 100%|█████████▉| 22583/22600 [51:15<00:15,  1.07pipeline/s]
Generation 225 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 22600/22600 [51:18<00:00,  1.07pipeline/s]Optimization Progress: 100%|██████████| 22600/22600 [51:18<00:00,  1.41pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22600/22600 [51:18<00:00,  1.41pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22600/22600 [51:18<00:00,  1.41pipeline/s]Optimization Progress: 100%|█████████▉| 22604/22700 [51:19<00:52,  1.83pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22604/22700 [51:19<00:52,  1.83pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22605/22700 [51:19<00:51,  1.83pipeline/s]Optimization Progress: 100%|█████████▉| 22607/22700 [51:26<01:40,  1.08s/pipeline]Optimization Progress: 100%|█████████▉| 22687/22700 [51:28<00:09,  1.31pipeline/s]
Generation 226 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22700/22700 [51:28<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22700/22700 [51:28<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 22700/22700 [51:28<00:00,  1.31pipeline/s]Optimization Progress: 100%|██████████| 22700/22700 [51:28<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:32:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22700/22700 [51:28<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 22700/22700 [51:29<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22700/22700 [51:29<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22700/22700 [51:29<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22700/22700 [51:30<00:00,  1.82pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:32:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22700/22700 [51:31<00:00,  1.82pipeline/s]Optimization Progress: 100%|█████████▉| 22704/22800 [51:32<01:02,  1.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22704/22800 [51:32<01:02,  1.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22705/22800 [51:32<01:01,  1.54pipeline/s]Optimization Progress: 100%|█████████▉| 22707/22800 [51:35<01:15,  1.23pipeline/s]Optimization Progress: 100%|█████████▉| 22787/22800 [51:38<00:07,  1.73pipeline/s]
Generation 227 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:33:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 22800/22800 [51:38<00:00,  1.73pipeline/s]Optimization Progress: 100%|██████████| 22800/22800 [51:38<00:00,  2.39pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22800/22800 [51:39<00:00,  2.39pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22800/22800 [51:39<00:00,  2.39pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 22800/22800 [51:39<00:00,  2.39pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 22800/22800 [51:41<00:00,  2.39pipeline/s]Optimization Progress: 100%|█████████▉| 22803/22900 [51:41<00:54,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22803/22900 [51:41<00:54,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22804/22900 [51:41<00:54,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22805/22900 [51:41<00:53,  1.77pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22806/22900 [51:41<00:53,  1.77pipeline/s]Optimization Progress: 100%|█████████▉| 22808/22900 [51:45<00:55,  1.66pipeline/s]Optimization Progress: 100%|█████████▉| 22888/22900 [51:47<00:05,  2.32pipeline/s]
Generation 228 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22900/22900 [51:48<00:00,  2.32pipeline/s]Optimization Progress: 100%|██████████| 22900/22900 [51:48<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 22900/22900 [51:49<00:00,  3.01pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22900/23000 [51:50<00:33,  3.01pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22901/23000 [51:50<00:32,  3.01pipeline/s]Optimization Progress: 100%|█████████▉| 22902/23000 [51:50<00:45,  2.15pipeline/s]Optimization Progress: 100%|█████████▉| 22904/23000 [51:54<01:30,  1.07pipeline/s]Optimization Progress: 100%|█████████▉| 22983/23000 [51:57<00:11,  1.50pipeline/s]
Generation 229 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23000/23000 [51:57<00:00,  1.50pipeline/s]Optimization Progress: 100%|██████████| 23000/23000 [51:57<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 23000/23000 [51:58<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23000/23000 [51:59<00:00,  2.11pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23000/23000 [52:00<00:00,  2.11pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23002/23100 [52:00<00:46,  2.11pipeline/s]Optimization Progress: 100%|█████████▉| 23003/23100 [52:00<01:00,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23003/23100 [52:00<01:00,  1.61pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23004/23100 [52:00<00:59,  1.61pipeline/s]Optimization Progress: 100%|█████████▉| 23006/23100 [52:04<01:21,  1.16pipeline/s]Optimization Progress: 100%|█████████▉| 23086/23100 [52:08<00:08,  1.61pipeline/s]
Generation 230 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23100/23100 [52:08<00:00,  1.61pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 23100/23100 [52:09<00:00,  1.61pipeline/s]Optimization Progress: 100%|██████████| 23100/23100 [52:09<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23100/23100 [52:09<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23100/23100 [52:10<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23100/23100 [52:10<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 23100/23100 [52:10<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 23100/23100 [52:10<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23100/23100 [52:11<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23100/23100 [52:11<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 23100/23100 [52:11<00:00,  2.25pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:33:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 23100/23100 [52:11<00:00,  2.25pipeline/s]Optimization Progress: 100%|█████████▉| 23102/23200 [52:12<01:19,  1.23pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23102/23200 [52:12<01:19,  1.23pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23103/23200 [52:12<01:19,  1.23pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23104/23200 [52:12<01:18,  1.23pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23105/23200 [52:12<01:17,  1.23pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23106/23200 [52:12<01:16,  1.23pipeline/s]Optimization Progress: 100%|█████████▉| 23108/23200 [52:16<01:10,  1.30pipeline/s]Optimization Progress: 100%|█████████▉| 23188/23200 [52:19<00:06,  1.82pipeline/s]
Generation 231 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23200/23200 [52:20<00:00,  1.82pipeline/s]Optimization Progress: 100%|██████████| 23200/23200 [52:20<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23200/23200 [52:20<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 23200/23200 [52:20<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23200/23200 [52:21<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23200/23200 [52:21<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 23200/23200 [52:21<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23200/23200 [52:22<00:00,  2.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 23200/23200 [52:22<00:00,  2.43pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23201/23300 [52:22<00:40,  2.43pipeline/s]Optimization Progress: 100%|█████████▉| 23202/23300 [52:22<01:03,  1.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23202/23300 [52:22<01:03,  1.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23203/23300 [52:22<01:02,  1.55pipeline/s]Optimization Progress: 100%|█████████▉| 23205/23300 [52:31<02:00,  1.27s/pipeline]Optimization Progress: 100%|█████████▉| 23285/23300 [52:35<00:13,  1.11pipeline/s]
Generation 232 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23300/23300 [52:35<00:00,  1.11pipeline/s]Optimization Progress: 100%|██████████| 23300/23300 [52:35<00:00,  1.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23300/23300 [52:36<00:00,  1.57pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23300/23300 [52:37<00:00,  1.57pipeline/s]Optimization Progress: 100%|█████████▉| 23304/23400 [52:39<01:07,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23304/23400 [52:39<01:07,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23305/23400 [52:39<01:07,  1.42pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23306/23400 [52:39<01:06,  1.42pipeline/s]Optimization Progress: 100%|█████████▉| 23307/23400 [52:39<00:46,  1.98pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23307/23400 [52:39<00:46,  1.98pipeline/s]Optimization Progress: 100%|█████████▉| 23308/23400 [52:50<00:46,  1.98pipeline/s]Optimization Progress: 100%|█████████▉| 23309/23400 [52:57<04:33,  3.00s/pipeline]Optimization Progress: 100%|█████████▉| 23389/23400 [53:06<00:23,  2.14s/pipeline]
Generation 233 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23400/23400 [53:06<00:00,  2.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 23400/23400 [53:06<00:00,  2.14s/pipeline]Optimization Progress: 100%|██████████| 23400/23400 [53:06<00:00,  1.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23400/23400 [53:06<00:00,  1.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23400/23400 [53:07<00:00,  1.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 23400/23400 [53:07<00:00,  1.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23400/23400 [53:07<00:00,  1.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 23400/23400 [53:08<00:00,  1.50s/pipeline]Optimization Progress: 100%|█████████▉| 23405/23500 [53:09<01:57,  1.24s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23405/23500 [53:09<01:57,  1.24s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23406/23500 [53:09<01:56,  1.24s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23407/23500 [53:09<01:55,  1.24s/pipeline]Optimization Progress: 100%|█████████▉| 23408/23500 [53:20<01:53,  1.24s/pipeline]Optimization Progress: 100%|█████████▉| 23409/23500 [53:24<03:02,  2.01s/pipeline]Optimization Progress: 100%|█████████▉| 23489/23500 [53:29<00:15,  1.42s/pipeline]
Generation 234 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 23500/23500 [53:29<00:00,  1.42s/pipeline]Optimization Progress: 100%|██████████| 23500/23500 [53:29<00:00,  1.01s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23500/23500 [53:30<00:00,  1.01s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 23500/23500 [53:31<00:00,  1.01s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23500/23500 [53:31<00:00,  1.01s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23500/23500 [53:31<00:00,  1.01s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 23500/23500 [53:31<00:00,  1.01s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 23500/23500 [53:31<00:00,  1.01s/pipeline]Optimization Progress: 100%|█████████▉| 23502/23600 [53:32<01:52,  1.14s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23502/23600 [53:32<01:52,  1.14s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23503/23600 [53:32<01:50,  1.14s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23504/23600 [53:32<01:49,  1.14s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23505/23600 [53:32<01:48,  1.14s/pipeline]Optimization Progress: 100%|█████████▉| 23507/23600 [53:39<01:52,  1.21s/pipeline]Optimization Progress: 100%|█████████▉| 23587/23600 [53:42<00:11,  1.17pipeline/s]
Generation 235 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 23600/23600 [53:42<00:00,  1.17pipeline/s]Optimization Progress: 100%|██████████| 23600/23600 [53:42<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23600/23600 [53:42<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23600/23600 [53:42<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23600/23600 [53:44<00:00,  1.62pipeline/s]Optimization Progress: 100%|█████████▉| 23602/23700 [53:45<01:18,  1.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23602/23700 [53:45<01:18,  1.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23603/23700 [53:45<01:17,  1.25pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23604/23700 [53:45<01:17,  1.25pipeline/s]Optimization Progress: 100%|█████████▉| 23606/23700 [53:49<01:20,  1.17pipeline/s]Optimization Progress: 100%|█████████▉| 23686/23700 [53:53<00:08,  1.62pipeline/s]
Generation 236 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23700/23700 [53:54<00:00,  1.62pipeline/s]Optimization Progress: 100%|██████████| 23700/23700 [53:54<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 23700/23700 [53:55<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23700/23700 [53:55<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23700/23700 [53:56<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23700/23700 [53:56<00:00,  2.18pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23700/23800 [53:57<00:45,  2.18pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23701/23800 [53:57<00:45,  2.18pipeline/s]Optimization Progress: 100%|█████████▉| 23702/23800 [53:57<01:06,  1.47pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23702/23800 [53:57<01:06,  1.47pipeline/s]Optimization Progress: 100%|█████████▉| 23704/23800 [54:03<02:14,  1.40s/pipeline]Optimization Progress: 100%|█████████▉| 23784/23800 [54:18<00:16,  1.04s/pipeline]
Generation 237 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23800/23800 [54:18<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 23800/23800 [54:18<00:00,  1.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23800/23800 [54:19<00:00,  1.04s/pipeline]Optimization Progress: 100%|██████████| 23800/23800 [54:19<00:00,  1.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 23800/23800 [54:20<00:00,  1.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 23800/23800 [54:21<00:00,  1.32pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:35:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 23800/23800 [54:21<00:00,  1.32pipeline/s]Optimization Progress: 100%|█████████▉| 23802/23900 [54:21<01:21,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23802/23900 [54:21<01:21,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23803/23900 [54:21<01:20,  1.21pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23804/23900 [54:21<01:19,  1.21pipeline/s]Optimization Progress: 100%|█████████▉| 23805/23900 [54:21<00:56,  1.69pipeline/s]Optimization Progress: 100%|█████████▉| 23807/23900 [54:24<01:21,  1.15pipeline/s]Optimization Progress: 100%|█████████▉| 23886/23900 [54:28<00:08,  1.60pipeline/s]
Generation 238 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 23900/23900 [54:28<00:00,  1.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 23900/23900 [54:29<00:00,  1.60pipeline/s]Optimization Progress: 100%|██████████| 23900/23900 [54:29<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23900/23900 [54:30<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 23900/23900 [54:30<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 23900/23900 [54:31<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:35:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 23900/23900 [54:31<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 23900/23900 [54:31<00:00,  2.17pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 23900/23900 [54:31<00:00,  2.17pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23901/24000 [54:32<00:45,  2.17pipeline/s]Optimization Progress: 100%|█████████▉| 23902/24000 [54:32<01:13,  1.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23902/24000 [54:32<01:13,  1.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23903/24000 [54:32<01:13,  1.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23904/24000 [54:32<01:12,  1.32pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23905/24000 [54:32<01:11,  1.32pipeline/s]Optimization Progress: 100%|█████████▉| 23907/24000 [54:36<01:10,  1.32pipeline/s]Optimization Progress: 100%|█████████▉| 23987/24000 [54:38<00:06,  1.86pipeline/s]
Generation 239 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:36:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24000/24000 [54:38<00:00,  1.86pipeline/s]Optimization Progress: 100%|██████████| 24000/24000 [54:38<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:36:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24000/24000 [54:39<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 24000/24000 [54:39<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:36:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24000/24000 [54:40<00:00,  2.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24000/24100 [54:41<00:39,  2.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24001/24100 [54:41<00:39,  2.53pipeline/s]Optimization Progress: 100%|█████████▉| 24002/24100 [54:41<01:10,  1.39pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24002/24100 [54:41<01:10,  1.39pipeline/s]Optimization Progress: 100%|█████████▉| 24004/24100 [54:55<04:06,  2.57s/pipeline]Optimization Progress: 100%|█████████▉| 24084/24100 [54:57<00:28,  1.81s/pipeline]
Generation 240 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24100/24100 [54:57<00:00,  1.81s/pipeline]Optimization Progress: 100%|██████████| 24100/24100 [54:57<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 24100/24100 [54:58<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24100/24100 [54:58<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:36:24] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24100/24100 [54:58<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:36:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24100/24100 [54:58<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24100/24100 [54:59<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24100/24100 [55:00<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 24100/24100 [55:00<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24100/24100 [55:00<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 24100/24100 [55:00<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24100/24100 [55:00<00:00,  1.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 24100/24100 [55:01<00:00,  1.27s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24101/24200 [55:01<02:06,  1.27s/pipeline]Optimization Progress: 100%|█████████▉| 24102/24200 [55:01<02:18,  1.41s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24102/24200 [55:01<02:18,  1.41s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24103/24200 [55:01<02:16,  1.41s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24104/24200 [55:01<02:15,  1.41s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24105/24200 [55:01<02:14,  1.41s/pipeline]Optimization Progress: 100%|█████████▉| 24107/24200 [55:10<02:21,  1.52s/pipeline]Optimization Progress: 100%|█████████▉| 24187/24200 [55:11<00:13,  1.07s/pipeline]
Generation 241 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 24200/24200 [55:13<00:00,  1.07s/pipeline]Optimization Progress: 100%|██████████| 24200/24200 [55:13<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:36:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24200/24200 [55:13<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:36:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24200/24200 [55:13<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24200/24200 [55:14<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 24200/24200 [55:14<00:00,  1.28pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 24200/24200 [55:14<00:00,  1.28pipeline/s]Optimization Progress: 100%|█████████▉| 24202/24300 [55:15<01:32,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24202/24300 [55:15<01:32,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24203/24300 [55:15<01:31,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24204/24300 [55:15<01:30,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24205/24300 [55:15<01:29,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24206/24300 [55:15<01:28,  1.06pipeline/s]Optimization Progress: 100%|█████████▉| 24208/24300 [55:22<01:30,  1.02pipeline/s]Optimization Progress: 100%|█████████▉| 24288/24300 [55:25<00:08,  1.43pipeline/s]
Generation 242 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 24300/24300 [55:27<00:00,  1.43pipeline/s]Optimization Progress: 100%|██████████| 24300/24300 [55:27<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:36:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24300/24300 [55:27<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 24300/24300 [55:28<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 24300/24300 [55:28<00:00,  1.83pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24300/24300 [55:28<00:00,  1.83pipeline/s]Optimization Progress: 100%|█████████▉| 24302/24400 [55:29<00:55,  1.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24302/24400 [55:29<00:55,  1.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24303/24400 [55:29<00:55,  1.76pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24304/24400 [55:29<00:54,  1.76pipeline/s]Optimization Progress: 100%|█████████▉| 24306/24400 [55:33<01:11,  1.31pipeline/s]Optimization Progress: 100%|█████████▉| 24386/24400 [55:36<00:07,  1.84pipeline/s]
Generation 243 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24400/24400 [55:37<00:00,  1.84pipeline/s]Optimization Progress: 100%|██████████| 24400/24400 [55:37<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24400/24400 [55:38<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 24400/24400 [55:38<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 24400/24400 [55:38<00:00,  2.60pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 24400/24400 [55:39<00:00,  2.60pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24401/24500 [55:40<00:38,  2.60pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24402/24500 [55:40<00:37,  2.60pipeline/s]Optimization Progress: 100%|█████████▉| 24403/24500 [55:40<00:56,  1.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24403/24500 [55:40<00:56,  1.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24404/24500 [55:40<00:56,  1.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24405/24500 [55:40<00:55,  1.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24406/24500 [55:40<00:54,  1.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24407/24500 [55:40<00:54,  1.71pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24408/24500 [55:40<00:53,  1.71pipeline/s]Optimization Progress: 100%|█████████▉| 24410/24500 [55:45<00:58,  1.54pipeline/s]Optimization Progress: 100%|█████████▉| 24490/24500 [55:46<00:04,  2.19pipeline/s]
Generation 244 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24500/24500 [55:47<00:00,  2.19pipeline/s]Optimization Progress: 100%|██████████| 24500/24500 [55:47<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:37:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24500/24500 [55:47<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24500/24500 [55:48<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24500/24500 [55:48<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 24500/24500 [55:48<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:37:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24500/24500 [55:48<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24500/24500 [55:48<00:00,  3.01pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:37:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24500/24500 [55:49<00:00,  3.01pipeline/s]Optimization Progress: 100%|█████████▉| 24504/24600 [55:50<00:43,  2.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24504/24600 [55:50<00:43,  2.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24505/24600 [55:50<00:43,  2.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24506/24600 [55:50<00:42,  2.20pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24507/24600 [55:50<00:42,  2.20pipeline/s]Optimization Progress: 100%|█████████▉| 24509/24600 [55:52<00:44,  2.06pipeline/s]Optimization Progress: 100%|█████████▉| 24589/24600 [55:57<00:03,  2.79pipeline/s]
Generation 245 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24600/24600 [55:58<00:00,  2.79pipeline/s]Optimization Progress: 100%|██████████| 24600/24600 [55:58<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 24600/24600 [55:59<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 24600/24600 [55:59<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24600/24600 [56:00<00:00,  3.75pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 24600/24600 [56:00<00:00,  3.75pipeline/s]Optimization Progress: 100%|█████████▉| 24602/24700 [56:01<01:03,  1.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24602/24700 [56:01<01:03,  1.55pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24603/24700 [56:01<01:02,  1.55pipeline/s]Optimization Progress: 100%|█████████▉| 24605/24700 [56:05<01:23,  1.14pipeline/s]Optimization Progress: 100%|█████████▉| 24685/24700 [56:14<00:09,  1.54pipeline/s]
Generation 246 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24700/24700 [56:15<00:00,  1.54pipeline/s]Optimization Progress: 100%|██████████| 24700/24700 [56:15<00:00,  2.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 24700/24700 [56:15<00:00,  2.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 24700/24700 [56:15<00:00,  2.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24700/24700 [56:16<00:00,  2.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 24700/24700 [56:16<00:00,  2.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:37:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24700/24700 [56:16<00:00,  2.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 24700/24700 [56:17<00:00,  2.14pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24700/24700 [56:18<00:00,  2.14pipeline/s]Optimization Progress: 100%|█████████▉| 24703/24800 [56:18<01:02,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24703/24800 [56:18<01:02,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24704/24800 [56:18<01:01,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24705/24800 [56:18<01:01,  1.56pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24706/24800 [56:18<01:00,  1.56pipeline/s]Optimization Progress: 100%|█████████▉| 24708/24800 [56:25<01:20,  1.15pipeline/s]Optimization Progress: 100%|█████████▉| 24788/24800 [56:28<00:07,  1.61pipeline/s]
Generation 247 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 24800/24800 [56:29<00:00,  1.61pipeline/s]Optimization Progress: 100%|██████████| 24800/24800 [56:29<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24800/24800 [56:30<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24800/24800 [56:30<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24800/24800 [56:31<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24800/24800 [56:31<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 24800/24800 [56:31<00:00,  2.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 24800/24800 [56:31<00:00,  2.18pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24800/24900 [56:32<00:45,  2.18pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24801/24900 [56:32<00:45,  2.18pipeline/s]Optimization Progress: 100%|█████████▉| 24802/24900 [56:32<01:14,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24802/24900 [56:32<01:14,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24803/24900 [56:32<01:13,  1.31pipeline/s]Optimization Progress: 100%|█████████▉| 24805/24900 [56:40<02:13,  1.40s/pipeline]Optimization Progress: 100%|█████████▉| 24885/24900 [56:43<00:14,  1.01pipeline/s]
Generation 248 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 24900/24900 [56:44<00:00,  1.01pipeline/s]Optimization Progress: 100%|██████████| 24900/24900 [56:44<00:00,  1.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24900/24900 [56:44<00:00,  1.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 24900/24900 [56:45<00:00,  1.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:38:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24900/24900 [56:45<00:00,  1.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 24900/24900 [56:46<00:00,  1.43pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:38:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 24900/24900 [56:47<00:00,  1.43pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24902/25000 [56:47<01:08,  1.43pipeline/s]Optimization Progress: 100%|█████████▉| 24903/25000 [56:47<01:16,  1.27pipeline/s]Optimization Progress: 100%|█████████▉| 24905/25000 [56:59<03:42,  2.35s/pipeline]Optimization Progress: 100%|█████████▉| 24984/25000 [57:01<00:26,  1.65s/pipeline]
Generation 249 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25000/25000 [57:01<00:00,  1.65s/pipeline]Optimization Progress: 100%|██████████| 25000/25000 [57:01<00:00,  1.16s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25000/25000 [57:02<00:00,  1.16s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25000/25000 [57:03<00:00,  1.16s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25000/25000 [57:04<00:00,  1.16s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25000/25000 [57:04<00:00,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25002/25100 [57:04<01:53,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25003/25100 [57:04<01:52,  1.16s/pipeline]Optimization Progress: 100%|█████████▉| 25004/25100 [57:04<01:42,  1.07s/pipeline]Optimization Progress: 100%|█████████▉| 25007/25100 [57:08<01:47,  1.15s/pipeline]Optimization Progress: 100%|█████████▉| 25085/25100 [57:11<00:12,  1.23pipeline/s]
Generation 250 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25100/25100 [57:11<00:00,  1.23pipeline/s]Optimization Progress: 100%|██████████| 25100/25100 [57:11<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25100/25100 [57:11<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25100/25100 [57:11<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25100/25100 [57:11<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 25100/25100 [57:12<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25100/25100 [57:12<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25100/25100 [57:13<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25100/25100 [57:14<00:00,  1.73pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25100/25100 [57:14<00:00,  1.73pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25102/25200 [57:14<00:56,  1.73pipeline/s]Optimization Progress: 100%|█████████▉| 25103/25200 [57:14<01:09,  1.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25103/25200 [57:14<01:09,  1.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25104/25200 [57:14<01:08,  1.40pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25105/25200 [57:14<01:07,  1.40pipeline/s]Optimization Progress: 100%|█████████▉| 25107/25200 [57:18<01:12,  1.28pipeline/s]Optimization Progress: 100%|█████████▉| 25187/25200 [57:21<00:07,  1.79pipeline/s]
Generation 251 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205334460.57469583	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25200/25200 [57:21<00:00,  1.79pipeline/s]Optimization Progress: 100%|██████████| 25200/25200 [57:21<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25200/25200 [57:21<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25200/25200 [57:21<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25200/25200 [57:21<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25200/25200 [57:21<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 25200/25200 [57:22<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:38:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 25200/25200 [57:22<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 25200/25200 [57:22<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 25200/25200 [57:22<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25200/25200 [57:22<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 25200/25200 [57:23<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 25200/25200 [57:23<00:00,  2.53pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25200/25200 [57:23<00:00,  2.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25202/25300 [57:24<00:38,  2.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25203/25300 [57:24<00:38,  2.53pipeline/s]Optimization Progress: 100%|█████████▉| 25204/25300 [57:24<00:46,  2.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25204/25300 [57:24<00:46,  2.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25205/25300 [57:24<00:45,  2.07pipeline/s]Optimization Progress: 100%|█████████▉| 25207/25300 [57:38<02:49,  1.83s/pipeline]Optimization Progress: 100%|█████████▉| 25287/25300 [57:40<00:16,  1.28s/pipeline]
Generation 252 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25300/25300 [57:41<00:00,  1.28s/pipeline]Optimization Progress: 100%|██████████| 25300/25300 [57:41<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 25300/25300 [57:42<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25300/25300 [57:43<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 25300/25300 [57:43<00:00,  1.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 25300/25300 [57:43<00:00,  1.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25301/25400 [57:44<01:31,  1.08pipeline/s]Optimization Progress: 100%|█████████▉| 25302/25400 [57:44<01:39,  1.01s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25302/25400 [57:44<01:39,  1.01s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25303/25400 [57:44<01:38,  1.01s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25304/25400 [57:44<01:37,  1.01s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25305/25400 [57:44<01:36,  1.01s/pipeline]Optimization Progress: 100%|█████████▉| 25307/25400 [57:52<01:52,  1.21s/pipeline]Optimization Progress: 100%|█████████▉| 25387/25400 [57:55<00:11,  1.17pipeline/s]
Generation 253 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 25400/25400 [57:57<00:00,  1.17pipeline/s]Optimization Progress: 100%|██████████| 25400/25400 [57:57<00:00,  1.55pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25400/25400 [57:58<00:00,  1.55pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25400/25400 [57:59<00:00,  1.55pipeline/s]Optimization Progress: 100%|█████████▉| 25402/25500 [57:59<01:23,  1.18pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25402/25500 [57:59<01:23,  1.18pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25403/25500 [57:59<01:22,  1.18pipeline/s]Optimization Progress: 100%|█████████▉| 25405/25500 [58:15<03:28,  2.19s/pipeline]Optimization Progress: 100%|█████████▉| 25485/25500 [58:17<00:23,  1.54s/pipeline]
Generation 254 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 25500/25500 [58:17<00:00,  1.54s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 25500/25500 [58:18<00:00,  1.54s/pipeline]Optimization Progress: 100%|██████████| 25500/25500 [58:18<00:00,  1.08s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 25500/25500 [58:18<00:00,  1.08s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:39:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 25500/25500 [58:18<00:00,  1.08s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 25500/25500 [58:18<00:00,  1.08s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 25500/25500 [58:20<00:00,  1.08s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25503/25600 [58:20<01:45,  1.08s/pipeline]Optimization Progress: 100%|█████████▉| 25504/25600 [58:20<01:33,  1.03pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25504/25600 [58:20<01:33,  1.03pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25505/25600 [58:20<01:32,  1.03pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25506/25600 [58:20<01:31,  1.03pipeline/s]Optimization Progress: 100%|█████████▉| 25508/25600 [58:32<02:20,  1.53s/pipeline]Optimization Progress: 100%|█████████▉| 25588/25600 [58:35<00:12,  1.08s/pipeline]
Generation 255 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 25600/25600 [58:35<00:00,  1.08s/pipeline]Optimization Progress: 100%|██████████| 25600/25600 [58:35<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25600/25600 [58:35<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 25600/25600 [58:35<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25600/25600 [58:36<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 25600/25600 [58:36<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25600/25600 [58:37<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25600/25600 [58:37<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 25600/25600 [58:37<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 25600/25600 [58:38<00:00,  1.31pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 25600/25600 [58:38<00:00,  1.31pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25601/25700 [58:38<01:15,  1.31pipeline/s]Optimization Progress: 100%|█████████▉| 25602/25700 [58:38<01:40,  1.03s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25602/25700 [58:38<01:40,  1.03s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25603/25700 [58:38<01:39,  1.03s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25604/25700 [58:38<01:38,  1.03s/pipeline]Optimization Progress: 100%|█████████▉| 25606/25700 [58:45<01:53,  1.21s/pipeline]Optimization Progress: 100%|█████████▉| 25686/25700 [58:46<00:11,  1.18pipeline/s]
Generation 256 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25700/25700 [58:46<00:00,  1.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25700/25700 [58:46<00:00,  1.18pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 25700/25700 [58:47<00:00,  1.18pipeline/s]Optimization Progress: 100%|██████████| 25700/25700 [58:47<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 25700/25700 [58:47<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25700/25700 [58:47<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25700/25700 [58:48<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:40:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 25700/25700 [58:48<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 [11:40:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 25700/25700 [58:48<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 25700/25700 [58:48<00:00,  1.62pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 25700/25700 [58:49<00:00,  1.62pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25701/25800 [58:49<01:01,  1.62pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25702/25800 [58:49<01:00,  1.62pipeline/s]Optimization Progress: 100%|█████████▉| 25703/25800 [58:49<01:03,  1.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25703/25800 [58:49<01:03,  1.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25704/25800 [58:49<01:02,  1.54pipeline/s]Optimization Progress: 100%|█████████▉| 25706/25800 [58:59<02:17,  1.46s/pipeline]Optimization Progress: 100%|█████████▉| 25786/25800 [59:02<00:14,  1.03s/pipeline]
Generation 257 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 25800/25800 [59:02<00:00,  1.03s/pipeline]Optimization Progress: 100%|██████████| 25800/25800 [59:02<00:00,  1.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 25800/25800 [59:03<00:00,  1.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 25800/25800 [59:03<00:00,  1.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25800/25800 [59:03<00:00,  1.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:40:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 25800/25800 [59:04<00:00,  1.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 25800/25800 [59:04<00:00,  1.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:40:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 25800/25800 [59:04<00:00,  1.36pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25800/25800 [59:05<00:00,  1.36pipeline/s]Optimization Progress: 100%|█████████▉| 25802/25900 [59:05<01:32,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25802/25900 [59:05<01:32,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25803/25900 [59:05<01:31,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25804/25900 [59:05<01:30,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25805/25900 [59:05<01:30,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25806/25900 [59:05<01:29,  1.06pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25807/25900 [59:05<01:28,  1.06pipeline/s]Optimization Progress: 100%|█████████▉| 25809/25900 [59:11<01:22,  1.11pipeline/s]Optimization Progress: 100%|█████████▉| 25889/25900 [59:15<00:07,  1.55pipeline/s]
Generation 258 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 25900/25900 [59:16<00:00,  1.55pipeline/s]Optimization Progress: 100%|██████████| 25900/25900 [59:16<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 25900/25900 [59:16<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 25900/25900 [59:16<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 25900/25900 [59:16<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 25900/25900 [59:17<00:00,  2.08pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:40:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 25900/25900 [59:17<00:00,  2.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25901/26000 [59:18<00:47,  2.08pipeline/s]Optimization Progress: 100%|█████████▉| 25902/26000 [59:18<01:02,  1.57pipeline/s]Optimization Progress: 100%|█████████▉| 25903/26000 [59:21<02:36,  1.62s/pipeline]Optimization Progress: 100%|█████████▉| 25983/26000 [59:23<00:19,  1.14s/pipeline]
Generation 259 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 26000/26000 [59:23<00:00,  1.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 26000/26000 [59:23<00:00,  1.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 26000/26000 [59:24<00:00,  1.14s/pipeline]Optimization Progress: 100%|██████████| 26000/26000 [59:24<00:00,  1.22pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 26000/26000 [59:26<00:00,  1.22pipeline/s]Optimization Progress: 100%|█████████▉| 26002/26100 [59:27<01:27,  1.12pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26002/26100 [59:27<01:27,  1.12pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26003/26100 [59:27<01:26,  1.12pipeline/s]Optimization Progress: 100%|█████████▉| 26005/26100 [59:32<01:52,  1.19s/pipeline]Optimization Progress: 100%|█████████▉| 26085/26100 [59:34<00:12,  1.19pipeline/s]
Generation 260 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 26100/26100 [59:35<00:00,  1.19pipeline/s]Optimization Progress: 100%|██████████| 26100/26100 [59:35<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 26100/26100 [59:36<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 26100/26100 [59:36<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 26100/26100 [59:37<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:41:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 26100/26100 [59:37<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 26100/26100 [59:37<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 26100/26100 [59:37<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 26100/26100 [59:37<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 26100/26100 [59:38<00:00,  1.67pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 [11:41:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 26100/26100 [59:38<00:00,  1.67pipeline/s]Optimization Progress: 100%|█████████▉| 26104/26200 [59:38<01:02,  1.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26104/26200 [59:38<01:02,  1.54pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26105/26200 [59:38<01:01,  1.54pipeline/s]Optimization Progress: 100%|█████████▉| 26107/26200 [59:43<01:34,  1.01s/pipeline]Optimization Progress: 100%|█████████▉| 26187/26200 [59:47<00:09,  1.39pipeline/s]
Generation 261 - Current Pareto front scores:
-1	-353357964.06561625	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05)
-2	-205263958.95755395	LinearSVR(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=3), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.1)
-3	-169949894.24980065	LinearSVR(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.65, Nystroem__kernel=rbf, Nystroem__n_components=6), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)
-4	-124226334.86098473	LinearSVR(MaxAbsScaler(Nystroem(RobustScaler(input_matrix), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)
-6	-112892035.93132177	LinearSVR(SelectPercentile(MaxAbsScaler(Nystroem(ZeroCount(RobustScaler(input_matrix)), Nystroem__gamma=0.55, Nystroem__kernel=rbf, Nystroem__n_components=7)), SelectPercentile__percentile=46), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.1, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.0001)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 26200/26200 [59:47<00:00,  1.39pipeline/s]Optimization Progress: 100%|██████████| 26200/26200 [59:47<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 26200/26200 [59:48<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 26200/26200 [59:49<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [11:41:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c5197dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c52a8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c52b5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c529ccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c5189f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d2f449dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d2f44067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d2f5c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d2f5ccb4]

.
Optimization Progress: 100%|██████████| 26200/26200 [59:49<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 26200/26200 [59:49<00:00,  1.97pipeline/s]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 26200/26200 [59:49<00:00,  1.97pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26200/26300 [59:50<00:50,  1.97pipeline/s]Optimization Progress: 100%|█████████▉| 26205/26300 [59:55<01:18,  1.21pipeline/s]                                                                                  
Optimization Progress: 100%|█████████▉| 26281/26300 [59:55<00:15,  1.21pipeline/s]                                                                                  60.04 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 26281/26300 [59:55<00:15,  1.21pipeline/s]                                                                                  
Optimization Progress: 100%|█████████▉| 26281/26300 [59:55<00:15,  1.21pipeline/s]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 26281/26300 [59:55<00:15,  1.21pipeline/s]                                                                                  Best pipeline:
0. RobustScaler()
1. ZeroCount()
2. Nystroem(gamma=0.55, n_components=7)
3. MaxAbsScaler()
4. SelectPercentile(percentile=46,
                 score_func=<function f_regression at 0x7fcdaba39b90>)
5. LinearSVR(C=25.0, epsilon=0.1)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
