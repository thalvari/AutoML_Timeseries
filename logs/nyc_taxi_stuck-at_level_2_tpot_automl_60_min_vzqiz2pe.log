30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:  17%|█▋        | 17/100 [00:08<00:42,  1.94pipeline/s]Optimization Progress:  97%|█████████▋| 97/100 [00:10<00:01,  2.72pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  2.72pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  2.50pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.50pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.50pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.50pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.50pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  2.50pipeline/s]Optimization Progress:  51%|█████     | 102/200 [00:17<01:46,  1.09s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  51%|█████     | 102/200 [00:17<01:46,  1.09s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 103/200 [00:17<01:45,  1.09s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 104/200 [00:17<01:44,  1.09s/pipeline]Optimization Progress:  53%|█████▎    | 106/200 [00:21<01:41,  1.08s/pipeline]Optimization Progress:  93%|█████████▎| 186/200 [00:24<00:10,  1.30pipeline/s]
Generation 1 - Current Pareto front scores:
-1	-1065087024.6265345	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:25<00:00,  1.30pipeline/s]Optimization Progress: 100%|██████████| 200/200 [00:25<00:00,  1.81pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:27<00:00,  1.81pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:28<00:00,  1.81pipeline/s]Optimization Progress:  68%|██████▊   | 204/300 [00:33<01:34,  1.02pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 204/300 [00:33<01:34,  1.02pipeline/s]Optimization Progress:  69%|██████▊   | 206/300 [00:40<02:47,  1.79s/pipeline]Optimization Progress:  95%|█████████▌| 286/300 [00:46<00:17,  1.27s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-1064636041.6809921	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [00:50<00:00,  1.27s/pipeline]Optimization Progress: 100%|██████████| 300/300 [00:50<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:50<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 300/300 [00:53<00:00,  1.02pipeline/s]Optimization Progress:  76%|███████▌  | 302/400 [00:55<02:14,  1.37s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [01:01<04:34,  2.83s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [01:06<00:34,  2.00s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-1064541497.559585	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-1041963693.6759955	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 400/400 [01:08<00:00,  2.00s/pipeline]Optimization Progress: 100%|██████████| 400/400 [01:08<00:00,  1.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:08<00:00,  1.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:09<00:00,  1.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:12<00:00,  1.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 400/400 [01:14<00:00,  1.42s/pipeline]Optimization Progress:  80%|████████  | 401/500 [01:37<16:22,  9.93s/pipeline]Optimization Progress:  96%|█████████▌| 481/500 [01:42<02:12,  6.97s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-1064541497.559585	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-1041963693.6759955	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:42<00:00,  6.97s/pipeline]Optimization Progress: 100%|██████████| 500/500 [01:42<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 500/500 [01:44<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [01:46<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 500/500 [01:46<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:47<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [01:48<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 500/500 [01:50<00:00,  4.88s/pipeline]Optimization Progress:  84%|████████▍ | 503/600 [01:57<07:57,  4.92s/pipeline]Optimization Progress:  97%|█████████▋| 581/600 [02:01<01:05,  3.46s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-1064541497.559585	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1064415318.1011015	GradientBoostingRegressor(ExtraTreesRegressor(CombineDFs(input_matrix, CombineDFs(input_matrix, input_matrix)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.55, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=6, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-1041963693.6759955	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:01<00:00,  3.46s/pipeline]Optimization Progress: 100%|██████████| 600/600 [02:01<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 600/600 [02:01<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 600/600 [02:01<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [02:02<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 600/600 [02:03<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:04<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 600/600 [02:10<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:11<00:00,  2.43s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 600/700 [02:12<04:02,  2.43s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [02:20<04:00,  2.43s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [03:02<17:40, 10.82s/pipeline]Optimization Progress:  97%|█████████▋| 682/700 [03:06<02:16,  7.59s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-1064541497.559585	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1046589640.3487651	GradientBoostingRegressor(CombineDFs(input_matrix, Binarizer(input_matrix, Binarizer__threshold=0.8)), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-1041963693.6759955	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-4	-1024063932.2033036	GradientBoostingRegressor(RobustScaler(PCA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), PCA__iterated_power=9, PCA__svd_solver=randomized)), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [03:11<00:00,  7.59s/pipeline]Optimization Progress: 100%|██████████| 700/700 [03:11<00:00,  5.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 700/700 [03:13<00:00,  5.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 700/700 [03:13<00:00,  5.40s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [03:17<09:10,  5.56s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [03:25<10:22,  6.35s/pipeline]Optimization Progress:  98%|█████████▊| 782/800 [03:31<01:20,  4.47s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-1063696418.0787007	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1046589640.3487651	GradientBoostingRegressor(CombineDFs(input_matrix, Binarizer(input_matrix, Binarizer__threshold=0.8)), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-1041963693.6759955	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-4	-1024063932.2033036	GradientBoostingRegressor(RobustScaler(PCA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), PCA__iterated_power=9, PCA__svd_solver=randomized)), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [03:36<00:00,  4.47s/pipeline]Optimization Progress: 100%|██████████| 800/800 [03:36<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 800/800 [03:37<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [03:37<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [03:39<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [03:39<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [03:41<00:00,  3.22s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [03:43<05:25,  3.33s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 802/900 [03:43<05:25,  3.33s/pipeline]Optimization Progress:  89%|████████▉ | 804/900 [04:22<12:55,  8.08s/pipeline]Optimization Progress:  98%|█████████▊| 884/900 [04:27<01:30,  5.68s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-1063696418.0787007	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1028622237.2405716	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-4	-981829963.4577852	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [04:32<00:00,  5.68s/pipeline]Optimization Progress: 100%|██████████| 900/900 [04:32<00:00,  4.06s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [04:34<00:00,  4.06s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [04:35<00:00,  4.06s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 900/1000 [04:38<06:46,  4.06s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [04:38<07:35,  4.60s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [04:48<10:16,  6.29s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [04:53<01:19,  4.42s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1028622237.2405716	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-4	-981829963.4577852	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [04:55<00:00,  4.42s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [04:55<00:00,  3.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [05:00<00:00,  3.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 1000/1000 [05:05<00:00,  3.14s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [05:17<14:15,  8.64s/pipeline]Optimization Progress:  98%|█████████▊| 1081/1100 [05:24<01:55,  6.08s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1028622237.2405716	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [05:26<00:00,  6.08s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [05:26<00:00,  4.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [05:26<00:00,  4.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 1100/1100 [05:28<00:00,  4.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1100/1100 [05:30<00:00,  4.29s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [05:37<10:28,  6.35s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [06:34<35:04, 21.47s/pipeline]Optimization Progress:  98%|█████████▊| 1182/1200 [06:42<04:31, 15.06s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1024954681.0485315	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [06:47<00:00, 15.06s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [06:47<00:00, 10.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [06:54<00:00, 10.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [06:54<00:00, 10.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 1200/1200 [06:58<00:00, 10.62s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [07:31<33:57, 20.58s/pipeline]Optimization Progress:  99%|█████████▊| 1281/1300 [07:38<04:34, 14.43s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1024954681.0485315	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)Optimization Progress: 100%|██████████| 1300/1300 [07:53<00:00, 10.34s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1300/1400 [07:53<17:14, 10.34s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  93%|█████████▎| 1301/1400 [07:53<17:03, 10.34s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [08:05<13:41,  8.47s/pipeline]Optimization Progress:  99%|█████████▉| 1383/1400 [10:08<01:48,  6.39s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1024954681.0485315	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [10:10<00:00,  6.39s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [10:10<00:00,  4.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [10:15<00:00,  4.51s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [10:23<07:12,  4.46s/pipeline]Optimization Progress:  94%|█████████▎| 1404/1500 [10:33<09:37,  6.01s/pipeline]Optimization Progress:  99%|█████████▉| 1484/1500 [10:40<01:07,  4.24s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1024954681.0485315	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [19:01:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f60ac976dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f60aca87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f60aca94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f60aca7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f60ac968f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f56ba7239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f56ba723067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f56ba73b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f56ba73bcb4]

.
Optimization Progress: 100%|██████████| 1500/1500 [10:43<00:00,  4.24s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [10:43<00:00,  3.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [10:46<00:00,  3.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1500/1500 [10:47<00:00,  3.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [10:49<00:00,  3.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 1500/1500 [10:52<00:00,  3.02s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [10:57<10:08,  6.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1501/1600 [10:57<10:08,  6.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1502/1600 [10:57<10:02,  6.15s/pipeline]Optimization Progress:  94%|█████████▍| 1504/1600 [11:11<09:09,  5.72s/pipeline]Optimization Progress:  99%|█████████▉| 1584/1600 [11:16<01:04,  4.03s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1024954681.0485315	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 1600/1600 [11:25<00:00,  4.03s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [11:25<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [11:29<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1600/1600 [11:31<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [11:31<00:00,  2.99s/pipeline]Optimization Progress:  94%|█████████▍| 1603/1700 [11:31<04:19,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1603/1700 [11:31<04:19,  2.67s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [11:44<05:59,  3.78s/pipeline]Optimization Progress:  99%|█████████▉| 1685/1700 [11:48<00:39,  2.66s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-1063326309.4711924	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1024954681.0485315	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [11:49<00:00,  2.66s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [11:49<00:00,  1.87s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [12:00<00:00,  1.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1700/1700 [12:01<00:00,  1.87s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [12:02<08:52,  5.38s/pipeline]Optimization Progress:  95%|█████████▍| 1702/1800 [12:15<12:20,  7.56s/pipeline]Optimization Progress:  99%|█████████▉| 1782/1800 [12:21<01:35,  5.31s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-1063297358.8949299	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [12:22<00:00,  5.31s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [12:22<00:00,  3.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [12:34<00:00,  3.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [12:35<00:00,  3.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1800/1900 [12:37<06:14,  3.74s/pipeline]Optimization Progress:  95%|█████████▍| 1801/1900 [12:37<11:43,  7.11s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [12:52<15:14,  9.33s/pipeline]Optimization Progress:  99%|█████████▉| 1882/1900 [13:01<01:58,  6.57s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-1063297358.8949299	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-4	-927119772.8627512	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-877406454.6412051	GradientBoostingRegressor(ExtraTreesRegressor(FastICA(RobustScaler(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1900/1900 [13:09<00:00,  6.57s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [13:09<00:00,  4.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1900/1900 [13:09<00:00,  4.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 1900/1900 [13:10<00:00,  4.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [13:13<00:00,  4.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1900/1900 [13:14<00:00,  4.73s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [13:18<07:30,  4.60s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [13:30<10:59,  6.80s/pipeline]Optimization Progress:  99%|█████████▉| 1983/2000 [13:35<01:21,  4.78s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-1063297358.8949299	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2000/2000 [13:35<00:00,  4.78s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [13:35<00:00,  3.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [13:39<00:00,  3.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2000/2000 [13:42<00:00,  3.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 2000/2000 [13:42<00:00,  3.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2000/2000 [13:43<00:00,  3.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2000/2000 [13:44<00:00,  3.35s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [13:50<00:00,  3.35s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [13:53<05:24,  3.41s/pipeline]Optimization Progress:  96%|█████████▌| 2006/2100 [14:45<28:23, 18.12s/pipeline]Optimization Progress:  99%|█████████▉| 2086/2100 [14:52<02:57, 12.71s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-1063155259.8350548	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-957597336.6312253	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2100/2100 [14:54<00:00, 12.71s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [14:54<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [14:58<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [14:59<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2100/2100 [14:59<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [15:04<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2100/2100 [15:04<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 2100/2100 [15:06<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2100/2100 [15:09<00:00,  8.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 2100/2100 [15:10<00:00,  8.93s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [15:12<14:46,  9.04s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [18:18<1:40:21, 62.08s/pipeline]Optimization Progress:  99%|█████████▉| 2183/2200 [18:48<12:20, 43.57s/pipeline]  
Generation 21 - Current Pareto front scores:
-1	-1063155259.8350548	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-944655442.5354112	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-822013403.2301228	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [18:56<00:00, 43.57s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [18:56<00:00, 30.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2200/2200 [19:00<00:00, 30.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [19:07<00:00, 30.64s/pipeline]Optimization Progress:  96%|█████████▌| 2201/2300 [19:07<40:59, 24.84s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [19:20<34:38, 21.21s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [19:29<04:27, 14.88s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-1062979798.546458	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-944655442.5354112	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-6	-844764096.3195685	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-822013403.2301228	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 2300/2300 [19:30<00:00, 14.88s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [19:30<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2300/2300 [19:30<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2300/2300 [19:31<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [19:34<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2300/2300 [19:34<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [19:37<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2300/2300 [19:38<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2300/2300 [19:39<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2300/2300 [19:40<00:00, 10.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2300/2300 [19:41<00:00, 10.43s/pipeline]Optimization Progress:  96%|█████████▌| 2305/2400 [19:48<13:20,  8.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2305/2400 [19:48<13:20,  8.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2306/2400 [19:48<13:12,  8.43s/pipeline]Optimization Progress:  96%|█████████▌| 2308/2400 [20:01<10:54,  7.12s/pipeline]Optimization Progress: 100%|█████████▉| 2388/2400 [20:06<01:00,  5.01s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-1062979798.546458	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-944655442.5354112	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2400/2400 [20:07<00:00,  5.01s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [20:07<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 2400/2400 [20:12<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [20:13<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [20:16<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [20:16<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2400/2400 [20:17<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2400/2400 [20:17<00:00,  3.51s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [20:20<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 2400/2400 [20:21<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [20:26<00:00,  3.51s/pipeline]Optimization Progress:  96%|█████████▌| 2402/2500 [20:26<08:40,  5.32s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [20:56<20:56, 12.95s/pipeline]Optimization Progress:  99%|█████████▉| 2483/2500 [21:04<02:34,  9.10s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-1062791087.1135309	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1015221462.3550228	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-944655442.5354112	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 2500/2500 [21:09<00:00,  9.10s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [21:09<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [21:10<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [21:13<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [21:14<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2500/2500 [21:15<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2500/2500 [21:15<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [21:17<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 2500/2500 [21:18<00:00,  6.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2500/2500 [21:19<00:00,  6.47s/pipeline]Optimization Progress:  96%|█████████▌| 2501/2600 [21:23<14:05,  8.54s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [21:35<15:57,  9.77s/pipeline]Optimization Progress:  99%|█████████▉| 2582/2600 [23:49<02:12,  7.34s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-1062791087.1135309	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1014937036.0915737	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-944655442.5354112	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [23:49<00:00,  7.34s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [23:49<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2600/2600 [23:49<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2600/2600 [23:54<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2600/2600 [23:55<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [23:57<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [24:00<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 2600/2600 [24:05<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2600/2600 [24:07<00:00,  5.14s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [24:08<10:43,  6.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [24:08<10:43,  6.56s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [25:51<31:58, 19.98s/pipeline]Optimization Progress:  99%|█████████▉| 2684/2700 [26:03<03:44, 14.03s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-1062788170.2020719	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1014937036.0915737	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-944655442.5354112	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [26:07<00:00, 14.03s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [26:07<00:00,  9.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [26:09<00:00,  9.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [26:13<00:00,  9.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 2700/2700 [26:17<00:00,  9.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [26:18<00:00,  9.89s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [26:24<14:00,  8.67s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [26:40<17:21, 10.85s/pipeline]Optimization Progress:  99%|█████████▉| 2784/2800 [27:17<02:03,  7.73s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-1062788170.2020719	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1014937036.0915737	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [27:17<00:00,  7.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2800/2800 [27:24<00:00,  7.73s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [27:24<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2800/2800 [27:32<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2800/2800 [27:32<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2800/2800 [27:33<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2800/2800 [27:37<00:00,  5.54s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [27:39<09:59,  6.12s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [27:51<13:03,  8.08s/pipeline]Optimization Progress:  99%|█████████▉| 2883/2900 [28:26<01:38,  5.78s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-1062788170.2020719	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1014937036.0915737	GradientBoostingRegressor(CombineDFs(Binarizer(input_matrix, Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [28:26<00:00,  5.78s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [28:26<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [28:28<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [28:28<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [28:28<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [28:28<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [28:30<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [28:35<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [28:37<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [28:39<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [28:39<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2900/2900 [28:39<00:00,  4.06s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [28:40<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 2900/2900 [28:45<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [28:46<00:00,  4.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2900/2900 [28:47<00:00,  4.06s/pipeline]Optimization Progress:  97%|█████████▋| 2901/3000 [29:08<25:24, 15.40s/pipeline]Optimization Progress:  99%|█████████▉| 2981/3000 [29:18<03:25, 10.82s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-1062788170.2020719	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [29:21<00:00, 10.82s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [29:21<00:00,  7.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 3000/3000 [29:31<00:00,  7.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3000/3000 [29:35<00:00,  7.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 3000/3000 [29:36<00:00,  7.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [29:42<00:00,  7.63s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [29:43<14:05,  8.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3002/3100 [29:43<14:05,  8.63s/pipeline]Optimization Progress:  97%|█████████▋| 3004/3100 [30:20<18:26, 11.53s/pipeline]Optimization Progress:  99%|█████████▉| 3084/3100 [30:30<02:09,  8.11s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-1062788170.2020719	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [30:31<00:00,  8.11s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [30:31<00:00,  5.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [30:32<00:00,  5.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [30:37<00:00,  5.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3100/3100 [30:46<00:00,  5.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3100/3100 [30:46<00:00,  5.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [30:47<00:00,  5.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 3100/3100 [30:48<00:00,  5.71s/pipeline]Optimization Progress:  97%|█████████▋| 3101/3200 [31:11<26:23, 16.00s/pipeline]Optimization Progress:  99%|█████████▉| 3181/3200 [31:26<03:33, 11.25s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-1062784666.4081051	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3200/3200 [31:28<00:00, 11.25s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [31:28<00:00,  7.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 3200/3200 [31:37<00:00,  7.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [31:39<00:00,  7.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3200/3200 [31:41<00:00,  7.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3200/3200 [31:42<00:00,  7.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [31:49<00:00,  7.92s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [31:50<14:19,  8.77s/pipeline]Optimization Progress:  97%|█████████▋| 3203/3300 [32:05<17:24, 10.77s/pipeline]Optimization Progress:  99%|█████████▉| 3283/3300 [32:13<02:08,  7.57s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-1062784666.4081051	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 3300/3300 [32:13<00:00,  7.57s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [32:13<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3300/3300 [32:18<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [32:23<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [32:25<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3300/3300 [32:32<00:00,  5.31s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [32:37<09:47,  6.06s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [34:53<1:12:08, 45.08s/pipeline]Optimization Progress: 100%|█████████▉| 3384/3400 [35:39<08:27, 31.73s/pipeline]  
Generation 33 - Current Pareto front scores:
-1	-1062761767.0807407	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3400/3400 [35:43<00:00, 31.73s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [35:43<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 3400/3400 [35:48<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [35:48<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3400/3400 [35:57<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [35:59<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 3400/3400 [36:02<00:00, 22.28s/pipeline]Optimization Progress:  97%|█████████▋| 3404/3500 [36:02<27:15, 17.04s/pipeline]Optimization Progress:  97%|█████████▋| 3405/3500 [36:15<25:00, 15.79s/pipeline]Optimization Progress: 100%|█████████▉| 3485/3500 [36:23<02:46, 11.09s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-1062761767.0807407	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [19:27:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f60ac976dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f60aca87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f60aca94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f60aca7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f60ac968f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f56ba7239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f56ba723067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f56ba73b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f56ba73bcb4]

.
Optimization Progress: 100%|██████████| 3500/3500 [36:33<00:00, 11.09s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [36:33<00:00,  7.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 3500/3500 [36:37<00:00,  7.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 3500/3500 [36:43<00:00,  7.97s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [36:46<15:30,  9.40s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [36:59<17:15, 10.56s/pipeline]Optimization Progress: 100%|█████████▉| 3582/3600 [37:10<02:13,  7.43s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-1062761767.0807407	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 3600/3600 [37:12<00:00,  7.43s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [37:12<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 3600/3600 [37:12<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3600/3600 [37:16<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3600/3600 [37:20<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [37:22<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3600/3600 [37:30<00:00,  5.23s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [37:33<11:05,  6.80s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [37:47<14:42,  9.10s/pipeline]Optimization Progress: 100%|█████████▉| 3683/3700 [37:56<01:48,  6.40s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-1062761767.0807407	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3700/3700 [37:56<00:00,  6.40s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [37:56<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [19:28:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f60ac976dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f60aca87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f60aca94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f60aca7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f60ac968f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f56ba7239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f56ba723067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f56ba73b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f56ba73bcb4]

.
Optimization Progress: 100%|██████████| 3700/3700 [38:03<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3700/3700 [38:05<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [19:28:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f60ac976dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f60aca87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f60aca94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f60aca7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f60ac968f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f56ba7239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f56ba723067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f56ba73b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f56ba73bcb4]

.
Optimization Progress: 100%|██████████| 3700/3700 [38:10<00:00,  4.49s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [38:10<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3700/3700 [38:12<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [38:14<00:00,  4.49s/pipeline]Optimization Progress:  97%|█████████▋| 3702/3800 [38:18<10:35,  6.48s/pipeline]Optimization Progress:  97%|█████████▋| 3703/3800 [40:44<1:18:00, 48.25s/pipeline]Optimization Progress: 100%|█████████▉| 3783/3800 [40:54<09:34, 33.81s/pipeline]  
Generation 37 - Current Pareto front scores:
-1	-1062761767.0807407	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3800/3800 [41:00<00:00, 33.81s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [41:00<00:00, 23.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [41:08<00:00, 23.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [41:14<00:00, 23.79s/pipeline]Optimization Progress:  97%|█████████▋| 3802/3900 [41:19<31:40, 19.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [41:19<31:40, 19.39s/pipeline]Optimization Progress:  98%|█████████▊| 3804/3900 [41:34<25:27, 15.91s/pipeline]Optimization Progress: 100%|█████████▉| 3884/3900 [41:42<02:58, 11.17s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-1062761430.6889032	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 3900/3900 [41:50<00:00, 11.17s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [41:50<00:00,  7.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3900/3900 [42:01<00:00,  7.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [42:03<00:00,  7.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3900/3900 [42:03<00:00,  7.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 3900/3900 [42:04<00:00,  7.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3900/3900 [42:05<00:00,  7.98s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [42:07<11:44,  7.27s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [42:47<27:25, 17.14s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [42:56<03:12, 12.03s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-1062744238.2887776	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-851806947.6412466	ExtraTreesRegressor(FastICA(LassoLarsCV(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), LassoLarsCV__normalize=False), FastICA__tol=0.7000000000000001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 4000/4000 [43:02<00:00, 12.03s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [43:02<00:00,  8.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4000/4000 [43:02<00:00,  8.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4000/4000 [43:07<00:00,  8.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [43:10<00:00,  8.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [43:12<00:00,  8.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [43:13<00:00,  8.54s/pipeline]Optimization Progress:  98%|█████████▊| 4001/4100 [43:19<18:14, 11.06s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [44:29<47:11, 28.89s/pipeline]Optimization Progress: 100%|█████████▉| 4082/4100 [45:05<06:06, 20.36s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-1062744238.2887776	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4100/4100 [45:05<00:00, 20.36s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [45:05<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4100/4100 [45:06<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4100/4100 [45:09<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 4100/4100 [45:10<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4100/4100 [45:13<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [45:17<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4100/4100 [45:17<00:00, 14.25s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [45:20<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4100/4100 [45:20<00:00, 14.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4100/4100 [45:29<00:00, 14.25s/pipeline]Optimization Progress:  98%|█████████▊| 4101/4200 [45:29<28:17, 17.15s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [46:05<37:14, 22.80s/pipeline]Optimization Progress: 100%|█████████▉| 4182/4200 [46:13<04:47, 15.99s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-1062744238.2887776	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:15<00:00, 15.99s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [46:15<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4200/4200 [46:16<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 4200/4200 [46:16<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4200/4200 [46:17<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:27<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:27<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:27<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:28<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4200/4200 [46:29<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:30<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 4200/4200 [46:32<00:00, 11.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:33<00:00, 11.23s/pipeline]Optimization Progress:  98%|█████████▊| 4201/4300 [46:34<22:28, 13.62s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [47:16<36:03, 22.08s/pipeline]Optimization Progress: 100%|█████████▉| 4282/4300 [47:24<04:38, 15.49s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [47:26<00:00, 15.49s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [47:26<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [47:27<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [47:29<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4300/4300 [47:32<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 4300/4300 [47:32<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4300/4300 [47:34<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [47:38<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4300/4300 [47:40<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4300/4300 [47:41<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [19:38:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f60ac976dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f60aca87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f60aca94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f60aca7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f60ac968f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f56ba7239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f56ba723067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f56ba73b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f56ba73bcb4]

.
Optimization Progress: 100%|██████████| 4300/4300 [47:48<00:00, 10.88s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [47:50<18:16, 11.19s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [48:08<21:15, 13.15s/pipeline]Optimization Progress: 100%|█████████▉| 4383/4400 [48:22<02:37,  9.26s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-8	-734256013.7726457	ElasticNetCV(GradientBoostingRegressor(ExtraTreesRegressor(FastICA(XGBRegressor(GradientBoostingRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [48:23<00:00,  9.26s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [48:23<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [48:25<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4400/4400 [48:26<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [48:28<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [48:32<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 4400/4400 [48:33<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 4400/4400 [48:33<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [48:36<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4400/4400 [48:38<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4400/4400 [48:39<00:00,  6.49s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [48:40<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 4400/4400 [48:41<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4400/4400 [48:41<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 4400/4400 [48:45<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [48:45<00:00,  6.49s/pipeline]Optimization Progress:  98%|█████████▊| 4401/4500 [49:09<30:23, 18.41s/pipeline]Optimization Progress: 100%|█████████▉| 4481/4500 [49:22<04:05, 12.94s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-8	-734256013.7726457	ElasticNetCV(GradientBoostingRegressor(ExtraTreesRegressor(FastICA(XGBRegressor(GradientBoostingRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [49:25<00:00, 12.94s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [49:25<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4500/4500 [49:30<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 4500/4500 [49:33<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [49:38<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [49:39<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [49:39<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 4500/4500 [49:40<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [49:45<00:00,  9.11s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [49:46<12:38,  7.90s/pipeline]Optimization Progress:  98%|█████████▊| 4505/4600 [50:02<16:28, 10.41s/pipeline]Optimization Progress: 100%|█████████▉| 4585/4600 [50:17<01:50,  7.34s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-8	-734256013.7726457	ElasticNetCV(GradientBoostingRegressor(ExtraTreesRegressor(FastICA(XGBRegressor(GradientBoostingRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [50:20<00:00,  7.34s/pipeline]Optimization Progress: 100%|██████████| 4600/4600 [50:20<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4600/4600 [50:31<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [50:31<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4600/4600 [50:31<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 4600/4600 [50:31<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4600/4600 [50:39<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4600/4600 [50:40<00:00,  5.20s/pipeline]Optimization Progress:  98%|█████████▊| 4605/4700 [50:41<07:45,  4.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4605/4700 [50:41<07:45,  4.90s/pipeline]Optimization Progress:  98%|█████████▊| 4607/4700 [53:28<44:13, 28.54s/pipeline]Optimization Progress: 100%|█████████▉| 4687/4700 [53:43<04:20, 20.03s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-8	-734256013.7726457	ElasticNetCV(GradientBoostingRegressor(ExtraTreesRegressor(FastICA(XGBRegressor(GradientBoostingRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 4700/4700 [53:46<00:00, 20.03s/pipeline]Optimization Progress: 100%|██████████| 4700/4700 [53:46<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [53:46<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4700/4700 [53:47<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [53:50<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [53:50<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4700/4700 [53:51<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [53:51<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [53:55<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [19:44:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f60ac976dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f60aca87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f60aca94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f60aca7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f60ac968f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f56ba7239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f56ba723067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f56ba73b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f56ba73bcb4]

.
Optimization Progress: 100%|██████████| 4700/4700 [53:57<00:00, 14.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 4700/4700 [54:00<00:00, 14.09s/pipeline]Optimization Progress:  98%|█████████▊| 4701/4800 [54:10<28:01, 16.98s/pipeline]Optimization Progress:  98%|█████████▊| 4702/4800 [54:30<29:21, 17.97s/pipeline]Optimization Progress: 100%|█████████▉| 4782/4800 [54:37<03:46, 12.61s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-8	-734256013.7726457	ElasticNetCV(GradientBoostingRegressor(ExtraTreesRegressor(FastICA(XGBRegressor(GradientBoostingRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4800/4800 [54:38<00:00, 12.61s/pipeline]Optimization Progress: 100%|██████████| 4800/4800 [54:38<00:00,  8.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [19:45:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f60ac976dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f60aca87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f60aca94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f60aca7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f60ac968f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f56ba7239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f56ba723067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f56ba73b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f56ba73bcb4]

.
Optimization Progress: 100%|██████████| 4800/4800 [54:40<00:00,  8.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4800/4800 [54:40<00:00,  8.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4800/4800 [54:49<00:00,  8.83s/pipeline]Optimization Progress: 100%|██████████| 4800/4800 [54:50<00:00,  8.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 4800/4800 [54:54<00:00,  8.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 4800/4800 [54:54<00:00,  8.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4800/4800 [55:03<00:00,  8.83s/pipeline]Optimization Progress:  98%|█████████▊| 4801/4900 [55:03<22:43, 13.78s/pipeline]Optimization Progress:  98%|█████████▊| 4802/4900 [55:54<40:31, 24.81s/pipeline]Optimization Progress: 100%|█████████▉| 4882/4900 [56:04<05:13, 17.41s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-756831766.4322048	AdaBoostRegressor(FastICA(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-750791105.2405198	AdaBoostRegressor(FastICA(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=20, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.001, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=1.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), FastICA__tol=0.9), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-7	-745159602.0094213	AdaBoostRegressor(ExtraTreesRegressor(FastICA(RobustScaler(SGDRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=1.0)), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-8	-734256013.7726457	ElasticNetCV(GradientBoostingRegressor(ExtraTreesRegressor(FastICA(XGBRegressor(GradientBoostingRegressor(RandomForestRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=6, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.35000000000000003), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=3, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4900/4900 [56:12<00:00, 17.41s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [56:12<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [56:15<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [56:16<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [56:16<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [56:23<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [56:30<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [56:32<00:00, 12.32s/pipeline]Optimization Progress:  98%|█████████▊| 4901/5000 [56:32<23:59, 14.54s/pipeline]Optimization Progress:  98%|█████████▊| 4902/5000 [56:49<25:16, 15.47s/pipeline]Optimization Progress: 100%|█████████▉| 4982/5000 [57:59<03:19, 11.09s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-731469169.450804	ExtraTreesRegressor(FastICA(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=polynomial, Nystroem__n_components=9), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5000/5000 [58:00<00:00, 11.09s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [58:00<00:00,  7.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [58:02<00:00,  7.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5000/5000 [58:02<00:00,  7.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [58:04<00:00,  7.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5000/5000 [58:16<00:00,  7.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 5000/5000 [58:17<00:00,  7.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 5000/5000 [58:23<00:00,  7.79s/pipeline]Optimization Progress:  98%|█████████▊| 5001/5100 [58:23<20:24, 12.37s/pipeline]Optimization Progress:  98%|█████████▊| 5002/5100 [58:42<23:20, 14.29s/pipeline]Optimization Progress: 100%|█████████▉| 5082/5100 [58:50<03:00, 10.03s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-731469169.450804	ExtraTreesRegressor(FastICA(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=polynomial, Nystroem__n_components=9), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5100/5100 [58:54<00:00, 10.03s/pipeline]Optimization Progress: 100%|██████████| 5100/5100 [58:54<00:00,  7.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [58:54<00:00,  7.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [58:54<00:00,  7.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5100/5100 [58:56<00:00,  7.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5100/5100 [59:04<00:00,  7.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 5100/5100 [59:06<00:00,  7.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5100/5100 [59:09<00:00,  7.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [59:10<00:00,  7.08s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5100/5200 [59:16<11:47,  7.08s/pipeline]Optimization Progress:  98%|█████████▊| 5101/5200 [59:16<19:20, 11.72s/pipeline]Optimization Progress:  98%|█████████▊| 5102/5200 [59:31<20:43, 12.69s/pipeline]Optimization Progress: 100%|█████████▉| 5182/5200 [59:40<02:40,  8.92s/pipeline]
Generation 51 - Current Pareto front scores:
-1	-1062735525.1878185	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-1008770122.7192293	GradientBoostingRegressor(CombineDFs(Binarizer(CombineDFs(input_matrix, input_matrix), Binarizer__threshold=1.0), input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4)
-3	-913277389.2589983	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)
-4	-731469169.450804	ExtraTreesRegressor(FastICA(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=polynomial, Nystroem__n_components=9), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.6000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=9, RandomForestRegressor__n_estimators=100), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5200/5200 [59:52<00:00,  8.92s/pipeline]Optimization Progress: 100%|██████████| 5200/5200 [59:52<00:00,  6.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5200/5200 [59:52<00:00,  6.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 5200/5200 [59:56<00:00,  6.44s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5200/5200 [59:57<00:00,  6.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5200/5200 [59:58<00:00,  6.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5200/5200 [1:00:00<00:00,  6.44s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5200/5200 [1:00:02<00:00,  6.44s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 5200/5200 [1:00:05<00:00,  6.44s/pipeline]Optimization Progress:  98%|█████████▊| 5201/5300 [1:00:07<15:07,  9.16s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 5201/5300 [1:00:07<15:07,  9.16s/pipeline]                                                                                  60.24 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress:  98%|█████████▊| 5201/5300 [1:00:07<15:07,  9.16s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 5201/5300 [1:00:07<15:07,  9.16s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress:  98%|█████████▊| 5201/5300 [1:00:07<15:07,  9.16s/pipeline]                                                                                  Best pipeline:
0. Nystroem(gamma=0.30000000000000004, kernel='polynomial', n_components=9)
1. StackingEstimator(estimator=RandomForestRegressor(max_features=0.6000000000000001,
                                                  min_samples_split=9))
2. FastICA(tol=0.55)
3. ExtraTreesRegressor(bootstrap=True, max_features=0.9000000000000001,
                    min_samples_leaf=5, min_samples_split=11)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
