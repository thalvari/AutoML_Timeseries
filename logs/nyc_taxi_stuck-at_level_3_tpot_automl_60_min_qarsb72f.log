30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:  11%|█         | 11/100 [00:11<01:36,  1.08s/pipeline]Optimization Progress:  91%|█████████ | 91/100 [00:15<00:06,  1.30pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.30pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.84pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  1.84pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:17<00:00,  1.84pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:18<00:00,  1.84pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  50%|█████     | 101/200 [00:21<00:53,  1.84pipeline/s]Optimization Progress:  52%|█████▏    | 103/200 [00:27<02:33,  1.58s/pipeline]Optimization Progress:  92%|█████████▏| 183/200 [00:31<00:19,  1.12s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-933007367.049402	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-834327275.1938341	LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:55:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f45209a4dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f4520ab5669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f4520ac2f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f4520aa9cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f4520996f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3b2e7519dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3b2e751067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3b2e76927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3b2e769cb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:31<00:00,  1.12s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:31<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:55:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f45209a4dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f4520ab5669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f4520ac2f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f4520aa9cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f4520996f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3b2e7519dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3b2e751067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3b2e76927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3b2e769cb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:31<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 200/200 [00:32<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:35<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:36<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:36<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:37<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:39<00:00,  1.26pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:39<00:00,  1.26pipeline/s]Optimization Progress:  68%|██████▊   | 204/300 [00:39<01:45,  1.10s/pipeline]Optimization Progress:  69%|██████▊   | 206/300 [00:48<03:32,  2.26s/pipeline]Optimization Progress:  95%|█████████▌| 285/300 [00:51<00:23,  1.59s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-933007367.049402	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-834327275.1938341	LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.59s/pipeline]Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [00:56<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:59<00:00,  1.18s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [01:00<02:06,  1.30s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  76%|███████▌  | 303/400 [01:00<02:06,  1.30s/pipeline]Optimization Progress:  76%|███████▋  | 305/400 [01:08<03:23,  2.15s/pipeline]Optimization Progress:  96%|█████████▋| 385/400 [01:13<00:22,  1.52s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-933007367.049402	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-834327275.1938341	LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 400/400 [01:14<00:00,  1.52s/pipeline]Optimization Progress: 100%|██████████| 400/400 [01:14<00:00,  1.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [01:16<00:00,  1.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:16<00:00,  1.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:17<00:00,  1.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:17<00:00,  1.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [01:19<00:00,  1.09s/pipeline]Optimization Progress:  80%|████████  | 402/500 [01:19<02:30,  1.53s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 402/500 [01:19<02:30,  1.53s/pipeline]Optimization Progress:  81%|████████  | 404/500 [01:48<08:36,  5.38s/pipeline]Optimization Progress:  97%|█████████▋| 484/500 [01:59<01:00,  3.81s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-851191512.9800701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-834327275.1938341	LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5), LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 500/500 [01:59<00:00,  3.81s/pipeline]Optimization Progress: 100%|██████████| 500/500 [01:59<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:02<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:02<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:05<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:05<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:06<00:00,  2.68s/pipeline]Optimization Progress:  84%|████████▍ | 503/600 [02:06<04:09,  2.57s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▍ | 503/600 [02:06<04:09,  2.57s/pipeline]Optimization Progress:  84%|████████▍ | 505/600 [02:19<05:48,  3.66s/pipeline]Optimization Progress:  98%|█████████▊| 585/600 [02:26<00:38,  2.59s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:57:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f45209a4dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f4520ab5669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f4520ac2f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f4520aa9cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f4520996f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3b2e7519dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3b2e751067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3b2e76927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3b2e769cb4]

.
Optimization Progress: 100%|██████████| 600/600 [02:30<00:00,  2.59s/pipeline]Optimization Progress: 100%|██████████| 600/600 [02:30<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:31<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [02:31<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [02:32<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:32<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:32<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:32<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:33<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:58:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f45209a4dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f4520ab5669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f4520ac2f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f4520aa9cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f4520996f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3b2e7519dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3b2e751067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3b2e76927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3b2e769cb4]

.
Optimization Progress: 100%|██████████| 600/600 [02:34<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [02:34<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 600/600 [02:34<00:00,  1.89s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [02:34<00:00,  1.89s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [02:34<03:11,  1.95s/pipeline]Optimization Progress:  86%|████████▌ | 603/700 [03:26<27:32, 17.03s/pipeline]Optimization Progress:  98%|█████████▊| 683/700 [03:35<03:23, 11.96s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 700/700 [03:35<00:00, 11.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [03:45<00:00, 11.96s/pipeline]Optimization Progress: 100%|██████████| 700/700 [03:45<00:00,  8.54s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [03:46<10:24,  6.31s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [04:20<23:38, 14.48s/pipeline]Optimization Progress:  98%|█████████▊| 782/800 [04:27<03:02, 10.16s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [04:28<00:00, 10.16s/pipeline]Optimization Progress: 100%|██████████| 800/800 [04:28<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [04:30<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [04:31<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [04:33<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [07:00:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f45209a4dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f4520ab5669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f4520ac2f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f4520aa9cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f4520996f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3b2e7519dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3b2e751067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3b2e76927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3b2e769cb4]

.
Optimization Progress: 100%|██████████| 800/800 [04:34<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 800/800 [04:35<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [04:35<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 800/800 [04:36<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [04:38<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 800/800 [04:38<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [04:39<00:00,  7.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [04:39<00:00,  7.13s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [04:40<13:55,  8.43s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [05:08<23:22, 14.31s/pipeline]Optimization Progress:  98%|█████████▊| 882/900 [05:37<03:02, 10.13s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:38<00:00, 10.13s/pipeline]Optimization Progress: 100%|██████████| 900/900 [05:38<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [05:38<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:38<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:38<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:39<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:40<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:41<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:41<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:41<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:41<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:41<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 900/900 [05:42<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:44<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:47<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [05:48<00:00,  7.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [05:48<00:00,  7.10s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [05:51<14:37,  8.87s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [06:17<23:19, 14.28s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [06:45<03:01, 10.10s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [06:47<00:00, 10.10s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [06:47<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [06:48<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [06:50<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [06:56<00:00,  7.11s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [07:00<11:20,  6.94s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [07:00<11:20,  6.94s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  91%|█████████ | 1003/1100 [07:00<11:13,  6.94s/pipeline]Optimization Progress:  91%|█████████▏| 1005/1100 [07:13<09:44,  6.15s/pipeline]Optimization Progress:  99%|█████████▊| 1085/1100 [07:35<01:05,  4.38s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:35<00:00,  4.38s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [07:35<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [07:36<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:38<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:38<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:45<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 1100/1100 [07:45<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 1100/1100 [07:46<00:00,  3.07s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [07:48<05:39,  3.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1103/1200 [07:48<05:39,  3.50s/pipeline]Optimization Progress:  92%|█████████▏| 1105/1200 [08:05<07:52,  4.97s/pipeline]Optimization Progress:  99%|█████████▉| 1185/1200 [08:16<00:52,  3.52s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 1200/1200 [08:16<00:00,  3.52s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [08:16<00:00,  2.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [08:17<00:00,  2.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [08:17<00:00,  2.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [08:18<00:00,  2.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [08:19<00:00,  2.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [08:26<00:00,  2.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [08:27<00:00,  2.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 1200/1200 [08:28<00:00,  2.47s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [08:30<04:01,  2.47s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [08:58<09:29,  5.87s/pipeline]Optimization Progress:  99%|█████████▊| 1283/1300 [09:09<01:10,  4.15s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:10<00:00,  4.15s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [09:10<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:11<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:11<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:14<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1300/1300 [09:15<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:16<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:16<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1300/1300 [09:18<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:18<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 1300/1300 [09:18<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1300/1300 [09:19<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:19<00:00,  2.93s/pipeline]Optimization Progress:  93%|█████████▎| 1302/1400 [09:20<05:39,  3.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1302/1400 [09:20<05:39,  3.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1303/1400 [09:20<05:35,  3.46s/pipeline]Optimization Progress:  93%|█████████▎| 1305/1400 [09:37<06:33,  4.15s/pipeline]Optimization Progress:  99%|█████████▉| 1385/1400 [09:54<00:44,  2.97s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:55<00:00,  2.97s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [09:55<00:00,  2.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:55<00:00,  2.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [09:56<00:00,  2.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:00<00:00,  2.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [10:01<00:00,  2.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:04<00:00,  2.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [10:04<00:00,  2.08s/pipeline]Optimization Progress:  93%|█████████▎| 1400/1500 [10:10<03:28,  2.08s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [10:21<15:13,  9.22s/pipeline]Optimization Progress:  99%|█████████▊| 1481/1500 [10:27<02:03,  6.48s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [10:32<00:00,  6.48s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [10:32<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [10:34<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 1500/1500 [10:34<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1500/1500 [10:35<00:00,  4.62s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [10:36<05:48,  3.59s/pipeline]Optimization Progress:  94%|█████████▍| 1504/1600 [10:57<14:04,  8.80s/pipeline]Optimization Progress:  99%|█████████▉| 1584/1600 [11:07<01:39,  6.20s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 100%|██████████| 1600/1600 [11:07<00:00,  6.20s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [11:07<00:00,  4.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [11:08<00:00,  4.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1600/1600 [11:09<00:00,  4.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [11:09<00:00,  4.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 1600/1600 [11:10<00:00,  4.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 1600/1600 [11:11<00:00,  4.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1600/1600 [11:14<00:00,  4.35s/pipeline]Optimization Progress:  94%|█████████▍| 1603/1700 [11:15<06:07,  3.79s/pipeline]Optimization Progress:  94%|█████████▍| 1604/1700 [11:25<09:05,  5.69s/pipeline]Optimization Progress:  99%|█████████▉| 1684/1700 [11:31<01:04,  4.00s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [11:32<00:00,  4.00s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [11:32<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [11:32<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [11:37<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [11:40<00:00,  2.81s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [11:41<04:42,  2.91s/pipeline]Optimization Progress:  95%|█████████▍| 1704/1800 [11:52<08:35,  5.37s/pipeline]Optimization Progress:  99%|█████████▉| 1784/1800 [11:58<01:00,  3.78s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [11:59<00:00,  3.78s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [11:59<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 1800/1800 [12:00<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1800/1800 [12:00<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [12:01<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [12:01<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [12:06<00:00,  2.68s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1800/1900 [12:07<04:27,  2.68s/pipeline]Optimization Progress:  95%|█████████▍| 1801/1900 [12:07<06:53,  4.17s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [12:19<10:49,  6.63s/pipeline]Optimization Progress:  99%|█████████▉| 1882/1900 [12:26<01:23,  4.67s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [12:28<00:00,  4.67s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [12:28<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [12:28<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [12:31<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [12:34<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 1900/1900 [12:35<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [12:35<00:00,  3.30s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [12:36<05:00,  3.10s/pipeline]Optimization Progress:  95%|█████████▌| 1904/2000 [12:45<08:09,  5.10s/pipeline]Optimization Progress:  99%|█████████▉| 1984/2000 [12:52<00:57,  3.59s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [12:53<00:00,  3.59s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [12:53<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 2000/2000 [12:56<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [12:57<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 2000/2000 [12:59<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [13:02<00:00,  2.54s/pipeline]Optimization Progress:  95%|█████████▌| 2001/2100 [13:02<07:17,  4.42s/pipeline]Optimization Progress:  95%|█████████▌| 2002/2100 [13:14<10:56,  6.70s/pipeline]Optimization Progress:  99%|█████████▉| 2082/2100 [13:23<01:24,  4.72s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [13:23<00:00,  4.72s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [13:23<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [13:23<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [13:25<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [13:26<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [13:26<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [13:30<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [13:31<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2100/2100 [13:31<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [13:33<00:00,  3.31s/pipeline]Optimization Progress:  96%|█████████▌| 2107/2200 [13:34<04:17,  2.77s/pipeline]Optimization Progress:  96%|█████████▌| 2108/2200 [13:47<08:55,  5.82s/pipeline]Optimization Progress:  99%|█████████▉| 2188/2200 [13:53<00:49,  4.10s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [13:53<00:00,  4.10s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [13:53<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [13:53<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [13:55<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [13:55<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [13:55<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [13:57<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [13:59<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 2200/2200 [13:59<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 2200/2200 [14:00<00:00,  2.87s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2201/2300 [14:04<04:44,  2.87s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [14:10<04:41,  2.87s/pipeline]Optimization Progress:  96%|█████████▌| 2203/2300 [14:17<07:06,  4.39s/pipeline]Optimization Progress:  99%|█████████▉| 2283/2300 [14:29<00:53,  3.12s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [14:29<00:00,  3.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [14:33<00:00,  3.12s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [14:33<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 2300/2300 [14:33<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2300/2300 [14:33<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 2300/2300 [14:36<00:00,  2.26s/pipeline]Optimization Progress:  96%|█████████▌| 2304/2400 [14:39<03:16,  2.05s/pipeline]Optimization Progress:  96%|█████████▌| 2305/2400 [14:49<06:53,  4.36s/pipeline]Optimization Progress:  99%|█████████▉| 2385/2400 [14:57<00:46,  3.08s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2400/2400 [14:57<00:00,  3.08s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [14:57<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 2400/2400 [14:57<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 2400/2400 [14:58<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [14:59<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [14:59<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [15:02<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2400/2400 [15:02<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2400/2400 [15:05<00:00,  2.16s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2402/2500 [15:08<03:31,  2.16s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [15:08<04:11,  2.59s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [15:20<08:33,  5.35s/pipeline]Optimization Progress:  99%|█████████▉| 2484/2500 [15:26<01:00,  3.77s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2500/2500 [15:26<00:00,  3.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 2500/2500 [15:32<00:00,  3.77s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [15:32<00:00,  2.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [15:34<00:00,  2.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [15:37<00:00,  2.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [15:37<00:00,  2.76s/pipeline]Optimization Progress:  96%|█████████▌| 2501/2600 [15:39<06:16,  3.80s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2501/2600 [15:39<06:16,  3.80s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [15:50<07:04,  4.38s/pipeline]Optimization Progress:  99%|█████████▉| 2583/2600 [16:00<00:52,  3.10s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:02<00:00,  3.10s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [16:02<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2600/2600 [16:03<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:03<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:06<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2600/2600 [16:07<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:08<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:09<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 2600/2600 [16:10<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:11<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 2600/2600 [16:12<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2600/2600 [16:12<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:12<00:00,  2.20s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [16:12<03:45,  2.34s/pipeline]Optimization Progress:  96%|█████████▋| 2605/2700 [16:23<07:37,  4.82s/pipeline]Optimization Progress:  99%|█████████▉| 2685/2700 [16:33<00:51,  3.41s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [16:33<00:00,  3.41s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [16:33<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2700/2700 [16:34<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2700/2700 [16:37<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 2700/2700 [16:37<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 100%|██████████| 2700/2700 [16:37<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [16:38<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [16:39<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [16:39<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2700/2700 [16:43<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [16:43<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2700/2700 [16:45<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2700/2700 [16:45<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [16:47<00:00,  2.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2704/2800 [16:49<03:49,  2.39s/pipeline]Optimization Progress:  97%|█████████▋| 2705/2800 [16:49<04:04,  2.58s/pipeline]Optimization Progress:  97%|█████████▋| 2706/2800 [17:49<31:21, 20.01s/pipeline]Optimization Progress: 100%|█████████▉| 2786/2800 [17:59<03:16, 14.05s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [18:01<00:00, 14.05s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [18:01<00:00,  9.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [18:01<00:00,  9.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2800/2800 [18:01<00:00,  9.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2800/2800 [18:02<00:00,  9.87s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2800/2800 [18:03<00:00,  9.87s/pipeline]Optimization Progress:  97%|█████████▋| 2804/2900 [18:10<12:13,  7.64s/pipeline]Optimization Progress:  97%|█████████▋| 2805/2900 [18:24<14:51,  9.38s/pipeline]Optimization Progress:  99%|█████████▉| 2885/2900 [18:35<01:39,  6.61s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [18:36<00:00,  6.61s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [18:36<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [18:37<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [18:37<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 2900/2900 [18:38<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [18:38<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [18:40<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [18:41<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [18:42<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [18:42<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [18:43<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [18:43<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [18:43<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [18:44<00:00,  4.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [18:45<00:00,  4.64s/pipeline]Optimization Progress:  97%|█████████▋| 2901/3000 [18:50<07:39,  4.64s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [19:00<11:13,  6.87s/pipeline]Optimization Progress:  99%|█████████▉| 2982/3000 [19:15<01:27,  4.87s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [19:17<00:00,  4.87s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [19:17<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [19:17<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 3000/3000 [19:17<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [19:17<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [19:18<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 3000/3000 [19:19<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 3000/3000 [19:21<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 3000/3000 [19:21<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 3000/3000 [19:26<00:00,  3.43s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [19:41<16:12,  9.82s/pipeline]Optimization Progress:  99%|█████████▉| 3081/3100 [19:54<02:11,  6.92s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [19:54<00:00,  6.92s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [19:54<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [19:54<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 3100/3100 [19:56<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [19:57<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [19:58<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [19:58<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:00<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:00<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [20:00<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:00<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 3100/3100 [20:00<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:00<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:01<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [20:02<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [20:03<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:05<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:05<00:00,  4.85s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [20:06<00:00,  4.85s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [20:10<07:50,  4.85s/pipeline]Optimization Progress:  97%|█████████▋| 3104/3200 [20:19<08:27,  5.29s/pipeline]Optimization Progress: 100%|█████████▉| 3184/3200 [20:32<00:59,  3.75s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [20:33<00:00,  3.75s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [20:33<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [20:38<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3200/3200 [20:38<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [20:38<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [20:39<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3200/3200 [20:42<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3200/3200 [20:43<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3200/3200 [20:43<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3200/3200 [20:45<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3200/3200 [20:45<00:00,  2.65s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [20:46<06:07,  3.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [20:46<06:07,  3.75s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [21:00<07:33,  4.72s/pipeline]Optimization Progress: 100%|█████████▉| 3284/3300 [21:08<00:53,  3.33s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3300/3300 [21:08<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 3300/3300 [21:08<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3300/3300 [21:09<00:00,  3.33s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [21:09<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3300/3300 [21:09<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [21:09<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [21:12<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [21:13<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [21:14<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [21:15<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [21:16<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [21:20<00:00,  2.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [21:21<00:00,  2.35s/pipeline]Optimization Progress:  97%|█████████▋| 3301/3400 [21:21<08:53,  5.39s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [21:32<11:26,  7.01s/pipeline]Optimization Progress:  99%|█████████▉| 3382/3400 [21:41<01:28,  4.94s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3400/3400 [21:44<00:00,  4.94s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [21:44<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3400/3400 [21:47<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3400/3400 [21:48<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3400/3400 [21:49<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [21:49<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3400/3400 [21:50<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 3400/3400 [21:51<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 3400/3400 [21:51<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [21:53<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3400/3400 [21:55<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3400/3400 [21:55<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [21:55<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [21:56<00:00,  3.50s/pipeline]Optimization Progress:  97%|█████████▋| 3401/3500 [21:56<10:19,  6.26s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [22:11<14:18,  8.76s/pipeline]Optimization Progress:  99%|█████████▉| 3482/3500 [22:19<01:50,  6.16s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [22:19<00:00,  6.16s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [22:19<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [22:24<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3500/3500 [22:24<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 3500/3500 [22:27<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3500/3500 [22:28<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3500/3500 [22:29<00:00,  4.32s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [22:30<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [22:31<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [22:32<00:00,  4.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [22:33<00:00,  4.32s/pipeline]Optimization Progress:  97%|█████████▋| 3504/3600 [22:33<06:31,  4.08s/pipeline]Optimization Progress:  97%|█████████▋| 3505/3600 [22:48<11:38,  7.35s/pipeline]Optimization Progress: 100%|█████████▉| 3585/3600 [23:00<01:17,  5.19s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3600/3600 [23:00<00:00,  5.19s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [23:00<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [23:04<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3600/3600 [23:05<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:05<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3600/3600 [23:05<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:08<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3600/3600 [23:08<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:09<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [23:09<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [23:09<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:12<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3600/3600 [23:13<00:00,  3.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3600/3600 [23:15<00:00,  3.65s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [23:20<06:00,  3.65s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [23:29<11:09,  6.83s/pipeline]Optimization Progress: 100%|█████████▉| 3682/3700 [23:38<01:26,  4.82s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [23:39<00:00,  4.82s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [23:39<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [23:40<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [23:41<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [23:42<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [23:44<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [23:45<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [23:46<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [23:46<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [23:49<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3700/3700 [23:50<00:00,  3.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 3700/3700 [23:54<00:00,  3.38s/pipeline]Optimization Progress:  97%|█████████▋| 3701/3800 [24:08<18:34, 11.25s/pipeline]Optimization Progress: 100%|█████████▉| 3781/3800 [24:17<02:30,  7.91s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3800/3800 [24:18<00:00,  7.91s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [24:18<00:00,  5.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3800/3800 [24:20<00:00,  5.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3800/3800 [24:20<00:00,  5.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:21<00:00,  5.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3800/3800 [24:22<00:00,  5.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 3800/3800 [24:24<00:00,  5.55s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:25<00:00,  5.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [24:27<00:00,  5.55s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [24:30<00:00,  5.55s/pipeline]Optimization Progress:  97%|█████████▋| 3801/3900 [24:47<20:59, 12.72s/pipeline]Optimization Progress: 100%|█████████▉| 3881/3900 [25:02<02:50,  8.96s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [25:02<00:00,  8.96s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [25:02<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [25:02<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [25:03<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [25:03<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3900/3900 [25:06<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3900/3900 [25:10<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [25:12<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [25:12<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3900/3900 [25:15<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [25:16<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3900/3900 [25:16<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3900/3900 [25:17<00:00,  6.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [25:18<00:00,  6.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3900/4000 [25:18<10:27,  6.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3901/4000 [25:18<10:21,  6.28s/pipeline]Optimization Progress:  98%|█████████▊| 3902/4000 [25:18<11:09,  6.83s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [25:18<11:09,  6.83s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [25:34<11:24,  7.13s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [25:47<01:20,  5.04s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [25:52<00:00,  5.04s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [25:52<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 4000/4000 [25:52<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4000/4000 [25:54<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4000/4000 [26:00<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4000/4000 [26:01<00:00,  3.61s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [26:03<06:49,  4.18s/pipeline]Optimization Progress:  98%|█████████▊| 4003/4100 [26:18<11:43,  7.26s/pipeline]Optimization Progress: 100%|█████████▉| 4083/4100 [26:35<01:27,  5.14s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:35<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [26:35<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [26:35<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:36<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:36<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [26:39<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [26:40<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:41<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [26:41<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:48<00:00,  3.61s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [26:50<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:50<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 4100/4100 [26:50<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:51<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [26:51<00:00,  3.61s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4100/4200 [26:52<06:00,  3.61s/pipeline]Optimization Progress:  98%|█████████▊| 4101/4200 [26:52<12:35,  7.63s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [27:08<16:22, 10.02s/pipeline]Optimization Progress: 100%|█████████▉| 4182/4200 [27:19<02:06,  7.05s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4200/4200 [27:19<00:00,  7.05s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [27:19<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4200/4200 [27:19<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4200/4200 [27:20<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [27:22<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4200/4200 [27:24<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4200/4200 [27:27<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [27:27<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [27:29<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [27:30<00:00,  4.94s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [27:30<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [27:31<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [27:34<00:00,  4.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [27:34<00:00,  4.94s/pipeline]Optimization Progress:  98%|█████████▊| 4201/4300 [27:36<14:26,  8.75s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [28:13<27:48, 17.03s/pipeline]Optimization Progress: 100%|█████████▉| 4282/4300 [28:21<03:35, 11.95s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:23<00:00, 11.95s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [28:23<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [28:24<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [28:25<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [28:27<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:27<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [28:27<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:28<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 4300/4300 [28:29<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:29<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [28:31<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:33<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:33<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [28:34<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:35<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:36<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [28:36<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:37<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [28:37<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:38<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:38<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [28:39<00:00,  8.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [28:40<00:00,  8.39s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [28:41<14:10,  8.68s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [28:55<16:16, 10.06s/pipeline]Optimization Progress: 100%|█████████▉| 4383/4400 [29:04<02:00,  7.08s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4400/4400 [29:07<00:00,  7.08s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [29:07<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4400/4400 [29:08<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4400/4400 [29:10<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4400/4400 [29:14<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4400/4400 [29:19<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [29:20<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4400/4400 [29:22<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [29:24<00:00,  5.01s/pipeline]Optimization Progress:  98%|█████████▊| 4401/4500 [29:38<21:27, 13.00s/pipeline]Optimization Progress: 100%|█████████▉| 4481/4500 [29:50<02:53,  9.14s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4500/4500 [29:50<00:00,  9.14s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [29:50<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4500/4500 [29:53<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [29:56<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4500/4500 [29:59<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [30:03<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [30:04<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4500/4500 [30:06<00:00,  6.41s/pipeline]Optimization Progress:  98%|█████████▊| 4502/4600 [30:08<11:31,  7.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4502/4600 [30:08<11:31,  7.06s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [30:23<11:39,  7.29s/pipeline]Optimization Progress: 100%|█████████▉| 4584/4600 [30:33<01:22,  5.14s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4600/4600 [30:38<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 4600/4600 [30:38<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4600/4600 [30:40<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4600/4600 [30:40<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [30:45<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4600/4600 [30:46<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4600/4600 [30:46<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [30:47<00:00,  3.69s/pipeline]Optimization Progress:  98%|█████████▊| 4604/4700 [30:48<05:16,  3.30s/pipeline]Optimization Progress:  98%|█████████▊| 4605/4700 [31:04<11:36,  7.33s/pipeline]Optimization Progress: 100%|█████████▉| 4685/4700 [31:16<01:17,  5.17s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [31:16<00:00,  5.17s/pipeline]Optimization Progress: 100%|██████████| 4700/4700 [31:16<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4700/4700 [31:17<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 4700/4700 [31:17<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 4700/4700 [31:19<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [31:20<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4700/4700 [31:20<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4700/4700 [31:23<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 4700/4700 [31:24<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4700/4700 [31:25<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [31:29<00:00,  3.63s/pipeline]Optimization Progress: 100%|██████████| 4700/4700 [31:30<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4700/4700 [31:31<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4700/4700 [31:32<00:00,  3.63s/pipeline]Optimization Progress:  98%|█████████▊| 4705/4800 [31:34<05:45,  3.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4705/4800 [31:34<05:45,  3.63s/pipeline]Optimization Progress:  98%|█████████▊| 4707/4800 [31:53<08:11,  5.28s/pipeline]Optimization Progress: 100%|█████████▉| 4787/4800 [32:03<00:48,  3.74s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4800/4800 [32:05<00:00,  3.74s/pipeline]Optimization Progress: 100%|██████████| 4800/4800 [32:05<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 4800/4800 [32:06<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4800/4800 [32:07<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4800/4800 [32:10<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4800/4800 [32:12<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4800/4800 [32:19<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4800/4800 [32:21<00:00,  2.67s/pipeline]Optimization Progress:  98%|█████████▊| 4801/4900 [32:22<11:21,  6.89s/pipeline]Optimization Progress:  98%|█████████▊| 4802/4900 [32:36<14:39,  8.97s/pipeline]Optimization Progress: 100%|█████████▉| 4882/4900 [32:46<01:53,  6.32s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4900/4900 [32:47<00:00,  6.32s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [32:47<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4900/4900 [32:48<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [32:48<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [32:48<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4900/4900 [32:52<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4900/4900 [32:53<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4900/4900 [32:53<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [32:53<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 4900/4900 [32:53<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [32:53<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [32:53<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4900/4900 [32:57<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 4900/4900 [32:57<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [32:58<00:00,  4.44s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [33:00<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [33:00<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4900/4900 [33:02<00:00,  4.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4900/5000 [33:05<07:23,  4.44s/pipeline]Optimization Progress:  98%|█████████▊| 4901/5000 [33:05<13:50,  8.38s/pipeline]Optimization Progress:  98%|█████████▊| 4902/5000 [33:18<16:00,  9.80s/pipeline]Optimization Progress: 100%|█████████▉| 4982/5000 [33:29<02:04,  6.90s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5000/5000 [33:30<00:00,  6.90s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [33:30<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [33:31<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [33:32<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5000/5000 [33:38<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [33:38<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5000/5000 [33:39<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5000/5000 [33:39<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [33:41<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [33:42<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [33:43<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 5000/5000 [33:44<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5000/5000 [33:45<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 5000/5000 [33:46<00:00,  4.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [33:47<00:00,  4.84s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [33:50<00:00,  4.84s/pipeline]Optimization Progress:  98%|█████████▊| 5001/5100 [33:50<15:28,  9.38s/pipeline]Optimization Progress:  98%|█████████▊| 5002/5100 [34:05<17:50, 10.92s/pipeline]Optimization Progress: 100%|█████████▉| 5082/5100 [34:22<02:18,  7.71s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-618533777.697501	GradientBoostingRegressor(ElasticNetCV(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=0.01), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5100/5100 [34:23<00:00,  7.71s/pipeline]Optimization Progress: 100%|██████████| 5100/5100 [34:23<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5100/5100 [34:24<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [34:24<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 100%|██████████| 5100/5100 [34:28<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5100/5100 [34:38<00:00,  5.41s/pipeline]Optimization Progress: 100%|██████████| 5100/5100 [34:40<00:00,  5.41s/pipeline]Optimization Progress:  98%|█████████▊| 5101/5200 [34:42<15:37,  9.47s/pipeline]Optimization Progress:  98%|█████████▊| 5102/5200 [34:59<19:03, 11.67s/pipeline]Optimization Progress: 100%|█████████▉| 5182/5200 [35:13<02:27,  8.22s/pipeline]
Generation 51 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-610928071.9949143	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.2, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5200/5200 [35:13<00:00,  8.22s/pipeline]Optimization Progress: 100%|██████████| 5200/5200 [35:13<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [35:15<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5200/5200 [35:15<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 5200/5200 [35:18<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5200/5200 [35:21<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [35:22<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 5200/5200 [35:22<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5200/5200 [35:27<00:00,  5.76s/pipeline]Optimization Progress: 100%|██████████| 5200/5200 [35:30<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5200/5200 [35:31<00:00,  5.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5200/5200 [35:32<00:00,  5.76s/pipeline]Optimization Progress:  98%|█████████▊| 5203/5300 [35:34<09:53,  6.12s/pipeline]Optimization Progress:  98%|█████████▊| 5204/5300 [35:51<15:17,  9.55s/pipeline]Optimization Progress: 100%|█████████▉| 5284/5300 [36:07<01:47,  6.75s/pipeline]
Generation 52 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-610928071.9949143	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.2, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5300/5300 [36:07<00:00,  6.75s/pipeline]Optimization Progress: 100%|██████████| 5300/5300 [36:07<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5300/5300 [36:08<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [36:09<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5300/5300 [36:13<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5300/5300 [36:16<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5300/5300 [36:18<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 5300/5300 [36:18<00:00,  4.72s/pipeline]Optimization Progress: 100%|██████████| 5300/5300 [36:20<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 5300/5300 [36:20<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5300/5300 [36:26<00:00,  4.72s/pipeline]Optimization Progress:  98%|█████████▊| 5301/5400 [36:42<22:47, 13.81s/pipeline]Optimization Progress: 100%|█████████▉| 5381/5400 [36:50<03:04,  9.70s/pipeline]
Generation 53 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-641067303.9038502	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-4	-610928071.9949143	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.2, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5400/5400 [36:50<00:00,  9.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 5400/5400 [36:50<00:00,  9.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5400/5400 [36:51<00:00,  9.70s/pipeline]Optimization Progress: 100%|██████████| 5400/5400 [36:51<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5400/5400 [36:55<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5400/5400 [36:57<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 5400/5400 [37:01<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5400/5400 [37:02<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5400/5400 [37:04<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5400/5400 [37:04<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [37:04<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [37:04<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5400/5400 [37:06<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5400/5400 [37:06<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [37:06<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5400/5400 [37:07<00:00,  6.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5400/5400 [37:09<00:00,  6.81s/pipeline]Optimization Progress:  98%|█████████▊| 5401/5500 [37:09<16:35, 10.05s/pipeline]Optimization Progress:  98%|█████████▊| 5402/5500 [37:24<19:01, 11.65s/pipeline]Optimization Progress: 100%|█████████▉| 5482/5500 [37:35<02:27,  8.19s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-641067303.9038502	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5500/5500 [37:37<00:00,  8.19s/pipeline]Optimization Progress: 100%|██████████| 5500/5500 [37:37<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5500/5500 [37:41<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [37:42<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5500/5500 [37:42<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 5500/5500 [37:45<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [37:48<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5500/5500 [37:49<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [37:50<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5500/5500 [37:51<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5500/5500 [37:51<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5500/5500 [37:53<00:00,  5.77s/pipeline]Optimization Progress:  98%|█████████▊| 5501/5600 [37:55<15:33,  9.43s/pipeline]Optimization Progress:  98%|█████████▊| 5502/5600 [38:59<42:12, 25.85s/pipeline]Optimization Progress: 100%|█████████▉| 5582/5600 [39:09<05:26, 18.13s/pipeline]
Generation 55 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-641067303.9038502	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [39:10<00:00, 18.13s/pipeline]Optimization Progress: 100%|██████████| 5600/5600 [39:10<00:00, 12.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [39:11<00:00, 12.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [39:14<00:00, 12.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [39:17<00:00, 12.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5600/5600 [39:17<00:00, 12.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5600/5600 [39:18<00:00, 12.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [39:26<00:00, 12.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 5600/5600 [39:27<00:00, 12.71s/pipeline]Optimization Progress:  98%|█████████▊| 5601/5700 [39:29<24:12, 14.67s/pipeline]Optimization Progress:  98%|█████████▊| 5602/5700 [39:44<24:06, 14.76s/pipeline]Optimization Progress: 100%|█████████▉| 5682/5700 [39:54<03:06, 10.37s/pipeline]
Generation 56 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-641067303.9038502	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [39:55<00:00, 10.37s/pipeline]Optimization Progress: 100%|██████████| 5700/5700 [39:55<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [39:55<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [39:55<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5700/5700 [39:56<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [39:59<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:01<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [40:01<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:04<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:04<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:05<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [40:06<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:09<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 5700/5700 [40:10<00:00,  7.26s/pipeline]Optimization Progress: 100%|██████████| 5700/5700 [40:10<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:11<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:11<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5700/5700 [40:11<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:12<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 5700/5700 [40:12<00:00,  7.26s/pipeline]Optimization Progress:  98%|█████████▊| 5702/5800 [40:14<12:56,  7.92s/pipeline]Optimization Progress:  98%|█████████▊| 5703/5800 [40:29<16:14, 10.05s/pipeline]Optimization Progress: 100%|█████████▉| 5783/5800 [40:36<02:00,  7.06s/pipeline]
Generation 57 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-638934805.9028171	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.5, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5800/5800 [40:37<00:00,  7.06s/pipeline]Optimization Progress: 100%|██████████| 5800/5800 [40:37<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5800/5800 [40:37<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [40:37<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [40:42<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [40:43<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [40:46<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 5800/5800 [40:50<00:00,  4.95s/pipeline]Optimization Progress: 100%|██████████| 5800/5800 [40:50<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [40:51<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 5800/5800 [40:52<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [40:54<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [40:56<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [40:59<00:00,  4.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5800/5800 [41:00<00:00,  4.95s/pipeline]Optimization Progress:  98%|█████████▊| 5801/5900 [41:15<24:35, 14.91s/pipeline]Optimization Progress: 100%|█████████▉| 5881/5900 [41:26<03:19, 10.48s/pipeline]
Generation 58 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-638934805.9028171	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.5, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5900/5900 [41:32<00:00, 10.48s/pipeline]Optimization Progress: 100%|██████████| 5900/5900 [41:32<00:00,  7.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5900/5900 [41:33<00:00,  7.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5900/5900 [41:34<00:00,  7.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5900/5900 [41:35<00:00,  7.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5900/5900 [41:36<00:00,  7.42s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5900/5900 [41:37<00:00,  7.42s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5900/5900 [41:42<00:00,  7.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5900/5900 [41:46<00:00,  7.42s/pipeline]Optimization Progress:  98%|█████████▊| 5901/6000 [41:46<15:38,  9.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5901/6000 [41:46<15:38,  9.48s/pipeline]Optimization Progress:  98%|█████████▊| 5903/6000 [42:03<14:53,  9.21s/pipeline]Optimization Progress: 100%|█████████▉| 5983/6000 [42:13<01:50,  6.48s/pipeline]
Generation 59 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-638934805.9028171	GradientBoostingRegressor(Nystroem(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.5, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6000/6000 [42:17<00:00,  6.48s/pipeline]Optimization Progress: 100%|██████████| 6000/6000 [42:17<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6000/6000 [42:17<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6000/6000 [42:18<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [42:19<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6000/6000 [42:19<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [42:20<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [42:24<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [42:24<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [42:24<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [42:24<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6000/6000 [42:28<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [42:28<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6000/6000 [42:32<00:00,  4.61s/pipeline]Optimization Progress:  98%|█████████▊| 6002/6100 [42:33<09:12,  5.64s/pipeline]Optimization Progress:  98%|█████████▊| 6003/6100 [42:49<13:59,  8.65s/pipeline]Optimization Progress: 100%|█████████▉| 6083/6100 [42:56<01:43,  6.08s/pipeline]
Generation 60 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-620672564.3365543	GradientBoostingRegressor(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6100/6100 [42:56<00:00,  6.08s/pipeline]Optimization Progress: 100%|██████████| 6100/6100 [42:56<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6100/6100 [42:58<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [42:59<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6100/6100 [43:02<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6100/6100 [43:03<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6100/6100 [43:04<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6100/6100 [43:05<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6100/6100 [43:08<00:00,  4.26s/pipeline]Optimization Progress: 100%|██████████| 6100/6100 [43:10<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6100/6100 [43:10<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6100/6100 [43:12<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6100/6100 [43:12<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [43:14<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6100/6100 [43:14<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6100/6100 [43:15<00:00,  4.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6100/6200 [43:18<07:06,  4.26s/pipeline]Optimization Progress:  98%|█████████▊| 6101/6200 [43:18<15:50,  9.60s/pipeline]Optimization Progress:  98%|█████████▊| 6102/6200 [43:32<17:53, 10.95s/pipeline]Optimization Progress: 100%|█████████▉| 6182/6200 [43:42<02:18,  7.70s/pipeline]
Generation 61 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-620672564.3365543	GradientBoostingRegressor(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [43:43<00:00,  7.70s/pipeline]Optimization Progress: 100%|██████████| 6200/6200 [43:43<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6200/6200 [43:45<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [43:45<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6200/6200 [43:47<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6200/6200 [43:47<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6200/6200 [43:47<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [43:48<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [43:48<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6200/6200 [43:49<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 6200/6200 [43:51<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6200/6200 [43:54<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6200/6200 [43:54<00:00,  5.41s/pipeline]Optimization Progress: 100%|██████████| 6200/6200 [44:00<00:00,  5.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6200/6200 [44:00<00:00,  5.41s/pipeline]Optimization Progress:  98%|█████████▊| 6201/6300 [44:19<23:48, 14.43s/pipeline]Optimization Progress: 100%|█████████▉| 6281/6300 [44:30<03:12, 10.14s/pipeline]
Generation 62 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-620672564.3365543	GradientBoostingRegressor(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6300/6300 [44:30<00:00, 10.14s/pipeline]Optimization Progress: 100%|██████████| 6300/6300 [44:30<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [44:33<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6300/6300 [44:34<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6300/6300 [44:35<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [44:38<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6300/6300 [44:42<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6300/6300 [44:43<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [44:43<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [44:43<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [44:45<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [44:45<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6300/6300 [44:46<00:00,  7.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 6300/6300 [44:47<00:00,  7.11s/pipeline]Optimization Progress: 100%|██████████| 6300/6300 [44:50<00:00,  7.11s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6300/6400 [44:50<11:50,  7.11s/pipeline]Optimization Progress:  98%|█████████▊| 6301/6400 [44:50<18:19, 11.11s/pipeline]Optimization Progress:  98%|█████████▊| 6302/6400 [45:11<22:45, 13.93s/pipeline]Optimization Progress: 100%|█████████▉| 6382/6400 [45:19<02:56,  9.78s/pipeline]
Generation 63 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-620672564.3365543	GradientBoostingRegressor(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:20<00:00,  9.78s/pipeline]Optimization Progress: 100%|██████████| 6400/6400 [45:20<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [45:23<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:23<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:23<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:24<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [45:26<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:30<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [45:34<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [45:36<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:38<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:38<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6400/6400 [45:39<00:00,  6.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 6400/6400 [45:39<00:00,  6.86s/pipeline]Optimization Progress:  98%|█████████▊| 6401/6500 [45:40<18:15, 11.06s/pipeline]Optimization Progress:  98%|█████████▊| 6402/6500 [45:56<20:26, 12.52s/pipeline]Optimization Progress: 100%|█████████▉| 6482/6500 [46:08<02:38,  8.81s/pipeline]
Generation 64 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-620672564.3365543	GradientBoostingRegressor(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6500/6500 [46:09<00:00,  8.81s/pipeline]Optimization Progress: 100%|██████████| 6500/6500 [46:09<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 6500/6500 [46:10<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [46:11<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 6500/6500 [46:13<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6500/6500 [46:14<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [46:16<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [46:16<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [46:16<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [46:16<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6500/6500 [46:23<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [46:24<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [46:24<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6500/6500 [46:25<00:00,  6.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6500/6500 [46:27<00:00,  6.19s/pipeline]Optimization Progress:  98%|█████████▊| 6501/6600 [47:02<33:30, 20.31s/pipeline]Optimization Progress: 100%|█████████▉| 6581/6600 [47:14<04:31, 14.26s/pipeline]
Generation 65 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6600/6600 [47:16<00:00, 14.26s/pipeline]Optimization Progress: 100%|██████████| 6600/6600 [47:16<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6600/6600 [47:16<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6600/6600 [47:17<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 6600/6600 [47:23<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [47:24<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6600/6600 [47:25<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6600/6600 [47:27<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 6600/6600 [47:31<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 6600/6600 [47:33<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6600/6600 [47:34<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6600/6600 [47:35<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 6600/6600 [47:35<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6600/6600 [47:36<00:00, 10.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [47:39<00:00, 10.00s/pipeline]Optimization Progress:  99%|█████████▊| 6601/6700 [47:56<31:37, 19.16s/pipeline]Optimization Progress: 100%|█████████▉| 6681/6700 [48:08<04:15, 13.46s/pipeline]
Generation 66 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:08<00:00, 13.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6700/6700 [48:11<00:00, 13.46s/pipeline]Optimization Progress: 100%|██████████| 6700/6700 [48:11<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6700/6700 [48:12<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6700/6700 [48:12<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6700/6700 [48:13<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6700/6700 [48:15<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:20<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:20<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:21<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6700/6700 [48:22<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6700/6700 [48:27<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6700/6700 [48:28<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:30<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:30<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:30<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:30<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6700/6700 [48:30<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6700/6700 [48:32<00:00,  9.47s/pipeline]Optimization Progress:  99%|█████████▊| 6701/6800 [48:32<21:28, 13.01s/pipeline]Optimization Progress:  99%|█████████▊| 6702/6800 [48:48<22:50, 13.99s/pipeline]Optimization Progress: 100%|█████████▉| 6782/6800 [48:58<02:56,  9.83s/pipeline]
Generation 67 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [49:02<00:00,  9.83s/pipeline]Optimization Progress: 100%|██████████| 6800/6800 [49:02<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6800/6800 [49:02<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [49:02<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [49:02<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6800/6800 [49:03<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [49:03<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6800/6800 [49:04<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [49:07<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [49:09<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6800/6800 [49:10<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6800/6800 [49:14<00:00,  6.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [49:19<00:00,  6.95s/pipeline]Optimization Progress:  99%|█████████▊| 6801/6900 [49:21<17:34, 10.65s/pipeline]Optimization Progress:  99%|█████████▊| 6802/6900 [49:36<19:33, 11.97s/pipeline]Optimization Progress: 100%|█████████▉| 6882/6900 [49:49<02:31,  8.43s/pipeline]
Generation 68 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [49:50<00:00,  8.43s/pipeline]Optimization Progress: 100%|██████████| 6900/6900 [49:50<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [49:51<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [49:51<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [49:51<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [49:53<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [49:54<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 6900/6900 [49:55<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6900/6900 [49:55<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6900/6900 [49:59<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [49:59<00:00,  5.91s/pipeline]Optimization Progress: 100%|██████████| 6900/6900 [50:00<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [50:00<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [50:02<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 6900/6900 [50:02<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [50:05<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [50:09<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [50:10<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [50:10<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [50:10<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [50:13<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6900/6900 [50:13<00:00,  5.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [50:14<00:00,  5.91s/pipeline]Optimization Progress:  99%|█████████▊| 6901/7000 [50:33<28:13, 17.11s/pipeline]Optimization Progress: 100%|█████████▉| 6981/7000 [50:49<03:48, 12.04s/pipeline]
Generation 69 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7000/7000 [50:49<00:00, 12.04s/pipeline]Optimization Progress: 100%|██████████| 7000/7000 [50:49<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7000/7000 [50:50<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7000/7000 [50:50<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [50:53<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [50:55<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [50:55<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7000/7000 [50:57<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [50:59<00:00,  8.43s/pipeline]Optimization Progress: 100%|██████████| 7000/7000 [51:00<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7000/7000 [51:00<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [51:02<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7000/7000 [51:03<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [51:07<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7000/7000 [51:10<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [51:11<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [51:11<00:00,  8.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7000/7000 [51:13<00:00,  8.43s/pipeline]Optimization Progress:  99%|█████████▊| 7001/7100 [51:13<21:36, 13.09s/pipeline]Optimization Progress:  99%|█████████▊| 7002/7100 [51:30<23:08, 14.17s/pipeline]Optimization Progress: 100%|█████████▉| 7082/7100 [51:40<02:59,  9.96s/pipeline]
Generation 70 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7100/7100 [51:41<00:00,  9.96s/pipeline]Optimization Progress: 100%|██████████| 7100/7100 [51:41<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [51:41<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7100/7100 [51:44<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [51:45<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7100/7100 [51:46<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7100/7100 [51:49<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [51:49<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7100/7100 [51:51<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7100/7100 [51:52<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [51:53<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7100/7100 [51:53<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [51:54<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [51:57<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [51:58<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7100/7100 [51:58<00:00,  6.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [51:59<00:00,  6.98s/pipeline]Optimization Progress:  99%|█████████▊| 7102/7200 [52:00<12:36,  7.72s/pipeline]Optimization Progress:  99%|█████████▊| 7103/7200 [52:15<15:54,  9.84s/pipeline]Optimization Progress: 100%|█████████▉| 7183/7200 [52:25<01:57,  6.93s/pipeline]
Generation 71 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [52:25<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [52:26<00:00,  6.93s/pipeline]Optimization Progress: 100%|██████████| 7200/7200 [52:26<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7200/7200 [52:26<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [52:27<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [52:27<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7200/7200 [52:28<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7200/7200 [52:29<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [52:31<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [52:31<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [52:31<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7200/7200 [52:31<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [52:32<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7200/7200 [52:34<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [52:35<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [52:39<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [52:45<00:00,  4.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7200/7200 [52:45<00:00,  4.88s/pipeline]Optimization Progress:  99%|█████████▊| 7201/7300 [53:03<23:34, 14.29s/pipeline]Optimization Progress: 100%|█████████▉| 7281/7300 [53:20<03:11, 10.07s/pipeline]
Generation 72 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7300/7300 [53:24<00:00, 10.07s/pipeline]Optimization Progress: 100%|██████████| 7300/7300 [53:24<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7300/7300 [53:24<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7300/7300 [53:26<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [53:28<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [53:28<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7300/7300 [53:30<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [53:31<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7300/7300 [53:36<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7300/7300 [53:37<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7300/7300 [53:37<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7300/7300 [53:38<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7300/7300 [53:38<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7300/7300 [53:38<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 7300/7300 [53:39<00:00,  7.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7300/7300 [53:40<00:00,  7.10s/pipeline]Optimization Progress:  99%|█████████▊| 7301/7400 [53:41<16:44, 10.14s/pipeline]Optimization Progress:  99%|█████████▊| 7302/7400 [53:55<18:39, 11.43s/pipeline]Optimization Progress: 100%|█████████▉| 7382/7400 [54:06<02:24,  8.04s/pipeline]
Generation 73 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7400/7400 [54:14<00:00,  8.04s/pipeline]Optimization Progress: 100%|██████████| 7400/7400 [54:14<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7400/7400 [54:14<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [54:15<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [54:15<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [54:15<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7400/7400 [54:24<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 7400/7400 [54:25<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7400/7400 [54:28<00:00,  5.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7400/7400 [54:29<00:00,  5.77s/pipeline]Optimization Progress:  99%|█████████▊| 7401/7500 [54:48<23:39, 14.34s/pipeline]Optimization Progress: 100%|█████████▉| 7481/7500 [55:00<03:11, 10.08s/pipeline]
Generation 74 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00100.
Optimization Progress: 100%|██████████| 7500/7500 [55:01<00:00, 10.08s/pipeline]Optimization Progress: 100%|██████████| 7500/7500 [55:01<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [55:04<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 7500/7500 [55:05<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [55:06<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [55:06<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [55:09<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [55:09<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 7500/7500 [55:09<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [55:11<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7500/7500 [55:13<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7500/7500 [55:14<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [55:16<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7500/7500 [55:18<00:00,  7.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7500/7500 [55:20<00:00,  7.07s/pipeline]Optimization Progress: 100%|██████████| 7500/7500 [55:20<00:00,  7.07s/pipeline]Optimization Progress:  99%|█████████▊| 7501/7600 [55:21<18:15, 11.07s/pipeline]Optimization Progress:  99%|█████████▊| 7502/7600 [55:36<19:58, 12.23s/pipeline]Optimization Progress: 100%|█████████▉| 7582/7600 [55:45<02:34,  8.60s/pipeline]
Generation 75 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [55:46<00:00,  8.60s/pipeline]Optimization Progress: 100%|██████████| 7600/7600 [55:46<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7600/7600 [55:46<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7600/7600 [55:48<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [55:49<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7600/7600 [55:52<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7600/7600 [55:52<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7600/7600 [55:54<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [55:55<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [55:55<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7600/7600 [55:58<00:00,  6.03s/pipeline]Optimization Progress: 100%|██████████| 7600/7600 [56:00<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [56:03<00:00,  6.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7600/7600 [56:07<00:00,  6.03s/pipeline]Optimization Progress:  99%|█████████▊| 7602/7700 [56:07<12:09,  7.45s/pipeline]Optimization Progress:  99%|█████████▊| 7603/7700 [56:25<17:11, 10.64s/pipeline]Optimization Progress: 100%|█████████▉| 7683/7700 [56:36<02:07,  7.49s/pipeline]
Generation 76 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:38<00:00,  7.49s/pipeline]Optimization Progress: 100%|██████████| 7700/7700 [56:38<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:38<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 7700/7700 [56:40<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:41<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:41<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 7700/7700 [56:50<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [56:52<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:53<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:53<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [56:53<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:53<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:53<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7700/7700 [56:54<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7700/7700 [56:55<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7700/7700 [56:56<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [56:57<00:00,  5.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [56:58<00:00,  5.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7700/7800 [56:58<08:47,  5.28s/pipeline]Optimization Progress:  99%|█████████▊| 7701/7800 [56:58<16:02,  9.72s/pipeline]Optimization Progress:  99%|█████████▊| 7702/7800 [57:13<18:24, 11.27s/pipeline]Optimization Progress: 100%|█████████▉| 7782/7800 [57:24<02:22,  7.94s/pipeline]
Generation 77 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7800/7800 [57:26<00:00,  7.94s/pipeline]Optimization Progress: 100%|██████████| 7800/7800 [57:26<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7800/7800 [57:28<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [57:28<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7800/7800 [57:31<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7800/7800 [57:32<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7800/7800 [57:32<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..
Optimization Progress: 100%|██████████| 7800/7800 [57:32<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 7800/7800 [57:36<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7800/7800 [57:39<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [57:42<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [57:43<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [57:43<00:00,  5.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [57:43<00:00,  5.59s/pipeline]Optimization Progress:  99%|█████████▊| 7801/7900 [58:12<29:11, 17.69s/pipeline]Optimization Progress: 100%|█████████▉| 7881/7900 [59:15<03:59, 12.62s/pipeline]
Generation 78 - Current Pareto front scores:
-1	-642130534.0945352	LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-3	-602289539.6189092	GradientBoostingRegressor(Nystroem(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=14, DecisionTreeRegressor__min_samples_split=14), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=7), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-4	-596348315.633106	GradientBoostingRegressor(Nystroem(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.001), Nystroem__gamma=0.1, Nystroem__kernel=chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7900/7900 [59:20<00:00, 12.62s/pipeline]Optimization Progress: 100%|██████████| 7900/7900 [59:20<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7900/7900 [59:25<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7900/7900 [59:28<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 7900/7900 [59:28<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7900/7900 [59:28<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [59:30<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [59:30<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [59:30<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7900/7900 [59:34<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7900/7900 [59:34<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7900/7900 [59:36<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7900/7900 [59:36<00:00,  8.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7900/7900 [59:37<00:00,  8.91s/pipeline]Optimization Progress:  99%|█████████▉| 7901/8000 [59:37<18:33, 11.25s/pipeline]Optimization Progress:  99%|█████████▉| 7902/8000 [59:55<21:49, 13.37s/pipeline]                                                                                
Optimization Progress: 100%|█████████▉| 7981/8000 [59:55<04:13, 13.37s/pipeline]                                                                                60.00 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 7981/8000 [59:55<04:13, 13.37s/pipeline]                                                                                
Optimization Progress: 100%|█████████▉| 7981/8000 [59:55<04:13, 13.37s/pipeline]                                                                                
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 7981/8000 [59:55<04:13, 13.37s/pipeline]                                                                                Best pipeline:
0. StackingEstimator(estimator=AdaBoostRegressor(learning_rate=0.001,
                                              loss='exponential',
                                              n_estimators=100))
1. VarianceThreshold(threshold=0.001)
2. Nystroem(gamma=0.1, kernel='chi2', n_components=10)
3. GradientBoostingRegressor(loss='lad', max_depth=4, max_features=0.45,
                          min_samples_leaf=12, min_samples_split=15,
                          subsample=0.7500000000000001)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
