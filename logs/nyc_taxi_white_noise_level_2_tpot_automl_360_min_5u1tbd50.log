30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   7%|▋         | 7/100 [00:06<01:30,  1.02pipeline/s]Optimization Progress:  87%|████████▋ | 87/100 [00:11<00:09,  1.43pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.43pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.43pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  2.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  2.02pipeline/s]Optimization Progress:  52%|█████▏    | 104/200 [00:17<01:12,  1.32pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 104/200 [00:17<01:12,  1.32pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▎    | 105/200 [00:17<01:12,  1.32pipeline/s]Optimization Progress:  54%|█████▎    | 107/200 [00:22<01:35,  1.03s/pipeline]Optimization Progress:  94%|█████████▎| 187/200 [00:24<00:09,  1.37pipeline/s]
Generation 1 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:26<00:00,  1.37pipeline/s]Optimization Progress: 100%|██████████| 200/200 [00:26<00:00,  1.85pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:28<00:00,  1.85pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:29<00:00,  1.85pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 200/200 [00:30<00:00,  1.85pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:31<00:00,  1.85pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:31<00:00,  1.85pipeline/s]Optimization Progress:  67%|██████▋   | 202/300 [00:32<02:07,  1.30s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  67%|██████▋   | 202/300 [00:32<02:07,  1.30s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 203/300 [00:32<02:06,  1.30s/pipeline]Optimization Progress:  68%|██████▊   | 205/300 [00:47<03:55,  2.48s/pipeline]Optimization Progress:  95%|█████████▌| 285/300 [00:52<00:26,  1.75s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-138572037.28683758	ElasticNetCV(RBFSampler(input_matrix, RBFSampler__gamma=0.45), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:53<00:00,  1.75s/pipeline]Optimization Progress: 100%|██████████| 300/300 [00:53<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:53<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:54<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:54<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 300/300 [00:55<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:56<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 300/300 [00:57<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:58<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 300/300 [00:58<00:00,  1.25s/pipeline]Optimization Progress:  76%|███████▋  | 305/400 [01:00<02:00,  1.26s/pipeline]Optimization Progress:  76%|███████▋  | 306/400 [01:03<03:05,  1.97s/pipeline]Optimization Progress:  96%|█████████▋| 386/400 [01:07<00:19,  1.39s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-138572037.28683758	ElasticNetCV(RBFSampler(input_matrix, RBFSampler__gamma=0.45), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 400/400 [01:10<00:00,  1.39s/pipeline]Optimization Progress: 100%|██████████| 400/400 [01:10<00:00,  1.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:11<00:00,  1.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:11<00:00,  1.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [01:12<00:00,  1.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 400/400 [01:12<00:00,  1.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [01:13<00:00,  1.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:14<00:00,  1.04s/pipeline]Optimization Progress:  82%|████████▏ | 410/500 [01:14<01:16,  1.18pipeline/s]Optimization Progress:  82%|████████▏ | 411/500 [01:18<03:00,  2.03s/pipeline]Optimization Progress:  98%|█████████▊| 491/500 [01:42<00:13,  1.51s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-136938742.44564897	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.75), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=20, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:42<00:00,  1.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [01:46<00:00,  1.51s/pipeline]Optimization Progress: 100%|██████████| 500/500 [01:46<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:46<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 500/500 [01:46<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:47<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 500/500 [01:48<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X needs to contain only non-negative integers..
Optimization Progress: 100%|██████████| 500/500 [01:49<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:49<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 500/500 [01:49<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [01:49<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [01:49<00:00,  1.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 500/500 [01:50<00:00,  1.18s/pipeline]Optimization Progress:  84%|████████▍ | 504/600 [01:50<01:50,  1.15s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▍ | 504/600 [01:50<01:50,  1.15s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▍ | 505/600 [01:50<01:49,  1.15s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▍ | 506/600 [01:50<01:48,  1.15s/pipeline]Optimization Progress:  85%|████████▍ | 508/600 [06:50<35:44, 23.31s/pipeline]                                                                              Skipped pipeline #518 due to time out. Continuing to the next pipeline.
Optimization Progress:  86%|████████▋ | 518/600 [06:50<31:51, 23.31s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  98%|█████████▊| 589/600 [06:52<02:59, 16.33s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-136938742.44564897	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.75), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=20, DecisionTreeRegressor__min_samples_split=17)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 601pipeline [06:53, 16.33s/pipeline]Optimization Progress: 601pipeline [06:53, 11.45s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 601pipeline [06:55, 11.45s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 601pipeline [06:55, 11.45s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 601pipeline [06:58, 11.45s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 601pipeline [06:58, 11.45s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 601pipeline [06:58, 11.45s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 601pipeline [06:59, 11.45s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 601pipeline [06:59, 11.45s/pipeline]Optimization Progress:  87%|████████▋ | 607/700 [06:59<12:51,  8.30s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  87%|████████▋ | 607/700 [06:59<12:51,  8.30s/pipeline]Optimization Progress:  87%|████████▋ | 609/700 [07:24<14:35,  9.62s/pipeline]Optimization Progress:  98%|█████████▊| 689/700 [07:28<01:14,  6.75s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-136938742.44564897	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.75), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=20, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 701pipeline [07:28,  6.75s/pipeline]Optimization Progress: 701pipeline [07:28,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 701pipeline [07:28,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 701pipeline [07:29,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 701pipeline [07:31,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 701pipeline [07:31,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 701pipeline [07:32,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 701pipeline [07:32,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 701pipeline [07:33,  4.73s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 701pipeline [07:33,  4.73s/pipeline]                                                           Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 703/800 [07:33<07:38,  4.73s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 704/800 [07:33<07:33,  4.73s/pipeline]Optimization Progress:  88%|████████▊ | 705/800 [07:33<05:50,  3.69s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 705/800 [07:33<05:50,  3.69s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 706/800 [07:33<05:47,  3.69s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 707/800 [07:33<05:43,  3.69s/pipeline]Optimization Progress:  89%|████████▊ | 709/800 [07:44<05:10,  3.41s/pipeline]Optimization Progress:  99%|█████████▊| 789/800 [08:12<00:27,  2.49s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-136938742.44564897	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.75), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=20, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 801pipeline [08:12,  2.49s/pipeline]Optimization Progress: 801pipeline [08:12,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 801pipeline [08:13,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 801pipeline [08:13,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 801pipeline [08:13,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 801pipeline [08:13,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 801pipeline [08:13,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 801pipeline [08:14,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 801pipeline [08:15,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00010.
Optimization Progress: 801pipeline [08:15,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 801pipeline [08:18,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 [03:51:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 801pipeline [08:18,  1.76s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=1 [03:51:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 801pipeline [08:18,  1.76s/pipeline]Optimization Progress:  89%|████████▉ | 805/900 [08:18<02:36,  1.65s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 805/900 [08:18<02:36,  1.65s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|████████▉ | 806/900 [08:18<02:35,  1.65s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|████████▉ | 807/900 [08:18<02:33,  1.65s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|████████▉ | 808/900 [08:18<02:31,  1.65s/pipeline]Optimization Progress:  90%|█████████ | 810/900 [08:46<04:15,  2.84s/pipeline]Optimization Progress:  99%|█████████▉| 890/900 [08:50<00:20,  2.00s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-136938742.44564897	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.75), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=20, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:50,  2.00s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:51,  2.00s/pipeline]Optimization Progress: 901pipeline [08:51,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:52,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:53,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:54,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:54,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:54,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 901pipeline [08:54,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:55,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:55,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:55,  1.42s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:55,  1.42s/pipeline]Optimization Progress:  90%|█████████ | 905/1000 [08:55<02:02,  1.29s/pipeline]Optimization Progress:  91%|█████████ | 906/1000 [09:35<20:04, 12.81s/pipeline]Optimization Progress:  99%|█████████▊| 986/1000 [09:38<02:05,  8.98s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-136938742.44564897	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.75), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=20, DecisionTreeRegressor__min_samples_split=17)
-3	-135467354.78189033	DecisionTreeRegressor(StandardScaler(RBFSampler(input_matrix, RBFSampler__gamma=0.4)), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=19)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:40,  8.98s/pipeline]Optimization Progress: 1001pipeline [09:40,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 1001pipeline [09:40,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:40,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 1001pipeline [09:40,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:40,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:41,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:41,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:41,  6.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:41,  6.32s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [09:42<07:27,  4.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████▏| 1004/1100 [09:42<07:27,  4.67s/pipeline]Optimization Progress:  91%|█████████▏| 1006/1100 [11:57<36:53, 23.55s/pipeline]Optimization Progress:  99%|█████████▊| 1086/1100 [12:00<03:50, 16.50s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-135467354.78189033	DecisionTreeRegressor(StandardScaler(RBFSampler(input_matrix, RBFSampler__gamma=0.4)), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=19)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1101pipeline [12:00, 16.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:00, 16.50s/pipeline]Optimization Progress: 1101pipeline [12:00, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1101pipeline [12:00, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 1101pipeline [12:00, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1101pipeline [12:00, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 1101pipeline [12:01, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:01, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:01, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1101pipeline [12:01, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:01, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:02, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 1101pipeline [12:02, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 1101pipeline [12:02, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1101pipeline [12:02, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 1101pipeline [12:02, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:03, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:03, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1101pipeline [12:03, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:03, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [12:03, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 1101pipeline [12:04, 11.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1101pipeline [12:04, 11.56s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [12:04<13:56,  8.62s/pipeline]Optimization Progress:  92%|█████████▏| 1105/1200 [12:15<12:13,  7.72s/pipeline]Optimization Progress:  99%|█████████▊| 1184/1200 [13:33<01:31,  5.70s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-135467354.78189033	DecisionTreeRegressor(StandardScaler(RBFSampler(input_matrix, RBFSampler__gamma=0.4)), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=19)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1201pipeline [13:33,  5.70s/pipeline]Optimization Progress: 1201pipeline [13:33,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [13:33,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [13:34,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [13:34,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1201pipeline [13:34,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [13:35,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [13:36,  3.99s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [13:50<06:35,  3.99s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [13:53<14:29,  8.88s/pipeline]Optimization Progress:  99%|█████████▊| 1282/1300 [14:00<01:52,  6.24s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-135467354.78189033	DecisionTreeRegressor(StandardScaler(RBFSampler(input_matrix, RBFSampler__gamma=0.4)), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=19)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [14:00,  6.24s/pipeline]Optimization Progress: 1301pipeline [14:00,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [14:00,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 1301pipeline [14:00,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 1301pipeline [14:00,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [14:01,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [14:01,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [14:01,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [14:02,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [14:02,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [14:02,  4.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1301pipeline [14:02,  4.37s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [14:09<07:10,  4.44s/pipeline]Optimization Progress:  99%|█████████▉| 1383/1400 [14:13<00:53,  3.12s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-135467354.78189033	DecisionTreeRegressor(StandardScaler(RBFSampler(input_matrix, RBFSampler__gamma=0.4)), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=19)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [14:13,  3.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [14:13,  3.12s/pipeline]Optimization Progress: 1401pipeline [14:13,  2.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [14:13,  2.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [14:13,  2.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [14:14,  2.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [14:14,  2.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [14:14,  2.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 1401pipeline [14:15,  2.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [14:15,  2.19s/pipeline]Optimization Progress:  94%|█████████▎| 1404/1500 [14:20<03:35,  2.24s/pipeline]Optimization Progress:  99%|█████████▊| 1481/1500 [14:40<00:42,  2.24s/pipeline]Optimization Progress:  99%|█████████▉| 1482/1500 [14:48<00:30,  1.68s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-135467354.78189033	DecisionTreeRegressor(StandardScaler(RBFSampler(input_matrix, RBFSampler__gamma=0.4)), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=19)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 1501pipeline [14:48,  1.68s/pipeline]Optimization Progress: 1501pipeline [14:48,  1.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 1501pipeline [14:49,  1.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [14:49,  1.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 1501pipeline [14:49,  1.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [14:49,  1.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1501pipeline [14:50,  1.18s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [15:00<01:56,  1.18s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [15:49<31:11, 19.10s/pipeline]Optimization Progress:  99%|█████████▉| 1582/1600 [15:53<04:00, 13.38s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1601pipeline [15:53, 13.38s/pipeline]Optimization Progress: 1601pipeline [15:53,  9.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1601pipeline [15:53,  9.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1601pipeline [15:53,  9.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1601pipeline [15:54,  9.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [15:54,  9.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 1601pipeline [15:54,  9.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 1601pipeline [15:54,  9.37s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1603/1700 [15:55<15:08,  9.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1604/1700 [15:55<14:59,  9.37s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [15:55<10:35,  6.69s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [16:10<10:35,  6.69s/pipeline]Optimization Progress:  94%|█████████▍| 1606/1700 [19:17<1:42:35, 65.49s/pipeline]Optimization Progress:  99%|█████████▉| 1686/1700 [19:20<10:41, 45.85s/pipeline]  
Generation 16 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:20, 45.85s/pipeline]Optimization Progress: 1701pipeline [19:20, 32.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:21, 32.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1701pipeline [19:21, 32.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:21, 32.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1701pipeline [19:21, 32.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 1701pipeline [19:21, 32.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:21, 32.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1701pipeline [19:22, 32.10s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1702/1800 [19:23<52:25, 32.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1703/1800 [19:23<51:53, 32.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1704/1800 [19:23<51:21, 32.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1705/1800 [19:23<50:49, 32.10s/pipeline]Optimization Progress:  95%|█████████▍| 1706/1800 [19:23<35:25, 22.61s/pipeline]Optimization Progress:  95%|█████████▍| 1706/1800 [19:40<35:25, 22.61s/pipeline]Optimization Progress:  95%|█████████▍| 1707/1800 [19:50<37:25, 24.14s/pipeline]Optimization Progress:  99%|█████████▉| 1787/1800 [19:54<03:39, 16.91s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [19:54, 16.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1801pipeline [19:54, 16.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 1801pipeline [19:54, 16.91s/pipeline]Optimization Progress: 1801pipeline [19:54, 11.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 1801pipeline [19:55, 11.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [19:55, 11.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [19:55, 11.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [19:56, 11.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 1801pipeline [19:56, 11.85s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1801/1900 [19:56<19:32, 11.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1802/1900 [19:56<19:20, 11.85s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [19:56<13:53,  8.59s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1803/1900 [19:56<13:53,  8.59s/pipeline]Optimization Progress:  95%|█████████▌| 1805/1900 [20:07<12:09,  7.68s/pipeline]Optimization Progress:  99%|█████████▉| 1885/1900 [20:08<01:20,  5.38s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1901pipeline [20:09,  5.38s/pipeline]Optimization Progress: 1901pipeline [20:09,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 1901pipeline [20:09,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [20:09,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1901pipeline [20:09,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [20:09,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 1901pipeline [20:09,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 1901pipeline [20:09,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 1901pipeline [20:10,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [20:10,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [20:10,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [20:10,  3.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [20:10,  3.78s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1901/2000 [20:10<06:13,  3.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1902/2000 [20:10<06:09,  3.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1903/2000 [20:10<06:06,  3.78s/pipeline]Optimization Progress:  95%|█████████▌| 1904/2000 [20:10<04:28,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1904/2000 [20:10<04:28,  2.79s/pipeline]Optimization Progress:  95%|█████████▌| 1905/2000 [20:30<04:25,  2.79s/pipeline]Optimization Progress:  95%|█████████▌| 1906/2000 [21:04<15:39,  9.99s/pipeline]Optimization Progress:  99%|█████████▉| 1986/2000 [21:19<01:38,  7.05s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2001pipeline [21:19,  7.05s/pipeline]Optimization Progress: 2001pipeline [21:19,  4.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 2001pipeline [21:19,  4.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [21:20,  4.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [21:20,  4.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [21:20,  4.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2001pipeline [21:20,  4.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2001pipeline [21:20,  4.94s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2001/2100 [21:21<08:09,  4.94s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2002/2100 [21:21<08:04,  4.94s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [21:21<06:03,  3.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2003/2100 [21:21<06:03,  3.75s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [21:40<05:59,  3.75s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [22:12<16:13, 10.25s/pipeline]Optimization Progress:  99%|█████████▉| 2085/2100 [22:15<01:47,  7.19s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 2101pipeline [22:16,  7.19s/pipeline]Optimization Progress: 2101pipeline [22:16,  5.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2101pipeline [22:16,  5.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2101pipeline [22:17,  5.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [22:17,  5.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [22:17,  5.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2101pipeline [22:18,  5.03s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2102/2200 [22:18<08:13,  5.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2103/2200 [22:18<08:08,  5.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2104/2200 [22:18<08:03,  5.03s/pipeline]Optimization Progress:  96%|█████████▌| 2105/2200 [22:18<05:51,  3.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2105/2200 [22:18<05:51,  3.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2106/2200 [22:18<05:47,  3.70s/pipeline]Optimization Progress:  96%|█████████▌| 2107/2200 [22:30<05:43,  3.70s/pipeline]Optimization Progress:  96%|█████████▌| 2108/2200 [22:49<08:41,  5.67s/pipeline]Optimization Progress:  99%|█████████▉| 2188/2200 [22:53<00:47,  3.99s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [22:53,  3.99s/pipeline]Optimization Progress: 2201pipeline [22:53,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2201pipeline [22:53,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [22:54,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [22:54,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2201pipeline [22:54,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2201pipeline [22:54,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [22:54,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2201pipeline [22:54,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [22:54,  2.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [22:55,  2.79s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2202/2300 [22:55<04:33,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2203/2300 [22:55<04:31,  2.79s/pipeline]Optimization Progress:  96%|█████████▌| 2204/2300 [22:55<03:21,  2.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2204/2300 [22:55<03:21,  2.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2205/2300 [22:55<03:19,  2.10s/pipeline]Optimization Progress:  96%|█████████▌| 2207/2300 [22:59<02:53,  1.87s/pipeline]Optimization Progress:  99%|█████████▉| 2287/2300 [23:00<00:17,  1.31s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [23:00,  1.31s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [23:00,  1.31s/pipeline]Optimization Progress: 2301pipeline [23:00,  1.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2301pipeline [23:00,  1.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [23:01,  1.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [23:01,  1.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2301pipeline [23:01,  1.08pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2302/2400 [23:01<01:30,  1.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2303/2400 [23:01<01:29,  1.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2304/2400 [23:01<01:28,  1.08pipeline/s]Optimization Progress:  96%|█████████▌| 2305/2400 [23:01<01:09,  1.36pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2305/2400 [23:01<01:09,  1.36pipeline/s]Optimization Progress:  96%|█████████▌| 2308/2400 [23:05<01:25,  1.07pipeline/s]Optimization Progress:  99%|█████████▉| 2387/2400 [23:09<00:08,  1.50pipeline/s]
Generation 23 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [23:09,  1.50pipeline/s]Optimization Progress: 2401pipeline [23:09,  2.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2401pipeline [23:09,  2.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [23:09,  2.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [23:10,  2.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2401pipeline [23:10,  2.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2401pipeline [23:10,  2.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2401pipeline [23:10,  2.13pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2401/2500 [23:11<00:46,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2402/2500 [23:11<00:46,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2403/2500 [23:11<00:45,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2404/2500 [23:11<00:45,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2405/2500 [23:11<00:44,  2.13pipeline/s]Optimization Progress:  96%|█████████▌| 2406/2500 [23:11<00:41,  2.26pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2406/2500 [23:11<00:41,  2.26pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2407/2500 [23:11<00:41,  2.26pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2408/2500 [23:11<00:40,  2.26pipeline/s]Optimization Progress:  96%|█████████▋| 2409/2500 [23:30<00:40,  2.26pipeline/s]Optimization Progress:  96%|█████████▋| 2410/2500 [25:20<14:58,  9.98s/pipeline]Optimization Progress: 100%|█████████▉| 2490/2500 [25:22<01:09,  7.00s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2501pipeline [25:23,  7.00s/pipeline]Optimization Progress: 2501pipeline [25:23,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [25:23,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [25:23,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [25:24,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [25:24,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [25:24,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [25:24,  4.92s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2502/2600 [25:24<08:02,  4.92s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [25:24<05:43,  3.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2503/2600 [25:24<05:43,  3.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2504/2600 [25:24<05:39,  3.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2505/2600 [25:24<05:35,  3.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2506/2600 [25:24<05:32,  3.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2507/2600 [25:24<05:28,  3.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2508/2600 [25:24<05:25,  3.54s/pipeline]Optimization Progress:  97%|█████████▋| 2510/2600 [25:26<03:51,  2.58s/pipeline]Optimization Progress: 100%|█████████▉| 2590/2600 [28:10<00:24,  2.42s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [28:10,  2.42s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [28:10,  2.42s/pipeline]Optimization Progress: 2601pipeline [28:10,  1.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [28:10,  1.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2601pipeline [28:10,  1.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [28:10,  1.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [28:10,  1.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [28:11,  1.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [28:11,  1.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2601pipeline [28:11,  1.70s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2601/2700 [28:11<02:47,  1.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [28:11<02:46,  1.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2603/2700 [28:11<02:44,  1.70s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [28:11<02:07,  1.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2604/2700 [28:11<02:07,  1.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2605/2700 [28:11<02:06,  1.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2606/2700 [28:11<02:05,  1.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2607/2700 [28:11<02:03,  1.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2608/2700 [28:11<02:02,  1.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2609/2700 [28:11<02:01,  1.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2610/2700 [28:11<01:59,  1.33s/pipeline]Optimization Progress:  97%|█████████▋| 2612/2700 [28:17<01:39,  1.14s/pipeline]Optimization Progress: 100%|█████████▉| 2692/2700 [28:19<00:06,  1.24pipeline/s]
Generation 26 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2701pipeline [28:19,  1.24pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:19,  1.24pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:20,  1.24pipeline/s]Optimization Progress: 2701pipeline [28:20,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:20,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:20,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 2701pipeline [28:20,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2701pipeline [28:20,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 2701pipeline [28:20,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:21,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2701pipeline [28:21,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:21,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:21,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:21,  1.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [28:21,  1.76pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2701/2800 [28:21<00:56,  1.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2702/2800 [28:21<00:55,  1.76pipeline/s]Optimization Progress:  97%|█████████▋| 2703/2800 [28:30<00:55,  1.76pipeline/s]Optimization Progress:  97%|█████████▋| 2704/2800 [29:27<11:23,  7.12s/pipeline]Optimization Progress:  99%|█████████▉| 2784/2800 [29:29<01:19,  4.99s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-135745907.06083947	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-3	-133865183.81724676	DecisionTreeRegressor(RBFSampler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), RBFSampler__gamma=0.35000000000000003), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=20)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [29:29,  4.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [29:29,  4.99s/pipeline]Optimization Progress: 2801pipeline [29:29,  3.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [29:29,  3.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2801pipeline [29:30,  3.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 2801pipeline [29:30,  3.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2801pipeline [29:30,  3.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 2801pipeline [29:31,  3.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [29:31,  3.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [29:31,  3.50s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2801/2900 [29:31<05:46,  3.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2802/2900 [29:31<05:43,  3.50s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [29:31<04:21,  2.69s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2803/2900 [29:31<04:21,  2.69s/pipeline]Optimization Progress:  97%|█████████▋| 2805/2900 [29:36<04:06,  2.60s/pipeline]Optimization Progress:  99%|█████████▉| 2885/2900 [29:38<00:27,  1.83s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2901pipeline [29:39,  1.83s/pipeline]Optimization Progress: 2901pipeline [29:39,  1.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2901pipeline [29:40,  1.29s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2902/3000 [29:40<02:06,  1.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2903/3000 [29:40<02:04,  1.29s/pipeline]Optimization Progress:  97%|█████████▋| 2904/3000 [29:40<01:38,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2904/3000 [29:40<01:38,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2905/3000 [29:40<01:37,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2906/3000 [29:40<01:36,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2907/3000 [29:40<01:35,  1.03s/pipeline]Optimization Progress:  97%|█████████▋| 2909/3000 [29:46<01:39,  1.10s/pipeline]Optimization Progress: 100%|█████████▉| 2989/3000 [29:48<00:08,  1.29pipeline/s]
Generation 29 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [29:48,  1.29pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [29:48,  1.29pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [29:48,  1.29pipeline/s]Optimization Progress: 3001pipeline [29:48,  1.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [29:48,  1.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [29:48,  1.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [29:49,  1.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [29:49,  1.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [29:49,  1.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [29:49,  1.83pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3001/3100 [29:50<00:54,  1.83pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3002/3100 [29:50<00:53,  1.83pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3003/3100 [29:50<00:53,  1.83pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3004/3100 [29:50<00:52,  1.83pipeline/s]Optimization Progress:  97%|█████████▋| 3005/3100 [29:50<00:46,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3005/3100 [29:50<00:46,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3006/3100 [29:50<00:45,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3007/3100 [29:50<00:45,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3008/3100 [29:50<00:44,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3009/3100 [29:50<00:44,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3010/3100 [29:50<00:43,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3011/3100 [29:50<00:43,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3012/3100 [29:50<00:42,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3013/3100 [29:50<00:42,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3014/3100 [29:50<00:41,  2.06pipeline/s]Optimization Progress:  97%|█████████▋| 3016/3100 [29:54<00:37,  2.22pipeline/s]Optimization Progress: 100%|█████████▉| 3096/3100 [29:56<00:01,  3.07pipeline/s]
Generation 30 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [29:57,  3.07pipeline/s]Optimization Progress: 3101pipeline [29:57,  3.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3101pipeline [29:57,  3.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3101pipeline [29:57,  3.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3101pipeline [29:57,  3.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 3101pipeline [29:57,  3.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3101pipeline [29:58,  3.99pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3102/3200 [29:58<00:24,  3.99pipeline/s]Optimization Progress:  97%|█████████▋| 3103/3200 [29:58<00:32,  2.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3103/3200 [29:58<00:32,  2.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3104/3200 [29:58<00:32,  2.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3105/3200 [29:58<00:31,  2.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3106/3200 [29:58<00:31,  2.99pipeline/s]Optimization Progress:  97%|█████████▋| 3108/3200 [30:01<00:41,  2.24pipeline/s]Optimization Progress: 100%|█████████▉| 3188/3200 [30:03<00:03,  3.13pipeline/s]
Generation 31 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3201pipeline [30:03,  3.13pipeline/s]Optimization Progress: 3201pipeline [30:03,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [30:03,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [30:04,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [30:04,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [30:05,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [30:05,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [30:05,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [30:05,  4.40pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3204/3300 [30:05<00:21,  4.40pipeline/s]Optimization Progress:  97%|█████████▋| 3205/3300 [30:05<00:27,  3.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3205/3300 [30:05<00:27,  3.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3206/3300 [30:05<00:26,  3.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3207/3300 [30:05<00:26,  3.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3208/3300 [30:05<00:26,  3.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3209/3300 [30:05<00:26,  3.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3210/3300 [30:05<00:25,  3.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3211/3300 [30:05<00:25,  3.49pipeline/s]Optimization Progress:  97%|█████████▋| 3212/3300 [30:20<00:25,  3.49pipeline/s]Optimization Progress:  97%|█████████▋| 3213/3300 [31:57<06:22,  4.40s/pipeline]Optimization Progress: 100%|█████████▉| 3293/3300 [31:59<00:21,  3.09s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3301pipeline [32:00,  3.09s/pipeline]Optimization Progress: 3301pipeline [32:00,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [32:00,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 3301pipeline [32:00,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [32:00,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3301pipeline [32:00,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [32:00,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3301pipeline [32:00,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3301pipeline [32:01,  2.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [32:01,  2.17s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [32:02<02:53,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3303/3400 [32:02<02:53,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3304/3400 [32:02<02:51,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3305/3400 [32:02<02:50,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3306/3400 [32:02<02:48,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3307/3400 [32:02<02:46,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3308/3400 [32:02<02:44,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3309/3400 [32:02<02:42,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3310/3400 [32:02<02:41,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3311/3400 [32:02<02:39,  1.79s/pipeline]Optimization Progress:  97%|█████████▋| 3313/3400 [32:06<02:01,  1.40s/pipeline]Optimization Progress: 100%|█████████▉| 3393/3400 [32:07<00:06,  1.02pipeline/s]
Generation 33 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [32:07,  1.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [32:08,  1.02pipeline/s]Optimization Progress: 3401pipeline [32:08,  1.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3401pipeline [32:08,  1.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 3401pipeline [32:08,  1.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [32:08,  1.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [32:09,  1.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3401pipeline [32:09,  1.40pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3401/3500 [32:09<01:10,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3402/3500 [32:09<01:09,  1.40pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3403/3500 [32:09<01:09,  1.40pipeline/s]Optimization Progress:  97%|█████████▋| 3404/3500 [32:09<00:58,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3404/3500 [32:09<00:58,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3405/3500 [32:09<00:57,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3406/3500 [32:09<00:57,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3407/3500 [32:09<00:56,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3408/3500 [32:09<00:56,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3409/3500 [32:09<00:55,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3410/3500 [32:09<00:54,  1.64pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3411/3500 [32:09<00:54,  1.64pipeline/s]Optimization Progress:  98%|█████████▊| 3413/3500 [32:15<00:54,  1.61pipeline/s]Optimization Progress: 100%|█████████▉| 3493/3500 [32:17<00:03,  2.25pipeline/s]
Generation 34 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [32:18,  2.25pipeline/s]Optimization Progress: 3501pipeline [32:18,  2.96pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [32:18,  2.96pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 3501pipeline [32:19,  2.96pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [32:19,  2.96pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 3501pipeline [32:20,  2.96pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [32:20,  2.96pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3501/3600 [32:20<00:33,  2.96pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3502/3600 [32:20<00:33,  2.96pipeline/s]Optimization Progress:  97%|█████████▋| 3503/3600 [32:20<00:46,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3503/3600 [32:20<00:46,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3504/3600 [32:20<00:46,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3505/3600 [32:20<00:45,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3506/3600 [32:20<00:45,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3507/3600 [32:20<00:44,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3508/3600 [32:20<00:44,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3509/3600 [32:20<00:43,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3510/3600 [32:20<00:43,  2.08pipeline/s]Optimization Progress:  98%|█████████▊| 3512/3600 [32:26<00:47,  1.87pipeline/s]Optimization Progress: 100%|█████████▉| 3592/3600 [32:26<00:03,  2.65pipeline/s]
Generation 35 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [32:27,  2.65pipeline/s]Optimization Progress: 3601pipeline [32:27,  3.68pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [32:27,  3.68pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 3601pipeline [32:28,  3.68pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [32:28,  3.68pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3603/3700 [32:28<00:26,  3.68pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3604/3700 [32:28<00:26,  3.68pipeline/s]Optimization Progress:  97%|█████████▋| 3605/3700 [32:28<00:29,  3.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3605/3700 [32:28<00:29,  3.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3606/3700 [32:28<00:29,  3.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3607/3700 [32:28<00:29,  3.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3608/3700 [32:28<00:28,  3.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3609/3700 [32:28<00:28,  3.18pipeline/s]Optimization Progress:  98%|█████████▊| 3611/3700 [32:33<00:39,  2.23pipeline/s]Optimization Progress: 100%|█████████▉| 3691/3700 [32:36<00:02,  3.07pipeline/s]
Generation 36 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 3701pipeline [32:36,  3.07pipeline/s]Optimization Progress: 3701pipeline [32:36,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [32:37,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3701pipeline [32:37,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [32:38,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3701pipeline [32:38,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [32:38,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3701pipeline [32:38,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [32:38,  4.20pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3701pipeline [32:38,  4.20pipeline/s]Optimization Progress:  97%|█████████▋| 3704/3800 [32:38<00:32,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3704/3800 [32:38<00:32,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3705/3800 [32:38<00:32,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3706/3800 [32:38<00:32,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3707/3800 [32:38<00:31,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3708/3800 [32:38<00:31,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3709/3800 [32:38<00:31,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3710/3800 [32:38<00:30,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3711/3800 [32:38<00:30,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3712/3800 [32:38<00:30,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3713/3800 [32:38<00:29,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3714/3800 [32:38<00:29,  2.92pipeline/s]Optimization Progress:  98%|█████████▊| 3716/3800 [32:42<00:29,  2.90pipeline/s]Optimization Progress: 100%|█████████▉| 3796/3800 [32:46<00:01,  3.94pipeline/s]
Generation 37 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3801pipeline [32:46,  3.94pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [32:47,  3.94pipeline/s]Optimization Progress: 3801pipeline [32:47,  4.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [32:47,  4.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [32:47,  4.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [32:47,  4.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3801pipeline [32:47,  4.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3801pipeline [32:47,  4.06pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [32:47<00:24,  4.06pipeline/s]Optimization Progress:  98%|█████████▊| 3803/3900 [32:47<00:25,  3.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3803/3900 [32:47<00:25,  3.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3804/3900 [32:47<00:24,  3.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3805/3900 [32:47<00:24,  3.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3806/3900 [32:47<00:24,  3.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3807/3900 [32:47<00:24,  3.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3808/3900 [32:47<00:23,  3.86pipeline/s]Optimization Progress:  98%|█████████▊| 3810/3900 [32:52<00:34,  2.59pipeline/s]Optimization Progress: 100%|█████████▉| 3890/3900 [32:54<00:02,  3.62pipeline/s]
Generation 38 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 3901pipeline [32:54,  3.62pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [32:54,  3.62pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3901pipeline [32:54,  3.62pipeline/s]Optimization Progress: 3901pipeline [32:54,  4.84pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 3901pipeline [32:54,  4.84pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [32:55,  4.84pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [32:55,  4.84pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3903/4000 [32:56<00:20,  4.84pipeline/s]Optimization Progress:  98%|█████████▊| 3904/4000 [32:56<00:29,  3.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3904/4000 [32:56<00:29,  3.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3905/4000 [32:56<00:28,  3.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3906/4000 [32:56<00:28,  3.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3907/4000 [32:56<00:28,  3.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3908/4000 [32:56<00:28,  3.28pipeline/s]Optimization Progress:  98%|█████████▊| 3910/4000 [33:00<00:37,  2.37pipeline/s]Optimization Progress: 100%|█████████▉| 3990/4000 [33:04<00:03,  3.23pipeline/s]
Generation 39 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [33:04,  3.23pipeline/s]Optimization Progress: 4001pipeline [33:04,  4.44pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 4001pipeline [33:05,  4.44pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [33:05,  4.44pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [33:05,  4.44pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4001/4100 [33:06<00:22,  4.44pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4002/4100 [33:06<00:22,  4.44pipeline/s]Optimization Progress:  98%|█████████▊| 4003/4100 [33:06<00:35,  2.75pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4003/4100 [33:06<00:35,  2.75pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4004/4100 [33:06<00:34,  2.75pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4005/4100 [33:06<00:34,  2.75pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4006/4100 [33:06<00:34,  2.75pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4007/4100 [33:06<00:33,  2.75pipeline/s]Optimization Progress:  98%|█████████▊| 4009/4100 [33:09<00:36,  2.53pipeline/s]Optimization Progress: 100%|█████████▉| 4089/4100 [33:11<00:03,  3.50pipeline/s]
Generation 40 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [33:12,  3.50pipeline/s]Optimization Progress: 4101pipeline [33:12,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [33:12,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [33:12,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [33:12,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [33:13,  4.40pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 4101pipeline [33:13,  4.40pipeline/s]Optimization Progress:  98%|█████████▊| 4103/4200 [33:13<00:29,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4103/4200 [33:13<00:29,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4104/4200 [33:13<00:28,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4105/4200 [33:13<00:28,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4106/4200 [33:13<00:28,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4107/4200 [33:13<00:27,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4108/4200 [33:13<00:27,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4109/4200 [33:13<00:27,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4110/4200 [33:13<00:27,  3.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4111/4200 [33:13<00:26,  3.33pipeline/s]Optimization Progress:  98%|█████████▊| 4113/4200 [33:17<00:27,  3.13pipeline/s]Optimization Progress: 100%|█████████▉| 4193/4200 [33:18<00:01,  4.34pipeline/s]
Generation 41 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 4201pipeline [33:19,  4.34pipeline/s]Optimization Progress: 4201pipeline [33:19,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [33:20,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [33:20,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [33:20,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [33:21,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [33:21,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [33:21,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [33:21,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [33:21,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [33:21,  5.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [33:21,  5.07pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4201/4300 [33:21<00:19,  5.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4202/4300 [33:21<00:19,  5.07pipeline/s]Optimization Progress:  98%|█████████▊| 4203/4300 [33:21<00:40,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [33:21<00:40,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4204/4300 [33:21<00:39,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4205/4300 [33:21<00:39,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4206/4300 [33:21<00:38,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4207/4300 [33:21<00:38,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4208/4300 [33:21<00:38,  2.42pipeline/s]Optimization Progress:  98%|█████████▊| 4210/4300 [33:25<00:41,  2.15pipeline/s]Optimization Progress: 100%|█████████▉| 4290/4300 [33:27<00:03,  3.00pipeline/s]
Generation 42 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 4301pipeline [33:27,  3.00pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:27,  3.00pipeline/s]Optimization Progress: 4301pipeline [33:27,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4301pipeline [33:28,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:28,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:28,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:29,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:29,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:29,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:29,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:29,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [33:29,  4.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4301pipeline [33:29,  4.14pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4303/4400 [33:29<00:23,  4.14pipeline/s]Optimization Progress:  98%|█████████▊| 4304/4400 [33:29<00:34,  2.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4304/4400 [33:29<00:34,  2.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4305/4400 [33:29<00:34,  2.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4306/4400 [33:29<00:34,  2.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4307/4400 [33:29<00:33,  2.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4308/4400 [33:29<00:33,  2.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4309/4400 [33:29<00:32,  2.76pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4310/4400 [33:29<00:32,  2.76pipeline/s]Optimization Progress:  98%|█████████▊| 4312/4400 [33:33<00:33,  2.63pipeline/s]Optimization Progress: 100%|█████████▉| 4392/4400 [33:35<00:02,  3.65pipeline/s]
Generation 43 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [33:35,  3.65pipeline/s]Optimization Progress: 4401pipeline [33:35,  5.05pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 4401pipeline [33:36,  5.05pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [33:37,  5.05pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [33:37,  5.05pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4402/4500 [33:37<00:19,  5.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4403/4500 [33:37<00:19,  5.05pipeline/s]Optimization Progress:  98%|█████████▊| 4404/4500 [33:37<00:36,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4404/4500 [33:37<00:36,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4405/4500 [33:37<00:35,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4406/4500 [33:37<00:35,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4407/4500 [33:37<00:34,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4408/4500 [33:37<00:34,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4409/4500 [33:37<00:34,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4410/4500 [33:37<00:33,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4411/4500 [33:37<00:33,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4412/4500 [33:37<00:33,  2.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4413/4500 [33:37<00:32,  2.67pipeline/s]Optimization Progress:  98%|█████████▊| 4415/4500 [33:43<00:35,  2.39pipeline/s]Optimization Progress: 100%|█████████▉| 4495/4500 [33:45<00:01,  3.33pipeline/s]
Generation 44 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4501pipeline [33:46,  3.33pipeline/s]Optimization Progress: 4501pipeline [33:46,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [33:46,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 4501pipeline [33:46,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [33:46,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4501pipeline [33:47,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [33:47,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [33:47,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [33:47,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [33:47,  4.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [33:48,  4.02pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4502/4600 [33:48<00:24,  4.02pipeline/s]Optimization Progress:  98%|█████████▊| 4503/4600 [33:48<00:47,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4503/4600 [33:48<00:47,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4504/4600 [33:48<00:46,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4505/4600 [33:48<00:46,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4506/4600 [33:48<00:45,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4507/4600 [33:48<00:45,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4508/4600 [33:48<00:44,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4509/4600 [33:48<00:44,  2.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4510/4600 [33:48<00:43,  2.06pipeline/s]Optimization Progress:  98%|█████████▊| 4512/4600 [33:55<00:50,  1.75pipeline/s]Optimization Progress: 100%|█████████▉| 4592/4600 [33:59<00:03,  2.40pipeline/s]
Generation 45 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4601pipeline [33:59,  2.40pipeline/s]Optimization Progress: 4601pipeline [33:59,  3.39pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [34:00,  3.39pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4601pipeline [34:00,  3.39pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4603/4700 [34:01<00:28,  3.39pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4604/4700 [34:01<00:28,  3.39pipeline/s]Optimization Progress:  98%|█████████▊| 4605/4700 [34:01<00:29,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4605/4700 [34:01<00:29,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4606/4700 [34:01<00:29,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4607/4700 [34:01<00:28,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4608/4700 [34:01<00:28,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4609/4700 [34:01<00:28,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4610/4700 [34:01<00:27,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4611/4700 [34:01<00:27,  3.23pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4612/4700 [34:01<00:27,  3.23pipeline/s]Optimization Progress:  98%|█████████▊| 4614/4700 [34:03<00:26,  3.27pipeline/s]Optimization Progress: 100%|█████████▉| 4694/4700 [34:05<00:01,  4.54pipeline/s]
Generation 46 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [34:05,  4.54pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 4701pipeline [34:05,  4.54pipeline/s]Optimization Progress: 4701pipeline [34:05,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [34:05,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4701pipeline [34:06,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [34:06,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [34:06,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4701pipeline [34:06,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4701pipeline [34:06,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4701pipeline [34:07,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [34:07,  6.26pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [34:07,  6.26pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4702/4800 [34:08<00:15,  6.26pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4703/4800 [34:08<00:15,  6.26pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4704/4800 [34:08<00:15,  6.26pipeline/s]Optimization Progress:  98%|█████████▊| 4705/4800 [34:08<00:28,  3.29pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4705/4800 [34:08<00:28,  3.29pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4706/4800 [34:08<00:28,  3.29pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4707/4800 [34:08<00:28,  3.29pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4708/4800 [34:08<00:27,  3.29pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4709/4800 [34:08<00:27,  3.29pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4710/4800 [34:08<00:27,  3.29pipeline/s]Optimization Progress:  98%|█████████▊| 4712/4800 [34:12<00:33,  2.66pipeline/s]Optimization Progress: 100%|█████████▉| 4792/4800 [34:15<00:02,  3.61pipeline/s]
Generation 47 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4801pipeline [34:15,  3.61pipeline/s]Optimization Progress: 4801pipeline [34:15,  5.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4801pipeline [34:15,  5.02pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4801pipeline [34:15,  5.02pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4801/4900 [34:18<00:19,  5.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4802/4900 [34:18<00:19,  5.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4803/4900 [34:18<00:19,  5.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4804/4900 [34:18<00:19,  5.02pipeline/s]Optimization Progress:  98%|█████████▊| 4805/4900 [34:18<00:32,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4805/4900 [34:18<00:32,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4806/4900 [34:18<00:32,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4807/4900 [34:18<00:31,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4808/4900 [34:18<00:31,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4809/4900 [34:18<00:31,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4810/4900 [34:18<00:30,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4811/4900 [34:18<00:30,  2.91pipeline/s]Optimization Progress:  98%|█████████▊| 4813/4900 [34:22<00:34,  2.49pipeline/s]Optimization Progress: 100%|█████████▉| 4893/4900 [34:23<00:01,  3.53pipeline/s]
Generation 48 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [34:23,  3.53pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 4901pipeline [34:24,  3.53pipeline/s]Optimization Progress: 4901pipeline [34:24,  4.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4901pipeline [34:24,  4.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [34:24,  4.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [34:25,  4.56pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4904/5000 [34:25<00:21,  4.56pipeline/s]Optimization Progress:  98%|█████████▊| 4905/5000 [34:25<00:27,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4905/5000 [34:25<00:27,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4906/5000 [34:25<00:27,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4907/5000 [34:25<00:26,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4908/5000 [34:25<00:26,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4909/5000 [34:25<00:26,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4910/5000 [34:25<00:26,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4911/5000 [34:25<00:25,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4912/5000 [34:25<00:25,  3.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4913/5000 [34:25<00:25,  3.45pipeline/s]Optimization Progress:  98%|█████████▊| 4915/5000 [34:29<00:26,  3.16pipeline/s]Optimization Progress: 100%|█████████▉| 4995/5000 [34:31<00:01,  4.35pipeline/s]
Generation 49 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5001pipeline [34:32,  4.35pipeline/s]Optimization Progress: 5001pipeline [34:32,  4.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [34:32,  4.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [34:33,  4.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [34:33,  4.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [34:34,  4.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [34:34,  4.88pipeline/s]Optimization Progress:  98%|█████████▊| 5004/5100 [34:34<00:31,  3.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5004/5100 [34:34<00:31,  3.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5005/5100 [34:34<00:30,  3.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5006/5100 [34:34<00:30,  3.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5007/5100 [34:34<00:30,  3.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5008/5100 [34:34<00:29,  3.07pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5009/5100 [34:34<00:29,  3.07pipeline/s]Optimization Progress:  98%|█████████▊| 5011/5100 [34:39<00:37,  2.40pipeline/s]Optimization Progress: 100%|█████████▉| 5091/5100 [34:41<00:02,  3.34pipeline/s]
Generation 50 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [34:41,  3.34pipeline/s]Optimization Progress: 5101pipeline [34:41,  4.64pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [34:41,  4.64pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 5101pipeline [34:42,  4.64pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [34:43,  4.64pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5101pipeline [34:43,  4.64pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 5101pipeline [34:43,  4.64pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5103/5200 [34:44<00:20,  4.64pipeline/s]Optimization Progress:  98%|█████████▊| 5104/5200 [34:44<00:41,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5104/5200 [34:44<00:41,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5105/5200 [34:44<00:40,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5106/5200 [34:44<00:40,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5107/5200 [34:44<00:39,  2.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5108/5200 [34:44<00:39,  2.33pipeline/s]Optimization Progress:  98%|█████████▊| 5110/5200 [34:51<00:58,  1.53pipeline/s]Optimization Progress: 100%|█████████▉| 5190/5200 [34:53<00:04,  2.14pipeline/s]
Generation 51 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 5201pipeline [34:54,  2.14pipeline/s]Optimization Progress: 5201pipeline [34:54,  2.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5201pipeline [34:54,  2.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5201pipeline [34:54,  2.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5201pipeline [34:55,  2.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5201pipeline [34:55,  2.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 5201pipeline [34:56,  2.97pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5202/5300 [34:56<00:32,  2.97pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5203/5300 [34:56<00:32,  2.97pipeline/s]Optimization Progress:  98%|█████████▊| 5204/5300 [34:56<00:44,  2.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5204/5300 [34:56<00:44,  2.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5205/5300 [34:56<00:43,  2.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5206/5300 [34:56<00:43,  2.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5207/5300 [34:56<00:42,  2.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5208/5300 [34:56<00:42,  2.18pipeline/s]Optimization Progress:  98%|█████████▊| 5210/5300 [35:00<00:47,  1.89pipeline/s]Optimization Progress: 100%|█████████▉| 5290/5300 [35:04<00:03,  2.60pipeline/s]
Generation 52 - Current Pareto front scores:
-1	-138780642.01089066	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=20)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5301pipeline [35:04,  2.60pipeline/s]Optimization Progress: 5301pipeline [35:04,  3.67pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5301pipeline [35:04,  3.67pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5301pipeline [35:05,  3.67pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5301pipeline [35:06,  3.67pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5301pipeline [35:06,  3.67pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5301pipeline [35:06,  3.67pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5301pipeline [35:06,  3.67pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5301pipeline [35:06,  3.67pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5301/5400 [35:07<00:26,  3.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5302/5400 [35:07<00:26,  3.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5303/5400 [35:07<00:26,  3.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5304/5400 [35:07<00:26,  3.67pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5305/5400 [35:07<00:25,  3.67pipeline/s]Optimization Progress:  98%|█████████▊| 5306/5400 [35:07<00:31,  2.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5306/5400 [35:07<00:31,  2.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5307/5400 [35:07<00:31,  2.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5308/5400 [35:07<00:31,  2.94pipeline/s]Optimization Progress:  98%|█████████▊| 5310/5400 [35:12<00:57,  1.55pipeline/s]Optimization Progress: 100%|█████████▉| 5390/5400 [35:16<00:04,  2.16pipeline/s]
Generation 53 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5401pipeline [35:16,  2.16pipeline/s]Optimization Progress: 5401pipeline [35:16,  3.03pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [35:16,  3.03pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [35:16,  3.03pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5401pipeline [35:16,  3.03pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [35:16,  3.03pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [35:16,  3.03pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [35:17,  3.03pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [35:18,  3.03pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5402/5500 [35:18<00:32,  3.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5403/5500 [35:18<00:32,  3.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5404/5500 [35:18<00:31,  3.03pipeline/s]Optimization Progress:  98%|█████████▊| 5405/5500 [35:18<00:38,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5405/5500 [35:18<00:38,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5406/5500 [35:18<00:37,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5407/5500 [35:18<00:37,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5408/5500 [35:18<00:37,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5409/5500 [35:18<00:36,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5410/5500 [35:18<00:36,  2.48pipeline/s]Optimization Progress:  98%|█████████▊| 5411/5500 [35:30<00:35,  2.48pipeline/s]Optimization Progress:  98%|█████████▊| 5412/5500 [35:53<02:34,  1.76s/pipeline]Optimization Progress: 100%|█████████▉| 5492/5500 [35:56<00:09,  1.25s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5501pipeline [35:57,  1.25s/pipeline]Optimization Progress: 5501pipeline [35:57,  1.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5501pipeline [35:57,  1.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5501pipeline [35:58,  1.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5501pipeline [35:58,  1.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 5501pipeline [35:58,  1.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5501pipeline [35:58,  1.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5501pipeline [35:58,  1.12pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5501/5600 [35:59<01:28,  1.12pipeline/s]Optimization Progress:  98%|█████████▊| 5502/5600 [35:59<01:50,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5502/5600 [35:59<01:50,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5503/5600 [35:59<01:49,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5504/5600 [35:59<01:47,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5505/5600 [35:59<01:46,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5506/5600 [35:59<01:45,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5507/5600 [35:59<01:44,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5508/5600 [35:59<01:43,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5509/5600 [35:59<01:42,  1.12s/pipeline]Optimization Progress:  98%|█████████▊| 5511/5600 [36:03<01:22,  1.08pipeline/s]Optimization Progress: 100%|█████████▉| 5591/5600 [36:05<00:05,  1.52pipeline/s]
Generation 55 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 5601pipeline [36:05,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5601pipeline [36:06,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5601pipeline [36:06,  1.52pipeline/s]Optimization Progress: 5601pipeline [36:06,  2.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5601pipeline [36:06,  2.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5601pipeline [36:06,  2.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5601pipeline [36:06,  2.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5601pipeline [36:06,  2.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5601pipeline [36:07,  2.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5601pipeline [36:07,  2.08pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5601pipeline [36:07,  2.08pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5601/5700 [36:08<00:47,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5602/5700 [36:08<00:47,  2.08pipeline/s]Optimization Progress:  98%|█████████▊| 5603/5700 [36:08<01:03,  1.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5603/5700 [36:08<01:03,  1.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5604/5700 [36:08<01:03,  1.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5605/5700 [36:08<01:02,  1.52pipeline/s]Optimization Progress:  98%|█████████▊| 5607/5700 [36:12<01:09,  1.34pipeline/s]Optimization Progress: 100%|█████████▉| 5687/5700 [36:17<00:07,  1.84pipeline/s]
Generation 56 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 5701pipeline [36:18,  1.84pipeline/s]Optimization Progress: 5701pipeline [36:18,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5701pipeline [36:18,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5701pipeline [36:18,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5701pipeline [36:18,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5701pipeline [36:18,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5701pipeline [36:18,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5701pipeline [36:19,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5701pipeline [36:19,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5701pipeline [36:19,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5701pipeline [36:20,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5701pipeline [36:20,  2.57pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5701pipeline [36:20,  2.57pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5701/5800 [36:20<00:38,  2.57pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5702/5800 [36:20<00:38,  2.57pipeline/s]Optimization Progress:  98%|█████████▊| 5703/5800 [36:20<00:52,  1.85pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5703/5800 [36:20<00:52,  1.85pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5704/5800 [36:20<00:51,  1.85pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5705/5800 [36:20<00:51,  1.85pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5706/5800 [36:20<00:50,  1.85pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5707/5800 [36:20<00:50,  1.85pipeline/s]Optimization Progress:  98%|█████████▊| 5708/5800 [36:30<00:49,  1.85pipeline/s]Optimization Progress:  98%|█████████▊| 5709/5800 [36:50<02:53,  1.90s/pipeline]Optimization Progress: 100%|█████████▉| 5789/5800 [36:52<00:14,  1.34s/pipeline]
Generation 57 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:52,  1.34s/pipeline]Optimization Progress: 5801pipeline [36:52,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:52,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 5801pipeline [36:52,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:53,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:53,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:53,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:54,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 5801pipeline [36:54,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:54,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5801pipeline [36:54,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5801pipeline [36:54,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5801pipeline [36:54,  1.06pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5803/5900 [36:55<01:31,  1.06pipeline/s]Optimization Progress:  98%|█████████▊| 5804/5900 [36:55<01:28,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5804/5900 [36:55<01:28,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5805/5900 [36:55<01:27,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5806/5900 [36:55<01:26,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5807/5900 [36:55<01:25,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5808/5900 [36:55<01:24,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5809/5900 [36:55<01:23,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5810/5900 [36:55<01:22,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5811/5900 [36:55<01:21,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 5812/5900 [36:55<01:20,  1.09pipeline/s]Optimization Progress:  99%|█████████▊| 5814/5900 [37:00<01:09,  1.24pipeline/s]Optimization Progress: 100%|█████████▉| 5894/5900 [37:03<00:03,  1.74pipeline/s]
Generation 58 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 5901pipeline [37:03,  1.74pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5901pipeline [37:03,  1.74pipeline/s]Optimization Progress: 5901pipeline [37:03,  2.36pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5901pipeline [37:04,  2.36pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5901pipeline [37:04,  2.36pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5902/6000 [37:05<00:41,  2.36pipeline/s]Optimization Progress:  98%|█████████▊| 5903/6000 [37:05<01:01,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5903/6000 [37:05<01:01,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5904/6000 [37:05<01:00,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5905/6000 [37:05<01:00,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5906/6000 [37:05<00:59,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5907/6000 [37:05<00:58,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5908/6000 [37:05<00:58,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5909/6000 [37:05<00:57,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5910/6000 [37:05<00:57,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 5911/6000 [37:05<00:56,  1.58pipeline/s]Optimization Progress:  99%|█████████▊| 5913/6000 [37:10<00:49,  1.74pipeline/s]Optimization Progress: 100%|█████████▉| 5993/6000 [37:12<00:02,  2.45pipeline/s]
Generation 59 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6001pipeline [37:12,  2.45pipeline/s]Optimization Progress: 6001pipeline [37:12,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6001pipeline [37:12,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6001pipeline [37:12,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6001pipeline [37:12,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6001pipeline [37:13,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6001pipeline [37:14,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6001pipeline [37:14,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 6001pipeline [37:14,  3.32pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6001pipeline [37:14,  3.32pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6002/6100 [37:14<00:29,  3.32pipeline/s]Optimization Progress:  98%|█████████▊| 6003/6100 [37:14<00:54,  1.77pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6003/6100 [37:14<00:54,  1.77pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6004/6100 [37:14<00:54,  1.77pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6005/6100 [37:14<00:53,  1.77pipeline/s]Optimization Progress:  98%|█████████▊| 6007/6100 [37:20<01:15,  1.22pipeline/s]Optimization Progress: 100%|█████████▉| 6087/6100 [37:24<00:07,  1.70pipeline/s]
Generation 60 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6101pipeline [37:24,  1.70pipeline/s]Optimization Progress: 6101pipeline [37:24,  2.42pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6101pipeline [37:24,  2.42pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6101pipeline [37:25,  2.42pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 6101pipeline [37:25,  2.42pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 6101pipeline [37:26,  2.42pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6102/6200 [37:26<00:40,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6103/6200 [37:26<00:40,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6104/6200 [37:26<00:39,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6105/6200 [37:26<00:39,  2.42pipeline/s]Optimization Progress:  98%|█████████▊| 6106/6200 [37:26<00:38,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6106/6200 [37:26<00:38,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6107/6200 [37:26<00:38,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6108/6200 [37:26<00:37,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6109/6200 [37:26<00:37,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6110/6200 [37:26<00:37,  2.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6111/6200 [37:26<00:36,  2.42pipeline/s]Optimization Progress:  99%|█████████▊| 6112/6200 [37:40<00:36,  2.42pipeline/s]Optimization Progress:  99%|█████████▊| 6113/6200 [37:54<02:07,  1.47s/pipeline]Optimization Progress: 100%|█████████▉| 6193/6200 [37:56<00:07,  1.04s/pipeline]
Generation 61 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6201pipeline [37:57,  1.04s/pipeline]Optimization Progress: 6201pipeline [37:57,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6201pipeline [37:58,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6201pipeline [37:58,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6201pipeline [37:59,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6201pipeline [37:59,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 6201pipeline [37:59,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6201pipeline [37:59,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6201pipeline [37:59,  1.30pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6201pipeline [37:59,  1.30pipeline/s]Optimization Progress:  98%|█████████▊| 6202/6300 [38:00<01:59,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6202/6300 [38:00<01:59,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6203/6300 [38:00<01:57,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6204/6300 [38:00<01:56,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6205/6300 [38:00<01:55,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6206/6300 [38:00<01:54,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6207/6300 [38:00<01:53,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6208/6300 [38:00<01:51,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6209/6300 [38:00<01:50,  1.22s/pipeline]Optimization Progress:  99%|█████████▊| 6211/6300 [38:04<01:28,  1.01pipeline/s]Optimization Progress: 100%|█████████▉| 6291/6300 [38:07<00:06,  1.42pipeline/s]
Generation 62 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6301pipeline [38:08,  1.42pipeline/s]Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6301pipeline [38:08,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6301pipeline [38:09,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6301pipeline [38:09,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6301pipeline [38:09,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6301pipeline [38:09,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6301pipeline [38:09,  1.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 6301pipeline [38:10,  1.99pipeline/s]Optimization Progress:  98%|█████████▊| 6303/6400 [38:10<01:05,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6303/6400 [38:10<01:05,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6304/6400 [38:10<01:04,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6305/6400 [38:10<01:04,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6306/6400 [38:10<01:03,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6307/6400 [38:10<01:02,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6308/6400 [38:10<01:02,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6309/6400 [38:10<01:01,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6310/6400 [38:10<01:00,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6311/6400 [38:10<01:00,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6312/6400 [38:10<00:59,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6313/6400 [38:10<00:58,  1.48pipeline/s]Optimization Progress:  99%|█████████▊| 6315/6400 [38:14<00:49,  1.71pipeline/s]Optimization Progress: 100%|█████████▉| 6395/6400 [38:16<00:02,  2.40pipeline/s]
Generation 63 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6401pipeline [38:17,  2.40pipeline/s]Optimization Progress: 6401pipeline [38:17,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 6401pipeline [38:17,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6401pipeline [38:17,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=3 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 6401pipeline [38:18,  3.28pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6401/6500 [38:19<00:30,  3.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6402/6500 [38:19<00:29,  3.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6403/6500 [38:19<00:29,  3.28pipeline/s]Optimization Progress:  99%|█████████▊| 6404/6500 [38:19<00:39,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6404/6500 [38:19<00:39,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6405/6500 [38:19<00:39,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6406/6500 [38:19<00:39,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6407/6500 [38:19<00:38,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6408/6500 [38:19<00:38,  2.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6409/6500 [38:19<00:37,  2.41pipeline/s]Optimization Progress:  99%|█████████▊| 6411/6500 [38:22<00:39,  2.27pipeline/s]Optimization Progress: 100%|█████████▉| 6491/6500 [38:24<00:02,  3.17pipeline/s]
Generation 64 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6501pipeline [38:24,  3.17pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6501pipeline [38:24,  3.17pipeline/s]Optimization Progress: 6501pipeline [38:24,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6501pipeline [38:24,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6501pipeline [38:24,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6501pipeline [38:25,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6501pipeline [38:25,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6501pipeline [38:25,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6501pipeline [38:25,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6501pipeline [38:25,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 6501pipeline [38:26,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 [04:21:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 6501pipeline [38:26,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 6501pipeline [38:26,  4.46pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6501pipeline [38:27,  4.46pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6501/6600 [38:27<00:22,  4.46pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6502/6600 [38:27<00:21,  4.46pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6503/6600 [38:27<00:21,  4.46pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6504/6600 [38:27<00:21,  4.46pipeline/s]Optimization Progress:  99%|█████████▊| 6505/6600 [38:27<00:37,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6505/6600 [38:27<00:37,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6506/6600 [38:27<00:37,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6507/6600 [38:27<00:37,  2.51pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6508/6600 [38:27<00:36,  2.51pipeline/s]Optimization Progress:  99%|█████████▊| 6510/6600 [38:31<00:48,  1.87pipeline/s]Optimization Progress: 100%|█████████▉| 6590/6600 [38:35<00:03,  2.58pipeline/s]
Generation 65 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6601pipeline [38:35,  2.58pipeline/s]Optimization Progress: 6601pipeline [38:35,  3.58pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6601pipeline [38:35,  3.58pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6601pipeline [38:35,  3.58pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6601pipeline [38:36,  3.58pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6601pipeline [38:36,  3.58pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6601pipeline [38:36,  3.58pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6601/6700 [38:37<00:27,  3.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6602/6700 [38:37<00:27,  3.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6603/6700 [38:37<00:27,  3.58pipeline/s]Optimization Progress:  99%|█████████▊| 6604/6700 [38:37<00:38,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6604/6700 [38:37<00:38,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6605/6700 [38:37<00:38,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6606/6700 [38:37<00:37,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6607/6700 [38:37<00:37,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6608/6700 [38:37<00:37,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6609/6700 [38:37<00:36,  2.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6610/6700 [38:37<00:36,  2.48pipeline/s]Optimization Progress:  99%|█████████▊| 6612/6700 [38:42<00:40,  2.18pipeline/s]Optimization Progress: 100%|█████████▉| 6692/6700 [38:45<00:02,  3.00pipeline/s]
Generation 66 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6701pipeline [38:46,  3.00pipeline/s]Optimization Progress: 6701pipeline [38:46,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6701pipeline [38:46,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6701pipeline [38:46,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6701pipeline [38:46,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6701pipeline [38:46,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6701pipeline [38:47,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6701pipeline [38:47,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6701pipeline [38:47,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6701pipeline [38:47,  3.97pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6701pipeline [38:47,  3.97pipeline/s]Optimization Progress:  99%|█████████▊| 6703/6800 [38:48<00:46,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6703/6800 [38:48<00:46,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6704/6800 [38:48<00:46,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6705/6800 [38:48<00:45,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6706/6800 [38:48<00:45,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6707/6800 [38:48<00:44,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6708/6800 [38:48<00:44,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6709/6800 [38:48<00:43,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6710/6800 [38:48<00:43,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6711/6800 [38:48<00:42,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6712/6800 [38:48<00:42,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6713/6800 [38:48<00:41,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6714/6800 [38:48<00:41,  2.08pipeline/s]Optimization Progress:  99%|█████████▉| 6716/6800 [38:52<00:37,  2.26pipeline/s]Optimization Progress: 100%|█████████▉| 6796/6800 [38:56<00:01,  3.10pipeline/s]
Generation 67 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6801pipeline [38:56,  3.10pipeline/s]Optimization Progress: 6801pipeline [38:56,  4.00pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 6801pipeline [38:57,  4.00pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6801pipeline [38:57,  4.00pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 6801pipeline [38:57,  4.00pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6802/6900 [38:58<00:24,  4.00pipeline/s]Optimization Progress:  99%|█████████▊| 6803/6900 [38:58<00:47,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6803/6900 [38:58<00:47,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6804/6900 [38:58<00:47,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6805/6900 [38:58<00:46,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6806/6900 [38:58<00:46,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6807/6900 [38:58<00:45,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6808/6900 [38:58<00:45,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6809/6900 [38:58<00:44,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6810/6900 [38:58<00:44,  2.03pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6811/6900 [38:58<00:43,  2.03pipeline/s]Optimization Progress:  99%|█████████▊| 6813/6900 [39:02<00:40,  2.16pipeline/s]Optimization Progress: 100%|█████████▉| 6893/6900 [39:06<00:02,  2.96pipeline/s]
Generation 68 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6901pipeline [39:06,  2.96pipeline/s]Optimization Progress: 6901pipeline [39:06,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6901pipeline [39:07,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6901pipeline [39:07,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6901pipeline [39:07,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 6901pipeline [39:08,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6901pipeline [39:08,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6901pipeline [39:08,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6901pipeline [39:08,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 6901pipeline [39:09,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 6901pipeline [39:09,  4.09pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 6901pipeline [39:09,  4.09pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6901/7000 [39:10<00:24,  4.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6902/7000 [39:10<00:23,  4.09pipeline/s]Optimization Progress:  99%|█████████▊| 6903/7000 [39:10<01:05,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6903/7000 [39:10<01:05,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6904/7000 [39:10<01:04,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6905/7000 [39:10<01:03,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6906/7000 [39:10<01:02,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6907/7000 [39:10<01:02,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6908/7000 [39:10<01:01,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6909/7000 [39:10<01:00,  1.49pipeline/s]Optimization Progress:  99%|█████████▊| 6910/7000 [39:20<01:00,  1.49pipeline/s]Optimization Progress:  99%|█████████▊| 6911/7000 [40:05<03:45,  2.54s/pipeline]Optimization Progress: 100%|█████████▉| 6991/7000 [40:13<00:16,  1.81s/pipeline]
Generation 69 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7001pipeline [40:13,  1.81s/pipeline]Optimization Progress: 7001pipeline [40:13,  1.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 7001pipeline [40:13,  1.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7001pipeline [40:15,  1.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7001pipeline [40:15,  1.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7001pipeline [40:15,  1.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7001pipeline [40:15,  1.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7001pipeline [40:15,  1.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7001pipeline [40:15,  1.27s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7002/7100 [40:15<02:04,  1.27s/pipeline]Optimization Progress:  99%|█████████▊| 7003/7100 [40:15<01:58,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7003/7100 [40:15<01:58,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7004/7100 [40:15<01:57,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7005/7100 [40:15<01:56,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7006/7100 [40:15<01:54,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7007/7100 [40:15<01:53,  1.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7008/7100 [40:15<01:52,  1.22s/pipeline]Optimization Progress:  99%|█████████▊| 7009/7100 [40:30<01:51,  1.22s/pipeline]Optimization Progress:  99%|█████████▊| 7010/7100 [42:04<08:17,  5.53s/pipeline]Optimization Progress: 100%|█████████▉| 7090/7100 [42:09<00:38,  3.89s/pipeline]
Generation 70 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7101pipeline [42:09,  3.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7101pipeline [42:09,  3.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 7101pipeline [42:09,  3.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7101pipeline [42:09,  3.89s/pipeline]Optimization Progress: 7101pipeline [42:09,  2.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 7101pipeline [42:10,  2.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7101pipeline [42:10,  2.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7101pipeline [42:11,  2.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7101pipeline [42:11,  2.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 7101pipeline [42:11,  2.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7101pipeline [42:11,  2.73s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7102/7200 [42:12<04:27,  2.73s/pipeline]Optimization Progress:  99%|█████████▊| 7103/7200 [42:12<03:40,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7103/7200 [42:12<03:40,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7104/7200 [42:12<03:38,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7105/7200 [42:12<03:35,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7106/7200 [42:12<03:33,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7107/7200 [42:12<03:31,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7108/7200 [42:12<03:29,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7109/7200 [42:12<03:26,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7110/7200 [42:12<03:24,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7111/7200 [42:12<03:22,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7112/7200 [42:12<03:20,  2.27s/pipeline]Optimization Progress:  99%|█████████▉| 7114/7200 [42:17<02:30,  1.74s/pipeline]Optimization Progress: 100%|█████████▉| 7194/7200 [42:20<00:07,  1.23s/pipeline]
Generation 71 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7201pipeline [42:21,  1.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7201pipeline [42:21,  1.23s/pipeline]Optimization Progress: 7201pipeline [42:21,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7201pipeline [42:21,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7201pipeline [42:21,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 7201pipeline [42:21,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 7201pipeline [42:22,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7201pipeline [42:22,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7201pipeline [42:22,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7201pipeline [42:22,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 7201pipeline [42:23,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7201pipeline [42:23,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7201pipeline [42:23,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 7201pipeline [42:23,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7201pipeline [42:23,  1.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 7201pipeline [42:23,  1.15pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7201/7300 [42:24<01:26,  1.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7202/7300 [42:24<01:25,  1.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7203/7300 [42:24<01:24,  1.15pipeline/s]Optimization Progress:  99%|█████████▊| 7204/7300 [42:24<01:27,  1.09pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7204/7300 [42:24<01:27,  1.09pipeline/s]Optimization Progress:  99%|█████████▊| 7206/7300 [42:28<02:04,  1.33s/pipeline]Optimization Progress: 100%|█████████▉| 7286/7300 [42:32<00:13,  1.06pipeline/s]
Generation 72 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7301pipeline [42:32,  1.06pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7301pipeline [42:32,  1.06pipeline/s]Optimization Progress: 7301pipeline [42:32,  1.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7301pipeline [42:33,  1.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7301pipeline [42:33,  1.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7301pipeline [42:34,  1.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 7301pipeline [42:34,  1.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7301pipeline [42:34,  1.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7301pipeline [42:34,  1.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7301pipeline [42:35,  1.50pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7302/7400 [42:35<01:05,  1.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7303/7400 [42:35<01:04,  1.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7304/7400 [42:35<01:03,  1.50pipeline/s]Optimization Progress:  99%|█████████▊| 7305/7400 [42:35<01:04,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7305/7400 [42:35<01:04,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7306/7400 [42:35<01:03,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7307/7400 [42:35<01:02,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7308/7400 [42:35<01:02,  1.48pipeline/s]Optimization Progress:  99%|█████████▉| 7310/7400 [42:43<01:27,  1.03pipeline/s]Optimization Progress: 100%|█████████▉| 7390/7400 [42:52<00:07,  1.41pipeline/s]
Generation 73 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7401pipeline [42:53,  1.41pipeline/s]Optimization Progress: 7401pipeline [42:53,  1.95pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7401pipeline [42:54,  1.95pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7401pipeline [42:54,  1.95pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7401pipeline [42:54,  1.95pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7401pipeline [42:54,  1.95pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 7401pipeline [42:54,  1.95pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 7401pipeline [42:54,  1.95pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7401pipeline [42:55,  1.95pipeline/s]Optimization Progress:  99%|█████████▊| 7403/7500 [42:55<01:06,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7403/7500 [42:55<01:06,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7404/7500 [42:55<01:05,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7405/7500 [42:55<01:04,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7406/7500 [42:55<01:04,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7407/7500 [42:55<01:03,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7408/7500 [42:55<01:02,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7409/7500 [42:55<01:02,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7410/7500 [42:55<01:01,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7411/7500 [42:55<01:00,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7412/7500 [42:55<00:59,  1.47pipeline/s]Optimization Progress:  99%|█████████▉| 7413/7500 [43:10<00:59,  1.47pipeline/s]Optimization Progress:  99%|█████████▉| 7414/7500 [46:17<08:35,  6.00s/pipeline]Optimization Progress: 100%|█████████▉| 7494/7500 [46:21<00:25,  4.21s/pipeline]
Generation 74 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7501pipeline [46:21,  4.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7501pipeline [46:21,  4.21s/pipeline]Optimization Progress: 7501pipeline [46:21,  2.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7501pipeline [46:21,  2.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 7501pipeline [46:21,  2.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7501pipeline [46:22,  2.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7501pipeline [46:22,  2.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 7501pipeline [46:22,  2.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7501pipeline [46:22,  2.97s/pipeline]Optimization Progress:  99%|█████████▊| 7502/7600 [46:23<04:26,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7502/7600 [46:23<04:26,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7503/7600 [46:23<04:23,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7504/7600 [46:23<04:21,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7505/7600 [46:23<04:18,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7506/7600 [46:23<04:15,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7507/7600 [46:23<04:13,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7508/7600 [46:23<04:10,  2.72s/pipeline]Optimization Progress:  99%|█████████▉| 7510/7600 [46:29<03:09,  2.10s/pipeline]Optimization Progress: 100%|█████████▉| 7590/7600 [46:32<00:14,  1.49s/pipeline]
Generation 75 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7601pipeline [46:32,  1.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 7601pipeline [46:32,  1.49s/pipeline]Optimization Progress: 7601pipeline [46:32,  1.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7601pipeline [46:32,  1.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7601pipeline [46:33,  1.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7601pipeline [46:33,  1.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7601pipeline [46:33,  1.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 7601pipeline [46:34,  1.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7601pipeline [46:34,  1.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7601pipeline [46:34,  1.05s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7602/7700 [46:35<01:43,  1.05s/pipeline]Optimization Progress:  99%|█████████▊| 7603/7700 [46:35<01:52,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7603/7700 [46:35<01:52,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7604/7700 [46:35<01:51,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7605/7700 [46:35<01:50,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7606/7700 [46:35<01:49,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7607/7700 [46:35<01:47,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7608/7700 [46:35<01:46,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7609/7700 [46:35<01:45,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7610/7700 [46:35<01:44,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7611/7700 [46:35<01:43,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7612/7700 [46:35<01:42,  1.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7613/7700 [46:35<01:40,  1.16s/pipeline]Optimization Progress:  99%|█████████▉| 7615/7700 [46:39<01:16,  1.11pipeline/s]Optimization Progress: 100%|█████████▉| 7695/7700 [46:43<00:03,  1.55pipeline/s]
Generation 76 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7701pipeline [46:43,  1.55pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7701pipeline [46:43,  1.55pipeline/s]Optimization Progress: 7701pipeline [46:43,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7701pipeline [46:43,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 7701pipeline [46:43,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7701pipeline [46:43,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7701pipeline [46:44,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7701pipeline [46:44,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7701pipeline [46:44,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7701pipeline [46:44,  2.11pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7701pipeline [46:45,  2.11pipeline/s]Optimization Progress:  99%|█████████▉| 7703/7800 [46:46<01:10,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7703/7800 [46:46<01:10,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7704/7800 [46:46<01:09,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7705/7800 [46:46<01:09,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7706/7800 [46:46<01:08,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7707/7800 [46:46<01:07,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7708/7800 [46:46<01:06,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7709/7800 [46:46<01:06,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7710/7800 [46:46<01:05,  1.38pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7711/7800 [46:46<01:04,  1.38pipeline/s]Optimization Progress:  99%|█████████▉| 7713/7800 [46:50<00:54,  1.59pipeline/s]Optimization Progress: 100%|█████████▉| 7793/7800 [46:53<00:03,  2.21pipeline/s]
Generation 77 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7801pipeline [46:53,  2.21pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 7801pipeline [46:53,  2.21pipeline/s]Optimization Progress: 7801pipeline [46:53,  2.92pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7801pipeline [46:53,  2.92pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 7801pipeline [46:54,  2.92pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7801pipeline [46:54,  2.92pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7801pipeline [46:54,  2.92pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7801pipeline [46:54,  2.92pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7801pipeline [46:55,  2.92pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7801pipeline [46:56,  2.92pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7801/7900 [46:56<00:33,  2.92pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7802/7900 [46:56<00:33,  2.92pipeline/s]Optimization Progress:  99%|█████████▉| 7803/7900 [46:56<01:00,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7803/7900 [46:56<01:00,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7804/7900 [46:56<00:59,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7805/7900 [46:56<00:59,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7806/7900 [46:56<00:58,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7807/7900 [46:56<00:57,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7808/7900 [46:56<00:57,  1.60pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7809/7900 [46:56<00:56,  1.60pipeline/s]Optimization Progress:  99%|█████████▉| 7811/7900 [47:02<00:59,  1.50pipeline/s]Optimization Progress: 100%|█████████▉| 7891/7900 [47:06<00:04,  2.08pipeline/s]
Generation 78 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7901pipeline [47:06,  2.08pipeline/s]Optimization Progress: 7901pipeline [47:06,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7901pipeline [47:06,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7901pipeline [47:07,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 7901pipeline [47:07,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7901pipeline [47:07,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 7901pipeline [47:07,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7901pipeline [47:07,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 7901pipeline [47:08,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7901pipeline [47:08,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7901pipeline [47:08,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 7901pipeline [47:08,  2.89pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 7901pipeline [47:08,  2.89pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7901/8000 [47:09<00:34,  2.89pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7902/8000 [47:09<00:33,  2.89pipeline/s]Optimization Progress:  99%|█████████▉| 7903/8000 [47:09<01:02,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7903/8000 [47:09<01:02,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7904/8000 [47:09<01:01,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7905/8000 [47:09<01:00,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7906/8000 [47:09<01:00,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7907/8000 [47:09<00:59,  1.56pipeline/s]Optimization Progress:  99%|█████████▉| 7909/8000 [47:13<01:00,  1.49pipeline/s]Optimization Progress: 100%|█████████▉| 7989/8000 [47:17<00:05,  2.07pipeline/s]
Generation 79 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8001pipeline [47:17,  2.07pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8001pipeline [47:18,  2.07pipeline/s]Optimization Progress: 8001pipeline [47:18,  2.70pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8001pipeline [47:20,  2.70pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8001pipeline [47:20,  2.70pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8001pipeline [47:20,  2.70pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 8001pipeline [47:20,  2.70pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8001pipeline [47:21,  2.70pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8001pipeline [47:21,  2.70pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 8001pipeline [47:21,  2.70pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8002/8100 [47:21<00:36,  2.70pipeline/s]Optimization Progress:  99%|█████████▉| 8003/8100 [47:21<01:02,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8003/8100 [47:21<01:02,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8004/8100 [47:21<01:01,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8005/8100 [47:21<01:00,  1.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8006/8100 [47:21<01:00,  1.56pipeline/s]Optimization Progress:  99%|█████████▉| 8008/8100 [47:30<01:31,  1.01pipeline/s]Optimization Progress: 100%|█████████▉| 8088/8100 [47:31<00:08,  1.43pipeline/s]
Generation 80 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 8101pipeline [47:31,  1.43pipeline/s]Optimization Progress: 8101pipeline [47:31,  2.01pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 8101pipeline [47:31,  2.01pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8101pipeline [47:32,  2.01pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8101pipeline [47:33,  2.01pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8101pipeline [47:33,  2.01pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 8101pipeline [47:34,  2.01pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8101/8200 [47:34<00:49,  2.01pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8102/8200 [47:34<00:48,  2.01pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8103/8200 [47:34<00:48,  2.01pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8104/8200 [47:34<00:47,  2.01pipeline/s]Optimization Progress:  99%|█████████▉| 8105/8200 [47:34<00:51,  1.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8105/8200 [47:34<00:51,  1.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8106/8200 [47:34<00:51,  1.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8107/8200 [47:34<00:50,  1.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8108/8200 [47:34<00:50,  1.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8109/8200 [47:34<00:49,  1.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8110/8200 [47:34<00:48,  1.84pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8111/8200 [47:34<00:48,  1.84pipeline/s]Optimization Progress:  99%|█████████▉| 8113/8200 [47:38<00:46,  1.88pipeline/s]Optimization Progress: 100%|█████████▉| 8193/8200 [47:41<00:02,  2.60pipeline/s]
Generation 81 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 8201pipeline [47:43,  2.60pipeline/s]Optimization Progress: 8201pipeline [47:43,  2.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 8201pipeline [47:43,  2.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8201pipeline [47:44,  2.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8201pipeline [47:44,  2.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8201pipeline [47:44,  2.88pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8201pipeline [47:44,  2.88pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8201/8300 [47:44<00:34,  2.88pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8202/8300 [47:44<00:33,  2.88pipeline/s]Optimization Progress:  99%|█████████▉| 8203/8300 [47:44<00:41,  2.34pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8203/8300 [47:44<00:41,  2.34pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8204/8300 [47:44<00:41,  2.34pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8205/8300 [47:44<00:40,  2.34pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8206/8300 [47:44<00:40,  2.34pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8207/8300 [47:44<00:39,  2.34pipeline/s]Optimization Progress:  99%|█████████▉| 8209/8300 [47:57<01:24,  1.07pipeline/s]Optimization Progress: 100%|█████████▉| 8289/8300 [48:00<00:07,  1.51pipeline/s]
Generation 82 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8301pipeline [48:00,  1.51pipeline/s]Optimization Progress: 8301pipeline [48:00,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8301pipeline [48:01,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8301pipeline [48:02,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8301pipeline [48:02,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8301pipeline [48:02,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8301pipeline [48:02,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8301pipeline [48:02,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8301pipeline [48:02,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8301pipeline [48:03,  2.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8301pipeline [48:03,  2.12pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8301/8400 [48:03<00:46,  2.12pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8302/8400 [48:03<00:46,  2.12pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8303/8400 [48:03<00:45,  2.12pipeline/s]Optimization Progress:  99%|█████████▉| 8304/8400 [48:03<00:55,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8304/8400 [48:03<00:55,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8305/8400 [48:03<00:54,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8306/8400 [48:03<00:54,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8307/8400 [48:03<00:53,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8308/8400 [48:03<00:53,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8309/8400 [48:03<00:52,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8310/8400 [48:03<00:51,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8311/8400 [48:03<00:51,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8312/8400 [48:03<00:50,  1.73pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8313/8400 [48:03<00:50,  1.73pipeline/s]Optimization Progress:  99%|█████████▉| 8315/8400 [48:09<00:49,  1.73pipeline/s]Optimization Progress: 100%|█████████▉| 8395/8400 [48:20<00:02,  2.25pipeline/s]
Generation 83 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8401pipeline [48:20,  2.25pipeline/s]Optimization Progress: 8401pipeline [48:20,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8401pipeline [48:20,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8401pipeline [48:21,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8401pipeline [48:21,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8401pipeline [48:21,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 8401pipeline [48:21,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8401pipeline [48:22,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8401pipeline [48:23,  2.98pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8401pipeline [48:23,  2.98pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8401/8500 [48:23<00:33,  2.98pipeline/s]Optimization Progress:  99%|█████████▉| 8402/8500 [48:23<01:59,  1.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8402/8500 [48:23<01:59,  1.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8403/8500 [48:23<01:57,  1.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8404/8500 [48:23<01:56,  1.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8405/8500 [48:23<01:55,  1.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8406/8500 [48:23<01:54,  1.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8407/8500 [48:23<01:52,  1.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8408/8500 [48:23<01:51,  1.21s/pipeline]Optimization Progress:  99%|█████████▉| 8410/8500 [48:29<01:34,  1.05s/pipeline]Optimization Progress: 100%|█████████▉| 8490/8500 [48:32<00:07,  1.34pipeline/s]
Generation 84 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8501pipeline [48:32,  1.34pipeline/s]Optimization Progress: 8501pipeline [48:32,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8501pipeline [48:32,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8501pipeline [48:33,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8501pipeline [48:33,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8501pipeline [48:33,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8501pipeline [48:33,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8501pipeline [48:34,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 8501pipeline [48:34,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8501pipeline [48:35,  1.90pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8501pipeline [48:35,  1.90pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8503/8600 [48:35<00:51,  1.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8504/8600 [48:35<00:50,  1.90pipeline/s]Optimization Progress:  99%|█████████▉| 8505/8600 [48:35<00:55,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8505/8600 [48:35<00:55,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8506/8600 [48:35<00:55,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8507/8600 [48:35<00:54,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8508/8600 [48:35<00:53,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8509/8600 [48:35<00:53,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8510/8600 [48:35<00:52,  1.71pipeline/s]Optimization Progress:  99%|█████████▉| 8512/8600 [48:41<00:58,  1.52pipeline/s]Optimization Progress: 100%|█████████▉| 8592/8600 [48:43<00:03,  2.13pipeline/s]
Generation 85 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8601pipeline [48:43,  2.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8601pipeline [48:43,  2.13pipeline/s]Optimization Progress: 8601pipeline [48:43,  2.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8601pipeline [48:44,  2.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8601pipeline [48:45,  2.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8601pipeline [48:45,  2.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8601pipeline [48:46,  2.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 8601pipeline [48:46,  2.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8601pipeline [48:46,  2.99pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8601pipeline [48:46,  2.99pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8601/8700 [48:46<00:33,  2.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8602/8700 [48:46<00:32,  2.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8603/8700 [48:46<00:32,  2.99pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8604/8700 [48:46<00:32,  2.99pipeline/s]Optimization Progress:  99%|█████████▉| 8605/8700 [48:46<00:41,  2.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8605/8700 [48:46<00:41,  2.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8606/8700 [48:46<00:41,  2.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8607/8700 [48:46<00:40,  2.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8608/8700 [48:46<00:40,  2.28pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8609/8700 [48:46<00:39,  2.28pipeline/s]Optimization Progress:  99%|█████████▉| 8611/8700 [48:51<00:50,  1.75pipeline/s]Optimization Progress: 100%|█████████▉| 8691/8700 [48:52<00:03,  2.48pipeline/s]
Generation 86 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8701pipeline [48:53,  2.48pipeline/s]Optimization Progress: 8701pipeline [48:53,  3.18pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8701pipeline [48:53,  3.18pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8701pipeline [48:53,  3.18pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8701pipeline [48:54,  3.18pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8701pipeline [48:54,  3.18pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8701pipeline [48:55,  3.18pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8701pipeline [48:55,  3.18pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8701/8800 [48:55<00:31,  3.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8702/8800 [48:55<00:30,  3.18pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8703/8800 [48:55<00:30,  3.18pipeline/s]Optimization Progress:  99%|█████████▉| 8704/8800 [48:55<00:35,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8704/8800 [48:55<00:35,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8705/8800 [48:55<00:34,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8706/8800 [48:55<00:34,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8707/8800 [48:55<00:34,  2.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8708/8800 [48:55<00:33,  2.71pipeline/s]Optimization Progress:  99%|█████████▉| 8710/8800 [49:00<00:44,  2.02pipeline/s]Optimization Progress: 100%|█████████▉| 8790/8800 [49:04<00:03,  2.76pipeline/s]
Generation 87 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8801pipeline [49:04,  2.76pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8801pipeline [49:04,  2.76pipeline/s]Optimization Progress: 8801pipeline [49:04,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8801pipeline [49:04,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8801pipeline [49:04,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8801pipeline [49:05,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8801pipeline [49:05,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8801pipeline [49:05,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8801pipeline [49:06,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8801pipeline [49:06,  3.85pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8801pipeline [49:07,  3.85pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8802/8900 [49:07<00:25,  3.85pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8803/8900 [49:07<00:25,  3.85pipeline/s]Optimization Progress:  99%|█████████▉| 8804/8900 [49:07<00:43,  2.21pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8804/8900 [49:07<00:43,  2.21pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8805/8900 [49:07<00:42,  2.21pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8806/8900 [49:07<00:42,  2.21pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8807/8900 [49:07<00:42,  2.21pipeline/s]Optimization Progress:  99%|█████████▉| 8809/8900 [49:13<01:01,  1.47pipeline/s]Optimization Progress: 100%|█████████▉| 8889/8900 [49:17<00:05,  2.04pipeline/s]
Generation 88 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:17,  2.04pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:17,  2.04pipeline/s]Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 8901pipeline [49:17,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:19,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8901pipeline [49:19,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8901pipeline [49:19,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 8901pipeline [49:19,  2.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 8901pipeline [49:19,  2.87pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8901/9000 [49:20<00:34,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8902/9000 [49:20<00:34,  2.87pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8903/9000 [49:20<00:33,  2.87pipeline/s]Optimization Progress:  99%|█████████▉| 8904/9000 [49:20<00:50,  1.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8904/9000 [49:20<00:50,  1.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8905/9000 [49:20<00:49,  1.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8906/9000 [49:20<00:49,  1.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8907/9000 [49:20<00:48,  1.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8908/9000 [49:20<00:48,  1.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8909/9000 [49:20<00:47,  1.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8910/9000 [49:20<00:47,  1.91pipeline/s]Optimization Progress:  99%|█████████▉| 8912/9000 [49:23<00:45,  1.94pipeline/s]Optimization Progress: 100%|█████████▉| 8992/9000 [49:27<00:03,  2.66pipeline/s]
Generation 89 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9001pipeline [49:27,  2.66pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9001pipeline [49:28,  2.66pipeline/s]Optimization Progress: 9001pipeline [49:28,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9001pipeline [49:28,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9001pipeline [49:28,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9001pipeline [49:29,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9001pipeline [49:29,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9001pipeline [49:29,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9001pipeline [49:30,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9001pipeline [49:30,  3.65pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9001pipeline [49:31,  3.65pipeline/s]Optimization Progress:  99%|█████████▉| 9004/9100 [49:31<00:50,  1.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9004/9100 [49:31<00:50,  1.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9005/9100 [49:31<00:49,  1.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9006/9100 [49:31<00:49,  1.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9007/9100 [49:31<00:48,  1.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9008/9100 [49:31<00:48,  1.90pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9009/9100 [49:31<00:47,  1.90pipeline/s]Optimization Progress:  99%|█████████▉| 9011/9100 [49:35<00:49,  1.81pipeline/s]Optimization Progress: 100%|█████████▉| 9091/9100 [49:38<00:03,  2.52pipeline/s]
Generation 90 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9101pipeline [49:38,  2.52pipeline/s]Optimization Progress: 9101pipeline [49:38,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9101pipeline [49:38,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9101pipeline [49:38,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9101pipeline [49:38,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9101pipeline [49:38,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 9101pipeline [49:39,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9101pipeline [49:39,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9101pipeline [49:39,  3.56pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 9101pipeline [49:40,  3.56pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9102/9200 [49:40<00:27,  3.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9103/9200 [49:40<00:27,  3.56pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9104/9200 [49:40<00:26,  3.56pipeline/s]Optimization Progress:  99%|█████████▉| 9105/9200 [49:40<00:32,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9105/9200 [49:40<00:32,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9106/9200 [49:40<00:32,  2.91pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9107/9200 [49:40<00:31,  2.91pipeline/s]Optimization Progress:  99%|█████████▉| 9109/9200 [49:54<01:58,  1.31s/pipeline]Optimization Progress: 100%|█████████▉| 9189/9200 [49:55<00:10,  1.09pipeline/s]
Generation 91 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9201pipeline [49:56,  1.09pipeline/s]Optimization Progress: 9201pipeline [49:56,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9201pipeline [49:56,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9201pipeline [49:56,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9201pipeline [49:56,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9201pipeline [49:56,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9201pipeline [49:57,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9201pipeline [49:57,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9201pipeline [49:57,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9201pipeline [49:57,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9201pipeline [49:57,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9201pipeline [49:58,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9201pipeline [49:58,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9201pipeline [49:59,  1.52pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 9201pipeline [49:59,  1.52pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9201/9300 [49:59<01:05,  1.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9202/9300 [49:59<01:04,  1.52pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9203/9300 [49:59<01:03,  1.52pipeline/s]Optimization Progress:  99%|█████████▉| 9204/9300 [49:59<01:12,  1.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9204/9300 [49:59<01:12,  1.33pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9205/9300 [49:59<01:11,  1.33pipeline/s]Optimization Progress:  99%|█████████▉| 9207/9300 [50:02<01:24,  1.10pipeline/s]Optimization Progress: 100%|█████████▉| 9287/9300 [50:06<00:08,  1.55pipeline/s]
Generation 92 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9301pipeline [50:06,  1.55pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9301pipeline [50:06,  1.55pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9301pipeline [50:06,  1.55pipeline/s]Optimization Progress: 9301pipeline [50:06,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9301pipeline [50:06,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9301pipeline [50:07,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 9301pipeline [50:07,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9301pipeline [50:07,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9301pipeline [50:07,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9301pipeline [50:07,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 9301pipeline [50:08,  2.15pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9301pipeline [50:08,  2.15pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9301/9400 [50:09<00:46,  2.15pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9302/9400 [50:09<00:45,  2.15pipeline/s]Optimization Progress:  99%|█████████▉| 9303/9400 [50:09<01:05,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9303/9400 [50:09<01:05,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9304/9400 [50:09<01:05,  1.47pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9305/9400 [50:09<01:04,  1.47pipeline/s]Optimization Progress:  99%|█████████▉| 9307/9400 [50:13<01:13,  1.27pipeline/s]Optimization Progress: 100%|█████████▉| 9387/9400 [50:17<00:07,  1.76pipeline/s]
Generation 93 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 9401pipeline [50:17,  1.76pipeline/s]Optimization Progress: 9401pipeline [50:17,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9401pipeline [50:18,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9401pipeline [50:18,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9401pipeline [50:18,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9401pipeline [50:18,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9401pipeline [50:19,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9401pipeline [50:19,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9401pipeline [50:19,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9401pipeline [50:20,  2.50pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 9401pipeline [50:20,  2.50pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9401/9500 [50:21<00:39,  2.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9402/9500 [50:21<00:39,  2.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9403/9500 [50:21<00:38,  2.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9404/9500 [50:21<00:38,  2.50pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9405/9500 [50:21<00:38,  2.50pipeline/s]Optimization Progress:  99%|█████████▉| 9406/9500 [50:21<00:45,  2.08pipeline/s]Optimization Progress:  99%|█████████▉| 9409/9500 [50:28<01:35,  1.05s/pipeline]Optimization Progress: 100%|█████████▉| 9487/9500 [50:32<00:09,  1.33pipeline/s]
Generation 94 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 9501pipeline [50:32,  1.33pipeline/s]Optimization Progress: 9501pipeline [50:32,  1.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9501pipeline [50:32,  1.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9501pipeline [50:32,  1.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9501pipeline [50:33,  1.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9501pipeline [50:34,  1.87pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9501pipeline [50:34,  1.87pipeline/s]Optimization Progress:  99%|█████████▉| 9505/9600 [50:34<00:49,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9505/9600 [50:34<00:49,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9506/9600 [50:34<00:48,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9507/9600 [50:34<00:47,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9508/9600 [50:34<00:47,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9509/9600 [50:34<00:46,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9510/9600 [50:34<00:46,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9511/9600 [50:34<00:45,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9512/9600 [50:34<00:45,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9513/9600 [50:34<00:44,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9514/9600 [50:34<00:44,  1.94pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9515/9600 [50:34<00:43,  1.94pipeline/s]Optimization Progress:  99%|█████████▉| 9517/9600 [50:38<00:38,  2.17pipeline/s]Optimization Progress: 100%|█████████▉| 9597/9600 [50:39<00:00,  3.06pipeline/s]
Generation 95 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9601pipeline [50:39,  3.06pipeline/s]Optimization Progress: 9601pipeline [50:39,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9601pipeline [50:39,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9601pipeline [50:39,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9601pipeline [50:39,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9601pipeline [50:40,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 9601pipeline [50:40,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9601pipeline [50:40,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9601pipeline [50:41,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9601pipeline [50:42,  3.83pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9601pipeline [50:42,  3.83pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9601/9700 [50:42<00:25,  3.83pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9602/9700 [50:42<00:25,  3.83pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9603/9700 [50:42<00:25,  3.83pipeline/s]Optimization Progress:  99%|█████████▉| 9604/9700 [50:42<00:48,  1.97pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9604/9700 [50:42<00:48,  1.97pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9605/9700 [50:43<00:48,  1.97pipeline/s]Optimization Progress:  99%|█████████▉| 9607/9700 [50:45<00:57,  1.63pipeline/s]Optimization Progress: 100%|█████████▉| 9687/9700 [50:49<00:05,  2.26pipeline/s]
Generation 96 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9701pipeline [50:49,  2.26pipeline/s]Optimization Progress: 9701pipeline [50:49,  3.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9701pipeline [50:50,  3.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9701pipeline [50:51,  3.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9701pipeline [50:51,  3.13pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9701pipeline [50:51,  3.13pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9703/9800 [50:52<00:31,  3.13pipeline/s]Optimization Progress:  99%|█████████▉| 9704/9800 [50:52<00:45,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9704/9800 [50:52<00:45,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9705/9800 [50:52<00:44,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9706/9800 [50:52<00:44,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9707/9800 [50:52<00:43,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9708/9800 [50:52<00:43,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9709/9800 [50:52<00:42,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9710/9800 [50:52<00:42,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9711/9800 [50:52<00:41,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9712/9800 [50:52<00:41,  2.13pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9713/9800 [50:52<00:40,  2.13pipeline/s]Optimization Progress:  99%|█████████▉| 9715/9800 [50:56<00:38,  2.23pipeline/s]Optimization Progress: 100%|█████████▉| 9795/9800 [50:59<00:01,  3.09pipeline/s]
Generation 97 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9801pipeline [50:59,  3.09pipeline/s]Optimization Progress: 9801pipeline [50:59,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9801pipeline [50:59,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9801pipeline [50:59,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9801pipeline [50:59,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9801pipeline [50:59,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9801pipeline [50:59,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9801pipeline [50:59,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9801pipeline [51:00,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9801pipeline [51:00,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9801pipeline [51:00,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9801pipeline [51:00,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9801pipeline [51:00,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9801pipeline [51:00,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9801pipeline [51:01,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9801pipeline [51:01,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9801pipeline [51:01,  4.12pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9801pipeline [51:01,  4.12pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9801/9900 [51:01<00:24,  4.12pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9802/9900 [51:01<00:23,  4.12pipeline/s]Optimization Progress:  99%|█████████▉| 9803/9900 [51:01<00:52,  1.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9803/9900 [51:01<00:52,  1.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9804/9900 [51:01<00:51,  1.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9805/9900 [51:01<00:50,  1.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9806/9900 [51:01<00:50,  1.86pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9807/9900 [51:01<00:49,  1.86pipeline/s]Optimization Progress:  99%|█████████▉| 9809/9900 [51:06<00:55,  1.63pipeline/s]Optimization Progress: 100%|█████████▉| 9889/9900 [51:10<00:04,  2.26pipeline/s]
Generation 98 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9901pipeline [51:10,  2.26pipeline/s]Optimization Progress: 9901pipeline [51:10,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9901pipeline [51:10,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9901pipeline [51:10,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9901pipeline [51:11,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9901pipeline [51:11,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9901pipeline [51:11,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 9901pipeline [51:11,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 9901pipeline [51:11,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9901pipeline [51:11,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 9901pipeline [51:11,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 9901pipeline [51:12,  3.14pipeline/s]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 9901pipeline [51:12,  3.14pipeline/s]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9901/10000 [51:12<00:31,  3.14pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9902/10000 [51:12<00:31,  3.14pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9903/10000 [51:12<00:30,  3.14pipeline/s]Optimization Progress:  99%|█████████▉| 9904/10000 [51:12<00:43,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9904/10000 [51:12<00:43,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9905/10000 [51:12<00:43,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9906/10000 [51:12<00:42,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9907/10000 [51:12<00:42,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9908/10000 [51:12<00:41,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9909/10000 [51:12<00:41,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9910/10000 [51:12<00:41,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9911/10000 [51:12<00:40,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9912/10000 [51:12<00:40,  2.19pipeline/s]                                                                                 Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9913/10000 [51:12<00:39,  2.19pipeline/s]Optimization Progress:  99%|█████████▉| 9915/10000 [51:19<00:43,  1.96pipeline/s]Optimization Progress: 100%|█████████▉| 9995/10000 [51:23<00:01,  2.69pipeline/s]
Generation 99 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                 _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 10001pipeline [51:23,  2.69pipeline/s]Optimization Progress: 10001pipeline [51:23,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10001pipeline [51:23,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10001pipeline [51:23,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10001pipeline [51:23,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10001pipeline [51:24,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10001pipeline [51:24,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10001pipeline [51:24,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10001pipeline [51:25,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10001pipeline [51:25,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 10001pipeline [51:25,  3.75pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10001pipeline [51:26,  3.75pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10001/10100 [51:26<00:26,  3.75pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10002/10100 [51:26<00:26,  3.75pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10003/10100 [51:26<00:25,  3.75pipeline/s]Optimization Progress:  99%|█████████▉| 10004/10100 [51:26<00:45,  2.10pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10004/10100 [51:26<00:45,  2.10pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10005/10100 [51:26<00:45,  2.10pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10006/10100 [51:26<00:44,  2.10pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10007/10100 [51:26<00:44,  2.10pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10008/10100 [51:26<00:43,  2.10pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10009/10100 [51:26<00:43,  2.10pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10010/10100 [51:26<00:42,  2.10pipeline/s]Optimization Progress:  99%|█████████▉| 10012/10100 [51:30<00:43,  2.01pipeline/s]Optimization Progress: 100%|█████████▉| 10092/10100 [51:34<00:02,  2.78pipeline/s]
Generation 100 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10101pipeline [51:34,  2.78pipeline/s]Optimization Progress: 10101pipeline [51:34,  3.90pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10101pipeline [51:34,  3.90pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10101pipeline [51:34,  3.90pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10101pipeline [51:35,  3.90pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10101pipeline [51:36,  3.90pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10101pipeline [51:36,  3.90pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10101/10200 [51:37<00:25,  3.90pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10102/10200 [51:37<00:25,  3.90pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10103/10200 [51:37<00:24,  3.90pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10104/10200 [51:37<00:24,  3.90pipeline/s]Optimization Progress:  99%|█████████▉| 10105/10200 [51:37<00:38,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10105/10200 [51:37<00:38,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10106/10200 [51:37<00:37,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10107/10200 [51:37<00:37,  2.48pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10108/10200 [51:37<00:37,  2.48pipeline/s]Optimization Progress:  99%|█████████▉| 10110/10200 [51:43<00:56,  1.59pipeline/s]Optimization Progress: 100%|█████████▉| 10189/10200 [52:00<00:06,  1.59pipeline/s]Optimization Progress: 100%|█████████▉| 10190/10200 [52:18<00:05,  1.74pipeline/s]
Generation 101 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 10201pipeline [52:19,  1.74pipeline/s]Optimization Progress: 10201pipeline [52:19,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10201pipeline [52:19,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10201pipeline [52:19,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 10201pipeline [52:19,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10201pipeline [52:19,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10201pipeline [52:19,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10201pipeline [52:20,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10201pipeline [52:20,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10201pipeline [52:20,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10201pipeline [52:20,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10201pipeline [52:20,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 10201pipeline [52:20,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10201pipeline [52:21,  2.40pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10201pipeline [52:21,  2.40pipeline/s]Optimization Progress:  99%|█████████▉| 10202/10300 [52:21<01:49,  1.12s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10202/10300 [52:21<01:49,  1.12s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10203/10300 [52:21<01:48,  1.12s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10204/10300 [52:21<01:47,  1.12s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10205/10300 [52:21<01:45,  1.12s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10206/10300 [52:21<01:44,  1.12s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10207/10300 [52:21<01:43,  1.12s/pipeline]Optimization Progress:  99%|█████████▉| 10209/10300 [52:26<01:28,  1.03pipeline/s]Optimization Progress: 100%|█████████▉| 10289/10300 [52:30<00:07,  1.44pipeline/s]
Generation 102 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10301pipeline [52:31,  1.44pipeline/s]Optimization Progress: 10301pipeline [52:31,  1.97pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10301pipeline [52:31,  1.97pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10301pipeline [52:31,  1.97pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10301pipeline [52:32,  1.97pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10301pipeline [52:32,  1.97pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 10301pipeline [52:32,  1.97pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10301pipeline [52:33,  1.97pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10301pipeline [52:33,  1.97pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10301/10400 [52:34<00:50,  1.97pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10302/10400 [52:34<00:49,  1.97pipeline/s]Optimization Progress:  99%|█████████▉| 10303/10400 [52:34<01:17,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10303/10400 [52:34<01:17,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10304/10400 [52:34<01:16,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10305/10400 [52:34<01:15,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10306/10400 [52:34<01:14,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10307/10400 [52:34<01:14,  1.26pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10308/10400 [52:34<01:13,  1.26pipeline/s]Optimization Progress:  99%|█████████▉| 10310/10400 [53:02<02:37,  1.75s/pipeline]Optimization Progress: 100%|█████████▉| 10390/10400 [53:04<00:12,  1.24s/pipeline]
Generation 103 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 10401pipeline [53:05,  1.24s/pipeline]Optimization Progress: 10401pipeline [53:05,  1.13pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10401pipeline [53:05,  1.13pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10401pipeline [53:05,  1.13pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 10401pipeline [53:06,  1.13pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10401pipeline [53:06,  1.13pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10401pipeline [53:06,  1.13pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10401pipeline [53:06,  1.13pipeline/s]Optimization Progress:  99%|█████████▉| 10403/10500 [53:07<01:30,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10403/10500 [53:07<01:30,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10404/10500 [53:07<01:30,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10405/10500 [53:07<01:29,  1.07pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10406/10500 [53:07<01:28,  1.07pipeline/s]Optimization Progress:  99%|█████████▉| 10408/10500 [53:10<01:19,  1.16pipeline/s]Optimization Progress: 100%|█████████▉| 10488/10500 [53:54<00:09,  1.30pipeline/s]
Generation 104 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10501pipeline [53:55,  1.30pipeline/s]Optimization Progress: 10501pipeline [53:55,  1.83pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10501pipeline [53:55,  1.83pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10501pipeline [53:56,  1.83pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10501pipeline [53:56,  1.83pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10501pipeline [53:57,  1.83pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10501/10600 [53:57<00:54,  1.83pipeline/s]Optimization Progress:  99%|█████████▉| 10502/10600 [53:57<01:54,  1.17s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10502/10600 [53:57<01:54,  1.17s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10503/10600 [53:57<01:53,  1.17s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10504/10600 [53:57<01:52,  1.17s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10505/10600 [53:57<01:51,  1.17s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10506/10600 [53:57<01:50,  1.17s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10507/10600 [53:57<01:48,  1.17s/pipeline]Optimization Progress:  99%|█████████▉| 10509/10600 [54:09<01:59,  1.31s/pipeline]Optimization Progress: 100%|█████████▉| 10589/10600 [54:13<00:10,  1.07pipeline/s]
Generation 105 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10601pipeline [54:13,  1.07pipeline/s]Optimization Progress: 10601pipeline [54:13,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10601pipeline [54:13,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10601pipeline [54:14,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10601pipeline [54:14,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10601pipeline [54:14,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10601pipeline [54:15,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10601pipeline [54:15,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10601pipeline [54:15,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10601pipeline [54:15,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10601pipeline [54:15,  1.50pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10601pipeline [54:16,  1.50pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10602/10700 [54:16<01:05,  1.50pipeline/s]Optimization Progress:  99%|█████████▉| 10603/10700 [54:16<01:30,  1.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10603/10700 [54:16<01:30,  1.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10604/10700 [54:16<01:29,  1.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10605/10700 [54:16<01:28,  1.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10606/10700 [54:16<01:27,  1.08pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10607/10700 [54:16<01:26,  1.08pipeline/s]Optimization Progress:  99%|█████████▉| 10609/10700 [54:20<01:17,  1.18pipeline/s]Optimization Progress: 100%|█████████▉| 10689/10700 [54:25<00:06,  1.64pipeline/s]
Generation 106 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10701pipeline [54:25,  1.64pipeline/s]Optimization Progress: 10701pipeline [54:25,  2.26pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10701pipeline [54:26,  2.26pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10701pipeline [54:27,  2.26pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10701pipeline [54:27,  2.26pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10701pipeline [54:27,  2.26pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10701pipeline [54:27,  2.26pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10701pipeline [54:27,  2.26pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10701pipeline [54:27,  2.26pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10702/10800 [54:27<00:43,  2.26pipeline/s]Optimization Progress:  99%|█████████▉| 10703/10800 [54:27<01:03,  1.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10703/10800 [54:27<01:03,  1.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10704/10800 [54:27<01:02,  1.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10705/10800 [54:27<01:02,  1.53pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10706/10800 [54:27<01:01,  1.53pipeline/s]Optimization Progress:  99%|█████████▉| 10708/10800 [56:01<09:21,  6.10s/pipeline]Optimization Progress: 100%|█████████▉| 10788/10800 [56:04<00:51,  4.28s/pipeline]
Generation 107 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 10801pipeline [56:04,  4.28s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 10801pipeline [56:04,  4.28s/pipeline]Optimization Progress: 10801pipeline [56:04,  3.01s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 10801pipeline [56:04,  3.01s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10801pipeline [56:05,  3.01s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 10801pipeline [56:05,  3.01s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10801pipeline [56:05,  3.01s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10801pipeline [56:06,  3.01s/pipeline]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10802/10900 [56:06<04:54,  3.01s/pipeline]Optimization Progress:  99%|█████████▉| 10803/10900 [56:06<03:50,  2.37s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10803/10900 [56:06<03:50,  2.37s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10804/10900 [56:06<03:47,  2.37s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10805/10900 [56:06<03:45,  2.37s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10806/10900 [56:06<03:42,  2.37s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10807/10900 [56:06<03:40,  2.37s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10808/10900 [56:06<03:38,  2.37s/pipeline]Optimization Progress:  99%|█████████▉| 10810/10900 [56:17<03:10,  2.11s/pipeline]Optimization Progress: 100%|█████████▉| 10890/10900 [56:22<00:15,  1.50s/pipeline]
Generation 108 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10901pipeline [56:23,  1.50s/pipeline]Optimization Progress: 10901pipeline [56:23,  1.06s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10901pipeline [56:23,  1.06s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 10901pipeline [56:23,  1.06s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10901pipeline [56:23,  1.06s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 10901pipeline [56:24,  1.06s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 10901pipeline [56:24,  1.06s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 10901pipeline [56:26,  1.06s/pipeline]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10901/11000 [56:26<01:44,  1.06s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10902/11000 [56:26<01:43,  1.06s/pipeline]Optimization Progress:  99%|█████████▉| 10903/11000 [56:26<01:56,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10903/11000 [56:26<01:56,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10904/11000 [56:26<01:55,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10905/11000 [56:26<01:54,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10906/11000 [56:26<01:53,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10907/11000 [56:26<01:51,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10908/11000 [56:26<01:50,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10909/11000 [56:26<01:49,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10910/11000 [56:26<01:48,  1.20s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10911/11000 [56:26<01:47,  1.20s/pipeline]Optimization Progress:  99%|█████████▉| 10913/11000 [56:35<01:37,  1.13s/pipeline]Optimization Progress: 100%|█████████▉| 10993/11000 [56:40<00:05,  1.24pipeline/s]
Generation 109 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11001pipeline [56:40,  1.24pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11001pipeline [56:41,  1.24pipeline/s]Optimization Progress: 11001pipeline [56:41,  1.65pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11001pipeline [56:42,  1.65pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 11001pipeline [56:42,  1.65pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11001pipeline [56:42,  1.65pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 11001pipeline [56:42,  1.65pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11001pipeline [56:42,  1.65pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 11001pipeline [56:43,  1.65pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11001pipeline [56:43,  1.65pipeline/s]Optimization Progress:  99%|█████████▉| 11003/11100 [56:43<01:10,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11003/11100 [56:43<01:10,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11004/11100 [56:43<01:09,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11005/11100 [56:43<01:08,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11006/11100 [56:43<01:08,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11007/11100 [56:43<01:07,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11008/11100 [56:43<01:06,  1.38pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11009/11100 [56:43<01:05,  1.38pipeline/s]Optimization Progress:  99%|█████████▉| 11011/11100 [58:12<05:41,  3.84s/pipeline]Optimization Progress: 100%|█████████▉| 11091/11100 [58:16<00:24,  2.70s/pipeline]
Generation 110 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11101pipeline [58:16,  2.70s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11101pipeline [58:16,  2.70s/pipeline]Optimization Progress: 11101pipeline [58:16,  1.91s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11101pipeline [58:17,  1.91s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11101pipeline [58:18,  1.91s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11101pipeline [58:18,  1.91s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11101pipeline [58:18,  1.91s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11101pipeline [58:18,  1.91s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11101pipeline [58:19,  1.91s/pipeline]Optimization Progress:  99%|█████████▉| 11102/11200 [58:20<03:49,  2.34s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11102/11200 [58:20<03:49,  2.34s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11103/11200 [58:20<03:47,  2.34s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11104/11200 [58:20<03:44,  2.34s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11105/11200 [58:20<03:42,  2.34s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11106/11200 [58:20<03:40,  2.34s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11107/11200 [58:20<03:37,  2.34s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11108/11200 [58:20<03:35,  2.34s/pipeline]Optimization Progress:  99%|█████████▉| 11110/11200 [59:08<05:11,  3.46s/pipeline]Optimization Progress: 100%|█████████▉| 11190/11200 [59:12<00:24,  2.44s/pipeline]
Generation 111 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11201pipeline [59:13,  2.44s/pipeline]Optimization Progress: 11201pipeline [59:13,  1.74s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11201pipeline [59:13,  1.74s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 11201pipeline [59:13,  1.74s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11201pipeline [59:14,  1.74s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11201pipeline [59:14,  1.74s/pipeline]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11201pipeline [59:14,  1.74s/pipeline]Optimization Progress:  99%|█████████▉| 11202/11300 [59:14<02:44,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11202/11300 [59:14<02:44,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11203/11300 [59:14<02:42,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11204/11300 [59:14<02:41,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11205/11300 [59:14<02:39,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11206/11300 [59:14<02:37,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11207/11300 [59:14<02:36,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11208/11300 [59:14<02:34,  1.68s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11209/11300 [59:14<02:32,  1.68s/pipeline]Optimization Progress:  99%|█████████▉| 11211/11300 [59:19<01:58,  1.33s/pipeline]Optimization Progress: 100%|█████████▉| 11291/11300 [59:21<00:08,  1.07pipeline/s]
Generation 112 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11301pipeline [59:22,  1.07pipeline/s]Optimization Progress: 11301pipeline [59:22,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11301pipeline [59:22,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 11301pipeline [59:23,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11301pipeline [59:23,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 [04:42:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 11301pipeline [59:23,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11301pipeline [59:23,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11301pipeline [59:23,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11301pipeline [59:23,  1.47pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11301pipeline [59:23,  1.47pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11301/11400 [59:24<01:07,  1.47pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11302/11400 [59:24<01:06,  1.47pipeline/s]Optimization Progress:  99%|█████████▉| 11303/11400 [59:24<01:14,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11303/11400 [59:24<01:14,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11304/11400 [59:24<01:14,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11305/11400 [59:24<01:13,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11306/11400 [59:24<01:12,  1.29pipeline/s]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11307/11400 [59:24<01:11,  1.29pipeline/s]Optimization Progress:  99%|█████████▉| 11308/11400 [59:40<01:11,  1.29pipeline/s]Optimization Progress:  99%|█████████▉| 11309/11400 [59:51<02:53,  1.90s/pipeline]Optimization Progress: 100%|█████████▉| 11389/11400 [59:53<00:14,  1.34s/pipeline]
Generation 113 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11401pipeline [59:53,  1.34s/pipeline]Optimization Progress: 11401pipeline [59:53,  1.06pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11401pipeline [59:54,  1.06pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11401pipeline [59:54,  1.06pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11401pipeline [59:55,  1.06pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11401pipeline [59:56,  1.06pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11401pipeline [59:56,  1.06pipeline/s]                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11401pipeline [59:57,  1.06pipeline/s]                                                             Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11402/11500 [59:57<01:32,  1.06pipeline/s]Optimization Progress:  99%|█████████▉| 11403/11500 [59:57<01:52,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11403/11500 [59:57<01:52,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11404/11500 [59:57<01:51,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11405/11500 [59:57<01:50,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11406/11500 [59:57<01:48,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11407/11500 [59:57<01:47,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11408/11500 [59:57<01:46,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11409/11500 [59:57<01:45,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11410/11500 [59:57<01:44,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11411/11500 [59:57<01:43,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11412/11500 [59:57<01:41,  1.16s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11413/11500 [59:57<01:40,  1.16s/pipeline]Optimization Progress:  99%|█████████▉| 11415/11500 [1:00:01<01:19,  1.07pipeline/s]Optimization Progress: 100%|█████████▉| 11495/11500 [1:00:04<00:03,  1.51pipeline/s]
Generation 114 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:05,  1.51pipeline/s]Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11501pipeline [1:00:05,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11501pipeline [1:00:07,  2.06pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11501/11600 [1:00:07<00:47,  2.06pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11502/11600 [1:00:07<00:47,  2.06pipeline/s]Optimization Progress:  99%|█████████▉| 11503/11600 [1:00:07<01:11,  1.36pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11503/11600 [1:00:07<01:11,  1.36pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11504/11600 [1:00:07<01:10,  1.36pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11505/11600 [1:00:07<01:09,  1.36pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11506/11600 [1:00:07<01:09,  1.36pipeline/s]Optimization Progress:  99%|█████████▉| 11508/11600 [1:00:14<01:21,  1.13pipeline/s]Optimization Progress: 100%|█████████▉| 11588/11600 [1:00:49<00:09,  1.33pipeline/s]
Generation 115 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 11601pipeline [1:00:52,  1.33pipeline/s]Optimization Progress: 11601pipeline [1:00:52,  1.70pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11601pipeline [1:00:52,  1.70pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 11601pipeline [1:00:52,  1.70pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11601pipeline [1:00:53,  1.70pipeline/s]Optimization Progress:  99%|█████████▉| 11603/11700 [1:00:53<00:57,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11603/11700 [1:00:53<00:57,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11604/11700 [1:00:53<00:56,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11605/11700 [1:00:53<00:55,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11606/11700 [1:00:53<00:55,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11607/11700 [1:00:53<00:54,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11608/11700 [1:00:53<00:54,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11609/11700 [1:00:53<00:53,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11610/11700 [1:00:53<00:52,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11611/11700 [1:00:53<00:52,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11612/11700 [1:00:53<00:51,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11613/11700 [1:00:53<00:51,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11614/11700 [1:00:53<00:50,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11615/11700 [1:00:53<00:49,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11616/11700 [1:00:53<00:49,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11617/11700 [1:00:53<00:48,  1.70pipeline/s]Optimization Progress:  99%|█████████▉| 11619/11700 [1:01:26<01:23,  1.03s/pipeline]Optimization Progress: 100%|█████████▉| 11699/11700 [1:01:28<00:00,  1.37pipeline/s]
Generation 116 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11701pipeline [1:01:29,  1.37pipeline/s]Optimization Progress: 11701pipeline [1:01:29,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11701pipeline [1:01:29,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [04:45:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 11701pipeline [1:01:29,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11701pipeline [1:01:29,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11701pipeline [1:01:29,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11701pipeline [1:01:30,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11701pipeline [1:01:30,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11701pipeline [1:01:30,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 11701pipeline [1:01:30,  1.75pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11701pipeline [1:01:31,  1.75pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11701/11800 [1:01:31<00:56,  1.75pipeline/s]Optimization Progress:  99%|█████████▉| 11702/11800 [1:01:31<02:03,  1.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11702/11800 [1:01:31<02:03,  1.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11703/11800 [1:01:31<02:01,  1.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11704/11800 [1:01:31<02:00,  1.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11705/11800 [1:01:31<01:59,  1.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11706/11800 [1:01:31<01:58,  1.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11707/11800 [1:01:31<01:56,  1.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11708/11800 [1:01:31<01:55,  1.26s/pipeline]Optimization Progress:  99%|█████████▉| 11710/11800 [1:01:35<01:32,  1.03s/pipeline]Optimization Progress: 100%|█████████▉| 11790/11800 [1:01:39<00:07,  1.36pipeline/s]
Generation 117 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 11801pipeline [1:01:39,  1.36pipeline/s]Optimization Progress: 11801pipeline [1:01:39,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11801pipeline [1:01:39,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11801pipeline [1:01:40,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11801pipeline [1:01:40,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11801pipeline [1:01:40,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11801pipeline [1:01:41,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11801pipeline [1:01:42,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 11801pipeline [1:01:42,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11801pipeline [1:01:42,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11801pipeline [1:01:42,  1.93pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11801/11900 [1:01:42<00:51,  1.93pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11802/11900 [1:01:42<00:50,  1.93pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11803/11900 [1:01:42<00:50,  1.93pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11804/11900 [1:01:42<00:49,  1.93pipeline/s]Optimization Progress:  99%|█████████▉| 11805/11900 [1:01:42<00:57,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11805/11900 [1:01:42<00:57,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11806/11900 [1:01:42<00:56,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11807/11900 [1:01:42<00:55,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11808/11900 [1:01:42<00:55,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11809/11900 [1:01:42<00:54,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11810/11900 [1:01:42<00:54,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11811/11900 [1:01:42<00:53,  1.66pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11812/11900 [1:01:42<00:52,  1.66pipeline/s]Optimization Progress:  99%|█████████▉| 11813/11900 [1:02:00<00:52,  1.66pipeline/s]Optimization Progress:  99%|█████████▉| 11814/11900 [1:02:41<03:24,  2.37s/pipeline]Optimization Progress: 100%|█████████▉| 11894/11900 [1:02:45<00:10,  1.67s/pipeline]
Generation 118 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11901pipeline [1:02:45,  1.67s/pipeline]Optimization Progress: 11901pipeline [1:02:45,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 11901pipeline [1:02:45,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11901pipeline [1:02:45,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 11901pipeline [1:02:45,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 11901pipeline [1:02:46,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11901pipeline [1:02:47,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 11901pipeline [1:02:47,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11901pipeline [1:02:47,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 11901pipeline [1:02:47,  1.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 11901pipeline [1:02:47,  1.18s/pipeline]Optimization Progress:  99%|█████████▉| 11903/12000 [1:02:47<01:57,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11903/12000 [1:02:47<01:57,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11904/12000 [1:02:47<01:55,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11905/12000 [1:02:47<01:54,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11906/12000 [1:02:47<01:53,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11907/12000 [1:02:47<01:52,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11908/12000 [1:02:47<01:51,  1.21s/pipeline]Optimization Progress:  99%|█████████▉| 11909/12000 [1:03:00<01:49,  1.21s/pipeline]Optimization Progress:  99%|█████████▉| 11910/12000 [1:04:46<08:53,  5.93s/pipeline]Optimization Progress: 100%|█████████▉| 11990/12000 [1:04:48<00:41,  4.16s/pipeline]
Generation 119 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12001pipeline [1:04:49,  4.16s/pipeline]Optimization Progress: 12001pipeline [1:04:49,  2.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12001pipeline [1:04:49,  2.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12001pipeline [1:04:49,  2.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12001pipeline [1:04:49,  2.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12001pipeline [1:04:50,  2.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12001pipeline [1:04:50,  2.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12001pipeline [1:04:51,  2.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12001pipeline [1:04:51,  2.93s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12002/12100 [1:04:51<04:47,  2.93s/pipeline]Optimization Progress:  99%|█████████▉| 12003/12100 [1:04:51<03:56,  2.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12003/12100 [1:04:51<03:56,  2.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12004/12100 [1:04:51<03:54,  2.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12005/12100 [1:04:51<03:51,  2.44s/pipeline]Optimization Progress:  99%|█████████▉| 12007/12100 [1:05:47<09:05,  5.86s/pipeline]Optimization Progress: 100%|█████████▉| 12087/12100 [1:05:55<00:53,  4.13s/pipeline]
Generation 120 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 12101pipeline [1:05:55,  4.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12101pipeline [1:05:55,  4.13s/pipeline]Optimization Progress: 12101pipeline [1:05:55,  2.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12101pipeline [1:05:55,  2.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12101pipeline [1:05:56,  2.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12101pipeline [1:05:56,  2.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12101pipeline [1:05:56,  2.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12101pipeline [1:05:57,  2.90s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12102/12200 [1:05:58<04:43,  2.90s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12103/12200 [1:05:58<04:41,  2.90s/pipeline]Optimization Progress:  99%|█████████▉| 12104/12200 [1:05:58<03:44,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12104/12200 [1:05:58<03:44,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12105/12200 [1:05:58<03:42,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12106/12200 [1:05:58<03:39,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12107/12200 [1:05:58<03:37,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12108/12200 [1:05:58<03:35,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12109/12200 [1:05:58<03:32,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12110/12200 [1:05:58<03:30,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12111/12200 [1:05:58<03:28,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12112/12200 [1:05:58<03:25,  2.34s/pipeline]Optimization Progress:  99%|█████████▉| 12114/12200 [1:06:07<02:44,  1.91s/pipeline]Optimization Progress: 100%|█████████▉| 12194/12200 [1:06:11<00:08,  1.35s/pipeline]
Generation 121 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12201pipeline [1:06:11,  1.35s/pipeline]Optimization Progress: 12201pipeline [1:06:11,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12201pipeline [1:06:11,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12201pipeline [1:06:11,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12201pipeline [1:06:12,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12201pipeline [1:06:12,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12201pipeline [1:06:12,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12201pipeline [1:06:12,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12201pipeline [1:06:12,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12201pipeline [1:06:13,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12201pipeline [1:06:13,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12201pipeline [1:06:14,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12201pipeline [1:06:14,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12201pipeline [1:06:14,  1.03pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12202/12300 [1:06:15<01:35,  1.03pipeline/s]Optimization Progress:  99%|█████████▉| 12203/12300 [1:06:15<01:51,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12203/12300 [1:06:15<01:51,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12204/12300 [1:06:15<01:50,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12205/12300 [1:06:15<01:49,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12206/12300 [1:06:15<01:48,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12207/12300 [1:06:15<01:47,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12208/12300 [1:06:15<01:45,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12209/12300 [1:06:15<01:44,  1.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12210/12300 [1:06:15<01:43,  1.15s/pipeline]Optimization Progress:  99%|█████████▉| 12211/12300 [1:06:30<01:42,  1.15s/pipeline]Optimization Progress:  99%|█████████▉| 12212/12300 [1:06:41<02:29,  1.70s/pipeline]Optimization Progress: 100%|█████████▉| 12292/12300 [1:06:47<00:09,  1.21s/pipeline]
Generation 122 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12301pipeline [1:06:47,  1.21s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12301pipeline [1:06:48,  1.21s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12301pipeline [1:06:48,  1.21s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12301pipeline [1:06:48,  1.21s/pipeline]Optimization Progress: 12301pipeline [1:06:48,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12301pipeline [1:06:48,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12301pipeline [1:06:48,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12301pipeline [1:06:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12301pipeline [1:06:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [04:50:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 12301pipeline [1:06:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12301pipeline [1:06:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12301pipeline [1:06:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 12301pipeline [1:06:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 12301pipeline [1:06:50,  1.13pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12301/12400 [1:06:50<01:27,  1.13pipeline/s]Optimization Progress:  99%|█████████▉| 12302/12400 [1:06:50<01:45,  1.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12302/12400 [1:06:50<01:45,  1.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12303/12400 [1:06:50<01:44,  1.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12304/12400 [1:06:50<01:43,  1.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12305/12400 [1:06:50<01:42,  1.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12306/12400 [1:06:50<01:41,  1.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12307/12400 [1:06:50<01:40,  1.08s/pipeline]Optimization Progress:  99%|█████████▉| 12309/12400 [1:06:56<01:31,  1.00s/pipeline]Optimization Progress: 100%|█████████▉| 12389/12400 [1:07:00<00:07,  1.40pipeline/s]
Generation 123 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12401pipeline [1:07:00,  1.40pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12401pipeline [1:07:00,  1.40pipeline/s]Optimization Progress: 12401pipeline [1:07:00,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12401pipeline [1:07:01,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12401pipeline [1:07:01,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12401pipeline [1:07:01,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12401pipeline [1:07:02,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12401pipeline [1:07:02,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12401pipeline [1:07:02,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 12401pipeline [1:07:02,  1.97pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12401pipeline [1:07:03,  1.97pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12402/12500 [1:07:03<00:49,  1.97pipeline/s]Optimization Progress:  99%|█████████▉| 12403/12500 [1:07:03<01:13,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12403/12500 [1:07:03<01:13,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12404/12500 [1:07:03<01:12,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12405/12500 [1:07:03<01:12,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12406/12500 [1:07:03<01:11,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12407/12500 [1:07:03<01:10,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12408/12500 [1:07:03<01:09,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12409/12500 [1:07:03<01:09,  1.32pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12410/12500 [1:07:03<01:08,  1.32pipeline/s]Optimization Progress:  99%|█████████▉| 12412/12500 [1:07:19<01:34,  1.08s/pipeline]Optimization Progress: 100%|█████████▉| 12492/12500 [1:07:24<00:06,  1.29pipeline/s]
Generation 124 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 12501pipeline [1:07:24,  1.29pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12501pipeline [1:07:25,  1.29pipeline/s]Optimization Progress: 12501pipeline [1:07:25,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12501pipeline [1:07:25,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12501pipeline [1:07:26,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12501pipeline [1:07:26,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 12501pipeline [1:07:26,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12501pipeline [1:07:26,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12501pipeline [1:07:26,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12501pipeline [1:07:26,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12501pipeline [1:07:27,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12501pipeline [1:07:27,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12501pipeline [1:07:28,  1.79pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12501pipeline [1:07:28,  1.79pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12501/12600 [1:07:28<00:55,  1.79pipeline/s]Optimization Progress:  99%|█████████▉| 12502/12600 [1:07:28<02:07,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12502/12600 [1:07:28<02:07,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12503/12600 [1:07:28<02:05,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12504/12600 [1:07:28<02:04,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12505/12600 [1:07:28<02:03,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12506/12600 [1:07:28<02:01,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12507/12600 [1:07:28<02:00,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12508/12600 [1:07:28<01:59,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12509/12600 [1:07:28<01:58,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12510/12600 [1:07:28<01:56,  1.30s/pipeline]Optimization Progress:  99%|█████████▉| 12512/12600 [1:07:38<01:47,  1.22s/pipeline]Optimization Progress: 100%|█████████▉| 12592/12600 [1:07:41<00:06,  1.16pipeline/s]
Generation 125 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12601pipeline [1:07:42,  1.16pipeline/s]Optimization Progress: 12601pipeline [1:07:42,  1.54pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12601pipeline [1:07:42,  1.54pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 12601pipeline [1:07:43,  1.54pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12601pipeline [1:07:44,  1.54pipeline/s]Optimization Progress:  99%|█████████▉| 12602/12700 [1:07:44<01:49,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12602/12700 [1:07:44<01:49,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12603/12700 [1:07:44<01:48,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12604/12700 [1:07:44<01:46,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12605/12700 [1:07:44<01:45,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12606/12700 [1:07:44<01:44,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12607/12700 [1:07:44<01:43,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12608/12700 [1:07:44<01:42,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12609/12700 [1:07:44<01:41,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12610/12700 [1:07:44<01:40,  1.11s/pipeline]Optimization Progress:  99%|█████████▉| 12612/12700 [1:08:07<02:07,  1.45s/pipeline]Optimization Progress: 100%|█████████▉| 12692/12700 [1:08:08<00:08,  1.02s/pipeline]
Generation 126 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 12701pipeline [1:08:08,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12701pipeline [1:08:09,  1.02s/pipeline]Optimization Progress: 12701pipeline [1:08:09,  1.34pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 12701pipeline [1:08:09,  1.34pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12701pipeline [1:08:09,  1.34pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12701pipeline [1:08:09,  1.34pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12701pipeline [1:08:10,  1.34pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 12701pipeline [1:08:10,  1.34pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12701pipeline [1:08:11,  1.34pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12701/12800 [1:08:11<01:14,  1.34pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12702/12800 [1:08:11<01:13,  1.34pipeline/s]Optimization Progress:  99%|█████████▉| 12703/12800 [1:08:11<01:25,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12703/12800 [1:08:11<01:25,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12704/12800 [1:08:11<01:24,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12705/12800 [1:08:11<01:23,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12706/12800 [1:08:11<01:22,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12707/12800 [1:08:11<01:21,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12708/12800 [1:08:11<01:21,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12709/12800 [1:08:11<01:20,  1.13pipeline/s]Optimization Progress:  99%|█████████▉| 12710/12800 [1:08:30<01:19,  1.13pipeline/s]Optimization Progress:  99%|█████████▉| 12711/12800 [1:11:56<13:24,  9.04s/pipeline]Optimization Progress: 100%|█████████▉| 12791/12800 [1:12:11<00:57,  6.39s/pipeline]
Generation 127 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12801pipeline [1:12:12,  6.39s/pipeline]Optimization Progress: 12801pipeline [1:12:12,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12801pipeline [1:12:12,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12801pipeline [1:12:12,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12801pipeline [1:12:12,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12801pipeline [1:12:12,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12801pipeline [1:12:13,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12801pipeline [1:12:14,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12801pipeline [1:12:14,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12801pipeline [1:12:14,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12801pipeline [1:12:14,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 12801pipeline [1:12:14,  4.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12801pipeline [1:12:15,  4.49s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12801/12900 [1:12:15<07:24,  4.49s/pipeline]Optimization Progress:  99%|█████████▉| 12802/12900 [1:12:15<06:29,  3.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12802/12900 [1:12:15<06:29,  3.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12803/12900 [1:12:15<06:25,  3.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12804/12900 [1:12:15<06:21,  3.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12805/12900 [1:12:15<06:17,  3.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12806/12900 [1:12:15<06:13,  3.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12807/12900 [1:12:15<06:09,  3.97s/pipeline]Optimization Progress:  99%|█████████▉| 12809/12900 [1:13:25<08:46,  5.79s/pipeline]Optimization Progress: 100%|█████████▉| 12889/12900 [1:13:31<00:44,  4.08s/pipeline]
Generation 128 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12901pipeline [1:13:32,  4.08s/pipeline]Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12901pipeline [1:13:32,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12901pipeline [1:13:33,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 12901pipeline [1:13:33,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 12901pipeline [1:13:34,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 12901pipeline [1:13:34,  2.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 12901pipeline [1:13:34,  2.86s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12901/13000 [1:13:34<04:42,  2.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12902/13000 [1:13:34<04:40,  2.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12903/13000 [1:13:34<04:37,  2.86s/pipeline]Optimization Progress:  99%|█████████▉| 12904/13000 [1:13:34<03:33,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12904/13000 [1:13:34<03:33,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12905/13000 [1:13:34<03:31,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12906/13000 [1:13:34<03:29,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12907/13000 [1:13:34<03:27,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12908/13000 [1:13:34<03:25,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 12909/13000 [1:13:34<03:22,  2.23s/pipeline]Optimization Progress:  99%|█████████▉| 12910/13000 [1:13:50<03:20,  2.23s/pipeline]Optimization Progress:  99%|█████████▉| 12911/13000 [1:18:10<19:54, 13.42s/pipeline]Optimization Progress: 100%|█████████▉| 12991/13000 [1:18:12<01:24,  9.40s/pipeline]
Generation 129 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 13001pipeline [1:18:12,  9.40s/pipeline]Optimization Progress: 13001pipeline [1:18:12,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13001pipeline [1:18:12,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:12,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 13001pipeline [1:18:12,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13001pipeline [1:18:13,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:14,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13001pipeline [1:18:14,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:14,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:14,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:14,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:14,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13001pipeline [1:18:14,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13001pipeline [1:18:15,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13001pipeline [1:18:15,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:15,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13001pipeline [1:18:15,  6.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13001pipeline [1:18:15,  6.58s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13002/13100 [1:18:15<10:45,  6.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13003/13100 [1:18:15<10:38,  6.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13004/13100 [1:18:15<10:31,  6.58s/pipeline]Optimization Progress:  99%|█████████▉| 13005/13100 [1:18:15<07:42,  4.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13005/13100 [1:18:15<07:42,  4.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13006/13100 [1:18:15<07:37,  4.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13007/13100 [1:18:15<07:32,  4.86s/pipeline]Optimization Progress:  99%|█████████▉| 13008/13100 [1:18:30<07:27,  4.86s/pipeline]Optimization Progress:  99%|█████████▉| 13009/13100 [1:20:00<17:01, 11.23s/pipeline]Optimization Progress: 100%|█████████▉| 13089/13100 [1:20:04<01:26,  7.88s/pipeline]
Generation 130 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13101pipeline [1:20:04,  7.88s/pipeline]Optimization Progress: 13101pipeline [1:20:04,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13101pipeline [1:20:04,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:03:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 13101pipeline [1:20:04,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13101pipeline [1:20:05,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13101pipeline [1:20:05,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13101pipeline [1:20:06,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13101pipeline [1:20:06,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13101pipeline [1:20:06,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13101pipeline [1:20:06,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13101pipeline [1:20:07,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13101pipeline [1:20:07,  5.53s/pipeline]Optimization Progress:  99%|█████████▉| 13102/13200 [1:20:07<07:28,  4.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13102/13200 [1:20:07<07:28,  4.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13103/13200 [1:20:07<07:24,  4.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13104/13200 [1:20:07<07:19,  4.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13105/13200 [1:20:07<07:15,  4.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13106/13200 [1:20:07<07:10,  4.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13107/13200 [1:20:07<07:05,  4.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13108/13200 [1:20:07<07:01,  4.58s/pipeline]Optimization Progress:  99%|█████████▉| 13110/13200 [1:20:19<05:30,  3.67s/pipeline]Optimization Progress: 100%|█████████▉| 13190/13200 [1:20:25<00:25,  2.59s/pipeline]
Generation 131 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 13201pipeline [1:20:25,  2.59s/pipeline]Optimization Progress: 13201pipeline [1:20:25,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13201pipeline [1:20:25,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13201pipeline [1:20:25,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13201pipeline [1:20:26,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13201pipeline [1:20:26,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13201pipeline [1:20:26,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 13201pipeline [1:20:26,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:04:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 13201pipeline [1:20:26,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13201pipeline [1:20:28,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13201pipeline [1:20:28,  1.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13201pipeline [1:20:28,  1.82s/pipeline]Optimization Progress:  99%|█████████▉| 13204/13300 [1:20:28<02:33,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13204/13300 [1:20:28<02:33,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13205/13300 [1:20:28<02:31,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13206/13300 [1:20:28<02:30,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13207/13300 [1:20:28<02:28,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13208/13300 [1:20:28<02:26,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13209/13300 [1:20:28<02:25,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13210/13300 [1:20:28<02:23,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13211/13300 [1:20:28<02:22,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13212/13300 [1:20:28<02:20,  1.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13213/13300 [1:20:28<02:18,  1.60s/pipeline]Optimization Progress:  99%|█████████▉| 13214/13300 [1:20:40<02:17,  1.60s/pipeline]Optimization Progress:  99%|█████████▉| 13215/13300 [1:21:01<02:51,  2.02s/pipeline]Optimization Progress: 100%|█████████▉| 13295/13300 [1:21:03<00:07,  1.42s/pipeline]
Generation 132 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:04,  1.42s/pipeline]Optimization Progress: 13301pipeline [1:21:04,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:04,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:04,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:04,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13301pipeline [1:21:05,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:05,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:05,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 13301pipeline [1:21:05,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:06,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13301pipeline [1:21:06,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 13301pipeline [1:21:07,  1.00s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13301/13400 [1:21:07<01:39,  1.00s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13302/13400 [1:21:07<01:38,  1.00s/pipeline]Optimization Progress:  99%|█████████▉| 13303/13400 [1:21:07<02:01,  1.25s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13303/13400 [1:21:07<02:01,  1.25s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13304/13400 [1:21:07<02:00,  1.25s/pipeline]Optimization Progress:  99%|█████████▉| 13306/13400 [1:21:14<02:22,  1.51s/pipeline]Optimization Progress: 100%|█████████▉| 13386/13400 [1:21:17<00:15,  1.07s/pipeline]
Generation 133 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13401pipeline [1:21:17,  1.07s/pipeline]Optimization Progress: 13401pipeline [1:21:17,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13401pipeline [1:21:18,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13401pipeline [1:21:18,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13401pipeline [1:21:18,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:04:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 13401pipeline [1:21:19,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 13401pipeline [1:21:19,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 13401pipeline [1:21:20,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 13401pipeline [1:21:20,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13401pipeline [1:21:20,  1.33pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13401pipeline [1:21:20,  1.33pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13401/13500 [1:21:20<01:14,  1.33pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13402/13500 [1:21:20<01:13,  1.33pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13403/13500 [1:21:20<01:13,  1.33pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13404/13500 [1:21:20<01:12,  1.33pipeline/s]Optimization Progress:  99%|█████████▉| 13405/13500 [1:21:20<01:08,  1.38pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13405/13500 [1:21:20<01:08,  1.38pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13406/13500 [1:21:20<01:08,  1.38pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13407/13500 [1:21:20<01:07,  1.38pipeline/s]Optimization Progress:  99%|█████████▉| 13408/13500 [1:21:40<01:06,  1.38pipeline/s]Optimization Progress:  99%|█████████▉| 13409/13500 [1:22:40<09:50,  6.49s/pipeline]Optimization Progress: 100%|█████████▉| 13489/13500 [1:22:48<00:50,  4.57s/pipeline]
Generation 134 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-131928249.87123322	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=5, DecisionTreeRegressor__min_samples_split=11)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13501pipeline [1:22:49,  4.57s/pipeline]Optimization Progress: 13501pipeline [1:22:49,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13501pipeline [1:22:49,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13501pipeline [1:22:49,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13501pipeline [1:22:50,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13501pipeline [1:22:50,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13501pipeline [1:22:50,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13501pipeline [1:22:50,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13501pipeline [1:22:51,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13501pipeline [1:22:51,  3.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 13501pipeline [1:22:51,  3.22s/pipeline]Optimization Progress:  99%|█████████▉| 13503/13600 [1:22:51<04:09,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13503/13600 [1:22:51<04:09,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13504/13600 [1:22:51<04:06,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13505/13600 [1:22:51<04:04,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13506/13600 [1:22:51<04:01,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13507/13600 [1:22:51<03:59,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13508/13600 [1:22:51<03:56,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13509/13600 [1:22:51<03:53,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13510/13600 [1:22:51<03:51,  2.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13511/13600 [1:22:51<03:48,  2.57s/pipeline]Optimization Progress:  99%|█████████▉| 13513/13600 [1:24:35<07:08,  4.92s/pipeline]Optimization Progress: 100%|█████████▉| 13593/13600 [1:24:37<00:24,  3.45s/pipeline]
Generation 135 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13601pipeline [1:24:37,  3.45s/pipeline]Optimization Progress: 13601pipeline [1:24:37,  2.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 13601pipeline [1:24:37,  2.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13601pipeline [1:24:37,  2.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13601pipeline [1:24:37,  2.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13601pipeline [1:24:37,  2.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13601pipeline [1:24:38,  2.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13601pipeline [1:24:38,  2.42s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13602/13700 [1:24:41<03:57,  2.42s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13603/13700 [1:24:41<03:55,  2.42s/pipeline]Optimization Progress:  99%|█████████▉| 13604/13700 [1:24:41<03:15,  2.03s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13604/13700 [1:24:41<03:15,  2.03s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13605/13700 [1:24:41<03:13,  2.03s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13606/13700 [1:24:41<03:11,  2.03s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13607/13700 [1:24:41<03:09,  2.03s/pipeline]Optimization Progress:  99%|█████████▉| 13608/13700 [1:25:00<03:07,  2.03s/pipeline]Optimization Progress:  99%|█████████▉| 13609/13700 [1:25:57<09:07,  6.02s/pipeline]Optimization Progress: 100%|█████████▉| 13689/13700 [1:26:19<00:47,  4.29s/pipeline]
Generation 136 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 13701pipeline [1:26:19,  4.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13701pipeline [1:26:19,  4.29s/pipeline]Optimization Progress: 13701pipeline [1:26:19,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13701pipeline [1:26:19,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13701pipeline [1:26:20,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13701pipeline [1:26:20,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13701pipeline [1:26:20,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13701pipeline [1:26:20,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13701pipeline [1:26:20,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 13701pipeline [1:26:21,  3.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13701pipeline [1:26:21,  3.02s/pipeline]Optimization Progress:  99%|█████████▉| 13704/13800 [1:26:21<03:42,  2.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13704/13800 [1:26:21<03:42,  2.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13705/13800 [1:26:21<03:39,  2.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13706/13800 [1:26:21<03:37,  2.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13707/13800 [1:26:21<03:35,  2.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13708/13800 [1:26:21<03:32,  2.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13709/13800 [1:26:21<03:30,  2.31s/pipeline]Optimization Progress:  99%|█████████▉| 13711/13800 [1:26:25<02:39,  1.79s/pipeline]Optimization Progress: 100%|█████████▉| 13791/13800 [1:26:30<00:11,  1.28s/pipeline]
Generation 137 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13801pipeline [1:26:30,  1.28s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13801pipeline [1:26:31,  1.28s/pipeline]Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13801pipeline [1:26:31,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13801pipeline [1:26:32,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 13801pipeline [1:26:32,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13801pipeline [1:26:32,  1.11pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13801pipeline [1:26:33,  1.11pipeline/s]Optimization Progress:  99%|█████████▉| 13803/13900 [1:26:33<01:41,  1.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13803/13900 [1:26:33<01:41,  1.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13804/13900 [1:26:33<01:40,  1.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13805/13900 [1:26:33<01:39,  1.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13806/13900 [1:26:33<01:38,  1.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13807/13900 [1:26:33<01:37,  1.05s/pipeline]Optimization Progress:  99%|█████████▉| 13809/13900 [1:26:39<01:31,  1.00s/pipeline]Optimization Progress: 100%|█████████▉| 13889/13900 [1:26:41<00:07,  1.40pipeline/s]
Generation 138 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 13901pipeline [1:26:41,  1.40pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 13901pipeline [1:26:42,  1.40pipeline/s]Optimization Progress: 13901pipeline [1:26:42,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13901pipeline [1:26:42,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13901pipeline [1:26:42,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13901pipeline [1:26:42,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13901pipeline [1:26:42,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13901pipeline [1:26:43,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 13901pipeline [1:26:43,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:10:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 13901pipeline [1:26:43,  1.98pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 13901pipeline [1:26:43,  1.98pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13903/14000 [1:26:43<00:48,  1.98pipeline/s]Optimization Progress:  99%|█████████▉| 13904/14000 [1:26:43<00:50,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13904/14000 [1:26:43<00:50,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13905/14000 [1:26:43<00:50,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13906/14000 [1:26:43<00:49,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13907/14000 [1:26:43<00:49,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13908/14000 [1:26:43<00:48,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13909/14000 [1:26:43<00:48,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13910/14000 [1:26:43<00:47,  1.89pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 13911/14000 [1:26:43<00:46,  1.89pipeline/s]Optimization Progress:  99%|█████████▉| 13912/14000 [1:27:00<00:46,  1.89pipeline/s]Optimization Progress:  99%|█████████▉| 13913/14000 [1:27:02<01:25,  1.02pipeline/s]Optimization Progress: 100%|█████████▉| 13993/14000 [1:27:07<00:04,  1.41pipeline/s]
Generation 139 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 14001pipeline [1:27:08,  1.41pipeline/s]Optimization Progress: 14001pipeline [1:27:08,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14001pipeline [1:27:08,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 14001pipeline [1:27:08,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 14001pipeline [1:27:08,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 14001pipeline [1:27:09,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 14001pipeline [1:27:09,  1.93pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 14001pipeline [1:27:10,  1.93pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14001/14100 [1:27:10<00:51,  1.93pipeline/s]Optimization Progress:  99%|█████████▉| 14002/14100 [1:27:10<01:41,  1.04s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14002/14100 [1:27:10<01:41,  1.04s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14003/14100 [1:27:10<01:40,  1.04s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14004/14100 [1:27:10<01:39,  1.04s/pipeline]Optimization Progress:  99%|█████████▉| 14006/14100 [1:27:32<03:41,  2.35s/pipeline]Optimization Progress: 100%|█████████▉| 14086/14100 [1:27:33<00:23,  1.65s/pipeline]
Generation 140 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 14101pipeline [1:27:34,  1.65s/pipeline]Optimization Progress: 14101pipeline [1:27:34,  1.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 14101pipeline [1:27:34,  1.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14101pipeline [1:27:34,  1.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 14101pipeline [1:27:35,  1.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 14101pipeline [1:27:35,  1.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 14101pipeline [1:27:36,  1.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 14101pipeline [1:27:36,  1.17s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14102/14200 [1:27:36<01:54,  1.17s/pipeline]Optimization Progress:  99%|█████████▉| 14103/14200 [1:27:36<01:57,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14103/14200 [1:27:36<01:57,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14104/14200 [1:27:36<01:56,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14105/14200 [1:27:36<01:55,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14106/14200 [1:27:36<01:53,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14107/14200 [1:27:36<01:52,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14108/14200 [1:27:36<01:51,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14109/14200 [1:27:36<01:50,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14110/14200 [1:27:36<01:49,  1.21s/pipeline]Optimization Progress:  99%|█████████▉| 14111/14200 [1:27:50<01:47,  1.21s/pipeline]Optimization Progress:  99%|█████████▉| 14112/14200 [1:28:57<05:10,  3.53s/pipeline]Optimization Progress: 100%|█████████▉| 14192/14200 [1:29:00<00:19,  2.48s/pipeline]
Generation 141 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 14201pipeline [1:29:00,  2.48s/pipeline]Optimization Progress: 14201pipeline [1:29:00,  1.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14201pipeline [1:29:00,  1.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:12:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14201pipeline [1:29:00,  1.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 14201pipeline [1:29:03,  1.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 14201pipeline [1:29:03,  1.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14201pipeline [1:29:03,  1.74s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14202/14300 [1:29:03<02:50,  1.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14203/14300 [1:29:04<02:48,  1.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14204/14300 [1:29:04<02:47,  1.74s/pipeline]Optimization Progress:  99%|█████████▉| 14205/14300 [1:29:04<02:22,  1.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14205/14300 [1:29:04<02:22,  1.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14206/14300 [1:29:04<02:20,  1.50s/pipeline]Optimization Progress:  99%|█████████▉| 14208/14300 [1:29:14<03:12,  2.09s/pipeline]Optimization Progress: 100%|█████████▉| 14288/14300 [1:29:18<00:17,  1.48s/pipeline]
Generation 142 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 14301pipeline [1:29:18,  1.48s/pipeline]Optimization Progress: 14301pipeline [1:29:18,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 14301pipeline [1:29:18,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 14301pipeline [1:29:18,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 14301pipeline [1:29:18,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14301pipeline [1:29:19,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 14301pipeline [1:29:19,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14301pipeline [1:29:19,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 14301pipeline [1:29:21,  1.04s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14303/14400 [1:29:21<01:40,  1.04s/pipeline]Optimization Progress:  99%|█████████▉| 14304/14400 [1:29:21<01:36,  1.00s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14304/14400 [1:29:21<01:36,  1.00s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14305/14400 [1:29:21<01:35,  1.00s/pipeline]Optimization Progress:  99%|█████████▉| 14306/14400 [1:29:40<01:34,  1.00s/pipeline]Optimization Progress:  99%|█████████▉| 14307/14400 [1:31:31<21:19, 13.76s/pipeline]Optimization Progress: 100%|█████████▉| 14387/14400 [1:31:37<02:05,  9.65s/pipeline]
Generation 143 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14401pipeline [1:31:37,  9.65s/pipeline]Optimization Progress: 14401pipeline [1:31:37,  6.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14401pipeline [1:31:37,  6.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 14401pipeline [1:31:38,  6.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 14401pipeline [1:31:38,  6.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 14401pipeline [1:31:39,  6.77s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14401/14500 [1:31:40<11:10,  6.77s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14402/14500 [1:31:40<11:03,  6.77s/pipeline]Optimization Progress:  99%|█████████▉| 14403/14500 [1:31:40<08:15,  5.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14403/14500 [1:31:40<08:15,  5.11s/pipeline]Optimization Progress:  99%|█████████▉| 14405/14500 [1:33:16<28:36, 18.07s/pipeline]Optimization Progress: 100%|█████████▉| 14485/14500 [1:33:26<03:10, 12.68s/pipeline]
Generation 144 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14501pipeline [1:33:26, 12.68s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:17:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14501pipeline [1:33:27, 12.68s/pipeline]Optimization Progress: 14501pipeline [1:33:27,  8.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14501pipeline [1:33:27,  8.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 14501pipeline [1:33:28,  8.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:17:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14501pipeline [1:33:28,  8.90s/pipeline]Optimization Progress:  99%|█████████▉| 14503/14600 [1:33:29<10:39,  6.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14503/14600 [1:33:29<10:39,  6.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14504/14600 [1:33:29<10:33,  6.60s/pipeline]Optimization Progress:  99%|█████████▉| 14506/14600 [1:33:39<08:44,  5.58s/pipeline]Optimization Progress: 100%|█████████▉| 14586/14600 [1:33:47<00:55,  3.94s/pipeline]
Generation 145 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 14601pipeline [1:33:48,  3.94s/pipeline]Optimization Progress: 14601pipeline [1:33:48,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:17:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14601pipeline [1:33:49,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 14601pipeline [1:33:49,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 14601pipeline [1:33:49,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14601pipeline [1:33:49,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14601pipeline [1:33:50,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:17:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14601pipeline [1:33:50,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 14601pipeline [1:33:50,  2.77s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14602/14700 [1:33:50<04:31,  2.77s/pipeline]Optimization Progress:  99%|█████████▉| 14603/14700 [1:33:50<03:45,  2.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14603/14700 [1:33:50<03:45,  2.32s/pipeline]Optimization Progress:  99%|█████████▉| 14605/14700 [1:35:33<26:58, 17.04s/pipeline]Optimization Progress: 100%|█████████▉| 14685/14700 [1:35:37<02:59, 11.94s/pipeline]
Generation 146 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 14701pipeline [1:35:39, 11.94s/pipeline]Optimization Progress: 14701pipeline [1:35:39,  8.39s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14701pipeline [1:35:40,  8.39s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:19:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14701pipeline [1:35:41,  8.39s/pipeline]Optimization Progress:  99%|█████████▉| 14702/14800 [1:35:41<10:31,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14702/14800 [1:35:41<10:31,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14703/14800 [1:35:41<10:25,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14704/14800 [1:35:41<10:18,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14705/14800 [1:35:41<10:12,  6.44s/pipeline]Optimization Progress:  99%|█████████▉| 14707/14800 [1:35:52<08:00,  5.17s/pipeline]Optimization Progress: 100%|█████████▉| 14787/14800 [1:35:57<00:47,  3.64s/pipeline]
Generation 147 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 14801pipeline [1:35:58,  3.64s/pipeline]Optimization Progress: 14801pipeline [1:35:58,  2.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 14801pipeline [1:35:58,  2.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 14801pipeline [1:36:00,  2.57s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14801/14900 [1:36:00<04:13,  2.57s/pipeline]Optimization Progress:  99%|█████████▉| 14802/14900 [1:36:00<04:03,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14802/14900 [1:36:00<04:03,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14803/14900 [1:36:00<04:01,  2.49s/pipeline]Optimization Progress:  99%|█████████▉| 14805/14900 [1:36:05<03:32,  2.23s/pipeline]Optimization Progress: 100%|█████████▉| 14885/14900 [1:36:08<00:23,  1.57s/pipeline]
Generation 148 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 14901pipeline [1:36:08,  1.57s/pipeline]Optimization Progress: 14901pipeline [1:36:08,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:19:42] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14901pipeline [1:36:09,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 14901pipeline [1:36:09,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 14901pipeline [1:36:10,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:19:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 14901pipeline [1:36:11,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 14901pipeline [1:36:11,  1.11s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14901/15000 [1:36:12<01:49,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 14902/15000 [1:36:12<01:48,  1.11s/pipeline]Optimization Progress:  99%|█████████▉| 14903/15000 [1:36:20<01:47,  1.11s/pipeline]Optimization Progress:  99%|█████████▉| 14904/15000 [1:38:09<20:40, 12.92s/pipeline]Optimization Progress: 100%|█████████▉| 14984/15000 [1:38:14<02:24,  9.06s/pipeline]
Generation 149 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [05:21:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15001pipeline [1:38:14,  9.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15001pipeline [1:38:14,  9.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 15001pipeline [1:38:14,  9.06s/pipeline]Optimization Progress: 15001pipeline [1:38:14,  6.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15001pipeline [1:38:14,  6.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15001pipeline [1:38:15,  6.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 15001pipeline [1:38:15,  6.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15001pipeline [1:38:15,  6.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:21:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15001pipeline [1:38:15,  6.35s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15002/15100 [1:38:18<10:21,  6.35s/pipeline]Optimization Progress:  99%|█████████▉| 15003/15100 [1:38:30<10:15,  6.35s/pipeline]Optimization Progress:  99%|█████████▉| 15004/15100 [1:40:07<25:08, 15.72s/pipeline]Optimization Progress: 100%|█████████▉| 15084/15100 [1:40:17<02:56, 11.04s/pipeline]
Generation 150 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 15101pipeline [1:40:18, 11.04s/pipeline]Optimization Progress: 15101pipeline [1:40:18,  7.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 15101pipeline [1:40:19,  7.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 15101pipeline [1:40:20,  7.74s/pipeline]Optimization Progress:  99%|█████████▉| 15102/15200 [1:40:20<10:04,  6.17s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15102/15200 [1:40:20<10:04,  6.17s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15103/15200 [1:40:20<09:58,  6.17s/pipeline]Optimization Progress:  99%|█████████▉| 15105/15200 [1:40:30<08:24,  5.31s/pipeline]Optimization Progress: 100%|█████████▉| 15185/15200 [1:40:39<00:56,  3.75s/pipeline]
Generation 151 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [05:24:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15201pipeline [1:40:39,  3.75s/pipeline]Optimization Progress: 15201pipeline [1:40:39,  2.63s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 15201pipeline [1:40:40,  2.63s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 15201pipeline [1:40:40,  2.63s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15201pipeline [1:40:40,  2.63s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:24:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15201pipeline [1:40:41,  2.63s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 15201pipeline [1:40:41,  2.63s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 15201pipeline [1:40:41,  2.63s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15201pipeline [1:40:42,  2.63s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15202/15300 [1:40:43<04:17,  2.63s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15203/15300 [1:40:43<04:14,  2.63s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15204/15300 [1:40:43<04:12,  2.63s/pipeline]Optimization Progress:  99%|█████████▉| 15205/15300 [1:40:50<04:09,  2.63s/pipeline]Optimization Progress:  99%|█████████▉| 15206/15300 [1:40:52<04:05,  2.61s/pipeline]Optimization Progress: 100%|█████████▉| 15286/15300 [1:40:55<00:25,  1.84s/pipeline]
Generation 152 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 15301pipeline [1:40:55,  1.84s/pipeline]Optimization Progress: 15301pipeline [1:40:55,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 15301pipeline [1:40:55,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15301pipeline [1:40:55,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15301pipeline [1:40:56,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 15301pipeline [1:40:56,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 15301pipeline [1:40:57,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 15301pipeline [1:40:57,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:24:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15301pipeline [1:40:57,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 15301pipeline [1:40:58,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15301pipeline [1:40:58,  1.30s/pipeline]Optimization Progress:  99%|█████████▉| 15305/15400 [1:40:58<01:45,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15305/15400 [1:40:58<01:45,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15306/15400 [1:40:58<01:44,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15307/15400 [1:40:58<01:43,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15308/15400 [1:40:58<01:42,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15309/15400 [1:40:58<01:41,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15310/15400 [1:40:58<01:40,  1.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15311/15400 [1:40:58<01:38,  1.11s/pipeline]Optimization Progress:  99%|█████████▉| 15312/15400 [1:41:10<01:37,  1.11s/pipeline]Optimization Progress:  99%|█████████▉| 15313/15400 [1:42:47<07:04,  4.88s/pipeline]Optimization Progress: 100%|█████████▉| 15393/15400 [1:42:53<00:24,  3.43s/pipeline]
Generation 153 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 15401pipeline [1:42:53,  3.43s/pipeline]Optimization Progress: 15401pipeline [1:42:53,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 15401pipeline [1:42:53,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:26:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15401pipeline [1:42:53,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 15401pipeline [1:42:53,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 15401pipeline [1:42:55,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:26:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15401pipeline [1:42:55,  2.41s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15403/15500 [1:42:56<03:53,  2.41s/pipeline]Optimization Progress:  99%|█████████▉| 15404/15500 [1:42:56<03:13,  2.01s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15404/15500 [1:42:56<03:13,  2.01s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15405/15500 [1:42:56<03:11,  2.01s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15406/15500 [1:42:56<03:09,  2.01s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15407/15500 [1:42:56<03:07,  2.01s/pipeline]Optimization Progress:  99%|█████████▉| 15409/15500 [1:43:07<03:05,  2.04s/pipeline]Optimization Progress: 100%|█████████▉| 15489/15500 [1:43:11<00:15,  1.45s/pipeline]
Generation 154 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15501pipeline [1:43:11,  1.45s/pipeline]Optimization Progress: 15501pipeline [1:43:11,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15501pipeline [1:43:13,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:26:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15501pipeline [1:43:13,  1.02s/pipeline]Optimization Progress:  99%|█████████▉| 15503/15600 [1:43:15<02:06,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15503/15600 [1:43:15<02:06,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15504/15600 [1:43:15<02:05,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15505/15600 [1:43:15<02:03,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15506/15600 [1:43:15<02:02,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15507/15600 [1:43:15<02:01,  1.30s/pipeline]Optimization Progress:  99%|█████████▉| 15508/15600 [1:43:30<01:59,  1.30s/pipeline]Optimization Progress:  99%|█████████▉| 15509/15600 [1:45:05<09:40,  6.38s/pipeline]Optimization Progress: 100%|█████████▉| 15589/15600 [1:46:22<00:52,  4.76s/pipeline]
Generation 155 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15601pipeline [1:46:23,  4.76s/pipeline]Optimization Progress: 15601pipeline [1:46:23,  3.34s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 15601pipeline [1:46:24,  3.34s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 15601pipeline [1:46:24,  3.34s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15601pipeline [1:46:24,  3.34s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 15601pipeline [1:46:24,  3.34s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:29:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15601pipeline [1:46:24,  3.34s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 15601pipeline [1:46:25,  3.34s/pipeline]Optimization Progress:  99%|█████████▉| 15604/15700 [1:46:25<04:09,  2.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15604/15700 [1:46:25<04:09,  2.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15605/15700 [1:46:25<04:07,  2.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15606/15700 [1:46:25<04:04,  2.60s/pipeline]Optimization Progress:  99%|█████████▉| 15608/15700 [1:46:32<03:31,  2.30s/pipeline]Optimization Progress: 100%|█████████▉| 15688/15700 [1:46:33<00:19,  1.62s/pipeline]
Generation 156 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15701pipeline [1:46:34,  1.62s/pipeline]Optimization Progress: 15701pipeline [1:46:34,  1.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:30:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15701pipeline [1:46:34,  1.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15701pipeline [1:46:35,  1.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 15701pipeline [1:46:36,  1.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:30:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15701pipeline [1:46:36,  1.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [05:30:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15701pipeline [1:46:36,  1.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 15701pipeline [1:46:37,  1.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 15701pipeline [1:46:37,  1.14s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15701/15800 [1:46:37<01:53,  1.14s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15702/15800 [1:46:37<01:52,  1.14s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15703/15800 [1:46:37<01:50,  1.14s/pipeline]Optimization Progress:  99%|█████████▉| 15704/15800 [1:46:37<01:44,  1.09s/pipeline]Optimization Progress:  99%|█████████▉| 15704/15800 [1:46:50<01:44,  1.09s/pipeline]Optimization Progress:  99%|█████████▉| 15705/15800 [1:48:18<49:15, 31.11s/pipeline]Optimization Progress: 100%|█████████▉| 15785/15800 [1:48:27<05:27, 21.81s/pipeline]
Generation 157 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 15801pipeline [1:48:27, 21.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 15801pipeline [1:48:29, 21.81s/pipeline]Optimization Progress: 15801pipeline [1:48:29, 15.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 15801pipeline [1:48:30, 15.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 15801pipeline [1:48:30, 15.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 15801pipeline [1:48:31, 15.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:32:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15801pipeline [1:48:31, 15.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 15801pipeline [1:48:31, 15.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:32:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 15801pipeline [1:48:31, 15.29s/pipeline]Optimization Progress:  99%|█████████▉| 15804/15900 [1:48:31<17:34, 10.99s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15804/15900 [1:48:31<17:34, 10.99s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15805/15900 [1:48:31<17:23, 10.99s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15806/15900 [1:48:31<17:12, 10.99s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15807/15900 [1:48:31<17:01, 10.99s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15808/15900 [1:48:31<16:51, 10.99s/pipeline]Optimization Progress:  99%|█████████▉| 15810/15900 [1:51:48<26:19, 17.55s/pipeline]Optimization Progress: 100%|█████████▉| 15890/15900 [1:51:53<02:02, 12.30s/pipeline]
Generation 158 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 15901pipeline [1:51:53, 12.30s/pipeline]Optimization Progress: 15901pipeline [1:51:53,  8.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15901pipeline [1:51:53,  8.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 15901pipeline [1:51:54,  8.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15901pipeline [1:51:54,  8.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 15901pipeline [1:51:55,  8.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 15901pipeline [1:51:55,  8.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 15901pipeline [1:51:55,  8.62s/pipeline]Optimization Progress:  99%|█████████▉| 15903/16000 [1:51:56<10:26,  6.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15903/16000 [1:51:56<10:26,  6.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 15904/16000 [1:51:56<10:19,  6.46s/pipeline]Optimization Progress:  99%|█████████▉| 15906/16000 [1:52:05<08:34,  5.48s/pipeline]Optimization Progress: 100%|█████████▉| 15986/16000 [1:52:10<00:53,  3.85s/pipeline]
Generation 159 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16001pipeline [1:52:10,  3.85s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:35:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16001pipeline [1:52:10,  3.85s/pipeline]Optimization Progress: 16001pipeline [1:52:10,  2.70s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16001pipeline [1:52:10,  2.70s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:35:45] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16001pipeline [1:52:12,  2.70s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:35:45] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16001pipeline [1:52:12,  2.70s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16001pipeline [1:52:12,  2.70s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16001pipeline [1:52:13,  2.70s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16002/16100 [1:52:13<04:24,  2.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16003/16100 [1:52:13<04:22,  2.70s/pipeline]Optimization Progress:  99%|█████████▉| 16004/16100 [1:52:13<03:29,  2.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16004/16100 [1:52:13<03:29,  2.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16005/16100 [1:52:13<03:27,  2.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16006/16100 [1:52:13<03:25,  2.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16007/16100 [1:52:13<03:23,  2.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16008/16100 [1:52:13<03:20,  2.18s/pipeline]Optimization Progress:  99%|█████████▉| 16010/16100 [1:52:22<02:57,  1.98s/pipeline]Optimization Progress: 100%|█████████▉| 16090/16100 [1:52:24<00:13,  1.39s/pipeline]
Generation 160 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 16101pipeline [1:52:24,  1.39s/pipeline]Optimization Progress: 16101pipeline [1:52:24,  1.02pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16101pipeline [1:52:25,  1.02pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 16101pipeline [1:52:26,  1.02pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:35:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16101pipeline [1:52:26,  1.02pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16103/16200 [1:52:27<01:35,  1.02pipeline/s]Optimization Progress:  99%|█████████▉| 16104/16200 [1:52:27<01:32,  1.03pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16104/16200 [1:52:27<01:32,  1.03pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16105/16200 [1:52:27<01:31,  1.03pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16106/16200 [1:52:27<01:30,  1.03pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16107/16200 [1:52:27<01:29,  1.03pipeline/s]Optimization Progress:  99%|█████████▉| 16109/16200 [1:52:38<01:59,  1.32s/pipeline]Optimization Progress: 100%|█████████▉| 16189/16200 [1:52:47<00:10,  1.04pipeline/s]
Generation 161 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16201pipeline [1:52:47,  1.04pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16201pipeline [1:52:49,  1.04pipeline/s]Optimization Progress: 16201pipeline [1:52:49,  1.38pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:36:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16201pipeline [1:52:49,  1.38pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 16201pipeline [1:52:49,  1.38pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:36:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16201pipeline [1:52:50,  1.38pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16201pipeline [1:52:50,  1.38pipeline/s]Optimization Progress:  99%|█████████▉| 16204/16300 [1:52:51<01:08,  1.41pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16204/16300 [1:52:51<01:08,  1.41pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16205/16300 [1:52:51<01:07,  1.41pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16206/16300 [1:52:51<01:06,  1.41pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16207/16300 [1:52:51<01:05,  1.41pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16208/16300 [1:52:51<01:05,  1.41pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16209/16300 [1:52:51<01:04,  1.41pipeline/s]Optimization Progress:  99%|█████████▉| 16211/16300 [1:54:33<07:12,  4.86s/pipeline]Optimization Progress: 100%|█████████▉| 16291/16300 [1:56:24<00:34,  3.82s/pipeline]
Generation 162 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 16301pipeline [1:56:24,  3.82s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:39:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16301pipeline [1:56:24,  3.82s/pipeline]Optimization Progress: 16301pipeline [1:56:24,  2.68s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:39:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16301pipeline [1:56:25,  2.68s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 16301pipeline [1:56:25,  2.68s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:39:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16301pipeline [1:56:25,  2.68s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16301pipeline [1:56:26,  2.68s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16302/16400 [1:56:27<04:22,  2.68s/pipeline]Optimization Progress:  99%|█████████▉| 16303/16400 [1:56:27<03:47,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16303/16400 [1:56:27<03:47,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16304/16400 [1:56:27<03:44,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16305/16400 [1:56:27<03:42,  2.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16306/16400 [1:56:27<03:40,  2.34s/pipeline]Optimization Progress:  99%|█████████▉| 16308/16400 [1:58:12<12:10,  7.94s/pipeline]Optimization Progress: 100%|█████████▉| 16388/16400 [1:58:21<01:07,  5.59s/pipeline]
Generation 163 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [05:41:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16401pipeline [1:58:22,  5.59s/pipeline]Optimization Progress: 16401pipeline [1:58:22,  3.92s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 16401pipeline [1:58:23,  3.92s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 16401pipeline [1:58:23,  3.92s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16401pipeline [1:58:23,  3.92s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 16401pipeline [1:58:24,  3.92s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16402/16500 [1:58:25<06:24,  3.92s/pipeline]Optimization Progress:  99%|█████████▉| 16403/16500 [1:58:25<05:15,  3.25s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16403/16500 [1:58:25<05:15,  3.25s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16404/16500 [1:58:25<05:11,  3.25s/pipeline]Optimization Progress:  99%|█████████▉| 16406/16500 [2:00:07<19:28, 12.43s/pipeline]Optimization Progress: 100%|█████████▉| 16486/16500 [2:00:15<02:02,  8.73s/pipeline]
Generation 164 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16501pipeline [2:00:16,  8.73s/pipeline]Optimization Progress: 16501pipeline [2:00:16,  6.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 16501pipeline [2:00:16,  6.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 16501pipeline [2:00:17,  6.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 16501pipeline [2:00:18,  6.12s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16501/16600 [2:00:20<10:05,  6.12s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16502/16600 [2:00:20<09:59,  6.12s/pipeline]Optimization Progress:  99%|█████████▉| 16503/16600 [2:00:20<07:51,  4.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16503/16600 [2:00:20<07:51,  4.86s/pipeline]Optimization Progress:  99%|█████████▉| 16504/16600 [2:00:30<07:46,  4.86s/pipeline]Optimization Progress:  99%|█████████▉| 16505/16600 [2:00:30<07:49,  4.94s/pipeline]Optimization Progress: 100%|█████████▉| 16585/16600 [2:00:39<00:52,  3.49s/pipeline]
Generation 165 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 16601pipeline [2:00:39,  3.49s/pipeline]Optimization Progress: 16601pipeline [2:00:39,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 16601pipeline [2:00:40,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:44:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16601pipeline [2:00:40,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16601pipeline [2:00:41,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 16601pipeline [2:00:41,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16601pipeline [2:00:41,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 16601pipeline [2:00:42,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:44:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 16601pipeline [2:00:43,  2.45s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16601/16700 [2:00:43<04:02,  2.45s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16602/16700 [2:00:43<04:00,  2.45s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16603/16700 [2:00:43<03:57,  2.45s/pipeline]Optimization Progress:  99%|█████████▉| 16604/16700 [2:00:43<03:18,  2.07s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16604/16700 [2:00:43<03:18,  2.07s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16605/16700 [2:00:43<03:16,  2.07s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16606/16700 [2:00:43<03:14,  2.07s/pipeline]Optimization Progress:  99%|█████████▉| 16608/16700 [2:00:52<03:16,  2.14s/pipeline]Optimization Progress: 100%|█████████▉| 16688/16700 [2:00:58<00:18,  1.52s/pipeline]
Generation 166 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 16701pipeline [2:01:01,  1.52s/pipeline]Optimization Progress: 16701pipeline [2:01:01,  1.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16701pipeline [2:01:01,  1.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 16701pipeline [2:01:01,  1.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 16701pipeline [2:01:02,  1.12s/pipeline]Optimization Progress:  99%|█████████▉| 16704/16800 [2:01:02<01:23,  1.15pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16704/16800 [2:01:02<01:23,  1.15pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16705/16800 [2:01:02<01:22,  1.15pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16706/16800 [2:01:02<01:21,  1.15pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16707/16800 [2:01:02<01:20,  1.15pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16708/16800 [2:01:02<01:19,  1.15pipeline/s]Optimization Progress:  99%|█████████▉| 16710/16800 [2:01:13<01:45,  1.17s/pipeline]Optimization Progress: 100%|█████████▉| 16790/16800 [2:01:17<00:08,  1.20pipeline/s]
Generation 167 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 16801pipeline [2:01:18,  1.20pipeline/s]Optimization Progress: 16801pipeline [2:01:18,  1.64pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 16801pipeline [2:01:19,  1.64pipeline/s]Optimization Progress:  99%|█████████▉| 16802/16900 [2:01:20<01:35,  1.03pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16802/16900 [2:01:20<01:35,  1.03pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16803/16900 [2:01:20<01:34,  1.03pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16804/16900 [2:01:20<01:33,  1.03pipeline/s]Optimization Progress:  99%|█████████▉| 16806/16900 [2:01:30<02:14,  1.43s/pipeline]Optimization Progress: 100%|█████████▉| 16886/16900 [2:01:40<00:14,  1.04s/pipeline]
Generation 168 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 16901pipeline [2:01:43,  1.04s/pipeline]Optimization Progress: 16901pipeline [2:01:43,  1.25pipeline/s]Optimization Progress:  99%|█████████▉| 16903/17000 [2:01:43<00:57,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16903/17000 [2:01:43<00:57,  1.70pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 16904/17000 [2:01:43<00:56,  1.70pipeline/s]Optimization Progress:  99%|█████████▉| 16906/17000 [2:03:39<18:41, 11.93s/pipeline]Optimization Progress: 100%|█████████▉| 16986/17000 [2:03:45<01:57,  8.37s/pipeline]
Generation 169 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17001pipeline [2:03:46,  8.37s/pipeline]Optimization Progress: 17001pipeline [2:03:46,  5.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:47:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17001pipeline [2:03:46,  5.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17001pipeline [2:03:47,  5.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 17001pipeline [2:03:47,  5.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 17001pipeline [2:03:47,  5.88s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17001/17100 [2:03:48<09:41,  5.88s/pipeline]Optimization Progress:  99%|█████████▉| 17002/17100 [2:03:48<07:44,  4.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17002/17100 [2:03:48<07:44,  4.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17003/17100 [2:03:48<07:39,  4.74s/pipeline]Optimization Progress:  99%|█████████▉| 17005/17100 [2:03:58<06:49,  4.31s/pipeline]Optimization Progress: 100%|█████████▉| 17085/17100 [2:04:01<00:45,  3.03s/pipeline]
Generation 170 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 17101pipeline [2:04:01,  3.03s/pipeline]Optimization Progress: 17101pipeline [2:04:01,  2.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:47:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17101pipeline [2:04:01,  2.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17101pipeline [2:04:03,  2.13s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17102/17200 [2:04:04<03:28,  2.13s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17103/17200 [2:04:04<03:26,  2.13s/pipeline]Optimization Progress:  99%|█████████▉| 17104/17200 [2:04:04<02:54,  1.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17104/17200 [2:04:04<02:54,  1.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17105/17200 [2:04:04<02:53,  1.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17106/17200 [2:04:04<02:51,  1.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17107/17200 [2:04:04<02:49,  1.82s/pipeline]Optimization Progress:  99%|█████████▉| 17108/17200 [2:04:20<02:47,  1.82s/pipeline]Optimization Progress:  99%|█████████▉| 17109/17200 [2:05:50<11:36,  7.65s/pipeline]Optimization Progress: 100%|█████████▉| 17189/17200 [2:05:56<00:59,  5.38s/pipeline]
Generation 171 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 17201pipeline [2:05:57,  5.38s/pipeline]Optimization Progress: 17201pipeline [2:05:57,  3.79s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 17201pipeline [2:05:58,  3.79s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:49:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17201pipeline [2:05:58,  3.79s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:49:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17201pipeline [2:05:59,  3.79s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17201/17300 [2:06:00<06:15,  3.79s/pipeline]Optimization Progress:  99%|█████████▉| 17202/17300 [2:06:00<05:38,  3.45s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17202/17300 [2:06:00<05:38,  3.45s/pipeline]Optimization Progress:  99%|█████████▉| 17204/17300 [2:07:44<28:45, 17.98s/pipeline]Optimization Progress: 100%|█████████▉| 17284/17300 [2:07:51<03:21, 12.61s/pipeline]
Generation 172 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 17301pipeline [2:07:52, 12.61s/pipeline]Optimization Progress: 17301pipeline [2:07:52,  8.85s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 17301pipeline [2:07:53,  8.85s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17301/17400 [2:07:54<14:36,  8.85s/pipeline]Optimization Progress:  99%|█████████▉| 17302/17400 [2:07:54<11:05,  6.79s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17302/17400 [2:07:54<11:05,  6.79s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17303/17400 [2:07:54<10:58,  6.79s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17304/17400 [2:07:54<10:51,  6.79s/pipeline]Optimization Progress:  99%|█████████▉| 17306/17400 [2:09:15<16:56, 10.82s/pipeline]Optimization Progress: 100%|█████████▉| 17386/17400 [2:09:23<01:46,  7.60s/pipeline]
Generation 173 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 17401pipeline [2:09:24,  7.60s/pipeline]Optimization Progress: 17401pipeline [2:09:24,  5.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:52:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17401pipeline [2:09:25,  5.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17401pipeline [2:09:26,  5.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [05:52:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17401pipeline [2:09:26,  5.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:52:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17401pipeline [2:09:26,  5.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:52:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17401pipeline [2:09:26,  5.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17401pipeline [2:09:26,  5.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 17401pipeline [2:09:27,  5.33s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17401/17500 [2:09:27<08:47,  5.33s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17402/17500 [2:09:27<08:42,  5.33s/pipeline]Optimization Progress:  99%|█████████▉| 17403/17500 [2:09:27<06:49,  4.22s/pipeline]Optimization Progress:  99%|█████████▉| 17403/17500 [2:09:40<06:49,  4.22s/pipeline]Optimization Progress:  99%|█████████▉| 17404/17500 [2:09:53<17:01, 10.64s/pipeline]Optimization Progress: 100%|█████████▉| 17484/17500 [2:10:02<01:59,  7.48s/pipeline]
Generation 174 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [05:53:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17501pipeline [2:10:03,  7.48s/pipeline]Optimization Progress: 17501pipeline [2:10:03,  5.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 17501pipeline [2:10:03,  5.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:53:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17501pipeline [2:10:05,  5.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17501pipeline [2:10:05,  5.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17501pipeline [2:10:05,  5.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:53:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17501pipeline [2:10:06,  5.26s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17501/17600 [2:10:06<08:40,  5.26s/pipeline]Optimization Progress:  99%|█████████▉| 17502/17600 [2:10:06<07:31,  4.61s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17502/17600 [2:10:06<07:31,  4.61s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17503/17600 [2:10:06<07:27,  4.61s/pipeline]Optimization Progress:  99%|█████████▉| 17505/17600 [2:10:16<06:41,  4.22s/pipeline]Optimization Progress: 100%|█████████▉| 17585/17600 [2:10:25<00:44,  2.99s/pipeline]
Generation 175 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 17601pipeline [2:10:25,  2.99s/pipeline]Optimization Progress: 17601pipeline [2:10:25,  2.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:53:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17601pipeline [2:10:26,  2.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 17601pipeline [2:10:27,  2.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 17601pipeline [2:10:27,  2.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 17601pipeline [2:10:28,  2.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 17601pipeline [2:10:28,  2.10s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17602/17700 [2:10:29<03:25,  2.10s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17603/17700 [2:10:29<03:23,  2.10s/pipeline]Optimization Progress:  99%|█████████▉| 17604/17700 [2:10:29<02:52,  1.80s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17604/17700 [2:10:29<02:52,  1.80s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17605/17700 [2:10:29<02:51,  1.80s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17606/17700 [2:10:29<02:49,  1.80s/pipeline]Optimization Progress:  99%|█████████▉| 17608/17700 [2:10:39<03:07,  2.04s/pipeline]Optimization Progress: 100%|█████████▉| 17688/17700 [2:10:42<00:17,  1.44s/pipeline]
Generation 176 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 17701pipeline [2:10:42,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:54:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17701pipeline [2:10:42,  1.44s/pipeline]Optimization Progress: 17701pipeline [2:10:42,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:54:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17701pipeline [2:10:42,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 17701pipeline [2:10:43,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 17701pipeline [2:10:44,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 17701pipeline [2:10:44,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 17701pipeline [2:10:45,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:54:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17701pipeline [2:10:45,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:54:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17701pipeline [2:10:45,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 17701pipeline [2:10:46,  1.02s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17701/17800 [2:10:46<01:40,  1.02s/pipeline]Optimization Progress:  99%|█████████▉| 17703/17800 [2:10:55<04:14,  2.62s/pipeline]Optimization Progress: 100%|█████████▉| 17783/17800 [2:10:57<00:31,  1.84s/pipeline]
Generation 177 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 17801pipeline [2:10:58,  1.84s/pipeline]Optimization Progress: 17801pipeline [2:10:58,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 17801pipeline [2:10:58,  1.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:54:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 17801pipeline [2:11:00,  1.30s/pipeline]Optimization Progress:  99%|█████████▉| 17804/17900 [2:11:01<01:58,  1.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17804/17900 [2:11:01<01:58,  1.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17805/17900 [2:11:01<01:56,  1.23s/pipeline]Optimization Progress:  99%|█████████▉| 17806/17900 [2:11:20<01:55,  1.23s/pipeline]Optimization Progress:  99%|█████████▉| 17807/17900 [2:13:50<27:38, 17.83s/pipeline]Optimization Progress: 100%|█████████▉| 17887/17900 [2:13:54<02:42, 12.50s/pipeline]
Generation 178 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 17901pipeline [2:13:55, 12.50s/pipeline]Optimization Progress: 17901pipeline [2:13:55,  8.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 17901pipeline [2:13:55,  8.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 17901pipeline [2:13:56,  8.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 17901pipeline [2:13:57,  8.76s/pipeline]Optimization Progress:  99%|█████████▉| 17903/18000 [2:13:57<10:34,  6.54s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17903/18000 [2:13:57<10:34,  6.54s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17904/18000 [2:13:57<10:27,  6.54s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17905/18000 [2:13:57<10:21,  6.54s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17906/18000 [2:13:57<10:14,  6.54s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17907/18000 [2:13:57<10:08,  6.54s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 17908/18000 [2:13:57<10:01,  6.54s/pipeline]Optimization Progress: 100%|█████████▉| 17910/18000 [2:15:47<13:53,  9.27s/pipeline]Optimization Progress: 100%|█████████▉| 17990/18000 [2:15:48<01:04,  6.49s/pipeline]
Generation 179 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18001pipeline [2:15:49,  6.49s/pipeline]Optimization Progress: 18001pipeline [2:15:49,  4.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18001pipeline [2:15:49,  4.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [05:59:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18001pipeline [2:15:50,  4.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18001pipeline [2:15:50,  4.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 18001pipeline [2:15:51,  4.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 18001pipeline [2:15:52,  4.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18001pipeline [2:15:52,  4.57s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18002/18100 [2:15:52<07:27,  4.57s/pipeline]Optimization Progress:  99%|█████████▉| 18003/18100 [2:15:52<06:02,  3.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18003/18100 [2:15:53<06:02,  3.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18004/18100 [2:15:53<05:58,  3.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18005/18100 [2:15:53<05:55,  3.74s/pipeline]Optimization Progress:  99%|█████████▉| 18006/18100 [2:16:10<05:51,  3.74s/pipeline]Optimization Progress:  99%|█████████▉| 18007/18100 [2:17:21<14:21,  9.26s/pipeline]Optimization Progress: 100%|█████████▉| 18087/18100 [2:17:27<01:24,  6.50s/pipeline]
Generation 180 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [06:01:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18101pipeline [2:17:28,  6.50s/pipeline]Optimization Progress: 18101pipeline [2:17:28,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:01:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18101pipeline [2:17:28,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18101pipeline [2:17:29,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 18101pipeline [2:17:29,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18101pipeline [2:17:29,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18101pipeline [2:17:30,  4.58s/pipeline]Optimization Progress:  99%|█████████▉| 18102/18200 [2:17:31<06:51,  4.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18102/18200 [2:17:31<06:51,  4.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18103/18200 [2:17:31<06:47,  4.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18104/18200 [2:17:31<06:43,  4.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18105/18200 [2:17:31<06:38,  4.20s/pipeline]Optimization Progress:  99%|█████████▉| 18107/18200 [2:19:03<13:04,  8.44s/pipeline]Optimization Progress: 100%|█████████▉| 18187/18200 [2:19:13<01:17,  5.95s/pipeline]
Generation 181 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-130151403.73079705	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 18201pipeline [2:19:14,  5.95s/pipeline]Optimization Progress: 18201pipeline [2:19:14,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18201pipeline [2:19:16,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18201pipeline [2:19:16,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18201pipeline [2:19:16,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:02:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18201pipeline [2:19:17,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:02:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18201pipeline [2:19:17,  4.18s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18202/18300 [2:19:18<06:49,  4.18s/pipeline]Optimization Progress:  99%|█████████▉| 18203/18300 [2:19:18<05:39,  3.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18203/18300 [2:19:18<05:39,  3.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18204/18300 [2:19:18<05:36,  3.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18205/18300 [2:19:18<05:32,  3.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18206/18300 [2:19:18<05:29,  3.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18207/18300 [2:19:18<05:25,  3.50s/pipeline]Optimization Progress: 100%|█████████▉| 18209/18300 [2:20:53<10:57,  7.22s/pipeline]Optimization Progress: 100%|█████████▉| 18289/18300 [2:22:14<00:58,  5.36s/pipeline]
Generation 182 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 18301pipeline [2:22:16,  5.36s/pipeline]Optimization Progress: 18301pipeline [2:22:16,  3.80s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:05:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18301pipeline [2:22:17,  3.80s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:05:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18301pipeline [2:22:17,  3.80s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18301/18400 [2:22:18<06:15,  3.80s/pipeline]Optimization Progress:  99%|█████████▉| 18302/18400 [2:22:18<05:43,  3.51s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18302/18400 [2:22:18<05:43,  3.51s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18303/18400 [2:22:18<05:40,  3.51s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18304/18400 [2:22:18<05:36,  3.51s/pipeline]Optimization Progress:  99%|█████████▉| 18306/18400 [2:25:10<23:59, 15.31s/pipeline]Optimization Progress: 100%|█████████▉| 18386/18400 [2:25:24<02:30, 10.77s/pipeline]
Generation 183 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18401pipeline [2:25:25, 10.77s/pipeline]Optimization Progress: 18401pipeline [2:25:25,  7.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 18401pipeline [2:25:25,  7.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 18401pipeline [2:25:25,  7.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 18401pipeline [2:25:26,  7.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:08:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18401pipeline [2:25:26,  7.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18401pipeline [2:25:26,  7.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 18401pipeline [2:25:27,  7.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 18401pipeline [2:25:28,  7.55s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18402/18500 [2:25:28<12:20,  7.55s/pipeline]Optimization Progress:  99%|█████████▉| 18403/18500 [2:25:28<09:13,  5.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18403/18500 [2:25:28<09:13,  5.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18404/18500 [2:25:28<09:07,  5.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18405/18500 [2:25:28<09:01,  5.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18406/18500 [2:25:28<08:55,  5.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18407/18500 [2:25:28<08:50,  5.70s/pipeline]Optimization Progress: 100%|█████████▉| 18409/18500 [2:25:38<06:50,  4.51s/pipeline]Optimization Progress: 100%|█████████▉| 18489/18500 [2:25:41<00:34,  3.17s/pipeline]
Generation 184 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18501pipeline [2:25:42,  3.17s/pipeline]Optimization Progress: 18501pipeline [2:25:42,  2.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [06:09:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18501pipeline [2:25:42,  2.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18501pipeline [2:25:42,  2.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:09:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18501pipeline [2:25:43,  2.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18501pipeline [2:25:44,  2.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18501pipeline [2:25:44,  2.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18501pipeline [2:25:44,  2.23s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18502/18600 [2:25:45<03:38,  2.23s/pipeline]Optimization Progress:  99%|█████████▉| 18503/18600 [2:25:45<03:16,  2.02s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18503/18600 [2:25:45<03:16,  2.02s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18504/18600 [2:25:45<03:14,  2.02s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18505/18600 [2:25:45<03:12,  2.02s/pipeline]Optimization Progress: 100%|█████████▉| 18507/18600 [2:25:55<03:21,  2.16s/pipeline]Optimization Progress: 100%|█████████▉| 18587/18600 [2:26:04<00:20,  1.55s/pipeline]
Generation 185 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 18601pipeline [2:26:04,  1.55s/pipeline]Optimization Progress: 18601pipeline [2:26:04,  1.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 18601pipeline [2:26:05,  1.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:09:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18601pipeline [2:26:06,  1.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 18601pipeline [2:26:06,  1.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18601pipeline [2:26:07,  1.09s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18602/18700 [2:26:08<01:47,  1.09s/pipeline]Optimization Progress:  99%|█████████▉| 18603/18700 [2:26:08<02:03,  1.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18603/18700 [2:26:08<02:03,  1.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18604/18700 [2:26:08<02:02,  1.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18605/18700 [2:26:08<02:01,  1.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18606/18700 [2:26:08<02:00,  1.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18607/18700 [2:26:08<01:58,  1.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18608/18700 [2:26:08<01:57,  1.28s/pipeline]Optimization Progress: 100%|█████████▉| 18610/18700 [2:26:13<01:42,  1.14s/pipeline]Optimization Progress: 100%|█████████▉| 18690/18700 [2:26:15<00:08,  1.25pipeline/s]
Generation 186 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18701pipeline [2:26:16,  1.25pipeline/s]Optimization Progress: 18701pipeline [2:26:16,  1.71pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18701pipeline [2:26:16,  1.71pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:09:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18701pipeline [2:26:18,  1.71pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18702/18800 [2:26:18<00:57,  1.71pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18703/18800 [2:26:18<00:56,  1.71pipeline/s]Optimization Progress:  99%|█████████▉| 18704/18800 [2:26:18<01:04,  1.48pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18704/18800 [2:26:18<01:04,  1.48pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18705/18800 [2:26:18<01:04,  1.48pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18706/18800 [2:26:18<01:03,  1.48pipeline/s]Optimization Progress: 100%|█████████▉| 18708/18800 [2:26:27<01:45,  1.15s/pipeline]Optimization Progress: 100%|█████████▉| 18788/18800 [2:26:32<00:09,  1.22pipeline/s]
Generation 187 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 18801pipeline [2:26:33,  1.22pipeline/s]Optimization Progress: 18801pipeline [2:26:33,  1.65pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 18801pipeline [2:26:33,  1.65pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 18801pipeline [2:26:34,  1.65pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18801pipeline [2:26:34,  1.65pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18801pipeline [2:26:34,  1.65pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18801pipeline [2:26:35,  1.65pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 18801pipeline [2:26:35,  1.65pipeline/s]Optimization Progress:  99%|█████████▉| 18803/18900 [2:26:46<03:53,  2.41s/pipeline]Optimization Progress: 100%|█████████▉| 18882/18900 [2:26:55<00:30,  1.72s/pipeline]
Generation 188 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [06:10:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18901pipeline [2:26:55,  1.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18901pipeline [2:26:56,  1.72s/pipeline]Optimization Progress: 18901pipeline [2:26:56,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:10:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 18901pipeline [2:26:56,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 18901pipeline [2:26:56,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18901pipeline [2:26:56,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 18901pipeline [2:26:57,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 18901pipeline [2:26:58,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 18901pipeline [2:26:59,  1.22s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18901/19000 [2:26:59<02:00,  1.22s/pipeline]Optimization Progress:  99%|█████████▉| 18902/19000 [2:26:59<02:49,  1.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18902/19000 [2:26:59<02:49,  1.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18903/19000 [2:26:59<02:48,  1.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 18904/19000 [2:26:59<02:46,  1.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 18905/19000 [2:26:59<02:44,  1.73s/pipeline]Optimization Progress: 100%|█████████▉| 18907/19000 [2:28:39<11:10,  7.21s/pipeline]Optimization Progress: 100%|█████████▉| 18987/19000 [2:29:34<01:08,  5.25s/pipeline]
Generation 189 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 19001pipeline [2:29:34,  5.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 19001pipeline [2:29:37,  5.25s/pipeline]Optimization Progress: 19001pipeline [2:29:37,  3.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 19001pipeline [2:29:37,  3.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19001pipeline [2:29:37,  3.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:13:11] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 19001pipeline [2:29:38,  3.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 19001pipeline [2:29:38,  3.73s/pipeline]Optimization Progress:  99%|█████████▉| 19002/19100 [2:29:38<05:11,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19002/19100 [2:29:38<05:11,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19003/19100 [2:29:38<05:08,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19004/19100 [2:29:38<05:05,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19005/19100 [2:29:38<05:02,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19006/19100 [2:29:38<04:59,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19007/19100 [2:29:38<04:55,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19008/19100 [2:29:39<04:52,  3.18s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19009/19100 [2:29:39<04:49,  3.18s/pipeline]Optimization Progress: 100%|█████████▉| 19011/19100 [2:31:24<08:30,  5.74s/pipeline]Optimization Progress: 100%|█████████▉| 19091/19100 [2:31:29<00:36,  4.04s/pipeline]
Generation 190 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19101pipeline [2:31:30,  4.04s/pipeline]Optimization Progress: 19101pipeline [2:31:30,  2.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 19101pipeline [2:31:30,  2.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:15:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 19101pipeline [2:31:32,  2.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 19101pipeline [2:31:33,  2.83s/pipeline]Optimization Progress: 100%|█████████▉| 19105/19200 [2:31:34<03:37,  2.29s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19105/19200 [2:31:34<03:37,  2.29s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19106/19200 [2:31:34<03:35,  2.29s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19107/19200 [2:31:34<03:33,  2.29s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19108/19200 [2:31:34<03:30,  2.29s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19109/19200 [2:31:34<03:28,  2.29s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19110/19200 [2:31:34<03:26,  2.29s/pipeline]Optimization Progress: 100%|█████████▉| 19111/19200 [2:31:50<03:23,  2.29s/pipeline]Optimization Progress: 100%|█████████▉| 19112/19200 [2:33:18<08:54,  6.07s/pipeline]Optimization Progress: 100%|█████████▉| 19192/19200 [2:34:55<00:36,  4.62s/pipeline]
Generation 191 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 19201pipeline [2:34:55,  4.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 19201pipeline [2:34:55,  4.62s/pipeline]Optimization Progress: 19201pipeline [2:34:55,  3.24s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19201pipeline [2:34:57,  3.24s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19201pipeline [2:34:57,  3.24s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 19201pipeline [2:34:58,  3.24s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19202/19300 [2:34:59<05:17,  3.24s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19203/19300 [2:34:59<05:13,  3.24s/pipeline]Optimization Progress: 100%|█████████▉| 19204/19300 [2:34:59<04:07,  2.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19204/19300 [2:34:59<04:07,  2.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19205/19300 [2:34:59<04:05,  2.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19206/19300 [2:34:59<04:02,  2.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19207/19300 [2:34:59<03:59,  2.58s/pipeline]Optimization Progress: 100%|█████████▉| 19209/19300 [2:35:08<03:37,  2.39s/pipeline]Optimization Progress: 100%|█████████▉| 19289/19300 [2:35:11<00:18,  1.68s/pipeline]
Generation 192 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 19301pipeline [2:35:12,  1.68s/pipeline]Optimization Progress: 19301pipeline [2:35:12,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19301pipeline [2:35:13,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19301pipeline [2:35:13,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 19301pipeline [2:35:14,  1.20s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19301/19400 [2:35:15<01:58,  1.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19302/19400 [2:35:15<01:57,  1.20s/pipeline]Optimization Progress: 100%|█████████▉| 19303/19400 [2:35:15<02:03,  1.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19303/19400 [2:35:15<02:03,  1.28s/pipeline]Optimization Progress: 100%|█████████▉| 19304/19400 [2:35:30<02:02,  1.28s/pipeline]Optimization Progress: 100%|█████████▉| 19305/19400 [2:36:50<24:00, 15.16s/pipeline]Optimization Progress: 100%|█████████▉| 19385/19400 [2:37:00<02:39, 10.65s/pipeline]
Generation 193 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19401pipeline [2:37:00, 10.65s/pipeline]Optimization Progress: 19401pipeline [2:37:00,  7.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 19401pipeline [2:37:01,  7.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19401pipeline [2:37:01,  7.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19401pipeline [2:37:02,  7.46s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19402/19500 [2:37:03<12:10,  7.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19403/19500 [2:37:03<12:03,  7.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19404/19500 [2:37:03<11:55,  7.46s/pipeline]Optimization Progress: 100%|█████████▉| 19405/19500 [2:37:03<08:38,  5.46s/pipeline]Optimization Progress: 100%|█████████▉| 19405/19500 [2:37:20<08:38,  5.46s/pipeline]Optimization Progress: 100%|█████████▉| 19406/19500 [2:39:40<1:19:48, 50.94s/pipeline]Optimization Progress: 100%|█████████▉| 19486/19500 [2:39:49<08:19, 35.69s/pipeline]  
Generation 194 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 19501pipeline [2:39:50, 35.69s/pipeline]Optimization Progress: 19501pipeline [2:39:50, 25.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19501pipeline [2:39:50, 25.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 19501pipeline [2:39:50, 25.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 19501pipeline [2:39:53, 25.00s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 19501/19600 [2:39:53<41:14, 25.00s/pipeline]Optimization Progress: 100%|█████████▉| 19502/19600 [2:39:53<30:19, 18.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19502/19600 [2:39:53<30:19, 18.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19503/19600 [2:39:53<30:01, 18.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19504/19600 [2:39:53<29:42, 18.57s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19505/19600 [2:39:53<29:24, 18.57s/pipeline]Optimization Progress: 100%|█████████▉| 19507/19600 [2:41:21<28:19, 18.28s/pipeline]Optimization Progress: 100%|█████████▉| 19587/19600 [2:41:30<02:46, 12.83s/pipeline]
Generation 195 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19601pipeline [2:41:32, 12.83s/pipeline]Optimization Progress: 19601pipeline [2:41:32,  9.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 19601pipeline [2:41:32,  9.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:25:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 19601pipeline [2:41:33,  9.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19601pipeline [2:41:34,  9.01s/pipeline]Optimization Progress: 100%|█████████▉| 19603/19700 [2:41:35<10:51,  6.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19603/19700 [2:41:35<10:51,  6.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19604/19700 [2:41:35<10:45,  6.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19605/19700 [2:41:35<10:38,  6.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19606/19700 [2:41:35<10:31,  6.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19607/19700 [2:41:35<10:24,  6.72s/pipeline]Optimization Progress: 100%|█████████▉| 19609/19700 [2:43:27<15:39, 10.33s/pipeline]Optimization Progress: 100%|█████████▉| 19689/19700 [2:43:36<01:19,  7.26s/pipeline]
Generation 196 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19701pipeline [2:43:37,  7.26s/pipeline]Optimization Progress: 19701pipeline [2:43:37,  5.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19701pipeline [2:43:37,  5.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19701pipeline [2:43:38,  5.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:27:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 19701pipeline [2:43:38,  5.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:27:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 19701pipeline [2:43:39,  5.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 19701pipeline [2:43:39,  5.11s/pipeline]Optimization Progress: 100%|█████████▉| 19702/19800 [2:43:40<07:14,  4.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19702/19800 [2:43:40<07:14,  4.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19703/19800 [2:43:40<07:10,  4.44s/pipeline]Optimization Progress: 100%|█████████▉| 19705/19800 [2:43:50<06:36,  4.17s/pipeline]Optimization Progress: 100%|█████████▉| 19785/19800 [2:43:55<00:44,  2.94s/pipeline]
Generation 197 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 19801pipeline [2:43:55,  2.94s/pipeline]Optimization Progress: 19801pipeline [2:43:55,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19801pipeline [2:43:55,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19801pipeline [2:43:57,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 19801pipeline [2:43:57,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:27:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 19801pipeline [2:43:57,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 19801pipeline [2:43:58,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 19801pipeline [2:43:58,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 19801pipeline [2:43:59,  2.06s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19801/19900 [2:43:59<03:23,  2.06s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19802/19900 [2:43:59<03:21,  2.06s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19803/19900 [2:43:59<03:19,  2.06s/pipeline]Optimization Progress: 100%|█████████▉| 19804/19900 [2:43:59<02:53,  1.80s/pipeline]Optimization Progress: 100%|█████████▉| 19806/19900 [2:44:09<04:21,  2.79s/pipeline]Optimization Progress: 100%|█████████▉| 19885/19900 [2:44:18<00:29,  1.98s/pipeline]
Generation 198 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 19901pipeline [2:44:19,  1.98s/pipeline]Optimization Progress: 19901pipeline [2:44:19,  1.40s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 19901pipeline [2:44:19,  1.40s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 19901pipeline [2:44:19,  1.40s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 19901pipeline [2:44:19,  1.40s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 19901pipeline [2:44:21,  1.40s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 19901pipeline [2:44:22,  1.40s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:27:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 19901pipeline [2:44:22,  1.40s/pipeline]Optimization Progress: 100%|█████████▉| 19903/20000 [2:44:22<02:27,  1.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19903/20000 [2:44:22<02:27,  1.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19904/20000 [2:44:22<02:25,  1.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19905/20000 [2:44:22<02:24,  1.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19906/20000 [2:44:22<02:22,  1.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 19907/20000 [2:44:22<02:21,  1.52s/pipeline]Optimization Progress: 100%|█████████▉| 19909/20000 [2:44:35<02:35,  1.71s/pipeline]Optimization Progress: 100%|█████████▉| 19989/20000 [2:44:44<00:13,  1.23s/pipeline]
Generation 199 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 20001pipeline [2:44:45,  1.23s/pipeline]Optimization Progress: 20001pipeline [2:44:45,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:28:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20001pipeline [2:44:46,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20001pipeline [2:44:47,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 20001pipeline [2:44:48,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:28:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20001pipeline [2:44:48,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20001pipeline [2:44:48,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20001pipeline [2:44:48,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 20001pipeline [2:44:48,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20001pipeline [2:44:49,  1.15pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:28:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20001pipeline [2:44:49,  1.15pipeline/s]Optimization Progress: 100%|█████████▉| 20002/20100 [2:44:49<03:23,  2.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20002/20100 [2:44:49<03:23,  2.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20003/20100 [2:44:50<03:21,  2.08s/pipeline]Optimization Progress: 100%|█████████▉| 20005/20100 [2:46:41<19:56, 12.59s/pipeline]Optimization Progress: 100%|█████████▉| 20085/20100 [2:46:46<02:12,  8.83s/pipeline]
Generation 200 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 20101pipeline [2:46:47,  8.83s/pipeline]Optimization Progress: 20101pipeline [2:46:47,  6.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:30:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20101pipeline [2:46:47,  6.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20101pipeline [2:46:48,  6.20s/pipeline]Optimization Progress: 100%|█████████▉| 20103/20200 [2:46:50<07:47,  4.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20103/20200 [2:46:50<07:47,  4.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20104/20200 [2:46:50<07:42,  4.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20105/20200 [2:46:50<07:37,  4.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20106/20200 [2:46:50<07:33,  4.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20107/20200 [2:46:50<07:28,  4.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20108/20200 [2:46:50<07:23,  4.82s/pipeline]Optimization Progress: 100%|█████████▉| 20110/20200 [2:48:36<11:53,  7.93s/pipeline]Optimization Progress: 100%|█████████▉| 20190/20200 [2:48:40<00:55,  5.56s/pipeline]
Generation 201 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20201pipeline [2:48:41,  5.56s/pipeline]Optimization Progress: 20201pipeline [2:48:41,  3.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 20201pipeline [2:48:42,  3.93s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20201pipeline [2:48:42,  3.93s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20201/20300 [2:48:43<06:28,  3.93s/pipeline]Optimization Progress: 100%|█████████▉| 20202/20300 [2:48:43<05:42,  3.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20202/20300 [2:48:43<05:42,  3.49s/pipeline]Optimization Progress: 100%|█████████▉| 20204/20300 [2:48:53<06:21,  3.98s/pipeline]Optimization Progress: 100%|█████████▉| 20284/20300 [2:49:11<00:45,  2.85s/pipeline]
Generation 202 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 20301pipeline [2:49:12,  2.85s/pipeline]Optimization Progress: 20301pipeline [2:49:12,  2.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 20301pipeline [2:49:12,  2.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:32:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20301pipeline [2:49:12,  2.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 20301pipeline [2:49:14,  2.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20301pipeline [2:49:14,  2.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20301pipeline [2:49:14,  2.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20301pipeline [2:49:14,  2.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20301pipeline [2:49:15,  2.00s/pipeline]Optimization Progress: 100%|█████████▉| 20304/20400 [2:49:15<02:46,  1.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20304/20400 [2:49:15<02:46,  1.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20305/20400 [2:49:15<02:44,  1.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20306/20400 [2:49:15<02:43,  1.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20307/20400 [2:49:15<02:41,  1.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20308/20400 [2:49:15<02:39,  1.74s/pipeline]Optimization Progress: 100%|█████████▉| 20310/20400 [2:50:10<05:56,  3.96s/pipeline]Optimization Progress: 100%|█████████▉| 20390/20400 [2:50:13<00:27,  2.78s/pipeline]
Generation 203 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [06:33:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20401pipeline [2:50:13,  2.78s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20401pipeline [2:50:13,  2.78s/pipeline]Optimization Progress: 20401pipeline [2:50:13,  1.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:33:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20401pipeline [2:50:14,  1.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 20401pipeline [2:50:14,  1.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:33:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20401pipeline [2:50:14,  1.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 20401pipeline [2:50:14,  1.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 20401pipeline [2:50:14,  1.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 20401pipeline [2:50:15,  1.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 20401pipeline [2:50:16,  1.97s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20401/20500 [2:50:16<03:15,  1.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20402/20500 [2:50:16<03:13,  1.97s/pipeline]Optimization Progress: 100%|█████████▉| 20403/20500 [2:50:16<02:56,  1.82s/pipeline]Optimization Progress: 100%|█████████▉| 20404/20500 [2:51:57<50:26, 31.52s/pipeline]Optimization Progress: 100%|█████████▉| 20484/20500 [2:52:00<05:53, 22.08s/pipeline]
Generation 204 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 20501pipeline [2:52:01, 22.08s/pipeline]Optimization Progress: 20501pipeline [2:52:01, 15.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 20501pipeline [2:52:01, 15.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20501pipeline [2:52:02, 15.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20501pipeline [2:52:02, 15.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 20501pipeline [2:52:02, 15.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 20501pipeline [2:52:03, 15.46s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20501pipeline [2:52:04, 15.46s/pipeline]Optimization Progress: 100%|█████████▉| 20503/20600 [2:52:04<18:14, 11.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20503/20600 [2:52:04<18:14, 11.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20504/20600 [2:52:04<18:03, 11.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20505/20600 [2:52:04<17:51, 11.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20506/20600 [2:52:04<17:40, 11.28s/pipeline]Optimization Progress: 100%|█████████▉| 20507/20600 [2:52:20<17:29, 11.28s/pipeline]Optimization Progress: 100%|█████████▉| 20508/20600 [2:53:36<20:34, 13.41s/pipeline]Optimization Progress: 100%|█████████▉| 20588/20600 [2:53:38<01:52,  9.40s/pipeline]
Generation 205 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20601pipeline [2:53:38,  9.40s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:37:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20601pipeline [2:53:39,  9.40s/pipeline]Optimization Progress: 20601pipeline [2:53:39,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20601pipeline [2:53:39,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 20601pipeline [2:53:40,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20601pipeline [2:53:40,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 20601pipeline [2:53:41,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20601pipeline [2:53:41,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20601pipeline [2:53:41,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20601pipeline [2:53:41,  6.59s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20602/20700 [2:53:42<10:45,  6.59s/pipeline]Optimization Progress: 100%|█████████▉| 20603/20700 [2:53:42<08:12,  5.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20603/20700 [2:53:42<08:12,  5.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20604/20700 [2:53:42<08:07,  5.08s/pipeline]Optimization Progress: 100%|█████████▉| 20605/20700 [2:54:00<08:02,  5.08s/pipeline]Optimization Progress: 100%|█████████▉| 20606/20700 [2:55:28<22:15, 14.21s/pipeline]Optimization Progress: 100%|█████████▉| 20686/20700 [2:55:34<02:19,  9.97s/pipeline]
Generation 206 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20701pipeline [2:55:34,  9.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20701pipeline [2:55:34,  9.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 [06:39:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20701pipeline [2:55:34,  9.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=3 [06:39:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 20701pipeline [2:55:34,  9.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20701pipeline [2:55:35,  9.97s/pipeline]Optimization Progress: 20701pipeline [2:55:35,  6.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20701pipeline [2:55:35,  6.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20701pipeline [2:55:36,  6.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 20701pipeline [2:55:37,  6.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 20701pipeline [2:55:37,  6.99s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20702/20800 [2:55:38<11:24,  6.99s/pipeline]Optimization Progress: 100%|█████████▉| 20703/20800 [2:55:38<08:46,  5.43s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20703/20800 [2:55:38<08:46,  5.43s/pipeline]Optimization Progress: 100%|█████████▉| 20705/20800 [2:55:49<08:34,  5.42s/pipeline]Optimization Progress: 100%|█████████▉| 20785/20800 [2:55:51<00:57,  3.80s/pipeline]
Generation 207 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 20801pipeline [2:55:52,  3.80s/pipeline]Optimization Progress: 20801pipeline [2:55:52,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 20801pipeline [2:55:53,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 20801pipeline [2:55:54,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 20801pipeline [2:55:54,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20801pipeline [2:55:54,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20801pipeline [2:55:54,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 20801pipeline [2:55:54,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 20801pipeline [2:55:54,  2.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 20801pipeline [2:55:54,  2.67s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20801/20900 [2:55:54<04:23,  2.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20802/20900 [2:55:55<04:21,  2.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20803/20900 [2:55:55<04:18,  2.67s/pipeline]Optimization Progress: 100%|█████████▉| 20804/20900 [2:55:55<03:27,  2.16s/pipeline]Optimization Progress: 100%|█████████▉| 20806/20900 [2:56:05<04:53,  3.13s/pipeline]Optimization Progress: 100%|█████████▉| 20885/20900 [2:56:14<00:33,  2.22s/pipeline]
Generation 208 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 20901pipeline [2:56:16,  2.22s/pipeline]Optimization Progress: 20901pipeline [2:56:16,  1.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 20901pipeline [2:56:16,  1.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 20901pipeline [2:56:17,  1.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 20901pipeline [2:56:18,  1.58s/pipeline]Optimization Progress: 100%|█████████▉| 20902/21000 [2:56:19<03:12,  1.96s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20902/21000 [2:56:19<03:12,  1.96s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 20903/21000 [2:56:19<03:10,  1.96s/pipeline]Optimization Progress: 100%|█████████▉| 20905/21000 [2:58:09<19:42, 12.45s/pipeline]Optimization Progress: 100%|█████████▉| 20985/21000 [2:58:12<02:10,  8.73s/pipeline]
Generation 209 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21001pipeline [2:58:13,  8.73s/pipeline]Optimization Progress: 21001pipeline [2:58:13,  6.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:41:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21001pipeline [2:58:15,  6.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21001pipeline [2:58:15,  6.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21001pipeline [2:58:15,  6.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21001pipeline [2:58:16,  6.11s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21001/21100 [2:58:16<10:05,  6.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21002/21100 [2:58:16<09:59,  6.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21003/21100 [2:58:16<09:52,  6.11s/pipeline]Optimization Progress: 100%|█████████▉| 21004/21100 [2:58:16<07:23,  4.62s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21004/21100 [2:58:16<07:23,  4.62s/pipeline]Optimization Progress: 100%|█████████▉| 21006/21100 [2:58:24<06:52,  4.39s/pipeline]Optimization Progress: 100%|█████████▉| 21086/21100 [2:58:29<00:43,  3.09s/pipeline]
Generation 210 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 21101pipeline [2:58:29,  3.09s/pipeline]Optimization Progress: 21101pipeline [2:58:29,  2.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21101pipeline [2:58:29,  2.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:42:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21101pipeline [2:58:30,  2.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 21101pipeline [2:58:31,  2.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21101pipeline [2:58:32,  2.17s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21101/21200 [2:58:33<03:35,  2.17s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21102/21200 [2:58:33<03:33,  2.17s/pipeline]Optimization Progress: 100%|█████████▉| 21103/21200 [2:58:33<03:16,  2.03s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21103/21200 [2:58:33<03:16,  2.03s/pipeline]Optimization Progress: 100%|█████████▉| 21105/21200 [2:58:42<04:25,  2.79s/pipeline]Optimization Progress: 100%|█████████▉| 21185/21200 [2:58:45<00:29,  1.97s/pipeline]
Generation 211 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21201pipeline [2:58:45,  1.97s/pipeline]Optimization Progress: 21201pipeline [2:58:45,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 21201pipeline [2:58:45,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21201pipeline [2:58:46,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 21201pipeline [2:58:46,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 21201pipeline [2:58:46,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 21201pipeline [2:58:46,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 21201pipeline [2:58:46,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21201pipeline [2:58:46,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [06:42:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21201pipeline [2:58:46,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21201pipeline [2:58:47,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 21201pipeline [2:58:47,  1.38s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:42:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21201pipeline [2:58:48,  1.38s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21202/21300 [2:58:48<02:15,  1.38s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21203/21300 [2:58:48<02:13,  1.38s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21204/21300 [2:58:48<02:12,  1.38s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21205/21300 [2:58:48<02:10,  1.38s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21206/21300 [2:58:48<02:09,  1.38s/pipeline]Optimization Progress: 100%|█████████▉| 21207/21300 [2:58:48<01:43,  1.12s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21207/21300 [2:58:48<01:43,  1.12s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21208/21300 [2:58:48<01:42,  1.12s/pipeline]Optimization Progress: 100%|█████████▉| 21211/21300 [2:58:58<02:15,  1.52s/pipeline]Optimization Progress: 100%|█████████▉| 21290/21300 [2:59:07<00:11,  1.10s/pipeline]
Generation 212 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21301pipeline [2:59:08,  1.10s/pipeline]Optimization Progress: 21301pipeline [2:59:08,  1.26pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21301pipeline [2:59:08,  1.26pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21301pipeline [2:59:09,  1.26pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21302/21400 [2:59:11<01:17,  1.26pipeline/s]Optimization Progress: 100%|█████████▉| 21303/21400 [2:59:11<01:28,  1.10pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21303/21400 [2:59:11<01:28,  1.10pipeline/s]Optimization Progress: 100%|█████████▉| 21305/21400 [2:59:20<03:15,  2.06s/pipeline]Optimization Progress: 100%|█████████▉| 21385/21400 [2:59:29<00:22,  1.48s/pipeline]
Generation 213 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21401pipeline [2:59:30,  1.48s/pipeline]Optimization Progress: 21401pipeline [2:59:30,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21401pipeline [2:59:31,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21401pipeline [2:59:31,  1.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 21401pipeline [2:59:32,  1.04s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21402/21500 [2:59:33<01:42,  1.04s/pipeline]Optimization Progress: 100%|█████████▉| 21403/21500 [2:59:33<01:55,  1.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21403/21500 [2:59:33<01:55,  1.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21404/21500 [2:59:33<01:54,  1.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21405/21500 [2:59:33<01:53,  1.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21406/21500 [2:59:33<01:52,  1.19s/pipeline]Optimization Progress: 100%|█████████▉| 21408/21500 [2:59:44<02:18,  1.51s/pipeline]Optimization Progress: 100%|█████████▉| 21488/21500 [2:59:54<00:13,  1.09s/pipeline]
Generation 214 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21501pipeline [2:59:56,  1.09s/pipeline]Optimization Progress: 21501pipeline [2:59:56,  1.23pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21501pipeline [2:59:56,  1.23pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:43:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21501pipeline [2:59:56,  1.23pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21501pipeline [2:59:56,  1.23pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 21501pipeline [2:59:58,  1.23pipeline/s]Optimization Progress: 100%|█████████▉| 21504/21600 [2:59:58<01:17,  1.23pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21504/21600 [2:59:58<01:17,  1.23pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21505/21600 [2:59:58<01:17,  1.23pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21506/21600 [2:59:58<01:16,  1.23pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21507/21600 [2:59:58<01:15,  1.23pipeline/s]Optimization Progress: 100%|█████████▉| 21509/21600 [3:01:50<11:01,  7.27s/pipeline]Optimization Progress: 100%|█████████▉| 21589/21600 [3:03:29<01:00,  5.46s/pipeline]
Generation 215 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21601pipeline [3:03:30,  5.46s/pipeline]Optimization Progress: 21601pipeline [3:03:30,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 21601pipeline [3:03:31,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 21601pipeline [3:03:31,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:47:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21601pipeline [3:03:32,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21601pipeline [3:03:32,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 21601pipeline [3:03:32,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:47:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21601pipeline [3:03:33,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:47:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21601pipeline [3:03:33,  3.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21601pipeline [3:03:33,  3.84s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21601/21700 [3:03:33<06:19,  3.84s/pipeline]Optimization Progress: 100%|█████████▉| 21602/21700 [3:03:33<06:04,  3.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21602/21700 [3:03:33<06:04,  3.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21603/21700 [3:03:33<06:00,  3.72s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21604/21700 [3:03:33<05:56,  3.72s/pipeline]Optimization Progress: 100%|█████████▉| 21606/21700 [3:05:05<14:48,  9.46s/pipeline]Optimization Progress: 100%|█████████▉| 21686/21700 [3:05:14<01:33,  6.66s/pipeline]
Generation 216 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21701pipeline [3:05:15,  6.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21701pipeline [3:05:16,  6.66s/pipeline]Optimization Progress: 21701pipeline [3:05:16,  4.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21701pipeline [3:05:16,  4.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21701pipeline [3:05:16,  4.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:48:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21701pipeline [3:05:17,  4.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 21701pipeline [3:05:17,  4.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21701pipeline [3:05:17,  4.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21701pipeline [3:05:18,  4.69s/pipeline]Optimization Progress: 100%|█████████▉| 21702/21800 [3:05:18<06:20,  3.88s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21702/21800 [3:05:18<06:20,  3.88s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21703/21800 [3:05:18<06:16,  3.88s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21704/21800 [3:05:18<06:12,  3.88s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21705/21800 [3:05:18<06:09,  3.88s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21706/21800 [3:05:18<06:05,  3.88s/pipeline]Optimization Progress: 100%|█████████▉| 21708/21800 [3:07:00<11:59,  7.82s/pipeline]Optimization Progress: 100%|█████████▉| 21788/21800 [3:07:09<01:06,  5.51s/pipeline]
Generation 217 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21801pipeline [3:07:09,  5.51s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 21801pipeline [3:07:10,  5.51s/pipeline]Optimization Progress: 21801pipeline [3:07:10,  3.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 21801pipeline [3:07:10,  3.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21801pipeline [3:07:11,  3.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 21801pipeline [3:07:11,  3.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 21801pipeline [3:07:11,  3.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21801pipeline [3:07:12,  3.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [06:50:45] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 21801pipeline [3:07:12,  3.86s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21803/21900 [3:07:12<06:14,  3.86s/pipeline]Optimization Progress: 100%|█████████▉| 21804/21900 [3:07:12<04:46,  2.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21804/21900 [3:07:12<04:46,  2.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21805/21900 [3:07:12<04:43,  2.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21806/21900 [3:07:12<04:40,  2.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21807/21900 [3:07:12<04:37,  2.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21808/21900 [3:07:12<04:34,  2.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21809/21900 [3:07:12<04:31,  2.98s/pipeline]Optimization Progress: 100%|█████████▉| 21811/21900 [3:07:23<03:46,  2.54s/pipeline]Optimization Progress: 100%|█████████▉| 21891/21900 [3:07:32<00:16,  1.81s/pipeline]
Generation 218 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 21901pipeline [3:07:33,  1.81s/pipeline]Optimization Progress: 21901pipeline [3:07:33,  1.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 21901pipeline [3:07:33,  1.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 21901pipeline [3:07:35,  1.29s/pipeline]Optimization Progress: 100%|█████████▉| 21903/22000 [3:07:36<02:11,  1.36s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21903/22000 [3:07:36<02:11,  1.36s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 21904/22000 [3:07:36<02:10,  1.36s/pipeline]Optimization Progress: 100%|█████████▉| 21906/22000 [3:07:46<03:10,  2.03s/pipeline]Optimization Progress: 100%|█████████▉| 21986/22000 [3:07:50<00:20,  1.43s/pipeline]
Generation 219 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [06:51:24] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22001pipeline [3:07:50,  1.43s/pipeline]Optimization Progress: 22001pipeline [3:07:50,  1.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22001pipeline [3:07:51,  1.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22001pipeline [3:07:52,  1.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 22001pipeline [3:07:52,  1.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 22001pipeline [3:07:53,  1.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 22001pipeline [3:07:53,  1.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 22001pipeline [3:07:53,  1.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 22001pipeline [3:07:53,  1.01s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22001/22100 [3:07:54<01:39,  1.01s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22002/22100 [3:07:54<01:38,  1.01s/pipeline]Optimization Progress: 100%|█████████▉| 22003/22100 [3:08:10<01:37,  1.01s/pipeline]Optimization Progress: 100%|█████████▉| 22004/22100 [3:09:15<14:36,  9.13s/pipeline]Optimization Progress: 100%|█████████▉| 22084/22100 [3:09:20<01:42,  6.41s/pipeline]
Generation 220 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 22101pipeline [3:09:20,  6.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 22101pipeline [3:09:21,  6.41s/pipeline]Optimization Progress: 22101pipeline [3:09:21,  4.51s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22101pipeline [3:09:21,  4.51s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 22101pipeline [3:09:21,  4.51s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 22101pipeline [3:09:22,  4.51s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:52:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22101pipeline [3:09:22,  4.51s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22101/22200 [3:09:23<07:26,  4.51s/pipeline]Optimization Progress: 100%|█████████▉| 22102/22200 [3:09:23<05:58,  3.66s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22102/22200 [3:09:23<05:58,  3.66s/pipeline]Optimization Progress: 100%|█████████▉| 22104/22200 [3:11:32<35:01, 21.89s/pipeline]Optimization Progress: 100%|█████████▉| 22184/22200 [3:11:34<04:05, 15.34s/pipeline]
Generation 221 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 22201pipeline [3:11:35, 15.34s/pipeline]Optimization Progress: 22201pipeline [3:11:35, 10.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 22201pipeline [3:11:36, 10.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22201pipeline [3:11:37, 10.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 22201pipeline [3:11:37, 10.74s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22202/22300 [3:11:39<17:32, 10.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22203/22300 [3:11:39<17:21, 10.74s/pipeline]Optimization Progress: 100%|█████████▉| 22204/22300 [3:11:39<12:41,  7.94s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22204/22300 [3:11:39<12:41,  7.94s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22205/22300 [3:11:39<12:33,  7.94s/pipeline]Optimization Progress: 100%|█████████▉| 22206/22300 [3:11:50<12:25,  7.94s/pipeline]Optimization Progress: 100%|█████████▉| 22207/22300 [3:12:29<16:20, 10.54s/pipeline]Optimization Progress: 100%|█████████▉| 22287/22300 [3:12:38<01:36,  7.41s/pipeline]
Generation 222 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-129115013.02776265	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=4, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 22301pipeline [3:12:39,  7.41s/pipeline]Optimization Progress: 22301pipeline [3:12:39,  5.21s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 22301pipeline [3:12:40,  5.21s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 22301pipeline [3:12:40,  5.21s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 22301pipeline [3:12:40,  5.21s/pipeline]Optimization Progress: 100%|█████████▉| 22302/22400 [3:12:41<07:12,  4.41s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22302/22400 [3:12:41<07:12,  4.41s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22303/22400 [3:12:41<07:08,  4.41s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22304/22400 [3:12:41<07:03,  4.41s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22305/22400 [3:12:41<06:59,  4.41s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22306/22400 [3:12:41<06:54,  4.41s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22307/22400 [3:12:41<06:50,  4.41s/pipeline]Optimization Progress: 100%|█████████▉| 22309/22400 [3:13:05<06:13,  4.10s/pipeline]Optimization Progress: 100%|█████████▉| 22389/22400 [3:14:34<00:35,  3.20s/pipeline]
Generation 223 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 22401pipeline [3:14:34,  3.20s/pipeline]Optimization Progress: 22401pipeline [3:14:34,  2.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 22401pipeline [3:14:35,  2.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 22401pipeline [3:14:36,  2.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 22401pipeline [3:14:37,  2.25s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22402/22500 [3:14:37<03:40,  2.25s/pipeline]Optimization Progress: 100%|█████████▉| 22403/22500 [3:14:37<03:20,  2.07s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22403/22500 [3:14:37<03:20,  2.07s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22404/22500 [3:14:37<03:18,  2.07s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22405/22500 [3:14:37<03:16,  2.07s/pipeline]Optimization Progress: 100%|█████████▉| 22407/22500 [3:14:47<03:24,  2.20s/pipeline]Optimization Progress: 100%|█████████▉| 22487/22500 [3:14:54<00:20,  1.56s/pipeline]
Generation 224 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 22501pipeline [3:14:54,  1.56s/pipeline]Optimization Progress: 22501pipeline [3:14:54,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22501pipeline [3:14:54,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 22501pipeline [3:14:54,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 22501pipeline [3:14:55,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:58:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22501pipeline [3:14:55,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 22501pipeline [3:14:55,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:58:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22501pipeline [3:14:56,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [06:58:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22501pipeline [3:14:56,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 22501pipeline [3:14:57,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 22501pipeline [3:14:58,  1.10s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [06:58:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22501pipeline [3:14:58,  1.10s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22502/22600 [3:14:58<01:47,  1.10s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22503/22600 [3:14:58<01:46,  1.10s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22504/22600 [3:14:58<01:45,  1.10s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22505/22600 [3:14:58<01:44,  1.10s/pipeline]Optimization Progress: 100%|█████████▉| 22506/22600 [3:14:58<01:34,  1.00s/pipeline]Optimization Progress: 100%|█████████▉| 22506/22600 [3:15:10<01:34,  1.00s/pipeline]Optimization Progress: 100%|█████████▉| 22507/22600 [3:16:22<40:07, 25.88s/pipeline]Optimization Progress: 100%|█████████▉| 22587/22600 [3:16:27<03:55, 18.14s/pipeline]
Generation 225 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 22601pipeline [3:16:27, 18.14s/pipeline]Optimization Progress: 22601pipeline [3:16:27, 12.71s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22601pipeline [3:16:28, 12.71s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22601pipeline [3:16:28, 12.71s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:00:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22601pipeline [3:16:29, 12.71s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 22601pipeline [3:16:29, 12.71s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22602/22700 [3:16:30<20:45, 12.71s/pipeline]Optimization Progress: 100%|█████████▉| 22603/22700 [3:16:30<15:05,  9.33s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22603/22700 [3:16:30<15:05,  9.33s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22604/22700 [3:16:30<14:55,  9.33s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22605/22700 [3:16:30<14:46,  9.33s/pipeline]Optimization Progress: 100%|█████████▉| 22607/22700 [3:18:07<21:23, 13.80s/pipeline]Optimization Progress: 100%|█████████▉| 22687/22700 [3:19:43<02:10, 10.02s/pipeline]
Generation 226 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 22701pipeline [3:19:44, 10.02s/pipeline]Optimization Progress: 22701pipeline [3:19:44,  7.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22701pipeline [3:19:46,  7.04s/pipeline]Optimization Progress: 100%|█████████▉| 22703/22800 [3:19:46<08:26,  5.22s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22703/22800 [3:19:46<08:26,  5.22s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22704/22800 [3:19:46<08:21,  5.22s/pipeline]Optimization Progress: 100%|█████████▉| 22706/22800 [3:19:54<06:53,  4.40s/pipeline]Optimization Progress: 100%|█████████▉| 22786/22800 [3:20:03<00:43,  3.11s/pipeline]
Generation 227 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 22801pipeline [3:20:03,  3.11s/pipeline]Optimization Progress: 22801pipeline [3:20:03,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22801pipeline [3:20:03,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 22801pipeline [3:20:04,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 22801pipeline [3:20:04,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 22801pipeline [3:20:04,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22801pipeline [3:20:04,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 22801pipeline [3:20:05,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:03:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22801pipeline [3:20:05,  2.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 22801pipeline [3:20:06,  2.20s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22801/22900 [3:20:06<03:37,  2.20s/pipeline]Optimization Progress: 100%|█████████▉| 22802/22900 [3:20:06<03:36,  2.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22802/22900 [3:20:06<03:36,  2.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22803/22900 [3:20:06<03:34,  2.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22804/22900 [3:20:06<03:32,  2.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22805/22900 [3:20:06<03:30,  2.21s/pipeline]Optimization Progress: 100%|█████████▉| 22807/22900 [3:20:17<03:25,  2.21s/pipeline]Optimization Progress: 100%|█████████▉| 22887/22900 [3:20:26<00:20,  1.58s/pipeline]
Generation 228 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [07:04:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22901pipeline [3:20:27,  1.58s/pipeline]Optimization Progress: 22901pipeline [3:20:27,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:04:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22901pipeline [3:20:28,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:04:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22901pipeline [3:20:28,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 22901pipeline [3:20:28,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:04:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22901pipeline [3:20:28,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:04:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22901pipeline [3:20:29,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 22901pipeline [3:20:29,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:04:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 22901pipeline [3:20:30,  1.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 22901pipeline [3:20:30,  1.13s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22901/23000 [3:20:31<01:51,  1.13s/pipeline]Optimization Progress: 100%|█████████▉| 22902/23000 [3:20:31<03:01,  1.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22902/23000 [3:20:31<03:01,  1.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22903/23000 [3:20:31<02:59,  1.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 22904/23000 [3:20:31<02:58,  1.86s/pipeline]Optimization Progress: 100%|█████████▉| 22906/23000 [3:22:01<12:36,  8.05s/pipeline]Optimization Progress: 100%|█████████▉| 22986/23000 [3:22:10<01:19,  5.67s/pipeline]
Generation 229 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23001pipeline [3:22:11,  5.67s/pipeline]Optimization Progress: 23001pipeline [3:22:11,  4.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:05:45] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23001pipeline [3:22:11,  4.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 23001pipeline [3:22:12,  4.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23001pipeline [3:22:13,  4.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:05:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23001pipeline [3:22:13,  4.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 23001pipeline [3:22:13,  4.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23001pipeline [3:22:13,  4.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:05:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23001pipeline [3:22:13,  4.00s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23001/23100 [3:22:14<06:36,  4.00s/pipeline]Optimization Progress: 100%|█████████▉| 23002/23100 [3:22:14<05:44,  3.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23002/23100 [3:22:14<05:44,  3.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23003/23100 [3:22:14<05:41,  3.52s/pipeline]Optimization Progress: 100%|█████████▉| 23005/23100 [3:22:23<05:25,  3.42s/pipeline]Optimization Progress: 100%|█████████▉| 23085/23100 [3:22:33<00:36,  2.43s/pipeline]
Generation 230 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 23101pipeline [3:22:34,  2.43s/pipeline]Optimization Progress: 23101pipeline [3:22:34,  1.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 23101pipeline [3:22:34,  1.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 23101pipeline [3:22:34,  1.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23101pipeline [3:22:35,  1.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 23101pipeline [3:22:35,  1.73s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 23101pipeline [3:22:36,  1.73s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23101/23200 [3:22:36<02:51,  1.73s/pipeline]Optimization Progress: 100%|█████████▉| 23102/23200 [3:22:36<03:07,  1.92s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23102/23200 [3:22:37<03:07,  1.92s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23103/23200 [3:22:37<03:05,  1.92s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23104/23200 [3:22:37<03:03,  1.92s/pipeline]Optimization Progress: 100%|█████████▉| 23106/23200 [3:24:05<12:30,  7.98s/pipeline]Optimization Progress: 100%|█████████▉| 23186/23200 [3:25:43<01:23,  5.95s/pipeline]
Generation 231 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23201pipeline [3:25:43,  5.95s/pipeline]Optimization Progress: 23201pipeline [3:25:43,  4.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23201pipeline [3:25:45,  4.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 23201pipeline [3:25:45,  4.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23201pipeline [3:25:47,  4.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23201pipeline [3:25:47,  4.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 23201pipeline [3:25:47,  4.17s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23201/23300 [3:25:47<06:52,  4.17s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23202/23300 [3:25:47<06:48,  4.17s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23203/23300 [3:25:47<06:44,  4.17s/pipeline]Optimization Progress: 100%|█████████▉| 23204/23300 [3:25:47<05:19,  3.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23204/23300 [3:25:47<05:19,  3.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23205/23300 [3:25:47<05:15,  3.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23206/23300 [3:25:47<05:12,  3.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23207/23300 [3:25:47<05:09,  3.32s/pipeline]Optimization Progress: 100%|█████████▉| 23208/23300 [3:26:00<05:05,  3.32s/pipeline]Optimization Progress: 100%|█████████▉| 23209/23300 [3:27:30<12:50,  8.47s/pipeline]Optimization Progress: 100%|█████████▉| 23289/23300 [3:27:33<01:05,  5.94s/pipeline]
Generation 232 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 23301pipeline [3:27:34,  5.94s/pipeline]Optimization Progress: 23301pipeline [3:27:34,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23301pipeline [3:27:35,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23301pipeline [3:27:35,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23301pipeline [3:27:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:11:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23301pipeline [3:27:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 23301pipeline [3:27:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 23301pipeline [3:27:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23301pipeline [3:27:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23301pipeline [3:27:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:11:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23301pipeline [3:27:37,  4.18s/pipeline]Optimization Progress: 100%|█████████▉| 23304/23400 [3:27:37<05:06,  3.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23304/23400 [3:27:37<05:06,  3.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23305/23400 [3:27:37<05:02,  3.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23306/23400 [3:27:37<04:59,  3.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23307/23400 [3:27:37<04:56,  3.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23308/23400 [3:27:37<04:53,  3.19s/pipeline]Optimization Progress: 100%|█████████▉| 23310/23400 [3:28:53<09:00,  6.01s/pipeline]Optimization Progress: 100%|█████████▉| 23390/23400 [3:28:55<00:42,  4.21s/pipeline]
Generation 233 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 23401pipeline [3:28:55,  4.21s/pipeline]Optimization Progress: 23401pipeline [3:28:55,  2.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 23401pipeline [3:28:57,  2.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:12:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23401pipeline [3:28:58,  2.97s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 23401pipeline [3:28:58,  2.97s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23401/23500 [3:28:59<04:54,  2.97s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23402/23500 [3:28:59<04:51,  2.97s/pipeline]Optimization Progress: 100%|█████████▉| 23403/23500 [3:28:59<04:07,  2.56s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23403/23500 [3:28:59<04:07,  2.56s/pipeline]Optimization Progress: 100%|█████████▉| 23405/23500 [3:29:06<04:33,  2.88s/pipeline]Optimization Progress: 100%|█████████▉| 23485/23500 [3:29:15<00:30,  2.05s/pipeline]
Generation 234 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23501pipeline [3:29:15,  2.05s/pipeline]Optimization Progress: 23501pipeline [3:29:15,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 23501pipeline [3:29:15,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:12:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23501pipeline [3:29:15,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 23501pipeline [3:29:16,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 23501pipeline [3:29:17,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23501pipeline [3:29:18,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23501pipeline [3:29:18,  1.44s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23502/23600 [3:29:19<02:20,  1.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23503/23600 [3:29:19<02:19,  1.44s/pipeline]Optimization Progress: 100%|█████████▉| 23504/23600 [3:29:30<02:17,  1.44s/pipeline]Optimization Progress: 100%|█████████▉| 23505/23600 [3:30:56<13:37,  8.60s/pipeline]Optimization Progress: 100%|█████████▉| 23585/23600 [3:31:05<01:30,  6.06s/pipeline]
Generation 235 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 23601pipeline [3:31:06,  6.06s/pipeline]Optimization Progress: 23601pipeline [3:31:06,  4.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 23601pipeline [3:31:07,  4.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23601pipeline [3:31:09,  4.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:14:42] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23601pipeline [3:31:09,  4.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 23601pipeline [3:31:09,  4.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:14:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23601pipeline [3:31:10,  4.25s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23601/23700 [3:31:10<07:00,  4.25s/pipeline]Optimization Progress: 100%|█████████▉| 23602/23700 [3:31:10<06:41,  4.09s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23602/23700 [3:31:10<06:41,  4.09s/pipeline]Optimization Progress: 100%|█████████▉| 23604/23700 [3:36:11<1:16:56, 48.09s/pipeline]                                                                                      Skipped pipeline #23660 due to time out. Continuing to the next pipeline.
Optimization Progress: 100%|█████████▉| 23660/23700 [3:36:11<32:03, 48.09s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 23685/23700 [3:36:21<08:25, 33.70s/pipeline]
Generation 236 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 23702pipeline [3:36:21, 33.70s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 23702pipeline [3:36:22, 33.70s/pipeline]Optimization Progress: 23702pipeline [3:36:22, 23.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 23702pipeline [3:36:22, 23.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 23702pipeline [3:36:23, 23.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23702pipeline [3:36:23, 23.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:19:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 23702pipeline [3:36:25, 23.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23702pipeline [3:36:25, 23.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 23702pipeline [3:36:25, 23.60s/pipeline]Optimization Progress: 100%|█████████▉| 23703/23800 [3:36:25<28:13, 17.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23703/23800 [3:36:25<28:13, 17.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23704/23800 [3:36:25<27:56, 17.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23705/23800 [3:36:25<27:38, 17.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23706/23800 [3:36:25<27:21, 17.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23707/23800 [3:36:25<27:03, 17.46s/pipeline]Optimization Progress: 100%|█████████▉| 23709/23800 [3:38:08<26:20, 17.37s/pipeline]Optimization Progress: 100%|█████████▉| 23789/23800 [3:38:11<02:13, 12.17s/pipeline]
Generation 237 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23802pipeline [3:38:12, 12.17s/pipeline]Optimization Progress: 23802pipeline [3:38:12,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 23802pipeline [3:38:12,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23802pipeline [3:38:12,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 23802pipeline [3:38:13,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 23802pipeline [3:38:13,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23802pipeline [3:38:13,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 23802pipeline [3:38:14,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 23802pipeline [3:38:15,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 23802pipeline [3:38:15,  8.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23802pipeline [3:38:15,  8.54s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23802/23900 [3:38:15<13:56,  8.54s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23803/23900 [3:38:15<13:48,  8.54s/pipeline]Optimization Progress: 100%|█████████▉| 23804/23900 [3:38:15<10:18,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23804/23900 [3:38:15<10:18,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23805/23900 [3:38:15<10:11,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23806/23900 [3:38:15<10:05,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23807/23900 [3:38:15<09:58,  6.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23808/23900 [3:38:15<09:52,  6.44s/pipeline]Optimization Progress: 100%|█████████▉| 23810/23900 [3:39:50<13:54,  9.28s/pipeline]Optimization Progress: 100%|█████████▉| 23890/23900 [3:39:58<01:05,  6.52s/pipeline]
Generation 238 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 23902pipeline [3:39:59,  6.52s/pipeline]Optimization Progress: 23902pipeline [3:39:59,  4.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 23902pipeline [3:40:00,  4.60s/pipeline]Optimization Progress: 100%|█████████▉| 23903/24000 [3:40:01<06:11,  3.83s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23903/24000 [3:40:01<06:11,  3.83s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23904/24000 [3:40:01<06:07,  3.83s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 23905/24000 [3:40:01<06:03,  3.83s/pipeline]Optimization Progress: 100%|█████████▉| 23907/24000 [3:41:32<14:37,  9.44s/pipeline]Optimization Progress: 100%|█████████▉| 23987/24000 [3:41:37<01:26,  6.63s/pipeline]
Generation 239 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [07:25:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24002pipeline [3:41:37,  6.63s/pipeline]Optimization Progress: 24002pipeline [3:41:37,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 24002pipeline [3:41:37,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24002pipeline [3:41:39,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24002pipeline [3:41:39,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 24002pipeline [3:41:40,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24002pipeline [3:41:40,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [07:25:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24002pipeline [3:41:40,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 24002pipeline [3:41:41,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 24002pipeline [3:41:41,  4.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24002pipeline [3:41:41,  4.64s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24002/24100 [3:41:41<07:34,  4.64s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24003/24100 [3:41:41<07:30,  4.64s/pipeline]Optimization Progress: 100%|█████████▉| 24004/24100 [3:41:50<07:25,  4.64s/pipeline]Optimization Progress: 100%|█████████▉| 24005/24100 [3:41:52<07:29,  4.73s/pipeline]Optimization Progress: 100%|█████████▉| 24085/24100 [3:42:02<00:50,  3.35s/pipeline]
Generation 240 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [07:25:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24102pipeline [3:42:03,  3.35s/pipeline]Optimization Progress: 24102pipeline [3:42:03,  2.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24102pipeline [3:42:04,  2.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:25:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24102pipeline [3:42:05,  2.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 24102pipeline [3:42:05,  2.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:25:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24102pipeline [3:42:05,  2.35s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24103/24200 [3:42:06<03:48,  2.35s/pipeline]Optimization Progress: 100%|█████████▉| 24104/24200 [3:42:06<03:22,  2.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24104/24200 [3:42:06<03:22,  2.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24105/24200 [3:42:06<03:20,  2.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24106/24200 [3:42:06<03:18,  2.11s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24107/24200 [3:42:06<03:15,  2.11s/pipeline]Optimization Progress: 100%|█████████▉| 24109/24200 [3:42:16<03:07,  2.06s/pipeline]Optimization Progress: 100%|█████████▉| 24189/24200 [3:42:19<00:15,  1.45s/pipeline]
Generation 241 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 24202pipeline [3:42:19,  1.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 24202pipeline [3:42:19,  1.45s/pipeline]Optimization Progress: 24202pipeline [3:42:19,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:25:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24202pipeline [3:42:19,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24202pipeline [3:42:20,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24202pipeline [3:42:20,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 24202pipeline [3:42:20,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:25:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24202pipeline [3:42:21,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24202pipeline [3:42:21,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24202pipeline [3:42:21,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 24202pipeline [3:42:21,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24202pipeline [3:42:21,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24202pipeline [3:42:21,  1.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24202pipeline [3:42:22,  1.02s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24202/24300 [3:42:23<01:40,  1.02s/pipeline]Optimization Progress: 100%|█████████▉| 24203/24300 [3:42:30<01:39,  1.02s/pipeline]Optimization Progress: 100%|█████████▉| 24204/24300 [3:42:33<04:39,  2.91s/pipeline]Optimization Progress: 100%|█████████▉| 24284/24300 [3:45:00<00:41,  2.59s/pipeline]
Generation 242 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 24302pipeline [3:45:01,  2.59s/pipeline]Optimization Progress: 24302pipeline [3:45:01,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:28:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24302pipeline [3:45:01,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:28:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24302pipeline [3:45:02,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 24302pipeline [3:45:02,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24302pipeline [3:45:02,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 24302pipeline [3:45:04,  1.83s/pipeline]Optimization Progress: 100%|█████████▉| 24304/24400 [3:45:04<02:43,  1.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24304/24400 [3:45:04<02:43,  1.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24305/24400 [3:45:04<02:41,  1.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24306/24400 [3:45:04<02:40,  1.70s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24307/24400 [3:45:04<02:38,  1.70s/pipeline]Optimization Progress: 100%|█████████▉| 24308/24400 [3:45:04<01:50,  1.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24308/24400 [3:45:04<01:50,  1.20s/pipeline]Optimization Progress: 100%|█████████▉| 24309/24400 [3:45:20<01:49,  1.20s/pipeline]Optimization Progress: 100%|█████████▉| 24310/24400 [3:45:31<07:14,  4.82s/pipeline]Optimization Progress: 100%|█████████▉| 24390/24400 [3:45:39<00:34,  3.41s/pipeline]
Generation 243 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24402pipeline [3:45:40,  3.41s/pipeline]Optimization Progress: 24402pipeline [3:45:40,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24402pipeline [3:45:40,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 24402pipeline [3:45:40,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:29:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24402pipeline [3:45:41,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 24402pipeline [3:45:41,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24402pipeline [3:45:41,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:29:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24402pipeline [3:45:42,  2.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24402pipeline [3:45:42,  2.41s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24402/24500 [3:45:43<03:56,  2.41s/pipeline]Optimization Progress: 100%|█████████▉| 24403/24500 [3:45:43<04:08,  2.56s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24403/24500 [3:45:43<04:08,  2.56s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24404/24500 [3:45:43<04:05,  2.56s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24405/24500 [3:45:43<04:03,  2.56s/pipeline]Optimization Progress: 100%|█████████▉| 24407/24500 [3:45:47<03:20,  2.16s/pipeline]Optimization Progress: 100%|█████████▉| 24487/24500 [3:45:55<00:19,  1.54s/pipeline]
Generation 244 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24502pipeline [3:45:55,  1.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24502pipeline [3:45:55,  1.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24502pipeline [3:45:56,  1.54s/pipeline]Optimization Progress: 24502pipeline [3:45:56,  1.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 24502pipeline [3:45:57,  1.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 24502pipeline [3:45:58,  1.09s/pipeline]Optimization Progress: 100%|█████████▉| 24503/24600 [3:45:58<02:26,  1.51s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24503/24600 [3:45:58<02:26,  1.51s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24504/24600 [3:45:58<02:25,  1.51s/pipeline]Optimization Progress: 100%|█████████▉| 24506/24600 [3:46:09<03:19,  2.12s/pipeline]Optimization Progress: 100%|█████████▉| 24586/24600 [3:46:18<00:21,  1.52s/pipeline]
Generation 245 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 24602pipeline [3:46:18,  1.52s/pipeline]Optimization Progress: 24602pipeline [3:46:21,  1.12s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24602/24700 [3:46:21<01:49,  1.12s/pipeline]Optimization Progress: 100%|█████████▉| 24604/24700 [3:46:28<02:53,  1.81s/pipeline]Optimization Progress: 100%|█████████▉| 24684/24700 [3:46:34<00:20,  1.29s/pipeline]
Generation 246 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24702pipeline [3:46:34,  1.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:30:08] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24702pipeline [3:46:34,  1.29s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 24702pipeline [3:46:35,  1.29s/pipeline]Optimization Progress: 24702pipeline [3:46:35,  1.10pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24702pipeline [3:46:35,  1.10pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:30:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24702pipeline [3:46:36,  1.10pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24702pipeline [3:46:36,  1.10pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24702pipeline [3:46:36,  1.10pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24702pipeline [3:46:37,  1.10pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24702/24800 [3:46:38<01:28,  1.10pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24703/24800 [3:46:38<01:28,  1.10pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24704/24800 [3:46:38<01:27,  1.10pipeline/s]Optimization Progress: 100%|█████████▉| 24705/24800 [3:46:38<01:27,  1.08pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24705/24800 [3:46:38<01:27,  1.08pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24706/24800 [3:46:38<01:26,  1.08pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24707/24800 [3:46:38<01:25,  1.08pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24708/24800 [3:46:38<01:24,  1.08pipeline/s]Optimization Progress: 100%|█████████▉| 24709/24800 [3:46:50<01:23,  1.08pipeline/s]Optimization Progress: 100%|█████████▉| 24710/24800 [3:48:11<09:23,  6.26s/pipeline]Optimization Progress: 100%|█████████▉| 24790/24800 [3:48:14<00:43,  4.39s/pipeline]
Generation 247 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 24802pipeline [3:48:14,  4.39s/pipeline]Optimization Progress: 24802pipeline [3:48:14,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:31:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24802pipeline [3:48:14,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24802pipeline [3:48:15,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 24802pipeline [3:48:16,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24802pipeline [3:48:16,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24802pipeline [3:48:16,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 24802pipeline [3:48:16,  3.09s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24802/24900 [3:48:17<05:02,  3.09s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24803/24900 [3:48:17<04:59,  3.09s/pipeline]Optimization Progress: 100%|█████████▉| 24804/24900 [3:48:17<04:16,  2.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24804/24900 [3:48:17<04:16,  2.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24805/24900 [3:48:18<04:13,  2.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24806/24900 [3:48:18<04:11,  2.67s/pipeline]Optimization Progress: 100%|█████████▉| 24808/24900 [3:48:29<04:14,  2.77s/pipeline]Optimization Progress: 100%|█████████▉| 24888/24900 [3:48:33<00:23,  1.95s/pipeline]
Generation 248 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 24902pipeline [3:48:33,  1.95s/pipeline]Optimization Progress: 24902pipeline [3:48:33,  1.37s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:32:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 24902pipeline [3:48:34,  1.37s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24902pipeline [3:48:34,  1.37s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 24902pipeline [3:48:35,  1.37s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 24902pipeline [3:48:35,  1.37s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 24902pipeline [3:48:36,  1.37s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24904/25000 [3:48:36<02:11,  1.37s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 24905/25000 [3:48:36<02:10,  1.37s/pipeline]Optimization Progress: 100%|█████████▉| 24907/25000 [3:48:47<02:46,  1.79s/pipeline]Optimization Progress: 100%|█████████▉| 24987/25000 [3:48:49<00:16,  1.26s/pipeline]
Generation 249 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25002pipeline [3:48:49,  1.26s/pipeline]Optimization Progress: 25002pipeline [3:48:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25002pipeline [3:48:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:32:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25002pipeline [3:48:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 25002pipeline [3:48:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 25002pipeline [3:48:49,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 25002pipeline [3:48:50,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 25002pipeline [3:48:51,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25002pipeline [3:48:51,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25002pipeline [3:48:52,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [07:32:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25002pipeline [3:48:52,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 25002pipeline [3:48:52,  1.13pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25002/25100 [3:48:52<01:26,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25003/25100 [3:48:52<01:25,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25004/25100 [3:48:52<01:24,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25005/25100 [3:48:52<01:23,  1.13pipeline/s]Optimization Progress: 100%|█████████▉| 25006/25100 [3:48:52<01:19,  1.18pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25006/25100 [3:48:52<01:19,  1.18pipeline/s]Optimization Progress: 100%|█████████▉| 25009/25100 [3:49:03<02:38,  1.74s/pipeline]Optimization Progress: 100%|█████████▉| 25088/25100 [3:49:13<00:15,  1.26s/pipeline]
Generation 250 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25102pipeline [3:49:14,  1.26s/pipeline]Optimization Progress: 25102pipeline [3:49:14,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 25102pipeline [3:49:14,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 25102pipeline [3:49:14,  1.13pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25102pipeline [3:49:15,  1.13pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25103/25200 [3:49:17<01:25,  1.13pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25104/25200 [3:49:17<01:24,  1.13pipeline/s]Optimization Progress: 100%|█████████▉| 25105/25200 [3:49:17<01:29,  1.06pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25105/25200 [3:49:17<01:29,  1.06pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25106/25200 [3:49:17<01:28,  1.06pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25107/25200 [3:49:17<01:27,  1.06pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25108/25200 [3:49:17<01:26,  1.06pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25109/25200 [3:49:17<01:25,  1.06pipeline/s]Optimization Progress: 100%|█████████▉| 25111/25200 [3:49:26<01:38,  1.11s/pipeline]Optimization Progress: 100%|█████████▉| 25191/25200 [3:49:35<00:07,  1.23pipeline/s]
Generation 251 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 25202pipeline [3:49:36,  1.23pipeline/s]Optimization Progress: 25202pipeline [3:49:36,  1.72pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 25202pipeline [3:49:37,  1.72pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25202pipeline [3:49:37,  1.72pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 25202pipeline [3:49:37,  1.72pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 25202pipeline [3:49:37,  1.72pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 25202pipeline [3:49:37,  1.72pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:33:11] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25202pipeline [3:49:38,  1.72pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25202/25300 [3:49:39<00:57,  1.72pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25203/25300 [3:49:39<00:56,  1.72pipeline/s]Optimization Progress: 100%|█████████▉| 25204/25300 [3:49:39<01:17,  1.24pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25204/25300 [3:49:39<01:17,  1.24pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25205/25300 [3:49:39<01:16,  1.24pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25206/25300 [3:49:39<01:15,  1.24pipeline/s]Optimization Progress: 100%|█████████▉| 25208/25300 [3:49:49<02:06,  1.38s/pipeline]Optimization Progress: 100%|█████████▉| 25288/25300 [3:49:52<00:11,  1.03pipeline/s]
Generation 252 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 25302pipeline [3:49:52,  1.03pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25302pipeline [3:49:53,  1.03pipeline/s]Optimization Progress: 25302pipeline [3:49:53,  1.42pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25302pipeline [3:49:53,  1.42pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25302pipeline [3:49:53,  1.42pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25302pipeline [3:49:53,  1.42pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 25302pipeline [3:49:54,  1.42pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25302/25400 [3:49:55<01:09,  1.42pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25303/25400 [3:49:55<01:08,  1.42pipeline/s]Optimization Progress: 100%|█████████▉| 25304/25400 [3:49:55<01:19,  1.21pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25304/25400 [3:49:55<01:19,  1.21pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25305/25400 [3:49:55<01:18,  1.21pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25306/25400 [3:49:55<01:17,  1.21pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25307/25400 [3:49:55<01:17,  1.21pipeline/s]Optimization Progress: 100%|█████████▉| 25309/25400 [3:50:07<01:54,  1.26s/pipeline]Optimization Progress: 100%|█████████▉| 25389/25400 [3:50:09<00:09,  1.12pipeline/s]
Generation 253 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 25402pipeline [3:50:13,  1.12pipeline/s]Optimization Progress: 25402pipeline [3:50:13,  1.44pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25402/25500 [3:50:13<01:08,  1.44pipeline/s]Optimization Progress: 100%|█████████▉| 25403/25500 [3:50:13<00:53,  1.80pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25403/25500 [3:50:13<00:53,  1.80pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25404/25500 [3:50:13<00:53,  1.80pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25405/25500 [3:50:13<00:52,  1.80pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25406/25500 [3:50:13<00:52,  1.80pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25407/25500 [3:50:13<00:51,  1.80pipeline/s]Optimization Progress: 100%|█████████▉| 25409/25500 [3:50:23<01:22,  1.11pipeline/s]Optimization Progress: 100%|█████████▉| 25489/25500 [3:50:25<00:07,  1.56pipeline/s]
Generation 254 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 25502pipeline [3:50:25,  1.56pipeline/s]Optimization Progress: 25502pipeline [3:50:25,  2.18pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25502pipeline [3:50:26,  2.18pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25502pipeline [3:50:27,  2.18pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 25502pipeline [3:50:28,  2.18pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25502pipeline [3:50:28,  2.18pipeline/s]Optimization Progress: 100%|█████████▉| 25504/25600 [3:50:39<03:47,  2.37s/pipeline]Optimization Progress: 100%|█████████▉| 25584/25600 [3:50:46<00:26,  1.68s/pipeline]
Generation 255 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [07:34:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25602pipeline [3:50:47,  1.68s/pipeline]Optimization Progress: 25602pipeline [3:50:47,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 25602pipeline [3:50:48,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 25602pipeline [3:50:48,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 25602pipeline [3:50:48,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25602pipeline [3:50:48,  1.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25602pipeline [3:50:49,  1.20s/pipeline]Optimization Progress: 100%|█████████▉| 25604/25700 [3:50:49<01:45,  1.10s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25604/25700 [3:50:49<01:45,  1.10s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25605/25700 [3:50:49<01:44,  1.10s/pipeline]Optimization Progress: 100%|█████████▉| 25607/25700 [3:52:22<15:39, 10.10s/pipeline]Optimization Progress: 100%|█████████▉| 25687/25700 [3:52:26<01:32,  7.09s/pipeline]
Generation 256 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25702pipeline [3:52:28,  7.09s/pipeline]Optimization Progress: 25702pipeline [3:52:28,  4.98s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:36:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25702pipeline [3:52:28,  4.98s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25702pipeline [3:52:28,  4.98s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:36:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25702pipeline [3:52:29,  4.98s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 25702pipeline [3:52:30,  4.98s/pipeline]Optimization Progress: 100%|█████████▉| 25704/25800 [3:52:31<06:22,  3.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25704/25800 [3:52:31<06:22,  3.98s/pipeline]Optimization Progress: 100%|█████████▉| 25706/25800 [3:52:41<06:46,  4.33s/pipeline]Optimization Progress: 100%|█████████▉| 25786/25800 [3:52:44<00:42,  3.04s/pipeline]
Generation 257 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25802pipeline [3:52:44,  3.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 25802pipeline [3:52:45,  3.04s/pipeline]Optimization Progress: 25802pipeline [3:52:45,  2.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25802pipeline [3:52:45,  2.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [07:36:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25802pipeline [3:52:45,  2.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 25802pipeline [3:52:47,  2.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 25802pipeline [3:52:47,  2.14s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25802/25900 [3:52:48<03:29,  2.14s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25803/25900 [3:52:48<03:27,  2.14s/pipeline]Optimization Progress: 100%|█████████▉| 25804/25900 [3:52:48<03:10,  1.98s/pipeline]Optimization Progress: 100%|█████████▉| 25806/25900 [3:52:58<04:31,  2.89s/pipeline]Optimization Progress: 100%|█████████▉| 25885/25900 [3:53:04<00:30,  2.05s/pipeline]
Generation 258 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 25902pipeline [3:53:05,  2.05s/pipeline]Optimization Progress: 25902pipeline [3:53:05,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:36:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25902pipeline [3:53:05,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [07:36:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 25902pipeline [3:53:05,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25902pipeline [3:53:07,  1.44s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 25902pipeline [3:53:07,  1.44s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25902/26000 [3:53:09<02:21,  1.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 25903/26000 [3:53:09<02:20,  1.44s/pipeline]Optimization Progress: 100%|█████████▉| 25904/26000 [3:53:09<02:28,  1.54s/pipeline]Optimization Progress: 100%|█████████▉| 25905/26000 [3:53:19<06:28,  4.09s/pipeline]Optimization Progress: 100%|█████████▉| 25985/26000 [3:53:24<00:43,  2.88s/pipeline]
Generation 259 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26002pipeline [3:53:24,  2.88s/pipeline]Optimization Progress: 26002pipeline [3:53:24,  2.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:36:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26002pipeline [3:53:26,  2.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:37:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26002pipeline [3:53:27,  2.02s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26003/26100 [3:53:28<03:16,  2.02s/pipeline]Optimization Progress: 100%|█████████▉| 26004/26100 [3:53:28<03:08,  1.96s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26004/26100 [3:53:28<03:08,  1.96s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26005/26100 [3:53:28<03:06,  1.96s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26006/26100 [3:53:28<03:04,  1.96s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26007/26100 [3:53:28<03:02,  1.96s/pipeline]Optimization Progress: 100%|█████████▉| 26009/26100 [3:53:35<02:45,  1.82s/pipeline]Optimization Progress: 100%|█████████▉| 26089/26100 [3:53:45<00:14,  1.31s/pipeline]
Generation 260 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 26102pipeline [3:53:45,  1.31s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 26102pipeline [3:53:45,  1.31s/pipeline]Optimization Progress: 26102pipeline [3:53:45,  1.07pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26102pipeline [3:53:46,  1.07pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:37:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26102pipeline [3:53:46,  1.07pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:37:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26102pipeline [3:53:46,  1.07pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [07:37:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26102pipeline [3:53:46,  1.07pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:37:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26102pipeline [3:53:48,  1.07pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26102pipeline [3:53:49,  1.07pipeline/s]Optimization Progress: 100%|█████████▉| 26104/26200 [3:53:49<01:56,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26104/26200 [3:53:49<01:56,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26105/26200 [3:53:49<01:55,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26106/26200 [3:53:49<01:53,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26107/26200 [3:53:49<01:52,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26108/26200 [3:53:49<01:51,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26109/26200 [3:53:49<01:50,  1.21s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26110/26200 [3:53:49<01:48,  1.21s/pipeline]Optimization Progress: 100%|█████████▉| 26112/26200 [3:55:46<07:39,  5.22s/pipeline]Optimization Progress: 100%|█████████▉| 26192/26200 [3:55:51<00:29,  3.68s/pipeline]
Generation 261 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 26202pipeline [3:55:51,  3.68s/pipeline]Optimization Progress: 26202pipeline [3:55:51,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26202pipeline [3:55:53,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26202pipeline [3:55:53,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 26202pipeline [3:55:53,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26202pipeline [3:55:54,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 26202pipeline [3:55:54,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 26202pipeline [3:55:54,  2.60s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26202/26300 [3:55:55<04:14,  2.60s/pipeline]Optimization Progress: 100%|█████████▉| 26203/26300 [3:55:55<04:24,  2.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26203/26300 [3:55:55<04:24,  2.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26204/26300 [3:55:55<04:22,  2.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26205/26300 [3:55:55<04:19,  2.73s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26206/26300 [3:55:55<04:16,  2.73s/pipeline]Optimization Progress: 100%|█████████▉| 26208/26300 [3:57:57<14:10,  9.24s/pipeline]Optimization Progress: 100%|█████████▉| 26288/26300 [3:58:06<01:18,  6.50s/pipeline]
Generation 262 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26302pipeline [3:58:08,  6.50s/pipeline]Optimization Progress: 26302pipeline [3:58:08,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 26302pipeline [3:58:08,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 26302pipeline [3:58:09,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:41:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26302pipeline [3:58:11,  4.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26302pipeline [3:58:11,  4.58s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26302/26400 [3:58:11<07:29,  4.58s/pipeline]Optimization Progress: 100%|█████████▉| 26303/26400 [3:58:11<06:58,  4.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26303/26400 [3:58:11<06:58,  4.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26304/26400 [3:58:11<06:53,  4.31s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26305/26400 [3:58:11<06:49,  4.31s/pipeline]Optimization Progress: 100%|█████████▉| 26307/26400 [4:00:01<17:22, 11.21s/pipeline]Optimization Progress: 100%|█████████▉| 26387/26400 [4:00:10<01:42,  7.89s/pipeline]
Generation 263 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 26402pipeline [4:00:10,  7.89s/pipeline]Optimization Progress: 26402pipeline [4:00:10,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 26402pipeline [4:00:11,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 26402pipeline [4:00:12,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 26402pipeline [4:00:12,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 26402pipeline [4:00:13,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 26402pipeline [4:00:13,  5.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 26402pipeline [4:00:13,  5.53s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26403/26500 [4:00:13<08:56,  5.53s/pipeline]Optimization Progress: 100%|█████████▉| 26404/26500 [4:00:13<06:51,  4.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26404/26500 [4:00:13<06:51,  4.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26405/26500 [4:00:13<06:46,  4.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26406/26500 [4:00:13<06:42,  4.28s/pipeline]Optimization Progress: 100%|█████████▉| 26408/26500 [4:00:29<06:22,  4.16s/pipeline]Optimization Progress: 100%|█████████▉| 26488/26500 [4:00:38<00:35,  2.95s/pipeline]
Generation 264 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 26502pipeline [4:00:38,  2.95s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:44:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26502pipeline [4:00:39,  2.95s/pipeline]Optimization Progress: 26502pipeline [4:00:39,  2.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 26502pipeline [4:00:39,  2.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26502pipeline [4:00:39,  2.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26502pipeline [4:00:40,  2.09s/pipeline]Optimization Progress: 100%|█████████▉| 26503/26600 [4:00:51<08:16,  5.12s/pipeline]Optimization Progress: 100%|█████████▉| 26583/26600 [4:01:00<01:01,  3.62s/pipeline]
Generation 265 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26602pipeline [4:01:01,  3.62s/pipeline]Optimization Progress: 26602pipeline [4:01:01,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 26602pipeline [4:01:01,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 26602pipeline [4:01:02,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:44:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26602pipeline [4:01:02,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 26602pipeline [4:01:03,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 26602pipeline [4:01:03,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:44:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26602pipeline [4:01:04,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 26602pipeline [4:01:04,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 26602pipeline [4:01:04,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26602pipeline [4:01:04,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:44:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26602pipeline [4:01:04,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 26602pipeline [4:01:05,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 26602pipeline [4:01:05,  2.54s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26602pipeline [4:01:05,  2.54s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26603/26700 [4:01:05<04:06,  2.54s/pipeline]Optimization Progress: 100%|█████████▉| 26604/26700 [4:01:05<03:51,  2.42s/pipeline]Optimization Progress: 100%|█████████▉| 26605/26700 [4:01:17<08:05,  5.12s/pipeline]Optimization Progress: 100%|█████████▉| 26685/26700 [4:01:27<00:54,  3.62s/pipeline]
Generation 266 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 26702pipeline [4:01:29,  3.62s/pipeline]Optimization Progress: 26702pipeline [4:01:29,  2.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26702pipeline [4:01:29,  2.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:45:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26702pipeline [4:01:29,  2.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26702pipeline [4:01:30,  2.57s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26702/26800 [4:01:30<04:11,  2.57s/pipeline]Optimization Progress: 100%|█████████▉| 26703/26800 [4:01:30<03:22,  2.09s/pipeline]Optimization Progress: 100%|█████████▉| 26704/26800 [4:03:11<51:05, 31.93s/pipeline]Optimization Progress: 100%|█████████▉| 26784/26800 [4:03:15<05:57, 22.37s/pipeline]
Generation 267 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 26802pipeline [4:03:15, 22.37s/pipeline]Optimization Progress: 26802pipeline [4:03:15, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26802pipeline [4:03:15, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:46:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26802pipeline [4:03:15, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 26802pipeline [4:03:17, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:46:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26802pipeline [4:03:17, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26802pipeline [4:03:18, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 26802pipeline [4:03:18, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:46:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26802pipeline [4:03:19, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 26802pipeline [4:03:19, 15.66s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:46:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 26802pipeline [4:03:19, 15.66s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26802/26900 [4:03:19<25:34, 15.66s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26803/26900 [4:03:19<25:18, 15.66s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26804/26900 [4:03:19<25:03, 15.66s/pipeline]Optimization Progress: 100%|█████████▉| 26805/26900 [4:03:30<24:47, 15.66s/pipeline]Optimization Progress: 100%|█████████▉| 26806/26900 [4:04:54<28:51, 18.42s/pipeline]Optimization Progress: 100%|█████████▉| 26886/26900 [4:04:58<03:00, 12.91s/pipeline]
Generation 268 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 26902pipeline [4:04:58, 12.91s/pipeline]Optimization Progress: 26902pipeline [4:04:58,  9.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 26902pipeline [4:04:58,  9.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 26902pipeline [4:04:58,  9.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 26902pipeline [4:04:59,  9.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26902pipeline [4:05:00,  9.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 26902pipeline [4:05:01,  9.04s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26903/27000 [4:05:01<14:36,  9.04s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26904/27000 [4:05:01<14:27,  9.04s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26905/27000 [4:05:01<14:18,  9.04s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26906/27000 [4:05:01<14:09,  9.04s/pipeline]Optimization Progress: 100%|█████████▉| 26907/27000 [4:05:01<10:05,  6.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26907/27000 [4:05:01<10:05,  6.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 26908/27000 [4:05:01<09:59,  6.52s/pipeline]Optimization Progress: 100%|█████████▉| 26909/27000 [4:05:20<09:52,  6.52s/pipeline]Optimization Progress: 100%|█████████▉| 26910/27000 [4:06:11<17:18, 11.54s/pipeline]Optimization Progress: 100%|█████████▉| 26990/27000 [4:06:14<01:20,  8.09s/pipeline]
Generation 269 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 27002pipeline [4:06:14,  8.09s/pipeline]Optimization Progress: 27002pipeline [4:06:14,  5.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27002pipeline [4:06:15,  5.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27002pipeline [4:06:15,  5.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:49:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27002pipeline [4:06:16,  5.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [07:49:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27002pipeline [4:06:16,  5.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 27002pipeline [4:06:17,  5.67s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27003/27100 [4:06:18<09:10,  5.67s/pipeline]Optimization Progress: 100%|█████████▉| 27004/27100 [4:06:18<07:09,  4.47s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27004/27100 [4:06:18<07:09,  4.47s/pipeline]Optimization Progress: 100%|█████████▉| 27006/27100 [4:06:28<07:14,  4.62s/pipeline]Optimization Progress: 100%|█████████▉| 27086/27100 [4:06:35<00:45,  3.26s/pipeline]
Generation 270 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 27102pipeline [4:06:36,  3.26s/pipeline]Optimization Progress: 27102pipeline [4:06:36,  2.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:50:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27102pipeline [4:06:36,  2.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 27102pipeline [4:06:37,  2.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 27102pipeline [4:06:37,  2.30s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:50:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27102pipeline [4:06:37,  2.30s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27103/27200 [4:06:39<03:43,  2.30s/pipeline]Optimization Progress: 100%|█████████▉| 27104/27200 [4:06:39<03:13,  2.02s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27104/27200 [4:06:39<03:13,  2.02s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27105/27200 [4:06:39<03:11,  2.02s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27106/27200 [4:06:39<03:09,  2.02s/pipeline]Optimization Progress: 100%|█████████▉| 27108/27200 [4:09:12<19:46, 12.89s/pipeline]Optimization Progress: 100%|█████████▉| 27188/27200 [4:10:41<01:52,  9.36s/pipeline]
Generation 271 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 27202pipeline [4:10:41,  9.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:54:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27202pipeline [4:10:42,  9.36s/pipeline]Optimization Progress: 27202pipeline [4:10:42,  6.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27202pipeline [4:10:42,  6.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27202pipeline [4:10:43,  6.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27202pipeline [4:10:43,  6.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 27202pipeline [4:10:43,  6.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 27202pipeline [4:10:44,  6.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27202pipeline [4:10:45,  6.56s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27203/27300 [4:10:46<10:36,  6.56s/pipeline]Optimization Progress: 100%|█████████▉| 27204/27300 [4:10:46<08:22,  5.23s/pipeline]Optimization Progress: 100%|█████████▉| 27205/27300 [4:12:39<59:31, 37.60s/pipeline]Optimization Progress: 100%|█████████▉| 27285/27300 [4:12:46<06:35, 26.34s/pipeline]
Generation 272 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 27302pipeline [4:12:47, 26.34s/pipeline]Optimization Progress: 27302pipeline [4:12:47, 18.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 27302pipeline [4:12:47, 18.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27302pipeline [4:12:47, 18.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27302pipeline [4:12:47, 18.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [07:56:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27302pipeline [4:12:47, 18.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 27302pipeline [4:12:48, 18.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 27302pipeline [4:12:50, 18.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 27302pipeline [4:12:50, 18.45s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27302/27400 [4:12:50<30:08, 18.45s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27303/27400 [4:12:50<29:49, 18.45s/pipeline]Optimization Progress: 100%|█████████▉| 27304/27400 [4:12:50<21:34, 13.48s/pipeline]Optimization Progress: 100%|█████████▉| 27305/27400 [4:14:11<53:13, 33.61s/pipeline]Optimization Progress: 100%|█████████▉| 27385/27400 [4:14:16<05:53, 23.55s/pipeline]
Generation 273 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [07:57:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27402pipeline [4:14:16, 23.55s/pipeline]Optimization Progress: 27402pipeline [4:14:16, 16.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27402pipeline [4:14:16, 16.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 27402pipeline [4:14:17, 16.49s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27402pipeline [4:14:18, 16.49s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27402/27500 [4:14:19<26:55, 16.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27403/27500 [4:14:19<26:39, 16.49s/pipeline]Optimization Progress: 100%|█████████▉| 27406/27500 [4:14:30<19:42, 12.58s/pipeline]Optimization Progress: 100%|█████████▉| 27485/27500 [4:14:32<02:12,  8.81s/pipeline]
Generation 274 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27502pipeline [4:14:32,  8.81s/pipeline]Optimization Progress: 27502pipeline [4:14:32,  6.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27502pipeline [4:14:35,  6.17s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 27502pipeline [4:14:35,  6.17s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27504/27600 [4:14:36<09:52,  6.17s/pipeline]Optimization Progress: 100%|█████████▉| 27505/27600 [4:14:36<07:23,  4.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27505/27600 [4:14:36<07:23,  4.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27506/27600 [4:14:36<07:19,  4.67s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27507/27600 [4:14:36<07:14,  4.67s/pipeline]Optimization Progress: 100%|█████████▉| 27509/27600 [4:14:43<05:45,  3.80s/pipeline]Optimization Progress: 100%|█████████▉| 27588/27600 [4:15:00<00:45,  3.80s/pipeline]Optimization Progress: 100%|█████████▉| 27589/27600 [4:16:20<00:33,  3.02s/pipeline]
Generation 275 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 27602pipeline [4:16:21,  3.02s/pipeline]Optimization Progress: 27602pipeline [4:16:21,  2.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27602pipeline [4:16:22,  2.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27602pipeline [4:16:22,  2.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [07:59:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27602pipeline [4:16:22,  2.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27602pipeline [4:16:22,  2.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27602pipeline [4:16:23,  2.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27602pipeline [4:16:23,  2.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27602pipeline [4:16:23,  2.15s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27602/27700 [4:16:24<03:30,  2.15s/pipeline]Optimization Progress: 100%|█████████▉| 27603/27700 [4:16:24<03:33,  2.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27603/27700 [4:16:24<03:33,  2.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27604/27700 [4:16:24<03:31,  2.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27605/27700 [4:16:24<03:28,  2.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27606/27700 [4:16:24<03:26,  2.20s/pipeline]Optimization Progress: 100%|█████████▉| 27608/27700 [4:17:55<10:44,  7.01s/pipeline]Optimization Progress: 100%|█████████▉| 27688/27700 [4:17:58<00:59,  4.92s/pipeline]
Generation 276 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [08:01:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27702pipeline [4:17:59,  4.92s/pipeline]Optimization Progress: 27702pipeline [4:17:59,  3.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 27702pipeline [4:17:59,  3.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 27702pipeline [4:17:59,  3.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27702pipeline [4:18:00,  3.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27702pipeline [4:18:00,  3.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27702pipeline [4:18:01,  3.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27702pipeline [4:18:02,  3.45s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27703/27800 [4:18:02<05:34,  3.45s/pipeline]Optimization Progress: 100%|█████████▉| 27704/27800 [4:18:10<05:30,  3.45s/pipeline]Optimization Progress: 100%|█████████▉| 27705/27800 [4:19:18<16:26, 10.39s/pipeline]Optimization Progress: 100%|█████████▉| 27785/27800 [4:19:27<01:49,  7.30s/pipeline]
Generation 277 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27802pipeline [4:19:28,  7.30s/pipeline]Optimization Progress: 27802pipeline [4:19:28,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 27802pipeline [4:19:29,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27802pipeline [4:19:29,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 27802pipeline [4:19:29,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:03:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27802pipeline [4:19:29,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27802pipeline [4:19:29,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27802pipeline [4:19:30,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 27802pipeline [4:19:30,  5.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 27802pipeline [4:19:30,  5.13s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27802/27900 [4:19:30<08:23,  5.13s/pipeline]Optimization Progress: 100%|█████████▉| 27803/27900 [4:19:30<06:46,  4.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27803/27900 [4:19:30<06:46,  4.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27804/27900 [4:19:30<06:42,  4.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27805/27900 [4:19:31<06:37,  4.19s/pipeline]Optimization Progress: 100%|█████████▉| 27807/27900 [4:19:40<05:39,  3.65s/pipeline]Optimization Progress: 100%|█████████▉| 27887/27900 [4:19:43<00:33,  2.57s/pipeline]
Generation 278 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27902pipeline [4:19:43,  2.57s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:03:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 27902pipeline [4:19:44,  2.57s/pipeline]Optimization Progress: 27902pipeline [4:19:44,  1.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 27902pipeline [4:19:44,  1.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 27902pipeline [4:19:45,  1.81s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27902/28000 [4:19:47<02:57,  1.81s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27903/28000 [4:19:47<02:55,  1.81s/pipeline]Optimization Progress: 100%|█████████▉| 27904/28000 [4:19:47<02:47,  1.75s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27904/28000 [4:19:47<02:47,  1.75s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 27905/28000 [4:19:47<02:46,  1.75s/pipeline]Optimization Progress: 100%|█████████▉| 27907/28000 [4:19:52<02:41,  1.73s/pipeline]Optimization Progress: 100%|█████████▉| 27987/28000 [4:19:56<00:15,  1.23s/pipeline]
Generation 279 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28002pipeline [4:19:58,  1.23s/pipeline]Optimization Progress: 28002pipeline [4:19:58,  1.12pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28002pipeline [4:19:58,  1.12pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28002pipeline [4:19:58,  1.12pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:03:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28002pipeline [4:20:00,  1.12pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 28002pipeline [4:20:01,  1.12pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [08:03:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28002pipeline [4:20:01,  1.12pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 28002pipeline [4:20:01,  1.12pipeline/s]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28002/28100 [4:20:01<01:27,  1.12pipeline/s]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28003/28100 [4:20:01<01:26,  1.12pipeline/s]Optimization Progress: 100%|█████████▉| 28004/28100 [4:20:01<01:43,  1.08s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28004/28100 [4:20:01<01:43,  1.08s/pipeline]Optimization Progress: 100%|█████████▉| 28006/28100 [4:21:36<23:23, 14.94s/pipeline]Optimization Progress: 100%|█████████▉| 28086/28100 [4:24:31<02:35, 11.11s/pipeline]
Generation 280 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28102pipeline [4:24:31, 11.11s/pipeline]Optimization Progress: 28102pipeline [4:24:31,  7.78s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28102/28200 [4:24:34<12:42,  7.78s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28103/28200 [4:24:34<12:34,  7.78s/pipeline]Optimization Progress: 100%|█████████▉| 28104/28200 [4:24:50<12:27,  7.78s/pipeline]Optimization Progress: 100%|█████████▉| 28105/28200 [4:26:13<24:50, 15.69s/pipeline]Optimization Progress: 100%|█████████▉| 28185/28200 [4:26:23<02:45, 11.02s/pipeline]
Generation 281 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [08:09:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28202pipeline [4:26:23, 11.02s/pipeline]Optimization Progress: 28202pipeline [4:26:23,  7.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28202pipeline [4:26:23,  7.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28202pipeline [4:26:24,  7.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28202pipeline [4:26:25,  7.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 28202pipeline [4:26:26,  7.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28202pipeline [4:26:26,  7.72s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28202/28300 [4:26:26<12:36,  7.72s/pipeline]Optimization Progress: 100%|█████████▉| 28203/28300 [4:26:40<12:28,  7.72s/pipeline]Optimization Progress: 100%|█████████▉| 28204/28300 [4:26:44<13:41,  8.55s/pipeline]Optimization Progress: 100%|█████████▉| 28284/28300 [4:26:53<01:36,  6.02s/pipeline]
Generation 282 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28302pipeline [4:26:53,  6.02s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28302pipeline [4:26:54,  6.02s/pipeline]Optimization Progress: 28302pipeline [4:26:54,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28302pipeline [4:26:54,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28302pipeline [4:26:54,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28302pipeline [4:26:54,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28302pipeline [4:26:55,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 28302pipeline [4:26:55,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:10:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28302pipeline [4:26:56,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 28302pipeline [4:26:56,  4.22s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28302/28400 [4:26:57<06:53,  4.22s/pipeline]Optimization Progress: 100%|█████████▉| 28303/28400 [4:27:10<06:49,  4.22s/pipeline]Optimization Progress: 100%|█████████▉| 28304/28400 [4:28:39<30:03, 18.79s/pipeline]Optimization Progress: 100%|█████████▉| 28384/28400 [4:28:49<03:31, 13.19s/pipeline]
Generation 283 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28402pipeline [4:28:50, 13.19s/pipeline]Optimization Progress: 28402pipeline [4:28:50,  9.24s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28402pipeline [4:28:52,  9.24s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 28402pipeline [4:28:52,  9.24s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:12:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28402pipeline [4:28:53,  9.24s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28402/28500 [4:28:53<15:05,  9.24s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28403/28500 [4:28:53<14:56,  9.24s/pipeline]Optimization Progress: 100%|█████████▉| 28404/28500 [4:28:53<10:58,  6.86s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28404/28500 [4:28:53<10:58,  6.86s/pipeline]Optimization Progress: 100%|█████████▉| 28406/28500 [4:29:04<10:07,  6.46s/pipeline]Optimization Progress: 100%|█████████▉| 28486/28500 [4:29:12<01:03,  4.56s/pipeline]
Generation 284 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28502pipeline [4:29:12,  4.56s/pipeline]Optimization Progress: 28502pipeline [4:29:12,  3.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 28502pipeline [4:29:13,  3.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:12:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28502pipeline [4:29:14,  3.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 28502pipeline [4:29:14,  3.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 28502pipeline [4:29:14,  3.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28502pipeline [4:29:14,  3.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28502pipeline [4:29:15,  3.20s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28502/28600 [4:29:15<05:13,  3.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28503/28600 [4:29:15<05:10,  3.20s/pipeline]Optimization Progress: 100%|█████████▉| 28504/28600 [4:29:15<04:17,  2.68s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28504/28600 [4:29:15<04:17,  2.68s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28505/28600 [4:29:15<04:14,  2.68s/pipeline]Optimization Progress: 100%|█████████▉| 28507/28600 [4:29:25<04:24,  2.85s/pipeline]Optimization Progress: 100%|█████████▉| 28587/28600 [4:29:35<00:26,  2.03s/pipeline]
Generation 285 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28602pipeline [4:29:35,  2.03s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28602pipeline [4:29:36,  2.03s/pipeline]Optimization Progress: 28602pipeline [4:29:36,  1.43s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 28602pipeline [4:29:36,  1.43s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:13:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28602pipeline [4:29:36,  1.43s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28602pipeline [4:29:36,  1.43s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 28602pipeline [4:29:37,  1.43s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 28602pipeline [4:29:38,  1.43s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 28602pipeline [4:29:39,  1.43s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28602/28700 [4:29:39<02:20,  1.43s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28603/28700 [4:29:39<02:19,  1.43s/pipeline]Optimization Progress: 100%|█████████▉| 28604/28700 [4:29:39<02:26,  1.53s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28604/28700 [4:29:39<02:26,  1.53s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28605/28700 [4:29:39<02:25,  1.53s/pipeline]Optimization Progress: 100%|█████████▉| 28607/28700 [4:31:06<15:09,  9.78s/pipeline]Optimization Progress: 100%|█████████▉| 28687/28700 [4:31:12<01:29,  6.87s/pipeline]
Generation 286 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28702pipeline [4:31:13,  6.87s/pipeline]Optimization Progress: 28702pipeline [4:31:13,  4.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:14:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28702pipeline [4:31:15,  4.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 28702pipeline [4:31:15,  4.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 28702pipeline [4:31:15,  4.81s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28705/28800 [4:31:16<07:37,  4.81s/pipeline]Optimization Progress: 100%|█████████▉| 28706/28800 [4:31:16<05:38,  3.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28706/28800 [4:31:16<05:38,  3.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28707/28800 [4:31:16<05:34,  3.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28708/28800 [4:31:16<05:31,  3.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28709/28800 [4:31:16<05:27,  3.60s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28710/28800 [4:31:16<05:24,  3.60s/pipeline]Optimization Progress: 100%|█████████▉| 28712/28800 [4:31:27<04:32,  3.10s/pipeline]Optimization Progress: 100%|█████████▉| 28792/28800 [4:31:35<00:17,  2.20s/pipeline]
Generation 287 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 28802pipeline [4:31:35,  2.20s/pipeline]Optimization Progress: 28802pipeline [4:31:35,  1.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:15:09] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 28802pipeline [4:31:36,  1.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28802pipeline [4:31:37,  1.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28802pipeline [4:31:37,  1.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28802pipeline [4:31:38,  1.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28802pipeline [4:31:38,  1.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28802pipeline [4:31:38,  1.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 28802pipeline [4:31:38,  1.55s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28803/28900 [4:31:38<02:30,  1.55s/pipeline]Optimization Progress: 100%|█████████▉| 28804/28900 [4:31:38<02:20,  1.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28804/28900 [4:31:38<02:20,  1.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28805/28900 [4:31:38<02:18,  1.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28806/28900 [4:31:38<02:17,  1.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28807/28900 [4:31:38<02:15,  1.46s/pipeline]Optimization Progress: 100%|█████████▉| 28809/28900 [4:31:49<02:33,  1.68s/pipeline]Optimization Progress: 100%|█████████▉| 28889/28900 [4:31:52<00:13,  1.19s/pipeline]
Generation 288 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28902pipeline [4:31:53,  1.19s/pipeline]Optimization Progress: 28902pipeline [4:31:53,  1.16pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28902pipeline [4:31:53,  1.16pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 28902pipeline [4:31:54,  1.16pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 28902pipeline [4:31:55,  1.16pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 28902pipeline [4:31:55,  1.16pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28902pipeline [4:31:55,  1.16pipeline/s]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 28902pipeline [4:31:55,  1.16pipeline/s]Optimization Progress: 100%|█████████▉| 28903/29000 [4:31:56<02:27,  1.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 28903/29000 [4:31:56<02:27,  1.52s/pipeline]Optimization Progress: 100%|█████████▉| 28905/29000 [4:33:23<22:17, 14.08s/pipeline]Optimization Progress: 100%|█████████▉| 28985/29000 [4:34:56<02:33, 10.21s/pipeline]
Generation 289 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29002pipeline [4:34:56, 10.21s/pipeline]Optimization Progress: 29002pipeline [4:34:56,  7.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:18:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29002pipeline [4:34:58,  7.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29002pipeline [4:34:58,  7.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:18:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29002pipeline [4:34:58,  7.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29002pipeline [4:34:59,  7.15s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29002/29100 [4:35:00<11:40,  7.15s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29003/29100 [4:35:00<11:33,  7.15s/pipeline]Optimization Progress: 100%|█████████▉| 29004/29100 [4:35:10<11:26,  7.15s/pipeline]Optimization Progress: 100%|█████████▉| 29005/29100 [4:37:20<30:42, 19.39s/pipeline]Optimization Progress: 100%|█████████▉| 29085/29100 [4:37:23<03:23, 13.59s/pipeline]
Generation 290 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [08:20:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29102pipeline [4:37:23, 13.59s/pipeline]Optimization Progress: 29102pipeline [4:37:23,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:20:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29102pipeline [4:37:24,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29102pipeline [4:37:25,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 29102pipeline [4:37:25,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29102pipeline [4:37:25,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29102pipeline [4:37:26,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 29102pipeline [4:37:26,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 29102pipeline [4:37:26,  9.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 29102pipeline [4:37:26,  9.52s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29102/29200 [4:37:26<15:32,  9.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29103/29200 [4:37:26<15:22,  9.52s/pipeline]Optimization Progress: 100%|█████████▉| 29105/29200 [4:37:35<12:23,  7.83s/pipeline]Optimization Progress: 100%|█████████▉| 29185/29200 [4:37:40<01:22,  5.50s/pipeline]
Generation 291 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [08:21:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29202pipeline [4:37:40,  5.50s/pipeline]Optimization Progress: 29202pipeline [4:37:40,  3.85s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:21:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29202pipeline [4:37:40,  3.85s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:21:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29202pipeline [4:37:43,  3.85s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 29202pipeline [4:37:43,  3.85s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29202pipeline [4:37:43,  3.85s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29202/29300 [4:37:44<06:17,  3.85s/pipeline]Optimization Progress: 100%|█████████▉| 29203/29300 [4:37:50<06:13,  3.85s/pipeline]Optimization Progress: 100%|█████████▉| 29204/29300 [4:37:56<08:06,  5.07s/pipeline]Optimization Progress: 100%|█████████▉| 29284/29300 [4:38:02<00:57,  3.57s/pipeline]
Generation 292 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 29302pipeline [4:38:02,  3.57s/pipeline]Optimization Progress: 29302pipeline [4:38:02,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29302pipeline [4:38:02,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:21:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29302pipeline [4:38:02,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 29302pipeline [4:38:03,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 29302pipeline [4:38:04,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29302pipeline [4:38:04,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 29302pipeline [4:38:05,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 29302pipeline [4:38:05,  2.50s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29302/29400 [4:38:05<04:05,  2.50s/pipeline]Optimization Progress: 100%|█████████▉| 29306/29400 [4:38:15<04:15,  2.72s/pipeline]Optimization Progress: 100%|█████████▉| 29384/29400 [4:38:21<00:30,  1.93s/pipeline]
Generation 293 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29402pipeline [4:38:22,  1.93s/pipeline]Optimization Progress: 29402pipeline [4:38:22,  1.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29402pipeline [4:38:22,  1.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:21:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29402pipeline [4:38:22,  1.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29402pipeline [4:38:23,  1.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29402pipeline [4:38:24,  1.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 29402pipeline [4:38:25,  1.36s/pipeline]Optimization Progress: 100%|█████████▉| 29404/29500 [4:38:25<02:16,  1.43s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29404/29500 [4:38:25<02:16,  1.43s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29405/29500 [4:38:25<02:15,  1.43s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29406/29500 [4:38:25<02:14,  1.43s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29407/29500 [4:38:25<02:12,  1.43s/pipeline]Optimization Progress: 100%|█████████▉| 29409/29500 [4:38:34<02:19,  1.53s/pipeline]Optimization Progress: 100%|█████████▉| 29489/29500 [4:40:05<00:15,  1.42s/pipeline]
Generation 294 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 29502pipeline [4:40:06,  1.42s/pipeline]Optimization Progress: 29502pipeline [4:40:06,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29502pipeline [4:40:06,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29502pipeline [4:40:06,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:23:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29502pipeline [4:40:07,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 29502pipeline [4:40:07,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 29502pipeline [4:40:09,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:23:42] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29502pipeline [4:40:09,  1.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29502pipeline [4:40:09,  1.00s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29502/29600 [4:40:09<01:38,  1.00s/pipeline]Optimization Progress: 100%|█████████▉| 29503/29600 [4:40:09<02:56,  1.82s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29503/29600 [4:40:09<02:56,  1.82s/pipeline]Optimization Progress: 100%|█████████▉| 29505/29600 [4:41:53<26:39, 16.84s/pipeline]Optimization Progress: 100%|█████████▉| 29585/29600 [4:43:24<03:01, 12.13s/pipeline]
Generation 295 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29602pipeline [4:43:25, 12.13s/pipeline]Optimization Progress: 29602pipeline [4:43:25,  8.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:27:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29602pipeline [4:43:26,  8.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:27:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29602pipeline [4:43:27,  8.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 29602pipeline [4:43:27,  8.52s/pipeline]Optimization Progress: 100%|█████████▉| 29604/29700 [4:43:28<10:02,  6.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29604/29700 [4:43:28<10:02,  6.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29605/29700 [4:43:28<09:56,  6.28s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29606/29700 [4:43:28<09:50,  6.28s/pipeline]Optimization Progress: 100%|█████████▉| 29608/29700 [4:43:46<08:54,  5.81s/pipeline]Optimization Progress: 100%|█████████▉| 29688/29700 [4:45:17<00:52,  4.41s/pipeline]
Generation 296 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 29702pipeline [4:45:17,  4.41s/pipeline]Optimization Progress: 29702pipeline [4:45:17,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29702pipeline [4:45:19,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29702pipeline [4:45:19,  3.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 29702pipeline [4:45:20,  3.09s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29703/29800 [4:45:20<04:59,  3.09s/pipeline]Optimization Progress: 100%|█████████▉| 29704/29800 [4:45:20<04:14,  2.65s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29704/29800 [4:45:20<04:14,  2.65s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29705/29800 [4:45:20<04:11,  2.65s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29706/29800 [4:45:20<04:08,  2.65s/pipeline]Optimization Progress: 100%|█████████▉| 29707/29800 [4:45:20<02:53,  1.86s/pipeline]Optimization Progress: 100%|█████████▉| 29709/29800 [4:45:36<05:35,  3.69s/pipeline]Optimization Progress: 100%|█████████▉| 29788/29800 [4:45:40<00:31,  2.59s/pipeline]
Generation 297 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [08:29:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29802pipeline [4:45:40,  2.59s/pipeline]Optimization Progress: 29802pipeline [4:45:40,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:29:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29802pipeline [4:45:40,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:29:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 29802pipeline [4:45:43,  1.83s/pipeline]Optimization Progress: 100%|█████████▉| 29804/29900 [4:45:43<02:50,  1.77s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29804/29900 [4:45:43<02:50,  1.77s/pipeline]Optimization Progress: 100%|█████████▉| 29806/29900 [4:46:10<08:09,  5.21s/pipeline]Optimization Progress: 100%|█████████▉| 29886/29900 [4:46:20<00:51,  3.68s/pipeline]
Generation 298 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 29902pipeline [4:46:21,  3.68s/pipeline]Optimization Progress: 29902pipeline [4:46:21,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 29902pipeline [4:46:21,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29902pipeline [4:46:21,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29902pipeline [4:46:21,  2.60s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 29902pipeline [4:46:23,  2.60s/pipeline]Optimization Progress: 100%|█████████▉| 29903/30000 [4:46:23<04:01,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29903/30000 [4:46:23<04:01,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29904/30000 [4:46:23<03:59,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29905/30000 [4:46:23<03:56,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29906/30000 [4:46:23<03:54,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29907/30000 [4:46:23<03:51,  2.49s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 29908/30000 [4:46:23<03:49,  2.49s/pipeline]Optimization Progress: 100%|█████████▉| 29909/30000 [4:46:23<02:39,  1.75s/pipeline]Optimization Progress: 100%|█████████▉| 29912/30000 [4:46:34<03:16,  2.24s/pipeline]Optimization Progress: 100%|█████████▉| 29990/30000 [4:46:36<00:15,  1.58s/pipeline]
Generation 299 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 30002pipeline [4:46:36,  1.58s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30002pipeline [4:46:37,  1.58s/pipeline]Optimization Progress: 30002pipeline [4:46:37,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 30002pipeline [4:46:37,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30002pipeline [4:46:37,  1.11s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 30002pipeline [4:46:38,  1.11s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30003/30100 [4:46:39<01:47,  1.11s/pipeline]Optimization Progress: 100%|█████████▉| 30004/30100 [4:46:39<01:54,  1.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30004/30100 [4:46:39<01:54,  1.19s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30005/30100 [4:46:39<01:52,  1.19s/pipeline]Optimization Progress: 100%|█████████▉| 30006/30100 [4:46:50<01:51,  1.19s/pipeline]Optimization Progress: 100%|█████████▉| 30007/30100 [4:48:07<14:54,  9.62s/pipeline]Optimization Progress: 100%|█████████▉| 30087/30100 [4:48:09<01:27,  6.74s/pipeline]
Generation 300 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 30102pipeline [4:48:10,  6.74s/pipeline]Optimization Progress: 30102pipeline [4:48:10,  4.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 30102pipeline [4:48:10,  4.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 30102pipeline [4:48:13,  4.74s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30103/30200 [4:48:14<07:39,  4.74s/pipeline]Optimization Progress: 100%|█████████▉| 30104/30200 [4:48:14<06:09,  3.85s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30104/30200 [4:48:14<06:09,  3.85s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30105/30200 [4:48:14<06:05,  3.85s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30106/30200 [4:48:14<06:01,  3.85s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30107/30200 [4:48:14<05:57,  3.85s/pipeline]Optimization Progress: 100%|█████████▉| 30109/30200 [4:50:05<14:11,  9.36s/pipeline]Optimization Progress: 100%|█████████▉| 30189/30200 [4:50:10<01:12,  6.57s/pipeline]
Generation 301 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30202pipeline [4:50:10,  6.57s/pipeline]Optimization Progress: 30202pipeline [4:50:10,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30202pipeline [4:50:10,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30202pipeline [4:50:11,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 30202pipeline [4:50:11,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 30202pipeline [4:50:11,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30202pipeline [4:50:12,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30202pipeline [4:50:12,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30202pipeline [4:50:12,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:33:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 30202pipeline [4:50:13,  4.61s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 30202pipeline [4:50:13,  4.61s/pipeline]Optimization Progress: 100%|█████████▉| 30204/30300 [4:50:13<05:54,  3.69s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30204/30300 [4:50:13<05:54,  3.69s/pipeline]Optimization Progress: 100%|█████████▉| 30206/30300 [4:51:52<27:17, 17.42s/pipeline]Optimization Progress: 100%|█████████▉| 30286/30300 [4:51:56<02:50, 12.20s/pipeline]
Generation 302 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 30302pipeline [4:51:56, 12.20s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30302pipeline [4:51:56, 12.20s/pipeline]Optimization Progress: 30302pipeline [4:51:56,  8.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30302pipeline [4:51:57,  8.55s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30302pipeline [4:51:57,  8.55s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30303/30400 [4:51:59<13:49,  8.55s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30304/30400 [4:51:59<13:40,  8.55s/pipeline]Optimization Progress: 100%|█████████▉| 30305/30400 [4:51:59<10:02,  6.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30305/30400 [4:51:59<10:02,  6.34s/pipeline]Optimization Progress: 100%|█████████▉| 30306/30400 [4:52:10<09:56,  6.34s/pipeline]Optimization Progress: 100%|█████████▉| 30307/30400 [4:52:11<09:28,  6.11s/pipeline]Optimization Progress: 100%|█████████▉| 30387/30400 [4:52:16<00:55,  4.30s/pipeline]
Generation 303 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30402pipeline [4:52:16,  4.30s/pipeline]Optimization Progress: 30402pipeline [4:52:16,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30402pipeline [4:52:16,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30402pipeline [4:52:16,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 30402pipeline [4:52:16,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30402pipeline [4:52:17,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30402pipeline [4:52:17,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:35:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 30402pipeline [4:52:17,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30402pipeline [4:52:18,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30402pipeline [4:52:18,  3.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30402pipeline [4:52:18,  3.01s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30402/30500 [4:52:19<04:55,  3.01s/pipeline]Optimization Progress: 100%|█████████▉| 30403/30500 [4:52:30<04:52,  3.01s/pipeline]Optimization Progress: 100%|█████████▉| 30404/30500 [4:53:38<23:01, 14.39s/pipeline]Optimization Progress: 100%|█████████▉| 30484/30500 [4:53:40<02:41, 10.08s/pipeline]
Generation 304 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30502pipeline [4:53:42, 10.08s/pipeline]Optimization Progress: 30502pipeline [4:53:42,  7.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30502pipeline [4:53:42,  7.09s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30502pipeline [4:53:43,  7.09s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30503/30600 [4:53:43<11:28,  7.09s/pipeline]Optimization Progress: 100%|█████████▉| 30504/30600 [4:53:43<08:18,  5.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30504/30600 [4:53:43<08:18,  5.20s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30505/30600 [4:53:44<08:13,  5.20s/pipeline]Optimization Progress: 100%|█████████▉| 30507/30600 [4:55:19<20:26, 13.18s/pipeline]Optimization Progress: 100%|█████████▉| 30587/30600 [4:56:44<02:04,  9.55s/pipeline]
Generation 305 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30602pipeline [4:56:44,  9.55s/pipeline]Optimization Progress: 30602pipeline [4:56:44,  6.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30602pipeline [4:56:44,  6.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30602pipeline [4:56:44,  6.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30602pipeline [4:56:45,  6.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 30602pipeline [4:56:46,  6.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30602pipeline [4:56:46,  6.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 30602pipeline [4:56:47,  6.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 30602pipeline [4:56:47,  6.69s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30602/30700 [4:56:48<10:55,  6.69s/pipeline]Optimization Progress: 100%|█████████▉| 30606/30700 [4:56:57<08:49,  5.63s/pipeline]Optimization Progress: 100%|█████████▉| 30684/30700 [4:57:01<01:03,  3.96s/pipeline]
Generation 306 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30702pipeline [4:57:01,  3.96s/pipeline]Optimization Progress: 30702pipeline [4:57:01,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30702pipeline [4:57:01,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30702pipeline [4:57:03,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 30702pipeline [4:57:04,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 30702pipeline [4:57:05,  2.77s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30702/30800 [4:57:05<04:31,  2.77s/pipeline]Optimization Progress: 100%|█████████▉| 30703/30800 [4:57:20<04:29,  2.77s/pipeline]Optimization Progress: 100%|█████████▉| 30704/30800 [4:58:37<26:11, 16.37s/pipeline]Optimization Progress: 100%|█████████▉| 30784/30800 [4:58:44<03:03, 11.48s/pipeline]
Generation 307 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 30802pipeline [4:58:45, 11.48s/pipeline]Optimization Progress: 30802pipeline [4:58:45,  8.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 30802pipeline [4:58:47,  8.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 30802pipeline [4:58:47,  8.07s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30802/30900 [4:58:47<13:10,  8.07s/pipeline]Optimization Progress: 100%|█████████▉| 30803/30900 [4:58:47<09:57,  6.16s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30803/30900 [4:58:47<09:57,  6.16s/pipeline]Optimization Progress: 100%|█████████▉| 30805/30900 [4:58:58<09:25,  5.95s/pipeline]Optimization Progress: 100%|█████████▉| 30885/30900 [4:59:01<01:02,  4.18s/pipeline]
Generation 308 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 30902pipeline [4:59:03,  4.18s/pipeline]Optimization Progress: 30902pipeline [4:59:03,  2.95s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 30902pipeline [4:59:04,  2.95s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:42:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 30902pipeline [4:59:04,  2.95s/pipeline]Optimization Progress: 100%|█████████▉| 30905/31000 [4:59:05<03:39,  2.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30905/31000 [4:59:05<03:39,  2.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30906/31000 [4:59:05<03:37,  2.32s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 30907/31000 [4:59:05<03:35,  2.32s/pipeline]Optimization Progress: 100%|█████████▉| 30909/31000 [5:00:38<12:59,  8.57s/pipeline]Optimization Progress: 100%|█████████▉| 30989/31000 [5:00:43<01:06,  6.02s/pipeline]
Generation 309 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 31002pipeline [5:00:43,  6.02s/pipeline]Optimization Progress: 31002pipeline [5:00:43,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 31002pipeline [5:00:43,  4.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 31002pipeline [5:00:44,  4.22s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31002/31100 [5:00:46<06:53,  4.22s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31003/31100 [5:00:46<06:49,  4.22s/pipeline]Optimization Progress: 100%|█████████▉| 31004/31100 [5:00:46<05:26,  3.40s/pipeline]Optimization Progress: 100%|█████████▉| 31004/31100 [5:01:00<05:26,  3.40s/pipeline]Optimization Progress: 100%|█████████▉| 31005/31100 [5:01:21<20:10, 12.74s/pipeline]Optimization Progress: 100%|█████████▉| 31085/31100 [5:01:23<02:13,  8.93s/pipeline]
Generation 310 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31102pipeline [5:01:24,  8.93s/pipeline]Optimization Progress: 31102pipeline [5:01:24,  6.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 31102pipeline [5:01:25,  6.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31102pipeline [5:01:25,  6.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 31102pipeline [5:01:25,  6.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31102pipeline [5:01:26,  6.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:44:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 31102pipeline [5:01:26,  6.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 31102pipeline [5:01:27,  6.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 31102pipeline [5:01:27,  6.26s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31102/31200 [5:01:28<10:13,  6.26s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31103/31200 [5:01:28<10:07,  6.26s/pipeline]Optimization Progress: 100%|█████████▉| 31104/31200 [5:01:28<07:55,  4.95s/pipeline]Optimization Progress: 100%|█████████▉| 31105/31200 [5:01:39<10:48,  6.82s/pipeline]Optimization Progress: 100%|█████████▉| 31185/31200 [5:01:42<01:11,  4.79s/pipeline]
Generation 311 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 31202pipeline [5:01:42,  4.79s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31202pipeline [5:01:43,  4.79s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 31202pipeline [5:01:43,  4.79s/pipeline]Optimization Progress: 31202pipeline [5:01:43,  3.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31202pipeline [5:01:43,  3.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:45:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 31202pipeline [5:01:43,  3.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:45:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 31202pipeline [5:01:46,  3.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:45:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 31202pipeline [5:01:46,  3.36s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 31202pipeline [5:01:46,  3.36s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31202/31300 [5:01:46<05:28,  3.36s/pipeline]Optimization Progress: 100%|█████████▉| 31203/31300 [5:02:00<05:25,  3.36s/pipeline]Optimization Progress: 100%|█████████▉| 31204/31300 [5:03:13<25:21, 15.84s/pipeline]Optimization Progress: 100%|█████████▉| 31284/31300 [5:03:22<02:58, 11.13s/pipeline]
Generation 312 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 31302pipeline [5:03:22, 11.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:46:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 31302pipeline [5:03:23, 11.13s/pipeline]Optimization Progress: 31302pipeline [5:03:23,  7.80s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31302pipeline [5:03:24,  7.80s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 31302pipeline [5:03:25,  7.80s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31302/31400 [5:03:26<12:44,  7.80s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31303/31400 [5:03:26<12:36,  7.80s/pipeline]Optimization Progress: 100%|█████████▉| 31304/31400 [5:03:26<09:28,  5.92s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31304/31400 [5:03:26<09:28,  5.92s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31305/31400 [5:03:26<09:22,  5.92s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31306/31400 [5:03:26<09:16,  5.92s/pipeline]Optimization Progress: 100%|█████████▉| 31308/31400 [5:03:33<07:09,  4.67s/pipeline]Optimization Progress: 100%|█████████▉| 31388/31400 [5:03:37<00:39,  3.28s/pipeline]
Generation 313 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 31402pipeline [5:03:39,  3.28s/pipeline]Optimization Progress: 31402pipeline [5:03:39,  2.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 31402pipeline [5:03:39,  2.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 31402pipeline [5:03:39,  2.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31402pipeline [5:03:41,  2.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 31402pipeline [5:03:41,  2.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 31402pipeline [5:03:41,  2.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31402pipeline [5:03:41,  2.33s/pipeline]Optimization Progress: 100%|█████████▉| 31404/31500 [5:03:41<03:16,  2.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31404/31500 [5:03:41<03:16,  2.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31405/31500 [5:03:41<03:14,  2.05s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31406/31500 [5:03:41<03:12,  2.05s/pipeline]Optimization Progress: 100%|█████████▉| 31408/31500 [5:04:03<04:38,  3.03s/pipeline]Optimization Progress: 100%|█████████▉| 31488/31500 [5:04:05<00:25,  2.13s/pipeline]
Generation 314 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 31502pipeline [5:04:05,  2.13s/pipeline]Optimization Progress: 31502pipeline [5:04:05,  1.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 31502pipeline [5:04:06,  1.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31502pipeline [5:04:06,  1.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31502pipeline [5:04:06,  1.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 31502pipeline [5:04:06,  1.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31502pipeline [5:04:08,  1.50s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31503/31600 [5:04:08<02:25,  1.50s/pipeline]Optimization Progress: 100%|█████████▉| 31504/31600 [5:04:08<02:26,  1.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31504/31600 [5:04:08<02:26,  1.52s/pipeline]Optimization Progress: 100%|█████████▉| 31505/31600 [5:04:20<02:24,  1.52s/pipeline]Optimization Progress: 100%|█████████▉| 31506/31600 [5:04:25<05:33,  3.55s/pipeline]Optimization Progress: 100%|█████████▉| 31586/31600 [5:04:29<00:34,  2.50s/pipeline]
Generation 315 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 31602pipeline [5:04:29,  2.50s/pipeline]Optimization Progress: 31602pipeline [5:04:29,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 31602pipeline [5:04:30,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 31602pipeline [5:04:30,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 31602pipeline [5:04:30,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 31602pipeline [5:04:30,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31602pipeline [5:04:31,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 31602pipeline [5:04:31,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31602pipeline [5:04:31,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 31602pipeline [5:04:32,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31602pipeline [5:04:33,  1.76s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 31602pipeline [5:04:33,  1.76s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31602/31700 [5:04:33<02:52,  1.76s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31603/31700 [5:04:33<02:50,  1.76s/pipeline]Optimization Progress: 100%|█████████▉| 31604/31700 [5:04:33<03:01,  1.89s/pipeline]Optimization Progress: 100%|█████████▉| 31604/31700 [5:04:50<03:01,  1.89s/pipeline]Optimization Progress: 100%|█████████▉| 31605/31700 [5:06:10<47:54, 30.26s/pipeline]Optimization Progress: 100%|█████████▉| 31685/31700 [5:06:13<05:17, 21.19s/pipeline]
Generation 316 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31702pipeline [5:06:13, 21.19s/pipeline]Optimization Progress: 31702pipeline [5:06:13, 14.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 31702pipeline [5:06:13, 14.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 31702pipeline [5:06:16, 14.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 31702pipeline [5:06:16, 14.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31702pipeline [5:06:16, 14.84s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31704/31800 [5:06:17<23:44, 14.84s/pipeline]Optimization Progress: 100%|█████████▉| 31705/31800 [5:06:17<17:00, 10.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31705/31800 [5:06:17<17:00, 10.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31706/31800 [5:06:17<16:50, 10.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31707/31800 [5:06:17<16:39, 10.74s/pipeline]Optimization Progress: 100%|█████████▉| 31708/31800 [5:06:30<16:28, 10.74s/pipeline]Optimization Progress: 100%|█████████▉| 31709/31800 [5:07:34<20:09, 13.29s/pipeline]Optimization Progress: 100%|█████████▉| 31789/31800 [5:07:38<01:42,  9.32s/pipeline]
Generation 317 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31802pipeline [5:07:38,  9.32s/pipeline]Optimization Progress: 31802pipeline [5:07:38,  6.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 31802pipeline [5:07:39,  6.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31802pipeline [5:07:39,  6.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 31802pipeline [5:07:40,  6.53s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 31802pipeline [5:07:41,  6.53s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31802/31900 [5:07:41<10:39,  6.53s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31803/31900 [5:07:41<10:33,  6.53s/pipeline]Optimization Progress: 100%|█████████▉| 31804/31900 [5:07:41<08:02,  5.03s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31804/31900 [5:07:41<08:02,  5.03s/pipeline]Optimization Progress: 100%|█████████▉| 31806/31900 [5:07:54<08:39,  5.53s/pipeline]Optimization Progress: 100%|█████████▉| 31886/31900 [5:08:04<00:54,  3.90s/pipeline]
Generation 318 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31902pipeline [5:08:04,  3.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 31902pipeline [5:08:04,  3.90s/pipeline]Optimization Progress: 31902pipeline [5:08:04,  2.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 31902pipeline [5:08:07,  2.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 31902pipeline [5:08:07,  2.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 [08:51:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 31902pipeline [5:08:07,  2.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:51:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 31902pipeline [5:08:07,  2.74s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31902/32000 [5:08:08<04:28,  2.74s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31903/32000 [5:08:08<04:25,  2.74s/pipeline]Optimization Progress: 100%|█████████▉| 31904/32000 [5:08:08<03:58,  2.48s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 31904/32000 [5:08:08<03:58,  2.48s/pipeline]Optimization Progress: 100%|█████████▉| 31905/32000 [5:08:20<03:55,  2.48s/pipeline]Optimization Progress: 100%|█████████▉| 31906/32000 [5:09:39<24:06, 15.38s/pipeline]Optimization Progress: 100%|█████████▉| 31986/32000 [5:09:44<02:31, 10.79s/pipeline]
Generation 319 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 32002pipeline [5:09:45, 10.79s/pipeline]Optimization Progress: 32002pipeline [5:09:45,  7.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:53:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 32002pipeline [5:09:46,  7.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [08:53:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 32002pipeline [5:09:46,  7.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 32002pipeline [5:09:47,  7.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 32002pipeline [5:09:47,  7.56s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 32002pipeline [5:09:47,  7.56s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32002/32100 [5:09:48<12:21,  7.56s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32003/32100 [5:09:48<12:13,  7.56s/pipeline]Optimization Progress: 100%|█████████▉| 32004/32100 [5:09:48<09:16,  5.80s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32004/32100 [5:09:48<09:16,  5.80s/pipeline]Optimization Progress: 100%|█████████▉| 32006/32100 [5:10:14<12:19,  7.87s/pipeline]Optimization Progress: 100%|█████████▉| 32086/32100 [5:10:20<01:17,  5.53s/pipeline]
Generation 320 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 32102pipeline [5:10:21,  5.53s/pipeline]Optimization Progress: 32102pipeline [5:10:21,  3.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 32102pipeline [5:10:21,  3.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 32102pipeline [5:10:22,  3.90s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 32102pipeline [5:10:22,  3.90s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32102/32200 [5:10:23<06:22,  3.90s/pipeline]Optimization Progress: 100%|█████████▉| 32103/32200 [5:10:23<05:33,  3.44s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32103/32200 [5:10:23<05:33,  3.44s/pipeline]Optimization Progress: 100%|█████████▉| 32105/32200 [5:11:24<18:08, 11.46s/pipeline]Optimization Progress: 100%|█████████▉| 32185/32200 [5:11:29<02:00,  8.04s/pipeline]
Generation 321 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 32202pipeline [5:11:30,  8.04s/pipeline]Optimization Progress: 32202pipeline [5:11:30,  5.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 32202pipeline [5:11:30,  5.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 32202pipeline [5:11:31,  5.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32202pipeline [5:11:32,  5.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32202pipeline [5:11:32,  5.64s/pipeline]Optimization Progress: 100%|█████████▉| 32203/32300 [5:11:33<07:42,  4.77s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32203/32300 [5:11:33<07:42,  4.77s/pipeline]Optimization Progress: 100%|█████████▉| 32205/32300 [5:11:44<07:53,  4.99s/pipeline]Optimization Progress: 100%|█████████▉| 32285/32300 [5:11:53<00:52,  3.53s/pipeline]
Generation 322 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 32302pipeline [5:11:55,  3.53s/pipeline]Optimization Progress: 32302pipeline [5:11:55,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32302pipeline [5:11:56,  2.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 32302pipeline [5:11:56,  2.50s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32302/32400 [5:11:57<04:04,  2.50s/pipeline]Optimization Progress: 100%|█████████▉| 32303/32400 [5:11:57<03:50,  2.38s/pipeline]Optimization Progress: 100%|█████████▉| 32304/32400 [5:13:37<50:30, 31.57s/pipeline]Optimization Progress: 100%|█████████▉| 32384/32400 [5:13:42<05:53, 22.12s/pipeline]
Generation 323 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 32402pipeline [5:13:43, 22.12s/pipeline]Optimization Progress: 32402pipeline [5:13:43, 15.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [08:57:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 32402pipeline [5:13:43, 15.50s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 32402pipeline [5:13:43, 15.50s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32402/32500 [5:13:45<25:18, 15.50s/pipeline]Optimization Progress: 100%|█████████▉| 32403/32500 [5:13:45<18:43, 11.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32403/32500 [5:13:45<18:43, 11.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32404/32500 [5:13:45<18:32, 11.58s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32405/32500 [5:13:46<18:20, 11.58s/pipeline]Optimization Progress: 100%|█████████▉| 32407/32500 [5:13:57<13:54,  8.97s/pipeline]Optimization Progress: 100%|█████████▉| 32487/32500 [5:15:20<01:25,  6.59s/pipeline]
Generation 324 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 32502pipeline [5:15:20,  6.59s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 32502pipeline [5:15:21,  6.59s/pipeline]Optimization Progress: 32502pipeline [5:15:21,  4.62s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 32502pipeline [5:15:24,  4.62s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32502/32600 [5:15:25<07:33,  4.62s/pipeline]Optimization Progress: 100%|█████████▉| 32503/32600 [5:15:40<07:28,  4.62s/pipeline]Optimization Progress: 100%|█████████▉| 32504/32600 [5:15:42<10:19,  6.45s/pipeline]Optimization Progress: 100%|█████████▉| 32584/32600 [5:15:58<01:13,  4.58s/pipeline]
Generation 325 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 32602pipeline [5:16:00,  4.58s/pipeline]Optimization Progress: 32602pipeline [5:16:00,  3.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32602pipeline [5:16:00,  3.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:59:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 32602pipeline [5:16:00,  3.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32602pipeline [5:16:00,  3.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 32602pipeline [5:16:01,  3.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 32602pipeline [5:16:01,  3.23s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [08:59:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 32602pipeline [5:16:01,  3.23s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32602/32700 [5:16:02<05:16,  3.23s/pipeline]Optimization Progress: 100%|█████████▉| 32603/32700 [5:16:02<05:00,  3.09s/pipeline]Optimization Progress: 100%|█████████▉| 32604/32700 [5:16:14<08:50,  5.52s/pipeline]Optimization Progress: 100%|█████████▉| 32684/32700 [5:16:29<01:02,  3.92s/pipeline]
Generation 326 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32702pipeline [5:16:31,  3.92s/pipeline]Optimization Progress: 32702pipeline [5:16:31,  2.78s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 32702pipeline [5:16:31,  2.78s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32702pipeline [5:16:31,  2.78s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 32702pipeline [5:16:31,  2.78s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 32702pipeline [5:16:32,  2.78s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 32702pipeline [5:16:33,  2.78s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32702/32800 [5:16:33<04:32,  2.78s/pipeline]Optimization Progress: 100%|█████████▉| 32703/32800 [5:16:33<04:07,  2.56s/pipeline]Optimization Progress: 100%|█████████▉| 32704/32800 [5:16:44<08:14,  5.15s/pipeline]Optimization Progress: 100%|█████████▉| 32784/32800 [5:18:16<01:03,  3.95s/pipeline]
Generation 327 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 32802pipeline [5:18:16,  3.95s/pipeline]Optimization Progress: 32802pipeline [5:18:16,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 32802pipeline [5:18:17,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:01:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 32802pipeline [5:18:18,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 32802pipeline [5:18:18,  2.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 32802pipeline [5:18:19,  2.77s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32802/32900 [5:18:19<04:31,  2.77s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32803/32900 [5:18:19<04:28,  2.77s/pipeline]Optimization Progress: 100%|█████████▉| 32804/32900 [5:18:19<03:47,  2.37s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32804/32900 [5:18:19<03:47,  2.37s/pipeline]Optimization Progress: 100%|█████████▉| 32805/32900 [5:18:30<03:45,  2.37s/pipeline]Optimization Progress: 100%|█████████▉| 32806/32900 [5:18:31<05:27,  3.48s/pipeline]Optimization Progress: 100%|█████████▉| 32886/32900 [5:18:35<00:34,  2.45s/pipeline]
Generation 328 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 32902pipeline [5:18:36,  2.45s/pipeline]Optimization Progress: 32902pipeline [5:18:36,  1.74s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:02:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 32902pipeline [5:18:37,  1.74s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32902/33000 [5:18:39<02:50,  1.74s/pipeline]Optimization Progress: 100%|█████████▉| 32903/33000 [5:18:39<03:12,  1.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32903/33000 [5:18:39<03:12,  1.98s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 32904/33000 [5:18:39<03:10,  1.98s/pipeline]Optimization Progress: 100%|█████████▉| 32906/33000 [5:18:51<04:05,  2.61s/pipeline]Optimization Progress: 100%|█████████▉| 32986/33000 [5:18:56<00:25,  1.84s/pipeline]
Generation 329 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33002pipeline [5:18:58,  1.84s/pipeline]Optimization Progress: 33002pipeline [5:18:58,  1.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33002pipeline [5:18:58,  1.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 33002pipeline [5:18:58,  1.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 33002pipeline [5:18:58,  1.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 33002pipeline [5:18:58,  1.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 33002pipeline [5:18:59,  1.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33002pipeline [5:18:59,  1.33s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33002pipeline [5:18:59,  1.33s/pipeline]Optimization Progress: 100%|█████████▉| 33003/33100 [5:18:59<02:17,  1.41s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33003/33100 [5:19:00<02:17,  1.41s/pipeline]Optimization Progress: 100%|█████████▉| 33005/33100 [5:19:21<06:38,  4.19s/pipeline]Optimization Progress: 100%|█████████▉| 33085/33100 [5:19:23<00:44,  2.95s/pipeline]
Generation 330 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 33102pipeline [5:19:24,  2.95s/pipeline]Optimization Progress: 33102pipeline [5:19:24,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33102pipeline [5:19:25,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 33102pipeline [5:19:26,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 33102pipeline [5:19:26,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 33102pipeline [5:19:26,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 33102pipeline [5:19:26,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [09:02:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 33102pipeline [5:19:26,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 33102pipeline [5:19:26,  2.07s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33102pipeline [5:19:27,  2.07s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33102/33200 [5:19:27<03:23,  2.07s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33103/33200 [5:19:27<03:21,  2.07s/pipeline]Optimization Progress: 100%|█████████▉| 33104/33200 [5:19:27<03:01,  1.89s/pipeline]Optimization Progress: 100%|█████████▉| 33104/33200 [5:19:40<03:01,  1.89s/pipeline]Optimization Progress: 100%|█████████▉| 33105/33200 [5:19:49<12:25,  7.84s/pipeline]Optimization Progress: 100%|█████████▉| 33185/33200 [5:19:54<01:22,  5.51s/pipeline]
Generation 331 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 33202pipeline [5:19:54,  5.51s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33202pipeline [5:19:54,  5.51s/pipeline]Optimization Progress: 33202pipeline [5:19:54,  3.87s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 33202pipeline [5:19:55,  3.87s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33202pipeline [5:19:56,  3.87s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 33202pipeline [5:19:57,  3.87s/pipeline]Optimization Progress: 100%|█████████▉| 33204/33300 [5:20:07<07:22,  4.61s/pipeline]Optimization Progress: 100%|█████████▉| 33283/33300 [5:20:17<00:55,  3.26s/pipeline]
Generation 332 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33302pipeline [5:20:19,  3.26s/pipeline]Optimization Progress: 33302pipeline [5:20:19,  2.31s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 33302pipeline [5:20:20,  2.31s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33302pipeline [5:20:20,  2.31s/pipeline]Optimization Progress: 100%|█████████▉| 33303/33400 [5:20:21<03:25,  2.12s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33303/33400 [5:20:21<03:25,  2.12s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33304/33400 [5:20:21<03:23,  2.12s/pipeline]Optimization Progress: 100%|█████████▉| 33306/33400 [5:20:51<07:02,  4.49s/pipeline]Optimization Progress: 100%|█████████▉| 33386/33400 [5:21:06<00:44,  3.20s/pipeline]
Generation 333 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 33402pipeline [5:21:07,  3.20s/pipeline]Optimization Progress: 33402pipeline [5:21:07,  2.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 33402pipeline [5:21:08,  2.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33402pipeline [5:21:10,  2.25s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:04:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 33402pipeline [5:21:10,  2.25s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33402/33500 [5:21:10<03:40,  2.25s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33403/33500 [5:21:10<03:38,  2.25s/pipeline]Optimization Progress: 100%|█████████▉| 33404/33500 [5:21:10<03:18,  2.06s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33404/33500 [5:21:10<03:18,  2.06s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33405/33500 [5:21:10<03:16,  2.06s/pipeline]Optimization Progress: 100%|█████████▉| 33407/33500 [5:21:19<03:43,  2.40s/pipeline]Optimization Progress: 100%|█████████▉| 33487/33500 [5:21:22<00:21,  1.69s/pipeline]
Generation 334 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 33502pipeline [5:21:23,  1.69s/pipeline]Optimization Progress: 33502pipeline [5:21:23,  1.19s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 33502pipeline [5:21:24,  1.19s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33502pipeline [5:21:25,  1.19s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33502pipeline [5:21:25,  1.19s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33502/33600 [5:21:26<01:56,  1.19s/pipeline]Optimization Progress: 100%|█████████▉| 33503/33600 [5:21:40<01:55,  1.19s/pipeline]Optimization Progress: 100%|█████████▉| 33504/33600 [5:21:56<09:18,  5.82s/pipeline]Optimization Progress: 100%|█████████▉| 33584/33600 [5:22:01<01:05,  4.09s/pipeline]
Generation 335 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 33602pipeline [5:22:02,  4.09s/pipeline]Optimization Progress: 33602pipeline [5:22:02,  2.89s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 33602pipeline [5:22:04,  2.89s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 33602pipeline [5:22:04,  2.89s/pipeline]Optimization Progress: 100%|█████████▉| 33603/33700 [5:22:05<04:30,  2.79s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33603/33700 [5:22:05<04:30,  2.79s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33604/33700 [5:22:05<04:27,  2.79s/pipeline]Optimization Progress: 100%|█████████▉| 33606/33700 [5:22:17<04:54,  3.13s/pipeline]Optimization Progress: 100%|█████████▉| 33686/33700 [5:24:04<00:36,  2.59s/pipeline]
Generation 336 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 33702pipeline [5:24:05,  2.59s/pipeline]Optimization Progress: 33702pipeline [5:24:05,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33702pipeline [5:24:05,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 33702pipeline [5:24:06,  1.83s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33702pipeline [5:24:07,  1.83s/pipeline]Optimization Progress: 100%|█████████▉| 33703/33800 [5:24:08<03:36,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33703/33800 [5:24:08<03:36,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33704/33800 [5:24:08<03:33,  2.23s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33705/33800 [5:24:08<03:31,  2.23s/pipeline]Optimization Progress: 100%|█████████▉| 33707/33800 [5:24:16<03:22,  2.18s/pipeline]Optimization Progress: 100%|█████████▉| 33787/33800 [5:26:24<00:26,  2.01s/pipeline]
Generation 337 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [09:09:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 33802pipeline [5:26:25,  2.01s/pipeline]Optimization Progress: 33802pipeline [5:26:25,  1.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33802pipeline [5:26:25,  1.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 33802pipeline [5:26:27,  1.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 33802pipeline [5:26:27,  1.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33802pipeline [5:26:27,  1.42s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33802pipeline [5:26:28,  1.42s/pipeline]Optimization Progress: 100%|█████████▉| 33804/33900 [5:26:29<02:29,  1.55s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33804/33900 [5:26:29<02:29,  1.55s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33805/33900 [5:26:29<02:27,  1.55s/pipeline]Optimization Progress: 100%|█████████▉| 33807/33900 [5:28:02<16:08, 10.41s/pipeline]Optimization Progress: 100%|█████████▉| 33887/33900 [5:28:07<01:34,  7.31s/pipeline]
Generation 338 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 33902pipeline [5:28:07,  7.31s/pipeline]Optimization Progress: 33902pipeline [5:28:07,  5.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33902pipeline [5:28:08,  5.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 33902pipeline [5:28:09,  5.12s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 33902pipeline [5:28:09,  5.12s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33902/34000 [5:28:10<08:21,  5.12s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 33903/34000 [5:28:10<08:16,  5.12s/pipeline]Optimization Progress: 100%|█████████▉| 33904/34000 [5:28:20<08:11,  5.12s/pipeline]Optimization Progress: 100%|█████████▉| 33905/34000 [5:28:25<08:32,  5.39s/pipeline]Optimization Progress: 100%|█████████▉| 33985/34000 [5:28:35<00:57,  3.81s/pipeline]
Generation 339 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 34002pipeline [5:28:36,  3.81s/pipeline]Optimization Progress: 34002pipeline [5:28:36,  2.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:12:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 34002pipeline [5:28:37,  2.69s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34002pipeline [5:28:38,  2.69s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34002/34100 [5:28:39<04:23,  2.69s/pipeline]Optimization Progress: 100%|█████████▉| 34003/34100 [5:28:39<04:17,  2.65s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34003/34100 [5:28:39<04:17,  2.65s/pipeline]Optimization Progress: 100%|█████████▉| 34005/34100 [5:28:51<05:52,  3.71s/pipeline]Optimization Progress: 100%|█████████▉| 34085/34100 [5:28:57<00:39,  2.62s/pipeline]
Generation 340 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 34102pipeline [5:28:57,  2.62s/pipeline]Optimization Progress: 34102pipeline [5:28:57,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:12:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 34102pipeline [5:28:58,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 [09:12:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 34102pipeline [5:28:58,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=2 [09:12:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 34102pipeline [5:28:58,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 34102pipeline [5:28:59,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34102pipeline [5:28:59,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:12:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 34102pipeline [5:29:00,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 34102pipeline [5:29:00,  1.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34102pipeline [5:29:00,  1.84s/pipeline]Optimization Progress: 100%|█████████▉| 34105/34200 [5:29:01<02:30,  1.59s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34105/34200 [5:29:01<02:30,  1.59s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34106/34200 [5:29:01<02:29,  1.59s/pipeline]Optimization Progress: 100%|█████████▉| 34107/34200 [5:29:01<01:44,  1.13s/pipeline]Optimization Progress: 100%|█████████▉| 34107/34200 [5:29:20<01:44,  1.13s/pipeline]Optimization Progress: 100%|█████████▉| 34108/34200 [5:30:19<37:11, 24.26s/pipeline]Optimization Progress: 100%|█████████▉| 34188/34200 [5:30:25<03:24, 17.00s/pipeline]
Generation 341 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34202pipeline [5:30:25, 17.00s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34202pipeline [5:30:25, 17.00s/pipeline]Optimization Progress: 34202pipeline [5:30:25, 11.91s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 34202pipeline [5:30:27, 11.91s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34202pipeline [5:30:28, 11.91s/pipeline]Optimization Progress: 100%|█████████▉| 34203/34300 [5:30:28<15:04,  9.33s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34203/34300 [5:30:29<15:04,  9.33s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34204/34300 [5:30:29<14:55,  9.33s/pipeline]Optimization Progress: 100%|█████████▉| 34206/34300 [5:30:37<11:35,  7.39s/pipeline]Optimization Progress: 100%|█████████▉| 34286/34300 [5:30:46<01:12,  5.21s/pipeline]
Generation 342 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34302pipeline [5:30:47,  5.21s/pipeline]Optimization Progress: 34302pipeline [5:30:47,  3.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34302pipeline [5:30:47,  3.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34302pipeline [5:30:47,  3.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34302pipeline [5:30:48,  3.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34302pipeline [5:30:48,  3.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 34302pipeline [5:30:48,  3.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34302pipeline [5:30:48,  3.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:14:22] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 34302pipeline [5:30:49,  3.65s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34302/34400 [5:30:50<05:58,  3.65s/pipeline]Optimization Progress: 100%|█████████▉| 34303/34400 [5:31:00<05:54,  3.65s/pipeline]Optimization Progress: 100%|█████████▉| 34304/34400 [5:32:15<25:22, 15.86s/pipeline]Optimization Progress: 100%|█████████▉| 34384/34400 [5:32:25<02:58, 11.14s/pipeline]
Generation 343 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [09:15:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 34402pipeline [5:32:25, 11.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34402pipeline [5:32:26, 11.14s/pipeline]Optimization Progress: 34402pipeline [5:32:26,  7.80s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 34402pipeline [5:32:28,  7.80s/pipeline]Optimization Progress: 100%|█████████▉| 34402/34500 [5:32:40<12:44,  7.80s/pipeline]Optimization Progress: 100%|█████████▉| 34403/34500 [5:32:45<18:17, 11.31s/pipeline]Optimization Progress: 100%|█████████▉| 34483/34500 [5:34:03<02:19,  8.21s/pipeline]
Generation 344 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 34502pipeline [5:34:04,  8.21s/pipeline]Optimization Progress: 34502pipeline [5:34:04,  5.77s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 34502pipeline [5:34:04,  5.77s/pipeline]Optimization Progress: 100%|█████████▉| 34505/34600 [5:34:06<06:42,  4.23s/pipeline]Optimization Progress: 100%|█████████▉| 34506/34600 [5:34:18<10:18,  6.58s/pipeline]Optimization Progress: 100%|█████████▉| 34586/34600 [5:34:24<01:04,  4.63s/pipeline]
Generation 345 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 34602pipeline [5:34:25,  4.63s/pipeline]Optimization Progress: 34602pipeline [5:34:25,  3.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34602pipeline [5:34:26,  3.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34602pipeline [5:34:26,  3.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 34602pipeline [5:34:27,  3.26s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 34602pipeline [5:34:27,  3.26s/pipeline]Optimization Progress: 100%|█████████▉| 34603/34700 [5:34:28<04:55,  3.04s/pipeline]Optimization Progress: 100%|█████████▉| 34604/34700 [5:35:53<44:25, 27.77s/pipeline]Optimization Progress: 100%|█████████▉| 34684/34700 [5:36:03<05:11, 19.47s/pipeline]
Generation 346 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34702pipeline [5:36:04, 19.47s/pipeline]Optimization Progress: 34702pipeline [5:36:04, 13.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 34702pipeline [5:36:04, 13.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 34702pipeline [5:36:04, 13.64s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 34702pipeline [5:36:05, 13.64s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34702/34800 [5:36:07<22:16, 13.64s/pipeline]Optimization Progress: 100%|█████████▉| 34704/34800 [5:36:16<18:21, 11.47s/pipeline]Optimization Progress: 100%|█████████▉| 34784/34800 [5:36:20<02:08,  8.04s/pipeline]
Generation 347 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 34802pipeline [5:36:22,  8.04s/pipeline]Optimization Progress: 34802pipeline [5:36:22,  5.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34802pipeline [5:36:22,  5.67s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34802pipeline [5:36:23,  5.67s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34802/34900 [5:36:24<09:15,  5.67s/pipeline]Optimization Progress: 100%|█████████▉| 34803/34900 [5:36:24<07:18,  4.52s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 34803/34900 [5:36:24<07:18,  4.52s/pipeline]Optimization Progress: 100%|█████████▉| 34805/34900 [5:36:54<12:08,  7.67s/pipeline]Optimization Progress: 100%|█████████▉| 34885/34900 [5:37:08<01:21,  5.42s/pipeline]
Generation 348 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34902pipeline [5:37:09,  5.42s/pipeline]Optimization Progress: 34902pipeline [5:37:09,  3.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34902pipeline [5:37:09,  3.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 34902pipeline [5:37:10,  3.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 34902pipeline [5:37:10,  3.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 34902pipeline [5:37:11,  3.81s/pipeline]Optimization Progress: 100%|█████████▉| 34902/35000 [5:37:20<06:13,  3.81s/pipeline]Optimization Progress: 100%|█████████▉| 34903/35000 [5:38:28<42:52, 26.52s/pipeline]Optimization Progress: 100%|█████████▉| 34983/35000 [5:38:38<05:16, 18.60s/pipeline]
Generation 349 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 35002pipeline [5:38:39, 18.60s/pipeline]Optimization Progress: 35002pipeline [5:38:39, 13.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:22:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 35002pipeline [5:38:40, 13.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 35002pipeline [5:38:41, 13.04s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 35002pipeline [5:38:41, 13.04s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35002/35100 [5:38:42<21:18, 13.04s/pipeline]Optimization Progress: 100%|█████████▉| 35003/35100 [5:38:42<15:53,  9.83s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35003/35100 [5:38:42<15:53,  9.83s/pipeline]Optimization Progress: 100%|█████████▉| 35005/35100 [5:40:46<40:20, 25.48s/pipeline]Optimization Progress: 100%|█████████▉| 35085/35100 [5:40:55<04:28, 17.87s/pipeline]
Generation 350 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 35102pipeline [5:40:56, 17.87s/pipeline]Optimization Progress: 35102pipeline [5:40:56, 12.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 35102pipeline [5:40:57, 12.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 35102pipeline [5:40:57, 12.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 35102pipeline [5:40:59, 12.52s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 35102pipeline [5:40:59, 12.52s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35102/35200 [5:40:59<20:27, 12.52s/pipeline]Optimization Progress: 100%|█████████▉| 35103/35200 [5:40:59<15:51,  9.81s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35103/35200 [5:40:59<15:51,  9.81s/pipeline]Optimization Progress: 100%|█████████▉| 35105/35200 [5:41:12<13:54,  8.78s/pipeline]Optimization Progress: 100%|█████████▉| 35185/35200 [5:41:47<01:34,  6.28s/pipeline]
Generation 351 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35202pipeline [5:41:47,  6.28s/pipeline]Optimization Progress: 35202pipeline [5:41:47,  4.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 35202pipeline [5:41:48,  4.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:25:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 35202pipeline [5:41:48,  4.41s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 35202pipeline [5:41:49,  4.41s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35202/35300 [5:41:50<07:11,  4.41s/pipeline]Optimization Progress: 100%|█████████▉| 35203/35300 [5:41:50<06:18,  3.90s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35203/35300 [5:41:50<06:18,  3.90s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35204/35300 [5:41:50<06:14,  3.90s/pipeline]Optimization Progress: 100%|█████████▉| 35206/35300 [5:41:58<05:32,  3.54s/pipeline]Optimization Progress: 100%|█████████▉| 35286/35300 [5:42:04<00:35,  2.50s/pipeline]
Generation 352 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 35302pipeline [5:42:04,  2.50s/pipeline]Optimization Progress: 35302pipeline [5:42:04,  1.75s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:25:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 35302pipeline [5:42:06,  1.75s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 35302pipeline [5:42:06,  1.75s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 35302pipeline [5:42:07,  1.75s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:25:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 35302pipeline [5:42:07,  1.75s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35302pipeline [5:42:07,  1.75s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 35302pipeline [5:42:07,  1.75s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35302/35400 [5:42:08<02:51,  1.75s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35303/35400 [5:42:08<02:50,  1.75s/pipeline]Optimization Progress: 100%|█████████▉| 35304/35400 [5:42:20<02:48,  1.75s/pipeline]Optimization Progress: 100%|█████████▉| 35305/35400 [5:44:11<21:57, 13.87s/pipeline]Optimization Progress: 100%|█████████▉| 35385/35400 [5:44:20<02:26,  9.74s/pipeline]
Generation 353 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 35402pipeline [5:44:21,  9.74s/pipeline]Optimization Progress: 35402pipeline [5:44:21,  6.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 35402pipeline [5:44:23,  6.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 35402pipeline [5:44:23,  6.84s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35402/35500 [5:44:24<11:10,  6.84s/pipeline]Optimization Progress: 100%|█████████▉| 35403/35500 [5:44:24<08:49,  5.46s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35403/35500 [5:44:24<08:49,  5.46s/pipeline]Optimization Progress: 100%|█████████▉| 35405/35500 [5:44:36<08:59,  5.68s/pipeline]Optimization Progress: 100%|█████████▉| 35485/35500 [5:44:46<01:00,  4.01s/pipeline]
Generation 354 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 35502pipeline [5:44:46,  4.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 35502pipeline [5:44:46,  4.01s/pipeline]Optimization Progress: 35502pipeline [5:44:46,  2.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 35502pipeline [5:44:46,  2.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 35502pipeline [5:44:47,  2.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35502pipeline [5:44:47,  2.81s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 35502pipeline [5:44:47,  2.81s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35502/35600 [5:44:49<04:35,  2.81s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35503/35600 [5:44:49<04:32,  2.81s/pipeline]Optimization Progress: 100%|█████████▉| 35504/35600 [5:45:00<04:29,  2.81s/pipeline]Optimization Progress: 100%|█████████▉| 35505/35600 [5:45:01<05:28,  3.46s/pipeline]Optimization Progress: 100%|█████████▉| 35585/35600 [5:45:07<00:36,  2.44s/pipeline]
Generation 355 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 35602pipeline [5:45:07,  2.44s/pipeline]Optimization Progress: 35602pipeline [5:45:07,  1.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 35602pipeline [5:45:08,  1.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 35602pipeline [5:45:10,  1.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 35602pipeline [5:45:10,  1.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 35602pipeline [5:45:10,  1.72s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35602pipeline [5:45:10,  1.72s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35602/35700 [5:45:10<02:48,  1.72s/pipeline]Optimization Progress: 100%|█████████▉| 35603/35700 [5:45:10<03:28,  2.15s/pipeline]Optimization Progress: 100%|█████████▉| 35604/35700 [5:45:22<07:58,  4.98s/pipeline]Optimization Progress: 100%|█████████▉| 35684/35700 [5:45:24<00:55,  3.49s/pipeline]
Generation 356 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35702pipeline [5:45:24,  3.49s/pipeline]Optimization Progress: 35702pipeline [5:45:24,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 35702pipeline [5:45:25,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 35702pipeline [5:45:25,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:29:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 35702pipeline [5:45:28,  2.45s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 35702pipeline [5:45:28,  2.45s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35702/35800 [5:45:28<04:00,  2.45s/pipeline]Optimization Progress: 100%|█████████▉| 35703/35800 [5:45:40<03:57,  2.45s/pipeline]Optimization Progress: 100%|█████████▉| 35704/35800 [5:47:07<27:19, 17.08s/pipeline]Optimization Progress: 100%|█████████▉| 35784/35800 [5:47:13<03:11, 11.98s/pipeline]
Generation 357 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35802pipeline [5:47:14, 11.98s/pipeline]Optimization Progress: 35802pipeline [5:47:14,  8.39s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 35802pipeline [5:47:14,  8.39s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 35802/35900 [5:47:17<13:42,  8.39s/pipeline]Optimization Progress: 100%|█████████▉| 35803/35900 [5:47:30<13:33,  8.39s/pipeline]Optimization Progress: 100%|█████████▉| 35804/35900 [5:47:31<13:36,  8.50s/pipeline]Optimization Progress: 100%|█████████▉| 35884/35900 [5:47:34<01:35,  5.96s/pipeline]
Generation 358 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 35902pipeline [5:47:34,  5.96s/pipeline]Optimization Progress: 35902pipeline [5:47:34,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 35902pipeline [5:47:35,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 35902pipeline [5:47:35,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35902pipeline [5:47:35,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 35902pipeline [5:47:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 35902pipeline [5:47:36,  4.18s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:31:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 35902pipeline [5:47:37,  4.18s/pipeline]Optimization Progress: 100%|█████████▉| 35902/36000 [5:47:50<06:49,  4.18s/pipeline]Optimization Progress: 100%|█████████▉| 35903/36000 [5:48:05<19:39, 12.15s/pipeline]Optimization Progress: 100%|█████████▉| 35983/36000 [5:48:15<02:25,  8.54s/pipeline]
Generation 359 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36002pipeline [5:48:15,  8.54s/pipeline]Optimization Progress: 36002pipeline [5:48:15,  5.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36002pipeline [5:48:15,  5.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36002pipeline [5:48:17,  5.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36002pipeline [5:48:17,  5.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36002pipeline [5:48:18,  5.99s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 36002pipeline [5:48:18,  5.99s/pipeline]Optimization Progress: 100%|█████████▉| 36004/36100 [5:48:30<10:11,  6.37s/pipeline]Optimization Progress: 100%|█████████▉| 36084/36100 [5:48:39<01:11,  4.50s/pipeline]
Generation 360 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36102pipeline [5:48:39,  4.50s/pipeline]Optimization Progress: 36102pipeline [5:48:39,  3.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 36102pipeline [5:48:39,  3.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36102pipeline [5:48:40,  3.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36102pipeline [5:48:41,  3.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 36102pipeline [5:48:41,  3.15s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36102pipeline [5:48:42,  3.15s/pipeline]Optimization Progress: 100%|█████████▉| 36102/36200 [5:48:50<05:08,  3.15s/pipeline]Optimization Progress: 100%|█████████▉| 36103/36200 [5:48:55<10:59,  6.80s/pipeline]Optimization Progress: 100%|█████████▉| 36183/36200 [5:49:00<01:21,  4.78s/pipeline]
Generation 361 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 36202pipeline [5:49:00,  4.78s/pipeline]Optimization Progress: 36202pipeline [5:49:00,  3.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36202pipeline [5:49:00,  3.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 36202pipeline [5:49:02,  3.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36202pipeline [5:49:03,  3.35s/pipeline]Optimization Progress: 100%|█████████▉| 36202/36300 [5:49:10<05:28,  3.35s/pipeline]Optimization Progress: 100%|█████████▉| 36203/36300 [5:51:14<1:08:42, 42.50s/pipeline]Optimization Progress: 100%|█████████▉| 36283/36300 [5:51:20<08:26, 29.77s/pipeline]  
Generation 362 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36302pipeline [5:51:20, 29.77s/pipeline]Optimization Progress: 36302pipeline [5:51:20, 20.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 36302pipeline [5:51:21, 20.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:34:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 36302pipeline [5:51:22, 20.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:34:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 36302pipeline [5:51:22, 20.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36302pipeline [5:51:22, 20.84s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36302pipeline [5:51:23, 20.84s/pipeline]Optimization Progress: 100%|█████████▉| 36303/36400 [5:51:30<33:41, 20.84s/pipeline]Optimization Progress: 100%|█████████▉| 36304/36400 [5:51:36<27:11, 17.00s/pipeline]Optimization Progress: 100%|█████████▉| 36384/36400 [5:51:39<03:10, 11.91s/pipeline]
Generation 363 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36402pipeline [5:51:40, 11.91s/pipeline]Optimization Progress: 36402pipeline [5:51:40,  8.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 36402pipeline [5:51:40,  8.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36402pipeline [5:51:41,  8.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36402pipeline [5:51:42,  8.35s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 36402pipeline [5:51:42,  8.35s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36402/36500 [5:51:43<13:38,  8.35s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36403/36500 [5:51:43<13:30,  8.35s/pipeline]Optimization Progress: 100%|█████████▉| 36404/36500 [5:51:43<10:06,  6.32s/pipeline]Optimization Progress: 100%|█████████▉| 36405/36500 [5:53:03<45:12, 28.55s/pipeline]Optimization Progress: 100%|█████████▉| 36485/36500 [5:53:07<05:00, 20.00s/pipeline]
Generation 364 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36502pipeline [5:53:08, 20.00s/pipeline]Optimization Progress: 36502pipeline [5:53:08, 14.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 36502pipeline [5:53:08, 14.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36502pipeline [5:53:09, 14.01s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 36502pipeline [5:53:09, 14.01s/pipeline]Optimization Progress: 100%|█████████▉| 36502/36600 [5:53:20<22:52, 14.01s/pipeline]Optimization Progress: 100%|█████████▉| 36503/36600 [5:53:22<22:34, 13.97s/pipeline]Optimization Progress: 100%|█████████▉| 36583/36600 [5:53:24<02:46,  9.79s/pipeline]
Generation 365 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36602pipeline [5:53:25,  9.79s/pipeline]Optimization Progress: 36602pipeline [5:53:25,  6.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36602pipeline [5:53:25,  6.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36602pipeline [5:53:26,  6.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36602pipeline [5:53:27,  6.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36602pipeline [5:53:27,  6.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36602pipeline [5:53:27,  6.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 36602pipeline [5:53:27,  6.86s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36602pipeline [5:53:27,  6.86s/pipeline]Optimization Progress: 100%|█████████▉| 36603/36700 [5:53:40<11:05,  6.86s/pipeline]Optimization Progress: 100%|█████████▉| 36604/36700 [5:54:51<28:19, 17.70s/pipeline]Optimization Progress: 100%|█████████▉| 36684/36700 [5:54:56<03:18, 12.41s/pipeline]
Generation 366 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36702pipeline [5:54:57, 12.41s/pipeline]Optimization Progress: 36702pipeline [5:54:57,  8.71s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36702pipeline [5:54:57,  8.71s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36702pipeline [5:54:58,  8.71s/pipeline]Optimization Progress: 100%|█████████▉| 36705/36800 [5:55:00<10:02,  6.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36705/36800 [5:55:00<10:02,  6.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36706/36800 [5:55:00<09:55,  6.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36707/36800 [5:55:00<09:49,  6.34s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36708/36800 [5:55:00<09:43,  6.34s/pipeline]Optimization Progress: 100%|█████████▉| 36709/36800 [5:55:00<06:44,  4.45s/pipeline]Optimization Progress: 100%|█████████▉| 36709/36800 [5:55:10<06:44,  4.45s/pipeline]Optimization Progress: 100%|█████████▉| 36710/36800 [5:56:25<43:04, 28.72s/pipeline]Optimization Progress: 100%|█████████▉| 36790/36800 [5:56:35<03:21, 20.14s/pipeline]
Generation 367 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 36802pipeline [5:56:35, 20.14s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36802pipeline [5:56:36, 20.14s/pipeline]Optimization Progress: 36802pipeline [5:56:36, 14.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 36802pipeline [5:56:37, 14.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36802pipeline [5:56:37, 14.13s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36802pipeline [5:56:37, 14.13s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36802/36900 [5:56:39<23:04, 14.13s/pipeline]Optimization Progress: 100%|█████████▉| 36803/36900 [5:56:39<17:10, 10.62s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36803/36900 [5:56:39<17:10, 10.62s/pipeline]Optimization Progress: 100%|█████████▉| 36805/36900 [5:56:52<14:57,  9.45s/pipeline]Optimization Progress: 100%|█████████▉| 36885/36900 [5:56:55<01:39,  6.63s/pipeline]
Generation 368 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36902pipeline [5:56:56,  6.63s/pipeline]Optimization Progress: 36902pipeline [5:56:56,  4.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 36902pipeline [5:56:58,  4.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 36902pipeline [5:56:58,  4.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 36902pipeline [5:56:59,  4.65s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 36902pipeline [5:56:59,  4.65s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36902/37000 [5:56:59<07:35,  4.65s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 36903/37000 [5:56:59<07:30,  4.65s/pipeline]Optimization Progress: 100%|█████████▉| 36904/37000 [5:56:59<06:03,  3.79s/pipeline]Optimization Progress: 100%|█████████▉| 36906/37000 [5:57:09<06:33,  4.18s/pipeline]Optimization Progress: 100%|█████████▉| 36985/37000 [5:57:12<00:44,  2.94s/pipeline]
Generation 369 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 37002pipeline [5:57:12,  2.94s/pipeline]Optimization Progress: 37002pipeline [5:57:12,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 37002pipeline [5:57:12,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 37002pipeline [5:57:13,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 37002pipeline [5:57:14,  2.06s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 [09:40:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 37002pipeline [5:57:14,  2.06s/pipeline]Optimization Progress: 100%|█████████▉| 37006/37100 [5:57:25<03:49,  2.45s/pipeline]Optimization Progress: 100%|█████████▉| 37083/37100 [5:57:30<00:29,  1.73s/pipeline]
Generation 370 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 [09:41:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa85e76edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa85e87f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa85e88cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa85e873cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa85e760f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9e6c51b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9e6c51b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9e6c53327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9e6c533cb4]

.
Optimization Progress: 37102pipeline [5:57:31,  1.73s/pipeline]Optimization Progress: 37102pipeline [5:57:31,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 37102pipeline [5:57:31,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 37102pipeline [5:57:31,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 37102pipeline [5:57:32,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 37102pipeline [5:57:32,  1.22s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 37102pipeline [5:57:34,  1.22s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 37102/37200 [5:57:34<01:59,  1.22s/pipeline]Optimization Progress: 100%|█████████▉| 37104/37200 [5:57:45<04:45,  2.97s/pipeline]Optimization Progress: 100%|█████████▉| 37184/37200 [5:57:56<00:33,  2.12s/pipeline]
Generation 371 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 37202pipeline [5:57:57,  2.12s/pipeline]Optimization Progress: 37202pipeline [5:57:57,  1.50s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 37202/37300 [5:57:59<02:27,  1.50s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 37203/37300 [5:57:59<02:25,  1.50s/pipeline]Optimization Progress: 100%|█████████▉| 37204/37300 [5:57:59<02:05,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 37204/37300 [5:57:59<02:05,  1.30s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 37205/37300 [5:57:59<02:03,  1.30s/pipeline]Optimization Progress: 100%|█████████▉| 37207/37300 [5:59:29<15:21,  9.91s/pipeline]Optimization Progress: 100%|█████████▉| 37287/37300 [5:59:34<01:30,  6.96s/pipeline]
Generation 372 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 37302pipeline [5:59:34,  6.96s/pipeline]Optimization Progress: 37302pipeline [5:59:34,  4.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 37302pipeline [5:59:35,  4.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 37302pipeline [5:59:36,  4.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 37302pipeline [5:59:37,  4.88s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 37302pipeline [5:59:37,  4.88s/pipeline]                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 37302/37400 [5:59:38<07:58,  4.88s/pipeline]                                                                                    Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress: 100%|█████████▉| 37303/37400 [5:59:38<07:53,  4.88s/pipeline]Optimization Progress: 100%|█████████▉| 37304/37400 [5:59:38<06:18,  3.94s/pipeline]Optimization Progress: 100%|█████████▉| 37305/37400 [5:59:51<10:36,  6.70s/pipeline]Optimization Progress: 100%|█████████▉| 37385/37400 [5:59:58<01:10,  4.72s/pipeline]
Generation 373 - Current Pareto front scores:
-1	-138764496.9455573	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002)
-2	-125125996.64749455	RandomForestRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.9500000000000001), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100)                                                                                    _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 37402pipeline [5:59:59,  4.72s/pipeline]Optimization Progress: 37402pipeline [5:59:59,  3.32s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 37402pipeline [5:59:59,  3.32s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 37402pipeline [5:59:59,  3.32s/pipeline]                                                               _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 37402pipeline [5:59:59,  3.32s/pipeline]                                                               
Optimization Progress: 100%|█████████▉| 37402/37500 [6:00:02<05:25,  3.32s/pipeline]                                                                                    360.11 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 37402/37500 [6:00:02<05:25,  3.32s/pipeline]                                                                                    
Optimization Progress: 100%|█████████▉| 37402/37500 [6:00:02<05:25,  3.32s/pipeline]                                                                                    
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 37402/37500 [6:00:02<05:25,  3.32s/pipeline]                                                                                    Best pipeline:
0. RBFSampler(gamma=0.9500000000000001)
1. RandomForestRegressor(max_features=0.7000000000000001, min_samples_leaf=8,
                      min_samples_split=14)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
