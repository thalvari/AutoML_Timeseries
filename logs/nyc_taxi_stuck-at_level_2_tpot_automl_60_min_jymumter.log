30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   6%|▌         | 6/100 [00:29<07:35,  4.85s/pipeline]Optimization Progress:  86%|████████▌ | 86/100 [00:32<00:47,  3.41s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:32<00:00,  3.41s/pipeline]Optimization Progress: 100%|██████████| 100/100 [00:32<00:00,  2.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:33<00:00,  2.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:33<00:00,  2.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:34<00:00,  2.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:36<00:00,  2.39s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  50%|█████     | 100/200 [00:39<03:59,  2.39s/pipeline]Optimization Progress:  52%|█████▏    | 103/200 [00:47<05:08,  3.18s/pipeline]Optimization Progress:  91%|█████████ | 182/200 [00:51<00:40,  2.24s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-1070276008.7063366	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-1054358671.2109156	SGDRegressor(StandardScaler(input_matrix), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:52<00:00,  2.24s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:52<00:00,  1.58s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:55<00:00,  1.58s/pipeline]Optimization Progress:  67%|██████▋   | 200/300 [01:10<02:37,  1.58s/pipeline]Optimization Progress:  67%|██████▋   | 201/300 [01:17<14:23,  8.72s/pipeline]Optimization Progress:  94%|█████████▎| 281/300 [01:24<01:56,  6.13s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-1070276008.7063366	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-1053383769.9464681	SGDRegressor(StandardScaler(input_matrix), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:24<00:00,  6.13s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:24<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 300/300 [01:25<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 300/300 [01:26<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:28<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:28<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [01:28<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=3 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:28<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=4 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 300/300 [01:28<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=5 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:28<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:28<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:29<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:29<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:29<00:00,  4.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [01:30<00:00,  4.30s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [01:30<06:23,  3.91s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [03:09<52:11, 32.28s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [03:13<06:24, 22.61s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-1070276008.7063366	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-1053383769.9464681	SGDRegressor(StandardScaler(input_matrix), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)
-3	-1040824442.014919	SGDRegressor(StandardScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [03:14<00:00, 22.61s/pipeline]Optimization Progress: 100%|██████████| 400/400 [03:14<00:00, 15.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 400/400 [03:16<00:00, 15.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 400/400 [03:17<00:00, 15.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [03:17<00:00, 15.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 400/400 [03:18<00:00, 15.86s/pipeline]Optimization Progress:  80%|████████  | 401/500 [03:19<20:36, 12.49s/pipeline]Optimization Progress:  80%|████████  | 402/500 [03:25<17:18, 10.60s/pipeline]Optimization Progress:  96%|█████████▋| 482/500 [03:28<02:13,  7.43s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-1066169130.8004043	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-1012152473.1444187	GradientBoostingRegressor(ZeroCount(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-1008584455.5274723	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-4	-986544695.6109072	LassoLarsCV(Normalizer(KNeighborsRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=0.0001), KNeighborsRegressor__n_neighbors=16, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), Normalizer__norm=l2), LassoLarsCV__normalize=False)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:30<00:00,  7.43s/pipeline]Optimization Progress: 100%|██████████| 500/500 [03:30<00:00,  5.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [03:30<00:00,  5.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [03:31<00:00,  5.23s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:35<00:00,  5.23s/pipeline]Optimization Progress:  84%|████████▍ | 503/600 [03:35<06:43,  4.16s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▍ | 503/600 [03:35<06:43,  4.16s/pipeline]Optimization Progress:  84%|████████▍ | 505/600 [07:15<56:58, 35.98s/pipeline]Optimization Progress:  98%|█████████▊| 585/600 [07:19<06:18, 25.20s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-1065878301.5978647	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-1012152473.1444187	GradientBoostingRegressor(ZeroCount(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-1008584455.5274723	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-4	-986544695.6109072	LassoLarsCV(Normalizer(KNeighborsRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=0.0001), KNeighborsRegressor__n_neighbors=16, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), Normalizer__norm=l2), LassoLarsCV__normalize=False)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [07:20<00:00, 25.20s/pipeline]Optimization Progress: 100%|██████████| 600/600 [07:20<00:00, 17.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [07:23<00:00, 17.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [07:26<00:00, 17.67s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [07:28<22:11, 13.58s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 602/700 [07:28<22:11, 13.58s/pipeline]Optimization Progress:  86%|████████▋ | 604/700 [07:58<22:22, 13.99s/pipeline]Optimization Progress:  98%|█████████▊| 684/700 [08:03<02:36,  9.81s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-1065878301.5978647	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-1012152473.1444187	GradientBoostingRegressor(ZeroCount(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 700/700 [08:03<00:00,  9.81s/pipeline]Optimization Progress: 100%|██████████| 700/700 [08:03<00:00,  6.87s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 700/700 [08:04<00:00,  6.87s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 700/700 [08:08<00:00,  6.87s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 700/700 [08:09<00:00,  6.87s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [08:15<11:20,  6.87s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [08:20<11:13,  6.87s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [08:26<11:32,  7.14s/pipeline]Optimization Progress:  98%|█████████▊| 783/800 [08:31<01:25,  5.02s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-1065878301.5978647	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-1012152473.1444187	GradientBoostingRegressor(ZeroCount(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [08:31<00:00,  5.02s/pipeline]Optimization Progress: 100%|██████████| 800/800 [08:31<00:00,  3.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [08:33<00:00,  3.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [08:35<00:00,  3.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [08:41<00:00,  3.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [08:41<00:00,  3.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [08:43<00:00,  3.51s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [08:50<05:44,  3.51s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [09:20<11:56,  7.39s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [09:28<01:28,  5.20s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-1065878301.5978647	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-1011522023.5697081	GradientBoostingRegressor(ZeroCount(input_matrix), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:30<00:00,  5.20s/pipeline]Optimization Progress: 100%|██████████| 900/900 [09:30<00:00,  3.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:31<00:00,  3.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:31<00:00,  3.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:34<00:00,  3.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [09:40<00:00,  3.68s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [10:03<20:17, 12.30s/pipeline]Optimization Progress:  98%|█████████▊| 981/1000 [10:21<02:44,  8.68s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-1065878301.5978647	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-1011522023.5697081	GradientBoostingRegressor(ZeroCount(input_matrix), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1000/1000 [10:22<00:00,  8.68s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [10:22<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 1000/1000 [10:23<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 1000/1000 [10:26<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 1000/1000 [10:26<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [10:27<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [10:29<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [10:35<00:00,  6.09s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [10:36<13:34,  8.23s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [10:36<13:34,  8.23s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [10:36<13:26,  8.23s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [11:11<14:49,  9.27s/pipeline]Optimization Progress:  99%|█████████▊| 1084/1100 [11:45<01:45,  6.62s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-1064132496.6612667	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 1100/1100 [11:46<00:00,  6.62s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [11:46<00:00,  4.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [11:47<00:00,  4.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [11:47<00:00,  4.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 1100/1100 [11:49<00:00,  4.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 1100/1100 [11:54<00:00,  4.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [11:55<00:00,  4.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [11:56<00:00,  4.66s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [11:59<11:22,  6.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1101/1200 [11:59<11:22,  6.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1102/1200 [11:59<11:15,  6.89s/pipeline]Optimization Progress:  92%|█████████▏| 1104/1200 [12:21<11:16,  7.05s/pipeline]Optimization Progress:  99%|█████████▊| 1184/1200 [12:27<01:19,  4.96s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-1063712728.8356575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [12:28<00:00,  4.96s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [12:28<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1200/1200 [12:29<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [12:32<00:00,  3.48s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [12:40<00:00,  3.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1200/1300 [12:40<05:47,  3.48s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [12:40<10:04,  6.11s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [13:01<17:04, 10.46s/pipeline]Optimization Progress:  99%|█████████▊| 1282/1300 [13:05<02:12,  7.34s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-1063712728.8356575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [13:05<00:00,  7.34s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [13:05<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1300/1300 [13:10<00:00,  5.14s/pipeline]Optimization Progress:  93%|█████████▎| 1306/1400 [13:18<06:38,  4.24s/pipeline]Optimization Progress:  93%|█████████▎| 1307/1400 [14:24<35:28, 22.88s/pipeline]Optimization Progress:  99%|█████████▉| 1387/1400 [14:29<03:28, 16.03s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-1063712728.8356575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 1400/1400 [14:36<00:00, 16.03s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [14:36<00:00, 11.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [14:43<00:00, 11.39s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [14:44<14:58,  9.17s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [14:59<17:36, 10.89s/pipeline]Optimization Progress:  99%|█████████▉| 1483/1500 [15:33<02:11,  7.75s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-1063712728.8356575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [15:41<00:00,  7.75s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [15:41<00:00,  5.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [15:47<00:00,  5.58s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [16:23<26:53, 16.30s/pipeline]Optimization Progress:  99%|█████████▉| 1581/1600 [16:35<03:37, 11.45s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-1063712728.8356575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [16:35<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [16:35<00:00, 11.45s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [16:35<00:00,  8.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 1600/1600 [16:38<00:00,  8.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [16:45<00:00,  8.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1600/1600 [16:45<00:00,  8.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [16:46<00:00,  8.02s/pipeline]Optimization Progress:  94%|█████████▍| 1601/1700 [16:50<13:13,  8.02s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [17:27<22:01, 13.48s/pipeline]Optimization Progress:  99%|█████████▉| 1682/1700 [17:48<02:51,  9.52s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-1063712728.8356575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [17:49<00:00,  9.52s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [17:49<00:00,  6.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1700/1700 [17:57<00:00,  6.68s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [18:03<14:36,  8.86s/pipeline]Optimization Progress:  95%|█████████▍| 1702/1800 [19:54<1:04:20, 39.40s/pipeline]Optimization Progress:  99%|█████████▉| 1782/1800 [19:59<08:16, 27.60s/pipeline]  
Generation 17 - Current Pareto front scores:
-1	-1063527380.7508093	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 1800/1800 [20:00<00:00, 27.60s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [20:00<00:00, 19.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [20:06<00:00, 19.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [20:13<00:00, 19.34s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [20:13<23:58, 14.83s/pipeline]Optimization Progress:  95%|█████████▍| 1804/1900 [20:59<38:33, 24.10s/pipeline]Optimization Progress:  99%|█████████▉| 1884/1900 [21:37<04:32, 17.01s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-1063527380.7508093	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 1900/1900 [21:50<00:00, 17.01s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [21:50<00:00, 12.14s/pipeline]Optimization Progress:  95%|█████████▌| 1901/2000 [21:51<15:00,  9.09s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [22:35<31:54, 19.53s/pipeline]Optimization Progress:  99%|█████████▉| 1982/2000 [22:56<04:07, 13.75s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-1063527380.7508093	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 2000/2000 [23:01<00:00, 13.75s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [23:01<00:00,  9.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [23:01<00:00,  9.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [23:05<00:00,  9.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 2000/2000 [23:06<00:00,  9.71s/pipeline]Optimization Progress:  95%|█████████▌| 2002/2100 [23:10<13:21,  8.18s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [24:37<51:29, 31.85s/pipeline]Optimization Progress:  99%|█████████▉| 2083/2100 [24:56<06:20, 22.37s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-1063527380.7508093	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [24:57<00:00, 22.37s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [24:57<00:00, 15.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2100/2100 [24:58<00:00, 15.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [25:04<00:00, 15.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [25:05<00:00, 15.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [25:08<00:00, 15.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [25:08<00:00, 15.67s/pipeline]Optimization Progress:  96%|█████████▌| 2101/2200 [25:12<25:29, 15.45s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [26:05<43:46, 26.80s/pipeline]Optimization Progress:  99%|█████████▉| 2182/2200 [26:31<05:39, 18.86s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2200/2200 [26:32<00:00, 18.86s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [26:32<00:00, 13.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 2200/2200 [26:39<00:00, 13.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [26:40<00:00, 13.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [26:46<00:00, 13.21s/pipeline]Optimization Progress:  96%|█████████▌| 2205/2300 [26:47<16:06, 10.17s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2205/2300 [26:47<16:06, 10.17s/pipeline]Optimization Progress:  96%|█████████▌| 2207/2300 [27:45<24:33, 15.85s/pipeline]Optimization Progress:  99%|█████████▉| 2287/2300 [28:19<02:25, 11.22s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 2300/2300 [28:23<00:00, 11.22s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [28:23<00:00,  7.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 2300/2300 [28:32<00:00,  7.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2300/2300 [28:32<00:00,  7.93s/pipeline]Optimization Progress:  96%|█████████▌| 2301/2400 [29:14<34:50, 21.12s/pipeline]Optimization Progress:  99%|█████████▉| 2381/2400 [29:34<04:42, 14.86s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2400/2400 [29:37<00:00, 14.86s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [29:37<00:00, 10.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [29:41<00:00, 10.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2400/2400 [29:44<00:00, 10.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [29:46<00:00, 10.46s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [30:33<39:47, 24.12s/pipeline]Optimization Progress:  99%|█████████▉| 2481/2500 [31:19<05:24, 17.06s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [31:27<00:00, 17.06s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [31:27<00:00, 12.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [31:30<00:00, 12.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [31:32<00:00, 12.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [31:35<00:00, 12.06s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [31:38<16:27, 10.07s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [32:32<37:55, 23.46s/pipeline]Optimization Progress:  99%|█████████▉| 2583/2600 [33:07<04:41, 16.55s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)Optimization Progress: 100%|██████████| 2600/2600 [33:27<00:00, 11.95s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2601/2700 [33:27<19:43, 11.95s/pipeline]Optimization Progress:  96%|█████████▋| 2603/2700 [38:29<1:02:19, 38.55s/pipeline]                                                                                  Skipped pipeline #2650 due to time out. Continuing to the next pipeline.
Optimization Progress:  98%|█████████▊| 2650/2700 [38:29<32:07, 38.55s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  99%|█████████▉| 2684/2700 [38:53<07:13, 27.07s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2701pipeline [38:56, 27.07s/pipeline]Optimization Progress: 2701pipeline [38:56, 19.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2701pipeline [38:56, 19.00s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2701pipeline [39:07, 19.00s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [39:12<23:50, 14.90s/pipeline]Optimization Progress:  97%|█████████▋| 2705/2800 [44:13<2:39:30, 100.74s/pipeline]                                                                                   Skipped pipeline #2718 due to time out. Continuing to the next pipeline.
Optimization Progress:  97%|█████████▋| 2718/2800 [44:13<2:17:40, 100.74s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 2786/2800 [44:49<16:29, 70.65s/pipeline]   
Generation 27 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-895437518.5644519	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=max), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 2802pipeline [44:52, 70.65s/pipeline]Optimization Progress: 2802pipeline [44:52, 49.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2802pipeline [44:53, 49.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2802pipeline [44:55, 49.51s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 2802pipeline [44:56, 49.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 2802pipeline [44:57, 49.51s/pipeline]Optimization Progress:  97%|█████████▋| 2804/2900 [45:05<58:37, 36.64s/pipeline]Optimization Progress:  97%|█████████▋| 2805/2900 [46:08<1:10:26, 44.49s/pipeline]Optimization Progress:  99%|█████████▉| 2885/2900 [46:57<07:49, 31.33s/pipeline]  
Generation 28 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-855995272.2345736	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=l1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2902pipeline [46:59, 31.33s/pipeline]Optimization Progress: 2902pipeline [46:59, 21.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2902pipeline [47:09, 21.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2902pipeline [47:11, 21.97s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [47:16<32:55, 20.37s/pipeline]Optimization Progress:  97%|█████████▋| 2904/3000 [48:25<56:10, 35.11s/pipeline]Optimization Progress:  99%|█████████▉| 2984/3000 [49:38<06:37, 24.85s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-1063395733.8564091	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-855995272.2345736	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=l1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3002pipeline [49:39, 24.85s/pipeline]Optimization Progress: 3002pipeline [49:39, 17.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3002pipeline [49:39, 17.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3002pipeline [49:46, 17.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3002pipeline [49:48, 17.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 3002pipeline [49:48, 17.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3002pipeline [49:51, 17.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3002pipeline [49:55, 17.41s/pipeline]Optimization Progress:  97%|█████████▋| 3005/3100 [49:56<21:59, 13.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3005/3100 [49:56<21:59, 13.89s/pipeline]Optimization Progress:  97%|█████████▋| 3007/3100 [50:52<28:13, 18.21s/pipeline]Optimization Progress: 100%|█████████▉| 3087/3100 [51:20<02:47, 12.85s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-1063382790.5801321	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-855995272.2345736	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=l1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 3102pipeline [51:24, 12.85s/pipeline]Optimization Progress: 3102pipeline [51:24,  9.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 3102pipeline [51:30,  9.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3102pipeline [51:35,  9.06s/pipeline]Optimization Progress:  97%|█████████▋| 3106/3200 [51:38<11:37,  7.42s/pipeline]Optimization Progress:  97%|█████████▋| 3107/3200 [52:54<43:17, 27.93s/pipeline]Optimization Progress: 100%|█████████▉| 3187/3200 [53:15<04:15, 19.63s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-1063382790.5801321	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-855995272.2345736	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=l1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 3202pipeline [53:17, 19.63s/pipeline]Optimization Progress: 3202pipeline [53:17, 13.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 3202pipeline [53:21, 13.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 3202pipeline [53:26, 13.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 3202pipeline [53:27, 13.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 3202pipeline [53:32, 13.78s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [53:34<19:32, 12.21s/pipeline]Optimization Progress:  97%|█████████▋| 3205/3300 [54:59<53:47, 33.98s/pipeline]Optimization Progress: 100%|█████████▉| 3285/3300 [55:53<05:59, 23.99s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-1063382790.5801321	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-855995272.2345736	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=l1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 3302pipeline [55:59, 23.99s/pipeline]Optimization Progress: 3302pipeline [55:59, 16.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3302pipeline [56:03, 16.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 3302pipeline [56:05, 16.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3302pipeline [56:06, 16.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3302pipeline [56:11, 16.89s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [56:12<25:20, 15.68s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [57:25<52:49, 33.01s/pipeline]Optimization Progress: 100%|█████████▉| 3384/3400 [57:44<06:10, 23.18s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-1063382790.5801321	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-855995272.2345736	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=l1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3402pipeline [57:57, 23.18s/pipeline]Optimization Progress: 3402pipeline [57:57, 16.44s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [58:02<21:10, 13.10s/pipeline]Optimization Progress:  97%|█████████▋| 3404/3500 [58:36<30:57, 19.35s/pipeline]Optimization Progress: 100%|█████████▉| 3484/3500 [58:54<03:37, 13.61s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-1063382790.5801321	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-1005599532.8029515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.0, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-855995272.2345736	GradientBoostingRegressor(Normalizer(RidgeCV(input_matrix), Normalizer__norm=l1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3502pipeline [58:57, 13.61s/pipeline]Optimization Progress: 3502pipeline [58:57,  9.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 3502pipeline [58:58,  9.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 3502pipeline [58:59,  9.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3502pipeline [59:08,  9.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3502pipeline [59:08,  9.57s/pipeline]Optimization Progress:  97%|█████████▋| 3504/3600 [59:10<13:56,  8.71s/pipeline]Optimization Progress:  97%|█████████▋| 3505/3600 [59:55<31:15, 19.74s/pipeline]                                                                                
Optimization Progress: 100%|█████████▉| 3584/3600 [59:56<05:15, 19.74s/pipeline]                                                                                60.05 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 3584/3600 [59:56<05:15, 19.74s/pipeline]                                                                                
Optimization Progress: 100%|█████████▉| 3584/3600 [59:56<05:15, 19.74s/pipeline]                                                                                
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 3584/3600 [59:56<05:15, 19.74s/pipeline]                                                                                Best pipeline:
0. StackingEstimator(estimator=LassoLarsCV(normalize=False))
1. StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.9, tol=0.001))
2. StackingEstimator(estimator=KNeighborsRegressor(n_neighbors=4,
                                                weights='distance'))
3. StackingEstimator(estimator=KNeighborsRegressor(n_neighbors=16, p=1,
                                                weights='distance'))
4. OneHotEncoder(minimum_fraction=0.1, sparse=False)
5. RobustScaler()
6. SelectFromModel(estimator=ExtraTreesRegressor(max_features=0.25), threshold=0.1)
7. Normalizer()
8. ExtraTreesRegressor(bootstrap=True, max_features=0.4, min_samples_leaf=14,
                    min_samples_split=9)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
