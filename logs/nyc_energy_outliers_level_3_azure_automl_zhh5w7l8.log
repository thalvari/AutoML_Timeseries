Running on local machine
Parent Run ID: AutoML_5fb753ae-a0a4-47eb-a8e9-6f8f1127c43f

Current status: DatasetFeaturization. Beginning to featurize the dataset.
Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.
Heuristic parameters: Target_Lag = '[0]', Target_Rolling_Window = '0', Max_Horizon = '24'.
WARNING - Converting non-string tag to string: (forecasting_target_lags: [0])
WARNING - Converting non-string tag to string: (forecasting_target_rolling_window_size: 0)
WARNING - Converting non-string tag to string: (forecasting_max_horizon: 24)
Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.

****************************************************************************************************
DATA GUARDRAILS: 

TYPE:         Frequency detection
STATUS:       PASSED
DESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.
              

****************************************************************************************************

TYPE:         Missing feature values imputation
STATUS:       PASSED
DESCRIPTION:  No feature missing values were detected in the training data.
              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization

****************************************************************************************************

TYPE:         Memory Issues Detection
STATUS:       PASSED
DESCRIPTION:  The selected horizon, lag and rolling window values were analyzed, and no potential memory issues were detected.
              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration

****************************************************************************************************
Current status: ModelSelection. Beginning model selection.

****************************************************************************************************
ITERATION: The iteration being evaluated.
PIPELINE: A summary description of the pipeline being evaluated.
DURATION: Time taken for the current iteration.
METRIC: The result of computing score on the fitted pipeline.
BEST: The best observed score thus far.
****************************************************************************************************

 ITERATION   PIPELINE                                       DURATION      METRIC      BEST
         0   MaxAbsScaler DecisionTree                      0:00:25       0.1528    0.1528
         1   RobustScaler ElasticNet                        0:00:24       0.1522    0.1522
         2   RobustScaler ElasticNet                        0:00:24       0.1503    0.1503
         3   RobustScaler ElasticNet                        0:00:24       0.1520    0.1503
         4   RobustScaler ElasticNet                        0:00:25       0.1450    0.1450
         5   MinMaxScaler DecisionTree                      0:00:24       0.1726    0.1450
         6   StandardScalerWrapper ElasticNet               0:00:24       0.1500    0.1450
         7   StandardScalerWrapper DecisionTree             0:00:23       0.1668    0.1450
         8   RobustScaler DecisionTree                      0:00:24       0.1739    0.1450
         9   StandardScalerWrapper DecisionTree             0:00:24       0.1723    0.1450
        10   MaxAbsScaler SGD                               0:00:25       0.1738    0.1450
        11   StandardScalerWrapper DecisionTree             0:00:23       0.1476    0.1450
        12   MinMaxScaler DecisionTree                      0:00:24       0.1579    0.1450
        13   MinMaxScaler SGD                               0:00:23       0.1549    0.1450
        14   RobustScaler DecisionTree                      0:00:26       0.1529    0.1450
        15   MinMaxScaler DecisionTree                      0:00:25       0.2204    0.1450
        16   StandardScalerWrapper DecisionTree             0:00:24       0.1663    0.1450
        17   StandardScalerWrapper SGD                      0:00:28       0.6110    0.1450
        18   RobustScaler ElasticNet                        0:00:24       0.1436    0.1436
        19   MinMaxScaler DecisionTree                      0:00:23       0.1532    0.1436
        20   MinMaxScaler ExtremeRandomTrees                0:00:57       0.1530    0.1436
        21   MinMaxScaler ExtremeRandomTrees                0:00:39       0.1403    0.1403
        22   MinMaxScaler RandomForest                      0:00:35       0.1450    0.1403
        23   StandardScalerWrapper RandomForest             0:00:37       0.1488    0.1403
        24   StandardScalerWrapper DecisionTree             0:00:24       0.1501    0.1403
        25   StandardScalerWrapper ExtremeRandomTrees       0:01:10       0.1382    0.1382
        26   RobustScaler ExtremeRandomTrees                0:01:27       0.1430    0.1382
        27   StandardScalerWrapper ExtremeRandomTrees       0:00:48       0.1400    0.1382
        28   WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_5fb753ae-a0a4-47eb-a8e9-6f8f1127c43f_28/outputs/internal_cross_validated_models.pkl?sv=2019-02-02&sr=b&sig=tgd4L3%2BSEj5CaI2DNQBJYzyROK8j16OzkObhEKWebGY%3D&st=2020-08-26T05%3A20%3A31Z&se=2020-08-27T05%3A30%3A31Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
RobustScaler ExtremeRandomTrees                0:03:46       0.1381    0.1381
        29   StandardScalerWrapper RandomForest             0:00:41       0.1457    0.1381
        30   StandardScalerWrapper ExtremeRandomTrees       0:00:41       0.1450    0.1381
        31   RobustScaler ExtremeRandomTrees                0:01:24       0.1466    0.1381
        32   StandardScalerWrapper ExtremeRandomTrees       0:00:38       0.1444    0.1381
        33   StandardScalerWrapper ExtremeRandomTrees       0:01:12       0.1393    0.1381
        34   StandardScalerWrapper RandomForest             0:00:39       0.1418    0.1381
        35   RobustScaler ExtremeRandomTrees                0:01:13       0.1398    0.1381
        36   StandardScalerWrapper ExtremeRandomTrees       0:00:41       0.1398    0.1381
        37   StandardScalerWrapper ExtremeRandomTrees       0:00:37       0.1403    0.1381
        38   StandardScalerWrapper RandomForest             0:00:38       0.1427    0.1381
        39   WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
WARNING - Connection pool is full, discarding connection: timeseriesws4297462746.blob.core.windows.net
VotingEnsemble                                 0:03:42       0.1290    0.1290
Stopping criteria reached at iteration 40. Ending experiment.
****************************************************************************************************
Current status: BestRunExplainModel. Best run model explanations started
Current status: ModelExplanationDataSetSetup. Model explanations data setup completed
Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations
Current status: EngineeredFeatureExplanations. Computation of engineered features started
Current status: EngineeredFeatureExplanations. Computation of engineered features completed
Current status: BestRunExplainModel. Best run model explanations completed
****************************************************************************************************
[('timeseriestransformer', TimeSeriesTransformer(featurization_config=None,
           pipeline_type=<TimeSeriesPipelineType.FULL: 1>)), ('prefittedsoftvotingregressor', PreFittedSoftVotingRegressor(estimators=[('28', Pipeline(memory=None,
     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=[10, 90], with_centering=True,
       with_scaling=True)), ('extratreesregressor', ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=None,
          max_features=None, max_leaf_n...    min_weight_fraction_leaf=0.0, presort=False, random_state=None,
           splitter='best'))]))],
               flatten_transform=None,
               weights=[0.21428571428571427, 0.14285714285714285, 0.07142857142857142, 0.2857142857142857, 0.07142857142857142, 0.07142857142857142, 0.14285714285714285]))]
