30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   9%|▉         | 9/100 [00:28<04:50,  3.20s/pipeline]Optimization Progress:  89%|████████▉ | 89/100 [00:31<00:24,  2.25s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:33<00:00,  2.25s/pipeline]Optimization Progress: 100%|██████████| 100/100 [00:33<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:33<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:34<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:36<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:38<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:38<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:38<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 100/100 [00:39<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:39<00:00,  1.61s/pipeline]Optimization Progress:  52%|█████▎    | 105/200 [00:39<02:25,  1.53s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▎    | 105/200 [00:39<02:25,  1.53s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  53%|█████▎    | 106/200 [00:39<02:23,  1.53s/pipeline]Optimization Progress:  54%|█████▍    | 108/200 [01:09<06:12,  4.05s/pipeline]Optimization Progress:  94%|█████████▍| 188/200 [01:15<00:34,  2.86s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-566432181.9912765	RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.5, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [01:16<00:00,  2.86s/pipeline]Optimization Progress: 100%|██████████| 200/200 [01:16<00:00,  2.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [01:16<00:00,  2.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [01:18<00:00,  2.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:19<00:00,  2.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:21<00:00,  2.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:23<00:00,  2.01s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 200/200 [01:23<00:00,  2.01s/pipeline]Optimization Progress:  67%|██████▋   | 202/300 [01:24<04:19,  2.65s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  67%|██████▋   | 202/300 [01:24<04:19,  2.65s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 203/300 [01:24<04:16,  2.65s/pipeline]Optimization Progress:  68%|██████▊   | 205/300 [02:01<08:47,  5.56s/pipeline]Optimization Progress:  95%|█████████▌| 285/300 [02:07<00:58,  3.91s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-554952926.7587936	RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.5, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [02:07<00:00,  3.91s/pipeline]Optimization Progress: 100%|██████████| 300/300 [02:07<00:00,  2.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [16:22:46] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f2398e76dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f2398f87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f2398f94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f2398f7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f2398e68f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f19a6c239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f19a6c23067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f19a6c3b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f19a6c3bcb4]

.
Optimization Progress: 100%|██████████| 300/300 [02:07<00:00,  2.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [02:09<00:00,  2.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [02:11<00:00,  2.74s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [02:20<04:31,  2.74s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [03:33<24:17, 14.87s/pipeline]Optimization Progress:  96%|█████████▌| 382/400 [03:38<03:07, 10.43s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-554952926.7587936	RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.5, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 400/400 [03:45<00:00, 10.43s/pipeline]Optimization Progress: 100%|██████████| 400/400 [03:45<00:00,  7.41s/pipeline]Optimization Progress:  80%|████████  | 402/500 [03:49<09:36,  5.88s/pipeline]Optimization Progress:  81%|████████  | 403/500 [06:26<1:22:42, 51.16s/pipeline]Optimization Progress:  97%|█████████▋| 483/500 [06:33<10:09, 35.84s/pipeline]  
Generation 4 - Current Pareto front scores:
-1	-554952926.7587936	RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.5, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-546262891.2941177	AdaBoostRegressor(StandardScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100)                                                                              _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [06:35<00:00, 35.84s/pipeline]Optimization Progress: 100%|██████████| 500/500 [06:35<00:00, 25.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 500/500 [06:36<00:00, 25.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [06:38<00:00, 25.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [16:27:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f2398e76dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f2398f87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f2398f94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f2398f7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f2398e68f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f19a6c239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f19a6c23067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f19a6c3b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f19a6c3bcb4]

.
Optimization Progress: 100%|██████████| 500/500 [06:41<00:00, 25.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [06:44<00:00, 25.11s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [06:46<34:40, 21.02s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▎ | 501/600 [06:46<34:40, 21.02s/pipeline]Optimization Progress:  84%|████████▍ | 503/600 [07:45<38:09, 23.60s/pipeline]Optimization Progress:  97%|█████████▋| 583/600 [11:32<04:55, 17.37s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-554952926.7587936	RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.5, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-546262891.2941177	AdaBoostRegressor(StandardScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [11:38<00:00, 17.37s/pipeline]Optimization Progress: 100%|██████████| 600/600 [11:38<00:00, 12.26s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [11:39<00:00, 12.26s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [11:40<00:00, 12.26s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [11:41<00:00, 12.26s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [11:44<17:24, 10.55s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [13:49<1:13:18, 44.89s/pipeline]Optimization Progress:  97%|█████████▋| 682/700 [13:55<09:25, 31.44s/pipeline]  
Generation 6 - Current Pareto front scores:
-1	-554952926.7587936	RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.5, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-2	-552422526.8890412	GradientBoostingRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=14, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-546262891.2941177	AdaBoostRegressor(StandardScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [13:56<00:00, 31.44s/pipeline]Optimization Progress: 100%|██████████| 700/700 [13:56<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [16:34:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f2398e76dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f2398f87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f2398f94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f2398f7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f2398e68f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f19a6c239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f19a6c23067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f19a6c3b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f19a6c3bcb4]

.
Optimization Progress: 100%|██████████| 700/700 [13:58<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 700/700 [13:59<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [13:59<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [14:02<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [14:02<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [14:04<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [14:05<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 700/700 [14:05<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [14:06<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 700/700 [14:07<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [14:07<00:00, 22.02s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [14:07<00:00, 22.02s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [14:08<28:09, 17.23s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  88%|████████▊ | 702/800 [14:08<28:09, 17.23s/pipeline]Optimization Progress:  88%|████████▊ | 704/800 [15:09<33:54, 21.20s/pipeline]Optimization Progress:  98%|█████████▊| 784/800 [15:13<03:57, 14.85s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-554841885.493042	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-548224007.899863	AdaBoostRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100)
-3	-546262891.2941177	AdaBoostRegressor(StandardScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 800/800 [15:15<00:00, 14.85s/pipeline]Optimization Progress: 100%|██████████| 800/800 [15:15<00:00, 10.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [15:20<00:00, 10.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [15:20<00:00, 10.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 800/800 [15:22<00:00, 10.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [15:24<00:00, 10.42s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  89%|████████▉ | 800/900 [15:27<17:22, 10.42s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [15:27<18:22, 11.13s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 801/900 [15:27<18:22, 11.13s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [15:41<15:55,  9.85s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [15:53<01:57,  6.94s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-554841885.493042	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-541381020.8427784	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [15:54<00:00,  6.94s/pipeline]Optimization Progress: 100%|██████████| 900/900 [15:54<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [16:04<00:00,  4.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 900/900 [16:04<00:00,  4.88s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [16:06<08:22,  5.13s/pipeline]                                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 902/1000 [16:06<08:22,  5.13s/pipeline]Optimization Progress:  90%|█████████ | 904/1000 [18:07<34:53, 21.81s/pipeline]Optimization Progress:  98%|█████████▊| 984/1000 [18:56<04:07, 15.45s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-554841885.493042	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-541381020.8427784	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [18:59<00:00, 15.45s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [18:59<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [19:03<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1000/1000 [19:03<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [19:04<00:00, 10.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [19:04<00:00, 10.88s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [19:09<13:20,  8.34s/pipeline]Optimization Progress:  91%|█████████▏| 1005/1100 [20:10<38:02, 24.03s/pipeline]Optimization Progress:  99%|█████████▊| 1085/1100 [20:22<04:12, 16.87s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-551398568.1175387	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-539746030.8353492	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [20:22<00:00, 16.87s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [20:22<00:00, 11.82s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1100/1100 [20:24<00:00, 11.82s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 1100/1100 [20:29<00:00, 11.82s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [20:34<16:19, 10.00s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [21:32<39:43, 24.57s/pipeline]Optimization Progress:  99%|█████████▊| 1183/1200 [21:40<04:52, 17.23s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-551398568.1175387	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-539746030.8353492	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [21:47<00:00, 17.23s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [21:47<00:00, 12.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [21:48<00:00, 12.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [21:48<00:00, 12.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [21:51<00:00, 12.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 1200/1200 [21:52<00:00, 12.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1200/1300 [21:52<20:17, 12.18s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [21:52<16:45, 10.16s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [22:03<17:01, 10.42s/pipeline]Optimization Progress:  99%|█████████▊| 1282/1300 [22:11<02:11,  7.33s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-542709798.6872083	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-2	-539746030.8353492	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [22:15<00:00,  7.33s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [22:15<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1300/1300 [22:16<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1300/1300 [22:19<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 1300/1300 [22:20<00:00,  5.20s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [22:21<00:00,  5.20s/pipeline]Optimization Progress:  93%|█████████▎| 1301/1400 [22:24<10:17,  6.24s/pipeline]Optimization Progress:  93%|█████████▎| 1302/1400 [22:33<11:49,  7.24s/pipeline]Optimization Progress:  99%|█████████▊| 1382/1400 [22:51<01:32,  5.14s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 1400/1400 [22:51<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [22:51<00:00,  3.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 1400/1400 [22:53<00:00,  3.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [22:54<00:00,  3.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [22:55<00:00,  3.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [22:56<00:00,  3.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [22:56<00:00,  3.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [22:58<00:00,  3.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 1400/1400 [22:59<00:00,  3.60s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1401/1500 [23:02<05:56,  3.60s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [23:10<05:52,  3.60s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [24:21<18:31, 11.46s/pipeline]Optimization Progress:  99%|█████████▉| 1483/1500 [24:26<02:16,  8.04s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [24:27<00:00,  8.04s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [24:27<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1500/1500 [24:27<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [24:27<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 1500/1500 [24:27<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [24:29<00:00,  5.65s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [24:37<08:57,  5.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1502/1600 [24:37<08:57,  5.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1503/1600 [24:37<08:52,  5.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1504/1600 [24:37<08:46,  5.49s/pipeline]Optimization Progress:  94%|█████████▍| 1506/1600 [24:46<07:03,  4.50s/pipeline]Optimization Progress:  99%|█████████▉| 1586/1600 [24:50<00:44,  3.17s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 1600/1600 [24:56<00:00,  3.17s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [24:56<00:00,  2.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [24:58<00:00,  2.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1600/1600 [24:59<00:00,  2.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [25:00<00:00,  2.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [25:01<00:00,  2.34s/pipeline]Optimization Progress:  94%|█████████▍| 1604/1700 [25:02<03:19,  2.08s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [25:10<05:59,  3.79s/pipeline]Optimization Progress:  99%|█████████▉| 1685/1700 [25:14<00:39,  2.67s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [25:18<00:00,  2.67s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [25:18<00:00,  1.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [25:18<00:00,  1.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [25:20<00:00,  1.95s/pipeline]Optimization Progress:  95%|█████████▍| 1702/1800 [25:28<04:33,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1702/1800 [25:28<04:33,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1703/1800 [25:28<04:30,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1704/1800 [25:28<04:27,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1705/1800 [25:28<04:25,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1706/1800 [25:28<04:22,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1707/1800 [25:28<04:19,  2.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1708/1800 [25:28<04:16,  2.79s/pipeline]Optimization Progress:  95%|█████████▌| 1710/1800 [26:29<06:23,  4.27s/pipeline]Optimization Progress:  99%|█████████▉| 1790/1800 [26:35<00:30,  3.01s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-537994333.4223739	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [26:36<00:00,  3.01s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [26:36<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [26:36<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [26:36<00:00,  2.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1800/1900 [26:49<03:33,  2.13s/pipeline]Optimization Progress:  95%|█████████▍| 1801/1900 [26:49<08:59,  5.45s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1801/1900 [26:49<08:59,  5.45s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [26:57<08:08,  5.03s/pipeline]Optimization Progress:  99%|█████████▉| 1883/1900 [27:03<01:00,  3.55s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [27:05<00:00,  3.55s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [27:05<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [27:05<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [27:08<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [27:12<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [27:14<00:00,  2.51s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [27:17<05:51,  3.59s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [28:17<33:12, 20.54s/pipeline]Optimization Progress:  99%|█████████▉| 1983/2000 [29:16<04:08, 14.60s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [29:20<00:00, 14.60s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [29:20<00:00, 10.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [29:20<00:00, 10.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [29:21<00:00, 10.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 2000/2000 [29:22<00:00, 10.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 2000/2000 [29:27<00:00, 10.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [29:31<00:00, 10.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [29:31<00:00, 10.29s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [29:32<13:36,  8.41s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [29:41<13:27,  8.41s/pipeline]Optimization Progress:  99%|█████████▉| 2084/2100 [29:46<01:34,  5.91s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-530417357.1068018	GradientBoostingRegressor(ElasticNetCV(MaxAbsScaler(input_matrix), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-526847998.41157484	GradientBoostingRegressor(FastICA(RidgeCV(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.2, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10)), FastICA__tol=0.25), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [29:47<00:00,  5.91s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [29:47<00:00,  4.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 2100/2100 [29:47<00:00,  4.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [29:48<00:00,  4.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2100/2100 [29:59<00:00,  4.16s/pipeline]Optimization Progress:  96%|█████████▌| 2104/2200 [30:02<06:24,  4.01s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2104/2200 [30:02<06:24,  4.01s/pipeline]Optimization Progress:  96%|█████████▌| 2106/2200 [30:20<08:38,  5.51s/pipeline]Optimization Progress:  99%|█████████▉| 2186/2200 [30:27<00:54,  3.89s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-530417357.1068018	GradientBoostingRegressor(ElasticNetCV(MaxAbsScaler(input_matrix), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-526847998.41157484	GradientBoostingRegressor(FastICA(RidgeCV(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.2, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10)), FastICA__tol=0.25), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [30:34<00:00,  3.89s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [30:34<00:00,  2.87s/pipeline]Optimization Progress:  96%|█████████▌| 2204/2300 [30:43<04:18,  2.69s/pipeline]Optimization Progress:  96%|█████████▌| 2205/2300 [30:53<07:54,  4.99s/pipeline]Optimization Progress:  99%|█████████▉| 2285/2300 [31:00<00:52,  3.52s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2300/2300 [31:03<00:00,  3.52s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [31:03<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [31:07<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 2300/2300 [31:09<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [31:10<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [31:14<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2300/2300 [31:15<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 2300/2300 [31:16<00:00,  2.52s/pipeline]Optimization Progress:  96%|█████████▌| 2301/2400 [31:16<09:35,  5.82s/pipeline]Optimization Progress:  96%|█████████▌| 2302/2400 [32:29<42:14, 25.86s/pipeline]Optimization Progress:  99%|█████████▉| 2382/2400 [32:35<05:26, 18.13s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [32:36<00:00, 18.13s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [32:36<00:00, 12.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2400/2400 [32:39<00:00, 12.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [32:40<00:00, 12.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [32:40<00:00, 12.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 2400/2400 [32:45<00:00, 12.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [32:46<00:00, 12.70s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [32:50<00:00, 12.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 2400/2400 [32:50<00:00, 12.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [32:50<00:00, 12.70s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [32:51<21:56, 13.30s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2401/2500 [32:51<21:56, 13.30s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [33:00<17:11, 10.63s/pipeline]Optimization Progress:  99%|█████████▉| 2483/2500 [33:07<02:06,  7.47s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [33:07<00:00,  7.47s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [33:07<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [33:07<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 2500/2500 [33:07<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [33:08<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [33:08<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 2500/2500 [33:09<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [33:16<00:00,  5.23s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [33:20<00:00,  5.23s/pipeline]Optimization Progress:  96%|█████████▌| 2501/2600 [34:03<33:47, 20.48s/pipeline]Optimization Progress:  99%|█████████▉| 2581/2600 [34:08<04:32, 14.36s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [34:17<00:00, 14.36s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [34:17<00:00, 10.18s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [34:24<13:29,  8.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [34:24<13:29,  8.26s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [34:33<11:27,  7.16s/pipeline]Optimization Progress:  99%|█████████▉| 2684/2700 [34:47<01:21,  5.07s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [34:55<00:00,  5.07s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [34:55<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [34:56<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2700/2700 [34:57<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [34:57<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 2700/2700 [35:00<00:00,  3.69s/pipeline]Optimization Progress:  96%|█████████▋| 2701/2800 [35:02<08:02,  4.87s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2701/2800 [35:02<08:02,  4.87s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [35:40<14:38,  9.06s/pipeline]Optimization Progress:  99%|█████████▉| 2783/2800 [35:45<01:48,  6.36s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [35:49<00:00,  6.36s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [35:49<00:00,  4.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [35:51<00:00,  4.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [35:51<00:00,  4.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [35:58<00:00,  4.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2800/2800 [35:58<00:00,  4.51s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [36:02<08:21,  5.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2802/2900 [36:02<08:21,  5.12s/pipeline]Optimization Progress:  97%|█████████▋| 2804/2900 [36:29<12:19,  7.71s/pipeline]Optimization Progress:  99%|█████████▉| 2884/2900 [36:37<01:26,  5.42s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-539431230.1008809	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [36:39<00:00,  5.42s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [36:39<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2900/2900 [36:41<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 2900/2900 [36:44<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [36:44<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [36:46<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 2900/2900 [36:49<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [36:49<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2900/2900 [36:50<00:00,  3.84s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [36:53<06:38,  4.11s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2903/3000 [36:53<06:38,  4.11s/pipeline]Optimization Progress:  97%|█████████▋| 2905/3000 [37:14<09:24,  5.95s/pipeline]Optimization Progress: 100%|█████████▉| 2985/3000 [37:22<01:02,  4.19s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3000/3000 [37:24<00:00,  4.19s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [37:24<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [37:24<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3000/3000 [37:24<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3000/3000 [37:24<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [37:28<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 3000/3000 [37:31<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [37:32<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 3000/3000 [37:32<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [37:33<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [37:34<00:00,  2.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 3000/3000 [37:35<00:00,  2.97s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [37:39<11:06,  6.73s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [37:48<12:13,  7.48s/pipeline]Optimization Progress:  99%|█████████▉| 3082/3100 [37:56<01:34,  5.27s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 3100/3100 [37:57<00:00,  5.27s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [37:57<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [37:58<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3100/3100 [37:58<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [38:06<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [38:08<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [38:09<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 3100/3100 [38:11<00:00,  3.71s/pipeline]Optimization Progress:  97%|█████████▋| 3102/3200 [38:11<07:38,  4.68s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [38:20<09:22,  5.80s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [38:41<01:10,  4.14s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [38:42<00:00,  4.14s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [38:42<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 3200/3200 [38:42<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [38:43<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 3200/3200 [38:48<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [38:48<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [38:50<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [38:50<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [38:51<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [38:53<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [38:53<00:00,  2.91s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3200/3300 [38:55<04:51,  2.91s/pipeline]Optimization Progress:  97%|█████████▋| 3201/3300 [38:55<09:40,  5.87s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [39:36<27:04, 16.57s/pipeline]Optimization Progress:  99%|█████████▉| 3282/3300 [40:08<03:30, 11.72s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 3300/3300 [40:09<00:00, 11.72s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [40:09<00:00,  8.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 3300/3300 [40:09<00:00,  8.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3300/3300 [40:10<00:00,  8.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3300/3300 [40:10<00:00,  8.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3300/3300 [40:10<00:00,  8.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [40:21<00:00,  8.22s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [40:23<12:48,  7.85s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [40:33<13:43,  8.49s/pipeline]Optimization Progress: 100%|█████████▉| 3383/3400 [40:38<01:41,  5.97s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 3400/3400 [40:40<00:00,  5.97s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [40:40<00:00,  4.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3400/3400 [40:42<00:00,  4.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3400/3400 [40:44<00:00,  4.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [40:45<00:00,  4.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3400/3400 [40:46<00:00,  4.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [40:46<00:00,  4.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 3400/3400 [40:47<00:00,  4.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [40:49<00:00,  4.20s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [40:55<08:32,  5.23s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [41:10<13:17,  8.22s/pipeline]Optimization Progress: 100%|█████████▉| 3483/3500 [41:16<01:38,  5.78s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3500/3500 [41:19<00:00,  5.78s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [41:19<00:00,  4.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [41:20<00:00,  4.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3500/3500 [41:24<00:00,  4.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [41:26<00:00,  4.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [41:27<00:00,  4.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3500/3500 [41:33<00:00,  4.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [41:34<00:00,  4.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3500/3600 [41:34<06:49,  4.09s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [41:34<12:05,  7.33s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [42:37<39:20, 24.09s/pipeline]Optimization Progress: 100%|█████████▉| 3582/3600 [42:42<05:03, 16.88s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-510027045.58247566	GradientBoostingRegressor(Nystroem(RidgeCV(input_matrix), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=3), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [42:48<00:00, 16.88s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [42:48<00:00, 11.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [42:56<00:00, 11.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 3600/3600 [42:58<00:00, 11.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [43:01<00:00, 11.92s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [44:07<52:49, 32.02s/pipeline]Optimization Progress:  99%|█████████▉| 3681/3700 [44:15<07:06, 22.44s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-532445224.01118165	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [44:18<00:00, 22.44s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [44:18<00:00, 15.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 3700/3700 [44:20<00:00, 15.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [44:24<00:00, 15.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 3700/3700 [44:24<00:00, 15.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 3700/3700 [44:42<00:00, 15.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [44:43<00:00, 15.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3700/3800 [44:46<26:15, 15.75s/pipeline]Optimization Progress:  97%|█████████▋| 3701/3800 [44:46<32:01, 19.41s/pipeline]Optimization Progress:  97%|█████████▋| 3702/3800 [45:16<36:57, 22.63s/pipeline]Optimization Progress: 100%|█████████▉| 3782/3800 [45:23<04:45, 15.87s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-499307722.06015146	GradientBoostingRegressor(StandardScaler(Nystroem(LassoLarsCV(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.6500000000000001, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.35000000000000003), LassoLarsCV__normalize=True), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=9)), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3800/3800 [45:29<00:00, 15.87s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [45:29<00:00, 11.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [45:45<00:00, 11.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [45:49<00:00, 11.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [45:51<00:00, 11.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [45:51<00:00, 11.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [45:51<00:00, 11.21s/pipeline]Optimization Progress:  98%|█████████▊| 3805/3900 [45:52<14:32,  9.18s/pipeline]Optimization Progress:  98%|█████████▊| 3806/3900 [46:03<15:31,  9.90s/pipeline]Optimization Progress: 100%|█████████▉| 3886/3900 [46:09<01:37,  6.96s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-501212816.7864238	GradientBoostingRegressor(PCA(GradientBoostingRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-5	-499307722.06015146	GradientBoostingRegressor(StandardScaler(Nystroem(LassoLarsCV(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.6500000000000001, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.35000000000000003), LassoLarsCV__normalize=True), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=9)), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [46:15<00:00,  6.96s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [46:15<00:00,  4.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [46:35<00:00,  4.99s/pipeline]Optimization Progress:  98%|█████████▊| 3902/4000 [46:38<11:16,  6.91s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [47:38<36:57, 22.86s/pipeline]Optimization Progress: 100%|█████████▉| 3983/4000 [48:04<04:33, 16.11s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-501212816.7864238	GradientBoostingRegressor(PCA(GradientBoostingRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-5	-499307722.06015146	GradientBoostingRegressor(StandardScaler(Nystroem(LassoLarsCV(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.6500000000000001, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.35000000000000003), LassoLarsCV__normalize=True), Nystroem__gamma=0.8, Nystroem__kernel=poly, Nystroem__n_components=9)), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:06<00:00, 16.11s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [48:06<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:06<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:06<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:06<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:10<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:10<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:14<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 4000/4000 [48:16<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 4000/4000 [48:17<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:17<00:00, 11.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [48:17<00:00, 11.30s/pipeline]Optimization Progress:  98%|█████████▊| 4001/4100 [48:18<19:12, 11.64s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4001/4100 [48:18<19:12, 11.64s/pipeline]Optimization Progress:  98%|█████████▊| 4003/4100 [48:28<15:26,  9.55s/pipeline]Optimization Progress: 100%|█████████▉| 4083/4100 [48:48<01:54,  6.76s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-487722205.42831457	GradientBoostingRegressor(PCA(GradientBoostingRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [48:50<00:00,  6.76s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [48:50<00:00,  4.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [48:55<00:00,  4.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [48:57<00:00,  4.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [49:03<00:00,  4.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [49:05<00:00,  4.76s/pipeline]Optimization Progress:  98%|█████████▊| 4101/4200 [49:05<13:09,  7.98s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [50:13<42:12, 25.85s/pipeline]Optimization Progress: 100%|█████████▉| 4182/4200 [50:17<05:25, 18.11s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-487722205.42831457	GradientBoostingRegressor(PCA(GradientBoostingRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 4200/4200 [50:18<00:00, 18.11s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [50:18<00:00, 12.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [50:19<00:00, 12.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [50:30<00:00, 12.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [50:30<00:00, 12.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [50:30<00:00, 12.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [50:31<00:00, 12.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [50:31<00:00, 12.69s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [50:31<00:00, 12.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [50:35<00:00, 12.69s/pipeline]Optimization Progress:  98%|█████████▊| 4201/4300 [50:36<23:42, 14.37s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4201/4300 [50:36<23:42, 14.37s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [50:46<18:42, 11.57s/pipeline]Optimization Progress: 100%|█████████▉| 4283/4300 [50:50<02:18,  8.12s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-487722205.42831457	GradientBoostingRegressor(PCA(GradientBoostingRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [50:51<00:00,  8.12s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [50:51<00:00,  5.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4300/4300 [50:51<00:00,  5.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4300/4300 [50:56<00:00,  5.69s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [51:01<00:00,  5.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [51:06<00:00,  5.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [52:09<00:00,  5.69s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [52:10<19:13, 11.90s/pipeline]Optimization Progress:  98%|█████████▊| 4304/4400 [52:22<19:17, 12.06s/pipeline]Optimization Progress: 100%|█████████▉| 4384/4400 [52:27<02:15,  8.46s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-504557061.24822295	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-472955817.8490146	GradientBoostingRegressor(PCA(GradientBoostingRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 4400/4400 [52:30<00:00,  8.46s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [52:30<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [52:31<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [52:35<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [52:36<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4400/4400 [52:37<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [52:38<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [52:38<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [52:42<00:00,  5.97s/pipeline]Optimization Progress:  98%|█████████▊| 4403/4500 [52:42<08:41,  5.38s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4403/4500 [52:42<08:41,  5.38s/pipeline]Optimization Progress:  98%|█████████▊| 4405/4500 [53:03<10:58,  6.94s/pipeline]Optimization Progress: 100%|█████████▉| 4485/4500 [53:13<01:13,  4.89s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-496686001.15374535	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-472955817.8490146	GradientBoostingRegressor(PCA(GradientBoostingRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [53:13<00:00,  4.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [53:17<00:00,  4.89s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [53:17<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4500/4500 [53:19<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [53:20<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [53:20<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4500/4500 [53:21<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [53:22<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 4500/4500 [53:24<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [53:24<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [53:26<00:00,  3.51s/pipeline]Optimization Progress:  98%|█████████▊| 4501/4600 [53:28<09:21,  5.68s/pipeline]Optimization Progress:  98%|█████████▊| 4502/4600 [58:31<2:35:06, 94.96s/pipeline]                                                                                  Skipped pipeline #4518 due to time out. Continuing to the next pipeline.
Optimization Progress:  98%|█████████▊| 4518/4600 [58:31<2:09:46, 94.96s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 4583/4600 [58:44<18:50, 66.52s/pipeline]  
Generation 45 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-496686001.15374535	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-426699168.8303782	GradientBoostingRegressor(PCA(XGBRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=1, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [58:46, 66.52s/pipeline]Optimization Progress: 4601pipeline [58:46, 46.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [58:47, 46.59s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [58:52, 46.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [58:52, 46.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4601pipeline [58:52, 46.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4601pipeline [58:57, 46.59s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4601/4700 [58:58<1:16:52, 46.59s/pipeline]Optimization Progress:  98%|█████████▊| 4602/4700 [58:58<59:20, 36.33s/pipeline]                                                                                  Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4602/4700 [58:58<59:20, 36.33s/pipeline]Optimization Progress:  98%|█████████▊| 4604/4700 [59:16<45:06, 28.20s/pipeline]Optimization Progress: 100%|█████████▉| 4684/4700 [59:25<05:16, 19.77s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-496686001.15374535	GradientBoostingRegressor(PCA(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-426699168.8303782	GradientBoostingRegressor(PCA(XGBRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=1, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [59:32, 19.77s/pipeline]Optimization Progress: 4701pipeline [59:32, 13.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [59:33, 13.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:34, 13.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [59:36, 13.98s/pipeline]Optimization Progress:  98%|█████████▊| 4703/4800 [59:37<17:02, 10.54s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4703/4800 [59:37<17:02, 10.54s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4704/4800 [59:38<16:51, 10.54s/pipeline]Optimization Progress:  98%|█████████▊| 4706/4800 [59:48<13:16,  8.47s/pipeline]Optimization Progress: 100%|█████████▉| 4786/4800 [59:56<01:23,  5.96s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-534543875.65170586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-531954207.3782627	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=7, DecisionTreeRegressor__min_samples_split=4), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-454426744.8057901	GradientBoostingRegressor(PCA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=1, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-426699168.8303782	GradientBoostingRegressor(PCA(XGBRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=1, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.25), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.9500000000000001, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [1:00:00,  5.96s/pipeline]Optimization Progress: 4801pipeline [1:00:00,  4.24s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4801pipeline [1:00:01,  4.24s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [17:20:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f2398e76dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f2398f87669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f2398f94f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f2398f7bcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f2398e68f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f19a6c239dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f19a6c23067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f19a6c3b27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f19a6c3bcb4]

.
Optimization Progress: 4801pipeline [1:00:05,  4.24s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [1:00:09,  4.24s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [1:00:09,  4.24s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4801pipeline [1:00:12,  4.24s/pipeline]Optimization Progress:  98%|█████████▊| 4805/4900 [1:00:12<06:10,  3.90s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 4805/4900 [1:00:12<06:10,  3.90s/pipeline]                                                                                  60.33 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress:  98%|█████████▊| 4805/4900 [1:00:12<06:10,  3.90s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 4805/4900 [1:00:12<06:10,  3.90s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress:  98%|█████████▊| 4805/4900 [1:00:12<06:10,  3.90s/pipeline]                                                                                  Best pipeline:
0. PolynomialFeatures(include_bias=False)
1. StackingEstimator(estimator=XGBRegressor(base_score=0.5, booster='gbtree',
                                         colsample_bylevel=1,
                                         colsample_bynode=1, colsample_bytree=1,
                                         gamma=0, gpu_id=-1,
                                         importance_type='gain',
                                         interaction_constraints='',
                                         learning_rate=0.1, max_delta_step=0,
                                         max_depth=3, min_child_weight=1,
                                         missing=nan, monotone_constraints='()',
                                         n_estimators=100, n_jobs=1, nthread=1,
                                         num_parallel_tree=1, random_state=0,
                                         reg_alpha=0, reg_lambda=1,
                                         scale_pos_weight=1, subsample=0.25,
                                         tree_method='exact',
                                         validate_parameters=1,
                                         verbosity=None))
2. PCA(iterated_power=8, svd_solver='randomized')
3. GradientBoostingRegressor(alpha=0.85, loss='quantile', max_depth=4,
                          max_features=0.9500000000000001, min_samples_leaf=2,
                          min_samples_split=10, subsample=0.55)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
