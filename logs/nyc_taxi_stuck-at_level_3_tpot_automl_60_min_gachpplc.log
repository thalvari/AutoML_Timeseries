30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:  14%|█▍        | 14/100 [00:06<00:38,  2.21pipeline/s]Optimization Progress:  94%|█████████▍| 94/100 [00:09<00:01,  3.03pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:10<00:00,  3.03pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:10<00:00,  4.10pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:10<00:00,  4.10pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:10<00:00,  4.10pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  4.10pipeline/s]Optimization Progress:  53%|█████▎    | 106/200 [00:14<00:37,  2.54pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  53%|█████▎    | 106/200 [00:14<00:37,  2.54pipeline/s]Optimization Progress:  54%|█████▍    | 108/200 [00:18<01:22,  1.11pipeline/s]Optimization Progress:  94%|█████████▍| 188/200 [00:22<00:07,  1.56pipeline/s]
Generation 1 - Current Pareto front scores:
-1	-859136079.2625672	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-857545523.8666912	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [00:22<00:00,  1.56pipeline/s]Optimization Progress: 100%|██████████| 200/200 [00:22<00:00,  2.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 200/200 [00:23<00:00,  2.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:24<00:00,  2.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00010.
Optimization Progress: 100%|██████████| 200/200 [00:24<00:00,  2.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:25<00:00,  2.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:25<00:00,  2.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 100%|██████████| 200/200 [00:27<00:00,  2.18pipeline/s]Optimization Progress:  68%|██████▊   | 204/300 [00:28<01:13,  1.31pipeline/s]Optimization Progress:  69%|██████▊   | 206/300 [00:32<01:49,  1.17s/pipeline]Optimization Progress:  95%|█████████▌| 285/300 [00:36<00:12,  1.20pipeline/s]
Generation 2 - Current Pareto front scores:
-1	-859136079.2625672	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-857233120.915411	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:26:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 300/300 [00:36<00:00,  1.20pipeline/s]Optimization Progress: 100%|██████████| 300/300 [00:36<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 300/300 [00:37<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 300/300 [00:37<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:38<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 300/300 [00:39<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:39<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:26:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 300/300 [00:40<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:26:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 300/300 [00:43<00:00,  1.70pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:43<00:00,  1.70pipeline/s]Optimization Progress:  76%|███████▌  | 303/400 [00:43<01:47,  1.11s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  76%|███████▌  | 303/400 [00:43<01:47,  1.11s/pipeline]Optimization Progress:  76%|███████▋  | 305/400 [00:48<02:14,  1.41s/pipeline]Optimization Progress:  96%|█████████▋| 385/400 [00:51<00:15,  1.00s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-859136079.2625672	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-855448211.1455141	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [00:52<00:00,  1.00s/pipeline]Optimization Progress: 100%|██████████| 400/400 [00:52<00:00,  1.41pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [00:53<00:00,  1.41pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 400/400 [00:55<00:00,  1.41pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [00:56<00:00,  1.41pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [00:56<00:00,  1.41pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [00:56<00:00,  1.41pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 400/400 [00:56<00:00,  1.41pipeline/s]Optimization Progress:  81%|████████  | 403/500 [01:06<03:02,  1.88s/pipeline]Optimization Progress:  96%|█████████▌| 481/500 [01:15<00:25,  1.35s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-859136079.2625672	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-851970220.7366222	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:26:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 500/500 [01:16<00:00,  1.35s/pipeline]Optimization Progress: 100%|██████████| 500/500 [01:16<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [01:19<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [01:19<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:20<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:20<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [01:21<00:00,  1.03pipeline/s]Optimization Progress:  84%|████████▎ | 501/600 [01:22<03:49,  2.31s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▎ | 501/600 [01:22<03:49,  2.31s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▎ | 502/600 [01:22<03:46,  2.31s/pipeline]Optimization Progress:  84%|████████▍ | 504/600 [01:28<03:36,  2.26s/pipeline]Optimization Progress:  97%|█████████▋| 584/600 [01:32<00:25,  1.59s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-858137735.0633523	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-851970220.7366222	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 600/600 [01:32<00:00,  1.59s/pipeline]Optimization Progress: 100%|██████████| 600/600 [01:32<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 600/600 [01:34<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [01:34<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [01:35<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [01:35<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [01:37<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:27:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 600/600 [01:39<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 600/600 [01:40<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:27:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 600/600 [01:40<00:00,  1.12s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 [12:27:19] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 600/600 [01:40<00:00,  1.12s/pipeline]Optimization Progress:  86%|████████▌ | 600/700 [01:50<01:52,  1.12s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [01:51<10:34,  6.41s/pipeline]Optimization Progress:  97%|█████████▋| 681/700 [01:56<01:25,  4.50s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-853661466.1922657	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-851970220.7366222	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [01:56<00:00,  4.50s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [01:57<00:00,  4.50s/pipeline]Optimization Progress: 100%|██████████| 700/700 [01:57<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [01:57<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:27:39] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 700/700 [01:59<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [02:01<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 700/700 [02:01<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 700/700 [02:01<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 700/700 [02:02<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [02:02<00:00,  3.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 700/700 [02:03<00:00,  3.17s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [02:05<05:31,  3.38s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [02:13<08:02,  4.97s/pipeline]Optimization Progress:  98%|█████████▊| 783/800 [02:19<00:59,  3.50s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-849886651.6986425	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [02:21<00:00,  3.50s/pipeline]Optimization Progress: 100%|██████████| 800/800 [02:21<00:00,  2.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 800/800 [02:21<00:00,  2.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 800/800 [02:23<00:00,  2.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [12:28:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f012a4e5dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f012a5f6669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f012a603f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f012a5eacbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f012a4d7f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7ef7382d29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7ef7382d2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7ef7382ea27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7ef7382eacb4]

.
Optimization Progress: 100%|██████████| 800/800 [02:23<00:00,  2.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [02:24<00:00,  2.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 800/800 [02:26<00:00,  2.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [02:27<00:00,  2.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [02:27<00:00,  2.48s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [02:29<04:05,  2.53s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 803/900 [02:29<04:05,  2.53s/pipeline]Optimization Progress:  89%|████████▉ | 805/900 [03:27<16:33, 10.46s/pipeline]Optimization Progress:  98%|█████████▊| 885/900 [03:33<01:50,  7.35s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-849886651.6986425	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-838351642.268897	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [03:34<00:00,  7.35s/pipeline]Optimization Progress: 100%|██████████| 900/900 [03:34<00:00,  5.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 900/900 [03:40<00:00,  5.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 900/900 [03:41<00:00,  5.16s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [03:43<00:00,  5.16s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 900/1000 [03:43<08:36,  5.16s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [03:43<10:26,  6.33s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [03:53<11:58,  7.33s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [04:01<01:32,  5.16s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-847515719.4204344	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-838351642.268897	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 1000/1000 [04:02<00:00,  5.16s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [04:02<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [04:02<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 1000/1000 [04:06<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 1000/1000 [04:07<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [04:09<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [04:10<00:00,  3.62s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [04:20<05:58,  3.62s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [04:22<09:01,  5.53s/pipeline]Optimization Progress:  98%|█████████▊| 1082/1100 [04:29<01:10,  3.90s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-844796840.0212452	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-838351642.268897	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [04:30<00:00,  3.90s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [04:30<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [04:31<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [04:33<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [04:35<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [04:37<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [04:40<00:00,  2.75s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [04:50<12:55,  7.83s/pipeline]Optimization Progress:  98%|█████████▊| 1181/1200 [04:56<01:44,  5.51s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-844796840.0212452	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-837279319.2688363	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [04:59<00:00,  5.51s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [04:59<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [05:03<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 1200/1200 [05:03<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [05:05<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [05:05<00:00,  3.90s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [05:18<14:00,  8.49s/pipeline]Optimization Progress:  99%|█████████▊| 1281/1300 [07:48<02:03,  6.50s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-836011023.3225453	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-833214869.0477644	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-760586287.1112716	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1300/1300 [07:49<00:00,  6.50s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [07:49<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [07:52<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:52<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 1300/1300 [07:52<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:56<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 1300/1300 [07:57<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:58<00:00,  4.57s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [07:58<06:41,  4.14s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1303/1400 [07:59<06:41,  4.14s/pipeline]Optimization Progress:  93%|█████████▎| 1305/1400 [08:06<06:27,  4.08s/pipeline]Optimization Progress:  99%|█████████▉| 1385/1400 [08:11<00:43,  2.87s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-836011023.3225453	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-833214869.0477644	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [08:11<00:00,  2.87s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [08:11<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [08:12<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [08:13<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [08:13<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [08:14<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [08:16<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [08:17<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 1400/1400 [08:18<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [08:19<00:00,  2.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1401/1500 [08:21<03:19,  2.02s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [08:30<03:17,  2.02s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [08:41<07:06,  4.40s/pipeline]Optimization Progress:  99%|█████████▉| 1483/1500 [08:51<00:52,  3.12s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-836011023.3225453	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-833214869.0477644	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 1500/1500 [08:51<00:00,  3.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [08:52<00:00,  3.12s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [08:52<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 1500/1500 [08:53<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [08:54<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1500/1500 [08:55<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [08:56<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [08:57<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [08:59<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 1500/1500 [09:00<00:00,  2.20s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [09:07<06:20,  3.88s/pipeline]Optimization Progress:  99%|█████████▉| 1582/1600 [09:15<00:49,  2.75s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-836011023.3225453	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-833214869.0477644	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [09:15<00:00,  2.75s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [09:15<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [09:18<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [09:18<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [09:19<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [09:21<00:00,  1.94s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [09:22<02:47,  1.77s/pipeline]Optimization Progress:  94%|█████████▍| 1606/1700 [09:30<05:33,  3.55s/pipeline]Optimization Progress:  99%|█████████▉| 1686/1700 [09:35<00:35,  2.50s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-836011023.3225453	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-833214869.0477644	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [09:37<00:00,  2.50s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [09:37<00:00,  1.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 1700/1700 [09:41<00:00,  1.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1700/1700 [09:43<00:00,  1.81s/pipeline]Optimization Progress:  95%|█████████▍| 1702/1800 [09:44<03:48,  2.33s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [09:55<07:52,  4.87s/pipeline]Optimization Progress:  99%|█████████▉| 1783/1800 [10:03<00:58,  3.44s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-834083099.6830721	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832304778.8810499	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [10:05<00:00,  3.44s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [10:05<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 1800/1800 [10:05<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [10:08<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [10:09<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [10:10<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [10:10<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [10:11<00:00,  2.45s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [10:13<04:39,  2.85s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [10:29<11:06,  6.87s/pipeline]Optimization Progress:  99%|█████████▉| 1883/1900 [10:37<01:22,  4.84s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-834083099.6830721	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832304778.8810499	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [10:38<00:00,  4.84s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [10:38<00:00,  3.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [10:42<00:00,  3.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [10:43<00:00,  3.41s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [10:47<05:20,  3.30s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1903/2000 [10:47<05:20,  3.30s/pipeline]Optimization Progress:  95%|█████████▌| 1905/2000 [11:03<07:21,  4.65s/pipeline]Optimization Progress:  99%|█████████▉| 1985/2000 [11:16<00:49,  3.30s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-834083099.6830721	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832304778.8810499	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-778039550.2705431	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 2000/2000 [11:21<00:00,  3.30s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [11:21<00:00,  2.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [11:23<00:00,  2.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [11:24<00:00,  2.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [11:28<00:00,  2.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2000/2000 [11:29<00:00,  2.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2000/2000 [11:29<00:00,  2.41s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [11:29<04:07,  2.55s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [12:42<37:38, 23.53s/pipeline]Optimization Progress:  99%|█████████▉| 2084/2100 [12:47<04:23, 16.49s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-834083099.6830721	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832003297.8711907	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:47<00:00, 16.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [12:49<00:00, 16.49s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [12:49<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [12:49<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [12:50<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2100/2100 [12:53<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:57<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [12:57<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 2100/2100 [12:58<00:00, 11.57s/pipeline]Optimization Progress:  96%|█████████▌| 2101/2200 [13:00<18:58, 11.50s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [15:53<1:38:00, 60.01s/pipeline]Optimization Progress:  99%|█████████▉| 2182/2200 [15:59<12:36, 42.03s/pipeline]  
Generation 21 - Current Pareto front scores:
-1	-834083099.6830721	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832003297.8711907	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [16:00<00:00, 42.03s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [16:00<00:00, 29.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [16:00<00:00, 29.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [16:03<00:00, 29.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [16:07<00:00, 29.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2200/2200 [16:09<00:00, 29.44s/pipeline]Optimization Progress:  96%|█████████▌| 2201/2300 [16:11<39:24, 23.88s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [16:22<32:42, 20.03s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [16:27<04:12, 14.04s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-834083099.6830721	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832003297.8711907	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [16:28<00:00, 14.04s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [16:28<00:00,  9.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [16:30<00:00,  9.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [16:32<00:00,  9.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [16:37<00:00,  9.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 2300/2300 [16:39<00:00,  9.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 2300/2300 [16:39<00:00,  9.84s/pipeline]Optimization Progress:  96%|█████████▌| 2302/2400 [16:39<14:02,  8.60s/pipeline]Optimization Progress:  96%|█████████▌| 2303/2400 [17:48<43:06, 26.66s/pipeline]Optimization Progress:  99%|█████████▉| 2383/2400 [18:42<05:20, 18.86s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832003297.8711907	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 2400/2400 [18:44<00:00, 18.86s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [18:44<00:00, 13.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [18:45<00:00, 13.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [18:51<00:00, 13.25s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [18:53<16:28, 10.19s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [23:55<2:36:04, 97.54s/pipeline]                                                                                  Skipped pipeline #2453 due to time out. Continuing to the next pipeline.
Optimization Progress:  98%|█████████▊| 2453/2500 [23:55<1:16:24, 97.54s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  99%|█████████▉| 2485/2500 [24:14<17:05, 68.35s/pipeline]  
Generation 24 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832003297.8711907	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-738350612.7435105	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.75), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2501pipeline [24:17, 68.35s/pipeline]Optimization Progress: 2501pipeline [24:17, 47.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2501pipeline [24:20, 47.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2501pipeline [24:28, 47.91s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [24:28<56:58, 35.24s/pipeline]Optimization Progress:  96%|█████████▋| 2504/2600 [25:20<1:04:16, 40.17s/pipeline]Optimization Progress:  99%|█████████▉| 2584/2600 [25:31<07:30, 28.16s/pipeline]  
Generation 25 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832003297.8711907	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-729041936.3820822	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.65), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [25:31, 28.16s/pipeline]Optimization Progress: 2601pipeline [25:31, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2601pipeline [25:33, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 2601pipeline [25:33, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2601pipeline [25:33, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2601pipeline [25:35, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 2601pipeline [25:36, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2601pipeline [25:40, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2601pipeline [25:40, 19.72s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [25:44, 19.72s/pipeline]Optimization Progress:  96%|█████████▋| 2601/2700 [25:50<32:32, 19.72s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [26:02<37:20, 22.86s/pipeline]Optimization Progress:  99%|█████████▉| 2682/2700 [26:23<04:49, 16.09s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-831622363.407644	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-729041936.3820822	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.65), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [26:23, 16.09s/pipeline]Optimization Progress: 2701pipeline [26:23, 11.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 2701pipeline [26:25, 11.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [26:26, 11.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2701pipeline [26:26, 11.26s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [26:30, 11.26s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [26:32, 11.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2701pipeline [26:32, 11.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [26:34, 11.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2701pipeline [26:36, 11.26s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [26:40<18:23, 11.26s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [31:23<1:25:30, 52.89s/pipeline]Optimization Progress:  99%|█████████▉| 2783/2800 [31:36<10:30, 37.07s/pipeline]  
Generation 27 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-831622363.407644	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-729041936.3820822	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.65), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [31:36, 37.07s/pipeline]Optimization Progress: 2801pipeline [31:36, 25.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [31:37, 25.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [31:38, 25.95s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 2801pipeline [31:43, 25.95s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [31:44, 25.95s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 2801pipeline [31:48, 25.95s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  97%|█████████▋| 2801/2900 [31:50<42:49, 25.95s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [32:08<45:23, 27.79s/pipeline]Optimization Progress:  99%|█████████▉| 2882/2900 [32:16<05:50, 19.48s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-831454448.9461355	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-729041936.3820822	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.65), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2901pipeline [32:17, 19.48s/pipeline]Optimization Progress: 2901pipeline [32:17, 13.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2901pipeline [32:18, 13.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 2901pipeline [32:21, 13.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2901pipeline [32:22, 13.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2901pipeline [32:24, 13.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [32:24, 13.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 2901pipeline [32:24, 13.66s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2901/3000 [32:29<22:31, 13.66s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [32:29<21:16, 13.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2902/3000 [32:29<21:16, 13.02s/pipeline]Optimization Progress:  97%|█████████▋| 2904/3000 [34:28<43:08, 26.96s/pipeline]Optimization Progress:  99%|█████████▉| 2984/3000 [34:41<05:02, 18.92s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-831454448.9461355	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-729041936.3820822	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.65), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 3001pipeline [34:42, 18.92s/pipeline]Optimization Progress: 3001pipeline [34:42, 13.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 3001pipeline [34:45, 13.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [34:46, 13.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [34:49, 13.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [34:49, 13.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [34:49, 13.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [34:49, 13.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3001pipeline [34:56, 13.27s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [34:56<21:51, 13.38s/pipeline]Optimization Progress:  97%|█████████▋| 3003/3100 [35:22<27:53, 17.26s/pipeline]Optimization Progress:  99%|█████████▉| 3083/3100 [35:33<03:26, 12.12s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-831454448.9461355	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=9), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-729041936.3820822	RandomForestRegressor(FastICA(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)), FastICA__tol=0.65), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [35:33, 12.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [35:36, 12.12s/pipeline]Optimization Progress: 3101pipeline [35:36,  8.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 3101pipeline [35:37,  8.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [35:38,  8.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3101pipeline [35:42,  8.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 3101pipeline [35:44,  8.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [35:44,  8.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3101pipeline [35:47,  8.54s/pipeline]Optimization Progress:  97%|█████████▋| 3102/3200 [35:48<15:25,  9.44s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [36:20<26:31, 16.41s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [36:46<03:16, 11.58s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-684298910.0062819	RandomForestRegressor(ZeroCount(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8)), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [36:48, 11.58s/pipeline]Optimization Progress: 3201pipeline [36:48,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 3201pipeline [36:50,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [36:50,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3201pipeline [36:51,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3201pipeline [36:51,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 3201pipeline [36:56,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [36:57,  8.14s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [36:58,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [36:58,  8.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [36:59,  8.14s/pipeline]Optimization Progress:  97%|█████████▋| 3203/3300 [37:00<12:08,  7.51s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [37:26<20:49, 13.02s/pipeline]Optimization Progress: 100%|█████████▉| 3284/3300 [37:37<02:26,  9.15s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-684298910.0062819	RandomForestRegressor(ZeroCount(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8)), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [37:39,  9.15s/pipeline]Optimization Progress: 3301pipeline [37:39,  6.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3301pipeline [37:41,  6.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3301pipeline [37:42,  6.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 3301pipeline [37:45,  6.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [37:51,  6.45s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [37:53<10:41,  6.62s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [42:55<2:32:26, 95.27s/pipeline]                                                                                  Skipped pipeline #3368 due to time out. Continuing to the next pipeline.
Optimization Progress:  99%|█████████▉| 3368/3400 [42:55<50:48, 95.27s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 3385/3400 [43:10<16:41, 66.74s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-684298910.0062819	RandomForestRegressor(ZeroCount(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8)), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 3402pipeline [43:14, 66.74s/pipeline]Optimization Progress: 3402pipeline [43:14, 46.80s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3402pipeline [43:18, 46.80s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 3402pipeline [43:19, 46.80s/pipeline]Optimization Progress:  97%|█████████▋| 3404/3500 [43:21<54:08, 33.84s/pipeline]Optimization Progress:  97%|█████████▋| 3405/3500 [45:08<1:27:57, 55.55s/pipeline]Optimization Progress: 100%|█████████▉| 3485/3500 [45:15<09:43, 38.91s/pipeline]  
Generation 34 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-684298910.0062819	RandomForestRegressor(ZeroCount(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8)), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3502pipeline [45:16, 38.91s/pipeline]Optimization Progress: 3502pipeline [45:16, 27.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3502pipeline [45:16, 27.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3502pipeline [45:17, 27.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3502pipeline [45:21, 27.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3502pipeline [45:22, 27.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3502pipeline [45:24, 27.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3502pipeline [45:27, 27.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 3502pipeline [45:27, 27.25s/pipeline]Optimization Progress: 3502pipeline [45:30, 27.25s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [45:34<39:27, 24.41s/pipeline]Optimization Progress:  97%|█████████▋| 3504/3600 [46:16<47:45, 29.84s/pipeline]Optimization Progress: 100%|█████████▉| 3584/3600 [46:24<05:34, 20.92s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-739974484.7975008	RandomForestRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.6500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)
-4	-684298910.0062819	RandomForestRegressor(ZeroCount(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8)), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3602pipeline [46:26, 20.92s/pipeline]Optimization Progress: 3602pipeline [46:26, 14.69s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3602pipeline [46:30, 14.69s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 3602pipeline [46:37, 14.69s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [46:38<22:22, 13.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3603/3700 [46:38<22:22, 13.85s/pipeline]Optimization Progress:  97%|█████████▋| 3605/3700 [51:35<1:25:48, 54.20s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 3685/3700 [51:48<09:29, 37.99s/pipeline]  
Generation 36 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-733760648.0263565	ExtraTreesRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.9), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=6, ExtraTreesRegressor__n_estimators=100)
-4	-684298910.0062819	RandomForestRegressor(ZeroCount(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.8)), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9500000000000001, RandomForestRegressor__min_samples_leaf=18, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=100)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3702pipeline [51:50, 37.99s/pipeline]Optimization Progress: 3702pipeline [51:50, 26.63s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 3702pipeline [51:59, 26.63s/pipeline]Optimization Progress:  97%|█████████▋| 3704/3800 [52:03<33:00, 20.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3704/3800 [52:03<33:00, 20.63s/pipeline]Optimization Progress:  98%|█████████▊| 3706/3800 [52:54<34:39, 22.13s/pipeline]Optimization Progress: 100%|█████████▉| 3786/3800 [54:02<03:40, 15.74s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-645582108.302223	AdaBoostRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.65), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3802pipeline [54:16, 15.74s/pipeline]Optimization Progress: 3802pipeline [54:16, 11.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3802pipeline [54:17, 11.27s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [54:18<14:00,  8.67s/pipeline]Optimization Progress:  98%|█████████▊| 3804/3900 [54:45<22:26, 14.03s/pipeline]Optimization Progress: 100%|█████████▉| 3884/3900 [54:55<02:37,  9.86s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-645582108.302223	AdaBoostRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.65), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3902pipeline [54:58,  9.86s/pipeline]Optimization Progress: 3902pipeline [54:58,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3902pipeline [54:58,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3902pipeline [55:05,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3902pipeline [55:08,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3902pipeline [55:09,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 3902pipeline [55:09,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3902pipeline [55:10,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3902pipeline [55:10,  6.96s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [55:11<11:21,  6.96s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [55:11<13:56,  8.63s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [55:25<16:21, 10.23s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [56:31<01:58,  7.41s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-832345344.5518357	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829825663.2715586	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=15), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-645582108.302223	AdaBoostRegressor(FastICA(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), FastICA__tol=0.65), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4002pipeline [56:35,  7.41s/pipeline]Optimization Progress: 4002pipeline [56:35,  5.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4002pipeline [56:38,  5.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 4002pipeline [56:46,  5.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4002pipeline [56:47,  5.24s/pipeline]Optimization Progress:  98%|█████████▊| 4003/4100 [56:47<11:55,  7.37s/pipeline]Optimization Progress:  98%|█████████▊| 4004/4100 [1:00:46<2:02:55, 76.83s/pipeline]                                                                                    
Optimization Progress: 100%|█████████▉| 4083/4100 [1:00:46<21:46, 76.83s/pipeline]                                                                                  60.86 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 4083/4100 [1:00:46<21:46, 76.83s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4083/4100 [1:00:46<21:46, 76.83s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 4083/4100 [1:00:46<21:46, 76.83s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=AdaBoostRegressor(loss='square', n_estimators=100))
1. FastICA(tol=0.65)
2. AdaBoostRegressor(learning_rate=0.01, loss='square', n_estimators=100)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
