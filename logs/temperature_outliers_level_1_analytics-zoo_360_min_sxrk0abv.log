Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
Adding /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.8.1-jar-with-dependencies.jar to BIGDL_JARS
Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
Current pyspark location is : /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/__init__.py
Start to getOrCreate SparkContext
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.11-2.4.3.jar) to method java.nio.Bits.unaligned()
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2021-01-16 21:20:39 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).

User settings:

   KMP_AFFINITY=granularity=fine,compact,1,0
   KMP_BLOCKTIME=0
   KMP_DUPLICATE_LIB_OK=True
   KMP_INIT_AT_FORK=FALSE
   KMP_SETTINGS=1
   OMP_NUM_THREADS=40

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=160
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=0
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_HAND_THREAD=false
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=true
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_FORKJOIN_FRAMES=true
   KMP_FORKJOIN_FRAMES_MODE=3
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_INIT_WAIT=2048
   KMP_ITT_PREPARE_DELAY=0
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NEXT_WAIT=1024
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=4M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=40
   KMP_TOPOLOGY_METHOD=all
   KMP_USER_LEVEL_MWAIT=false
   KMP_VERSION=false
   KMP_WARNINGS=true
   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'
   OMP_ALLOCATOR=omp_default_mem_alloc
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_AFFINITY=false
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=2147483647
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED=false
   OMP_NUM_THREADS='40'
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='intel'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=4M
   OMP_TARGET_OFFLOAD=DEFAULT
   OMP_THREAD_LIMIT=2147483647
   OMP_TOOL=enabled
   OMP_TOOL_LIBRARIES: value is not defined
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'

cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
Successfully got a SparkContext
2021-01-16 21:20:42,513	WARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.
2021-01-16 21:20:42,514	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2021-01-16_21-20-42_514247_19297/logs.
2021-01-16 21:20:42,631	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:64821 to respond...
2021-01-16 21:20:42,749	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:33116 to respond...
2021-01-16 21:20:42,750	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2021-01-16 21:20:42,777	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2021-01-16_21-20-42_514247_19297/logs.
2021-01-16 21:20:42,778	WARNING services.py:1298 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2021-01-16 21:20:42,778	INFO services.py:1446 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2021-01-16 21:20:43,223	WARNING bayesopt.py:69 -- `reward_attr` is deprecated and will be removed in a future version of Tune. Setting `metric=reward_metric` and `mode=max`.
2021-01-16 21:20:43,332	INFO tune.py:65 -- Did not find checkpoint file in /scratch/project_2003107/ray_results_qxprf6nj/automl.
2021-01-16 21:20:43,333	INFO tune.py:233 -- Starting a new experiment.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/200.9 GB

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 10 ({'RUNNING': 1, 'PENDING': 9})
PENDING trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	PENDING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	PENDING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	PENDING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	PENDING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	PENDING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	PENDING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	PENDING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	PENDING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	PENDING
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING

[2m[36m(pid=19644)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19620)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19652)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19636)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19635)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19636)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19614)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19637)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19653)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19635)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19651)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19644)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19650)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19620)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19652)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19630)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19648)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19646)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19626)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19633)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19637)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19614)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19653)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19651)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19650)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19629)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19623)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19616)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19638)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19617)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19649)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19634)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19622)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19647)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19647)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19643)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19643)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19618)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19618)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19640)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19639)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19639)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19624)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19624)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19633)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19630)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19654)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19648)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19646)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19641)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19641)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19619)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19619)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19626)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19649)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19640)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19654)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19615)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19615)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19629)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19642)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19642)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19621)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19621)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19623)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19628)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=19628)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19616)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19638)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19617)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19634)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19622)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21413)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21422)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21422)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21413)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21400)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21400)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21415)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21415)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21414)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21414)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21408)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21408)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21418)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21418)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21403)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21403)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21412)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21412)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=21425)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=21425)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19636)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19636)[0m   agg_primitives: ['count']
[2m[36m(pid=19636)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19636)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19614)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19614)[0m   agg_primitives: ['count']
[2m[36m(pid=19614)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19614)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19637)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19637)[0m   agg_primitives: ['count']
[2m[36m(pid=19637)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19637)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19653)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19653)[0m   agg_primitives: ['count']
[2m[36m(pid=19653)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19653)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19635)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19635)[0m   agg_primitives: ['count']
[2m[36m(pid=19635)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19635)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19651)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19651)[0m   agg_primitives: ['count']
[2m[36m(pid=19651)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19651)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19644)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19644)[0m   agg_primitives: ['count']
[2m[36m(pid=19644)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19644)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19650)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19650)[0m   agg_primitives: ['count']
[2m[36m(pid=19650)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19650)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19620)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19620)[0m   agg_primitives: ['count']
[2m[36m(pid=19620)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19620)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19652)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19652)[0m   agg_primitives: ['count']
[2m[36m(pid=19652)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19652)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19636)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19636)[0m Instructions for updating:
[2m[36m(pid=19636)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19636)[0m LSTM is selected.
[2m[36m(pid=19614)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19614)[0m Instructions for updating:
[2m[36m(pid=19614)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19614)[0m LSTM is selected.
[2m[36m(pid=19637)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19637)[0m Instructions for updating:
[2m[36m(pid=19637)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19637)[0m LSTM is selected.
[2m[36m(pid=19653)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19653)[0m Instructions for updating:
[2m[36m(pid=19653)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19653)[0m LSTM is selected.
[2m[36m(pid=19635)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19635)[0m Instructions for updating:
[2m[36m(pid=19635)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19635)[0m LSTM is selected.
[2m[36m(pid=19651)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19651)[0m Instructions for updating:
[2m[36m(pid=19651)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19644)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19644)[0m Instructions for updating:
[2m[36m(pid=19644)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19651)[0m LSTM is selected.
[2m[36m(pid=19644)[0m LSTM is selected.
[2m[36m(pid=19650)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19650)[0m Instructions for updating:
[2m[36m(pid=19650)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19650)[0m LSTM is selected.
[2m[36m(pid=19620)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19620)[0m Instructions for updating:
[2m[36m(pid=19620)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19652)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19652)[0m Instructions for updating:
[2m[36m(pid=19652)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19620)[0m LSTM is selected.
[2m[36m(pid=19652)[0m LSTM is selected.
[2m[36m(pid=19636)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19636)[0m Instructions for updating:
[2m[36m(pid=19636)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19614)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19614)[0m Instructions for updating:
[2m[36m(pid=19614)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19637)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19637)[0m Instructions for updating:
[2m[36m(pid=19637)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19653)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19653)[0m Instructions for updating:
[2m[36m(pid=19653)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19635)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19635)[0m Instructions for updating:
[2m[36m(pid=19635)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19644)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19644)[0m Instructions for updating:
[2m[36m(pid=19644)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19650)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19650)[0m Instructions for updating:
[2m[36m(pid=19650)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19620)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19620)[0m Instructions for updating:
[2m[36m(pid=19620)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19652)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19652)[0m Instructions for updating:
[2m[36m(pid=19652)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19651)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19651)[0m Instructions for updating:
[2m[36m(pid=19651)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19636)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19636)[0m 2021-01-16 21:20:52.564612: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19614)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19614)[0m 2021-01-16 21:20:52.537591: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19614)[0m 2021-01-16 21:20:52.544989: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19614)[0m 2021-01-16 21:20:52.546863: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5569102620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19614)[0m 2021-01-16 21:20:52.546883: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19637)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19637)[0m 2021-01-16 21:20:52.544750: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19637)[0m 2021-01-16 21:20:52.552129: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19637)[0m 2021-01-16 21:20:52.553985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0bd0b1900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19637)[0m 2021-01-16 21:20:52.554005: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19644)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19644)[0m 2021-01-16 21:20:52.549071: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19644)[0m 2021-01-16 21:20:52.556427: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19644)[0m 2021-01-16 21:20:52.558481: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f37cd0e8c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19644)[0m 2021-01-16 21:20:52.558501: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19650)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19650)[0m 2021-01-16 21:20:52.554566: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19650)[0m 2021-01-16 21:20:52.562059: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19650)[0m 2021-01-16 21:20:52.564265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdef511d300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19650)[0m 2021-01-16 21:20:52.564288: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19652)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19652)[0m 2021-01-16 21:20:52.569993: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19636)[0m 2021-01-16 21:20:52.572180: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19636)[0m 2021-01-16 21:20:52.574393: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe95d0e96c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19636)[0m 2021-01-16 21:20:52.574418: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19653)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19653)[0m 2021-01-16 21:20:52.577153: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19653)[0m 2021-01-16 21:20:52.585113: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19653)[0m 2021-01-16 21:20:52.587389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f01bd0e5ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19653)[0m 2021-01-16 21:20:52.587415: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19635)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19635)[0m 2021-01-16 21:20:52.581014: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19635)[0m 2021-01-16 21:20:52.588809: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19635)[0m 2021-01-16 21:20:52.591022: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd175103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19635)[0m 2021-01-16 21:20:52.591045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19651)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19651)[0m 2021-01-16 21:20:52.576954: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19651)[0m 2021-01-16 21:20:52.584766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19651)[0m 2021-01-16 21:20:52.586946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f69710e5cb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19651)[0m 2021-01-16 21:20:52.586968: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19620)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19620)[0m 2021-01-16 21:20:52.593297: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19620)[0m 2021-01-16 21:20:52.601203: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19620)[0m 2021-01-16 21:20:52.603400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f89b90ce9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19620)[0m 2021-01-16 21:20:52.603426: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19652)[0m 2021-01-16 21:20:52.577774: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19652)[0m 2021-01-16 21:20:52.580001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4f50fda70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19652)[0m 2021-01-16 21:20:52.580024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:119: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 21.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 10 ({'RUNNING': 10})
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	RUNNING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	RUNNING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	RUNNING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	RUNNING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	RUNNING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19637], 5 s, 1 iter

[2m[36m(pid=19636)[0m 2021-01-16 21:20:55,746	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19636)[0m Traceback (most recent call last):
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19636)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19636)[0m     param_dset[:] = val
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19636)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19636)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19636)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19636)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19636)[0m , filename = '/tmp/thalvari/4565627/automl_save_hp_tlsff/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe95e7ef448, total write size = 773040, bytes this sub-write = 773040, bytes actually written = 18446744073709551615, offset = 589824)
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19636)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19636)[0m Traceback (most recent call last):
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19636)[0m     self._entrypoint()
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19636)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19636)[0m     output = train_func(config, reporter)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19636)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19636)[0m     config=config)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19636)[0m     model.save(model_path, config_path)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19636)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19636)[0m     self.model.save(model_path)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19636)[0m     signatures)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19636)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19636)[0m     f.close()
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19636)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19636)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19636)[0m , filename = '/tmp/thalvari/4565627/automl_save_hp_tlsff/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe95e431e10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19636)[0m Exception in thread Thread-1:
[2m[36m(pid=19636)[0m Traceback (most recent call last):
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19636)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19636)[0m     param_dset[:] = val
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19636)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19636)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19636)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19636)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19636)[0m , filename = '/tmp/thalvari/4565627/automl_save_hp_tlsff/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe95e7ef448, total write size = 773040, bytes this sub-write = 773040, bytes actually written = 18446744073709551615, offset = 589824)
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19636)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19636)[0m Traceback (most recent call last):
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19636)[0m     self._entrypoint()
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19636)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19636)[0m     output = train_func(config, reporter)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19636)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19636)[0m     config=config)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19636)[0m     model.save(model_path, config_path)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19636)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19636)[0m     self.model.save(model_path)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19636)[0m     signatures)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19636)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19636)[0m     f.close()
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19636)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19636)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19636)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19636)[0m , filename = '/tmp/thalvari/4565627/automl_save_hp_tlsff/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe95e431e10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19636)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19636)[0m Traceback (most recent call last):
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19636)[0m     self.run()
[2m[36m(pid=19636)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19636)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19636)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19614)[0m 2021-01-16 21:20:55,793	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19614)[0m Traceback (most recent call last):
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19614)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19614)[0m     param_dset[:] = val
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19614)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19614)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19614)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19614)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19614)[0m , filename = '/tmp/thalvari/4565627/automl_save_ssemz736/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f556a14f714, total write size = 7788, bytes this sub-write = 7788, bytes actually written = 18446744073709551615, offset = 1142784)
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19614)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19614)[0m Traceback (most recent call last):
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19614)[0m     self._entrypoint()
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19614)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19614)[0m     output = train_func(config, reporter)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19614)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19614)[0m     config=config)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19614)[0m     model.save(model_path, config_path)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19614)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19614)[0m     self.model.save(model_path)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19614)[0m     signatures)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19614)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19614)[0m     f.close()
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19614)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19614)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19614)[0m , filename = '/tmp/thalvari/4565627/automl_save_ssemz736/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f556a5b80e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19614)[0m Exception in thread Thread-1:
[2m[36m(pid=19614)[0m Traceback (most recent call last):
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19614)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19614)[0m     param_dset[:] = val
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19614)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19614)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19614)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19614)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19614)[0m , filename = '/tmp/thalvari/4565627/automl_save_ssemz736/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f556a14f714, total write size = 7788, bytes this sub-write = 7788, bytes actually written = 18446744073709551615, offset = 1142784)
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19614)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19614)[0m Traceback (most recent call last):
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19614)[0m     self._entrypoint()
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19614)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19614)[0m     output = train_func(config, reporter)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19614)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19614)[0m     config=config)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19614)[0m     model.save(model_path, config_path)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19614)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19614)[0m     self.model.save(model_path)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19614)[0m     signatures)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19614)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19614)[0m     f.close()
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19614)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19614)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19614)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19614)[0m , filename = '/tmp/thalvari/4565627/automl_save_ssemz736/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f556a5b80e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19614)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19614)[0m Traceback (most recent call last):
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19614)[0m     self.run()
[2m[36m(pid=19614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19614)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19614)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19652)[0m 2021-01-16 21:20:55,872	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19652)[0m Traceback (most recent call last):
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19652)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19652)[0m     param_dset[:] = val
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19652)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19652)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19652)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19652)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19652)[0m , filename = '/tmp/thalvari/4565627/automl_save_jt3enswu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f540e970, total write size = 63232, bytes this sub-write = 63232, bytes actually written = 18446744073709551615, offset = 1060864)
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19652)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19652)[0m Traceback (most recent call last):
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19652)[0m     self._entrypoint()
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19652)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19652)[0m     output = train_func(config, reporter)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19652)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19652)[0m     config=config)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19652)[0m     model.save(model_path, config_path)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19652)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19652)[0m     self.model.save(model_path)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19652)[0m     signatures)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19652)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19652)[0m     f.close()
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19652)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19652)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19652)[0m , filename = '/tmp/thalvari/4565627/automl_save_jt3enswu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f5584af0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19652)[0m Exception in thread Thread-1:
[2m[36m(pid=19652)[0m Traceback (most recent call last):
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19652)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19652)[0m     param_dset[:] = val
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19652)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19652)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19652)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19652)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19652)[0m , filename = '/tmp/thalvari/4565627/automl_save_jt3enswu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f540e970, total write size = 63232, bytes this sub-write = 63232, bytes actually written = 18446744073709551615, offset = 1060864)
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19652)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19652)[0m Traceback (most recent call last):
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19652)[0m     self._entrypoint()
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19652)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19652)[0m     output = train_func(config, reporter)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19652)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19652)[0m     config=config)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19652)[0m     model.save(model_path, config_path)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19652)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19652)[0m     self.model.save(model_path)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19652)[0m     signatures)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19652)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19652)[0m     f.close()
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19652)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19652)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19652)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:55 2021
[2m[36m(pid=19652)[0m , filename = '/tmp/thalvari/4565627/automl_save_jt3enswu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f5584af0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19652)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19652)[0m Traceback (most recent call last):
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19652)[0m     self.run()
[2m[36m(pid=19652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19652)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19652)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19644)[0m 2021-01-16 21:20:56,005	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19644)[0m Traceback (most recent call last):
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19644)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19644)[0m     param_dset[:] = val
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19644)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19644)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19644)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19644)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19644)[0m , filename = '/tmp/thalvari/4565627/automl_save_6x37yfwg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37ce84be98, total write size = 252652, bytes this sub-write = 252652, bytes actually written = 18446744073709551615, offset = 1425408)
[2m[36m(pid=19644)[0m 
[2m[36m(pid=19644)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19644)[0m 
[2m[36m(pid=19644)[0m Traceback (most recent call last):
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19644)[0m     self._entrypoint()
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19644)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19644)[0m     output = train_func(config, reporter)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19644)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19644)[0m     config=config)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19644)[0m     model.save(model_path, config_path)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19644)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19644)[0m     self.model.save(model_path)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19644)[0m     signatures)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19644)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19644)[0m     f.close()
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19644)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19644)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19644)[0m , filename = '/tmp/thalvari/4565627/automl_save_6x37yfwg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37ce213ef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19644)[0m Exception in thread Thread-1:
[2m[36m(pid=19644)[0m Traceback (most recent call last):
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19644)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19644)[0m     param_dset[:] = val
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19644)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19644)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19644)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19644)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19644)[0m , filename = '/tmp/thalvari/4565627/automl_save_6x37yfwg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37ce84be98, total write size = 252652, bytes this sub-write = 252652, bytes actually written = 18446744073709551615, offset = 1425408)
[2m[36m(pid=19644)[0m 
[2m[36m(pid=19644)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19644)[0m 
[2m[36m(pid=19644)[0m Traceback (most recent call last):
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19644)[0m     self._entrypoint()
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19644)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19644)[0m     output = train_func(config, reporter)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19644)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19644)[0m     config=config)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19644)[0m     model.save(model_path, config_path)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19644)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19644)[0m     self.model.save(model_path)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19644)[0m     signatures)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19644)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19644)[0m     f.close()
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19644)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19644)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19644)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19644)[0m , filename = '/tmp/thalvari/4565627/automl_save_6x37yfwg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37ce213ef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19644)[0m 
[2m[36m(pid=19644)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19644)[0m 
[2m[36m(pid=19644)[0m Traceback (most recent call last):
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19644)[0m     self.run()
[2m[36m(pid=19644)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19644)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19644)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19644)[0m 
2021-01-16 21:20:56,878	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19614, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:20:56,882	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19635)[0m 2021-01-16 21:20:56,864	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19635)[0m Traceback (most recent call last):
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19635)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19635)[0m     param_dset[:] = val
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19635)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19635)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19635)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19635)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19635)[0m , filename = '/tmp/thalvari/4565627/automl_save_hegzbn06/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd17633cfb0, total write size = 243532, bytes this sub-write = 243532, bytes actually written = 18446744073709551615, offset = 1417216)
[2m[36m(pid=19635)[0m 
[2m[36m(pid=19635)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19635)[0m 
[2m[36m(pid=19635)[0m Traceback (most recent call last):
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19635)[0m     self._entrypoint()
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19635)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19635)[0m     output = train_func(config, reporter)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19635)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19635)[0m     config=config)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19635)[0m     model.save(model_path, config_path)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19635)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19635)[0m     self.model.save(model_path)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19635)[0m     signatures)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19635)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19635)[0m     f.close()
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19635)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19635)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19635)[0m , filename = '/tmp/thalvari/4565627/automl_save_hegzbn06/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd1761b23a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19635)[0m Exception in thread Thread-1:
[2m[36m(pid=19635)[0m Traceback (most recent call last):
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19635)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19635)[0m     param_dset[:] = val
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19635)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19635)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19635)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19635)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19635)[0m , filename = '/tmp/thalvari/4565627/automl_save_hegzbn06/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd17633cfb0, total write size = 243532, bytes this sub-write = 243532, bytes actually written = 18446744073709551615, offset = 1417216)
[2m[36m(pid=19635)[0m 
[2m[36m(pid=19635)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19635)[0m 
[2m[36m(pid=19635)[0m Traceback (most recent call last):
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19635)[0m     self._entrypoint()
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19635)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19635)[0m     output = train_func(config, reporter)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19635)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19635)[0m     config=config)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19635)[0m     model.save(model_path, config_path)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19635)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19635)[0m     self.model.save(model_path)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19635)[0m     signatures)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19635)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19635)[0m     f.close()
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19635)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19635)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19635)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:20:56 2021
[2m[36m(pid=19635)[0m , filename = '/tmp/thalvari/4565627/automl_save_hegzbn06/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd1761b23a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19635)[0m 
[2m[36m(pid=19635)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19635)[0m 
[2m[36m(pid=19635)[0m Traceback (most recent call last):
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19635)[0m     self.run()
[2m[36m(pid=19635)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19635)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19635)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19635)[0m 
2021-01-16 21:20:56,918	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19636, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:20:56,921	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:20:57,050	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19644, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:20:57,053	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19614)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19614)[0m 
[2m[36m(pid=19614)[0m Stack (most recent call first):
2021-01-16 21:20:57,088	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19652, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:20:57,091	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19636)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19636)[0m 
[2m[36m(pid=19636)[0m Stack (most recent call first):
[2m[36m(pid=19644)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19644)[0m 
[2m[36m(pid=19644)[0m Stack (most recent call first):
[2m[36m(pid=19652)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19652)[0m 
[2m[36m(pid=19652)[0m Stack (most recent call first):
2021-01-16 21:20:58,044	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19635, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:20:58,049	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19635)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19635)[0m 
[2m[36m(pid=19635)[0m Stack (most recent call first):
[2m[36m(pid=21400)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21400)[0m   agg_primitives: ['count']
[2m[36m(pid=21400)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21400)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21415)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21415)[0m   agg_primitives: ['count']
[2m[36m(pid=21415)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21415)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21414)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21414)[0m   agg_primitives: ['count']
[2m[36m(pid=21414)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21414)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21403)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21403)[0m   agg_primitives: ['count']
[2m[36m(pid=21403)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21403)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 16 ({'RUNNING': 9, 'ERROR': 5, 'TERMINATED': 2})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-20-43f29pn5w0/error_2021-01-16_21-20-56.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pcaxcfs3/error_2021-01-16_21-20-56.txt
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19620], 9 s, 2 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19653], 8 s, 1 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	RUNNING
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAKE(datetime)=0.86333,bayes_feature_IS_BUSY_HOURS(datetime)=0.4354,bayes_feature_IS_WEEKEND(datetime)=0.74762,bayes_feature_MONTH(datetime)=0.66727,bayes_feature_WEEKDAY(datetime)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	RUNNING
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19650], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19637], 8 s, 5 iter

[2m[36m(pid=21415)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21415)[0m Instructions for updating:
[2m[36m(pid=21415)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21415)[0m LSTM is selected.
[2m[36m(pid=21414)[0m LSTM is selected.
[2m[36m(pid=21400)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21400)[0m Instructions for updating:
[2m[36m(pid=21400)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21400)[0m LSTM is selected.
[2m[36m(pid=21414)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21414)[0m Instructions for updating:
[2m[36m(pid=21414)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21403)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21403)[0m Instructions for updating:
[2m[36m(pid=21403)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21403)[0m LSTM is selected.
[2m[36m(pid=21412)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21412)[0m   agg_primitives: ['count']
[2m[36m(pid=21412)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21412)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21400)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21400)[0m Instructions for updating:
[2m[36m(pid=21400)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21415)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21415)[0m Instructions for updating:
[2m[36m(pid=21415)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21414)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21414)[0m Instructions for updating:
[2m[36m(pid=21414)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21403)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21403)[0m Instructions for updating:
[2m[36m(pid=21403)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21412)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21412)[0m Instructions for updating:
[2m[36m(pid=21412)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21412)[0m LSTM is selected.
[2m[36m(pid=21412)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21412)[0m Instructions for updating:
[2m[36m(pid=21412)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21422)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21422)[0m   agg_primitives: ['count']
[2m[36m(pid=21422)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21422)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21400)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21400)[0m 2021-01-16 21:21:02.693222: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21400)[0m 2021-01-16 21:21:02.701934: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21400)[0m 2021-01-16 21:21:02.705701: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbda50fd530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21400)[0m 2021-01-16 21:21:02.705731: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21415)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21415)[0m 2021-01-16 21:21:02.709193: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21415)[0m 2021-01-16 21:21:02.718584: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21415)[0m 2021-01-16 21:21:02.721900: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f62f50b1a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21415)[0m 2021-01-16 21:21:02.721935: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21414)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21414)[0m 2021-01-16 21:21:02.696336: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21414)[0m 2021-01-16 21:21:02.704309: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21414)[0m 2021-01-16 21:21:02.706576: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1d9511ca90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21414)[0m 2021-01-16 21:21:02.706601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21403)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21403)[0m 2021-01-16 21:21:02.750962: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21403)[0m 2021-01-16 21:21:02.759569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21403)[0m 2021-01-16 21:21:02.762342: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f19a1137860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21403)[0m 2021-01-16 21:21:02.762377: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21422)[0m LSTM is selected.
[2m[36m(pid=21422)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21422)[0m Instructions for updating:
[2m[36m(pid=21422)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21412)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21412)[0m 2021-01-16 21:21:03.638341: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21412)[0m 2021-01-16 21:21:03.647898: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21412)[0m 2021-01-16 21:21:03.650813: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0a890e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21412)[0m 2021-01-16 21:21:03.650850: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21422)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21422)[0m Instructions for updating:
[2m[36m(pid=21422)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21413)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21413)[0m   agg_primitives: ['count']
[2m[36m(pid=21413)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21413)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21413)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21413)[0m Instructions for updating:
[2m[36m(pid=21413)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21413)[0m LSTM is selected.
[2m[36m(pid=21422)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21422)[0m 2021-01-16 21:21:04.770880: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21422)[0m 2021-01-16 21:21:04.780757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21422)[0m 2021-01-16 21:21:04.785789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90b10dca70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21422)[0m 2021-01-16 21:21:04.785836: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21413)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21413)[0m Instructions for updating:
[2m[36m(pid=21413)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 19.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 17 ({'RUNNING': 10, 'ERROR': 5, 'TERMINATED': 2})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-20-43f29pn5w0/error_2021-01-16_21-20-56.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pcaxcfs3/error_2021-01-16_21-20-56.txt
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19620], 13 s, 4 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19651], 10 s, 1 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19653], 14 s, 3 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=21400], 5 s, 1 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	RUNNING
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAKE(datetime)=0.86333,bayes_feature_IS_BUSY_HOURS(datetime)=0.4354,bayes_feature_IS_WEEKEND(datetime)=0.74762,bayes_feature_MONTH(datetime)=0.66727,bayes_feature_WEEKDAY(datetime)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	RUNNING
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19650], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19637], 8 s, 5 iter

[2m[36m(pid=21413)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21413)[0m 2021-01-16 21:21:06.276932: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21413)[0m 2021-01-16 21:21:06.289842: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21413)[0m 2021-01-16 21:21:06.294691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3690e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21413)[0m 2021-01-16 21:21:06.294739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21412)[0m 2021-01-16 21:21:07,312	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=21412)[0m Traceback (most recent call last):
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=21412)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=21412)[0m     param_dset[:] = val
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21412)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21412)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21412)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21412)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:07 2021
[2m[36m(pid=21412)[0m , filename = '/tmp/thalvari/4565627/automl_save_eu1fjscx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0a8a6641a8, total write size = 213960, bytes this sub-write = 213960, bytes actually written = 18446744073709551615, offset = 1409024)
[2m[36m(pid=21412)[0m 
[2m[36m(pid=21412)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21412)[0m 
[2m[36m(pid=21412)[0m Traceback (most recent call last):
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21412)[0m     self._entrypoint()
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21412)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21412)[0m     output = train_func(config, reporter)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21412)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21412)[0m     config=config)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21412)[0m     model.save(model_path, config_path)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21412)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21412)[0m     self.model.save(model_path)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21412)[0m     signatures)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21412)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21412)[0m     f.close()
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21412)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21412)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:07 2021
[2m[36m(pid=21412)[0m , filename = '/tmp/thalvari/4565627/automl_save_eu1fjscx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0a8a1b86c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21412)[0m Exception in thread Thread-1:
[2m[36m(pid=21412)[0m Traceback (most recent call last):
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=21412)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=21412)[0m     param_dset[:] = val
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21412)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21412)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21412)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21412)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:07 2021
[2m[36m(pid=21412)[0m , filename = '/tmp/thalvari/4565627/automl_save_eu1fjscx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0a8a6641a8, total write size = 213960, bytes this sub-write = 213960, bytes actually written = 18446744073709551615, offset = 1409024)
[2m[36m(pid=21412)[0m 
[2m[36m(pid=21412)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21412)[0m 
[2m[36m(pid=21412)[0m Traceback (most recent call last):
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21412)[0m     self._entrypoint()
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21412)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21412)[0m     output = train_func(config, reporter)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21412)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21412)[0m     config=config)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21412)[0m     model.save(model_path, config_path)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21412)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21412)[0m     self.model.save(model_path)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21412)[0m     signatures)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21412)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21412)[0m     f.close()
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21412)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21412)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21412)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:07 2021
[2m[36m(pid=21412)[0m , filename = '/tmp/thalvari/4565627/automl_save_eu1fjscx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0a8a1b86c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21412)[0m 
[2m[36m(pid=21412)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21412)[0m 
[2m[36m(pid=21412)[0m Traceback (most recent call last):
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=21412)[0m     self.run()
[2m[36m(pid=21412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=21412)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=21412)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=21412)[0m 
2021-01-16 21:21:08,380	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=21412, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:08,384	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAKE(datetime)=0.86333,bayes_feature_IS_BUSY_HOURS(datetime)=0.4354,bayes_feature_IS_WEEKEND(datetime)=0.74762,bayes_feature_MONTH(datetime)=0.66727,bayes_feature_WEEKDAY(datetime)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=21412)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=21412)[0m 
[2m[36m(pid=21412)[0m Stack (most recent call first):
[2m[36m(pid=21414)[0m 2021-01-16 21:21:09,654	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=21414)[0m Traceback (most recent call last):
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=21414)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=21414)[0m     param_dset[:] = val
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21414)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21414)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21414)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21414)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:09 2021
[2m[36m(pid=21414)[0m , filename = '/tmp/thalvari/4565627/automl_save_e3v2p9qo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d9541089c, total write size = 597684, bytes this sub-write = 597684, bytes actually written = 18446744073709551615, offset = 1404928)
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21414)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21414)[0m Traceback (most recent call last):
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21414)[0m     self._entrypoint()
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21414)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21414)[0m     output = train_func(config, reporter)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21414)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21414)[0m     config=config)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21414)[0m     model.save(model_path, config_path)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21414)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21414)[0m     self.model.save(model_path)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21414)[0m     signatures)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21414)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21414)[0m     f.close()
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21414)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21414)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:09 2021
[2m[36m(pid=21414)[0m , filename = '/tmp/thalvari/4565627/automl_save_e3v2p9qo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d95e20c30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21414)[0m Exception in thread Thread-1:
[2m[36m(pid=21414)[0m Traceback (most recent call last):
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=21414)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=21414)[0m     param_dset[:] = val
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21414)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21414)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21414)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21414)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:09 2021
[2m[36m(pid=21414)[0m , filename = '/tmp/thalvari/4565627/automl_save_e3v2p9qo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d9541089c, total write size = 597684, bytes this sub-write = 597684, bytes actually written = 18446744073709551615, offset = 1404928)
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21414)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21414)[0m Traceback (most recent call last):
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21414)[0m     self._entrypoint()
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21414)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21414)[0m     output = train_func(config, reporter)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21414)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21414)[0m     config=config)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21414)[0m     model.save(model_path, config_path)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21414)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21414)[0m     self.model.save(model_path)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21414)[0m     signatures)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21414)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21414)[0m     f.close()
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21414)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21414)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21414)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:09 2021
[2m[36m(pid=21414)[0m , filename = '/tmp/thalvari/4565627/automl_save_e3v2p9qo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d95e20c30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21414)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21414)[0m Traceback (most recent call last):
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=21414)[0m     self.run()
[2m[36m(pid=21414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=21414)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=21414)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21415)[0m 2021-01-16 21:21:10,438	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=21415)[0m Traceback (most recent call last):
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=21415)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=21415)[0m     param_dset[:] = val
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21415)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21415)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21415)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21415)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:10 2021
[2m[36m(pid=21415)[0m , filename = '/tmp/thalvari/4565627/automl_save_q1rlqn31/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f62f67dd0d0, total write size = 848412, bytes this sub-write = 848412, bytes actually written = 18446744073709551615, offset = 1396736)
[2m[36m(pid=21415)[0m 
[2m[36m(pid=21415)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21415)[0m 
[2m[36m(pid=21415)[0m Traceback (most recent call last):
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21415)[0m     self._entrypoint()
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21415)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21415)[0m     output = train_func(config, reporter)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21415)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21415)[0m     config=config)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21415)[0m     model.save(model_path, config_path)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21415)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21415)[0m     self.model.save(model_path)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21415)[0m     signatures)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21415)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21415)[0m     f.close()
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21415)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21415)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:10 2021
[2m[36m(pid=21415)[0m , filename = '/tmp/thalvari/4565627/automl_save_q1rlqn31/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f62f5846560, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21415)[0m Exception in thread Thread-1:
[2m[36m(pid=21415)[0m Traceback (most recent call last):
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=21415)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=21415)[0m     param_dset[:] = val
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21415)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21415)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21415)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21415)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:10 2021
[2m[36m(pid=21415)[0m , filename = '/tmp/thalvari/4565627/automl_save_q1rlqn31/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f62f67dd0d0, total write size = 848412, bytes this sub-write = 848412, bytes actually written = 18446744073709551615, offset = 1396736)
[2m[36m(pid=21415)[0m 
[2m[36m(pid=21415)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21415)[0m 
[2m[36m(pid=21415)[0m Traceback (most recent call last):
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21415)[0m     self._entrypoint()
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21415)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21415)[0m     output = train_func(config, reporter)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21415)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21415)[0m     config=config)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21415)[0m     model.save(model_path, config_path)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21415)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21415)[0m     self.model.save(model_path)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21415)[0m     signatures)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21415)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21415)[0m     f.close()
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21415)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21415)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21415)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:10 2021
[2m[36m(pid=21415)[0m , filename = '/tmp/thalvari/4565627/automl_save_q1rlqn31/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f62f5846560, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21415)[0m 
[2m[36m(pid=21415)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21415)[0m 
[2m[36m(pid=21415)[0m Traceback (most recent call last):
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=21415)[0m     self.run()
[2m[36m(pid=21415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=21415)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=21415)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=21415)[0m 
2021-01-16 21:21:10,843	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=21414, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:10,847	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=21414)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=21414)[0m 
[2m[36m(pid=21414)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 20 ({'TERMINATED': 3, 'ERROR': 7, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-20-43f29pn5w0/error_2021-01-16_21-20-56.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pcaxcfs3/error_2021-01-16_21-20-56.txt
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAK_2021-01-16_21-20-5732ifxrab/error_2021-01-16_21-21-10.txt
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAKE(datetime)=0.86333,bayes_feature_IS_BUSY_HOURS(datetime)=0.4354,bayes_feature_IS_WEEKEND(datetime)=0.74762,bayes_feature_MONTH(datetime)=0.66727,bayes_feature_WEEKDAY(datetime)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAK_2021-01-16_21-20-583uo2cjtd/error_2021-01-16_21-21-08.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19651], 16 s, 2 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19653], 19 s, 4 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=21400], 9 s, 3 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=21403], 8 s, 2 iter
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=21422], 6 s, 1 iter
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=21413], 7 s, 1 iter
 - train_func_18_batch_size_log=8.7464,bayes_feature_DAY(datetime)=0.912,bayes_feature_HOUR(datetime)=0.68056,bayes_feature_IS_AWAKE(datetime)=0.46688,bayes_feature_IS_BUSY_HOURS(datetime)=0.94813,bayes_feature_IS_WEEKEND(datetime)=0.75889,bayes_feature_MONTH(datetime)=0.85761,bayes_feature_WEEKDAY(datetime)=0.45109,dropout_1=0.48413,dropout_2=0.4848,epochs=5,lr=0.0027681,lstm_1_units_float=126.63,lstm_2_units_float=127.4,past_seq_len=2:	RUNNING
 - train_func_19_batch_size_log=5.3437,bayes_feature_DAY(datetime)=0.86718,bayes_feature_HOUR(datetime)=0.86306,bayes_feature_IS_AWAKE(datetime)=0.58556,bayes_feature_IS_BUSY_HOURS(datetime)=0.96126,bayes_feature_IS_WEEKEND(datetime)=0.61999,bayes_feature_MONTH(datetime)=0.85166,bayes_feature_WEEKDAY(datetime)=0.95074,dropout_1=0.25837,dropout_2=0.31902,epochs=5,lr=0.0032245,lstm_1_units_float=127.61,lstm_2_units_float=127.21,past_seq_len=2:	RUNNING
 - train_func_20_batch_size_log=8.664,bayes_feature_DAY(datetime)=0.56827,bayes_feature_HOUR(datetime)=0.98575,bayes_feature_IS_AWAKE(datetime)=0.39403,bayes_feature_IS_BUSY_HOURS(datetime)=0.62621,bayes_feature_IS_WEEKEND(datetime)=0.95107,bayes_feature_MONTH(datetime)=0.33758,bayes_feature_WEEKDAY(datetime)=0.96781,dropout_1=0.24555,dropout_2=0.28327,epochs=5,lr=0.0029481,lstm_1_units_float=127.94,lstm_2_units_float=126.59,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19650], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19637], 8 s, 5 iter

2021-01-16 21:21:11,750	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=21415, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:11,753	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=21415)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=21415)[0m 
[2m[36m(pid=21415)[0m Stack (most recent call first):
[2m[36m(pid=19629)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19629)[0m   agg_primitives: ['count']
[2m[36m(pid=19629)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19629)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19629)[0m LSTM is selected.
[2m[36m(pid=19629)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19629)[0m Instructions for updating:
[2m[36m(pid=19629)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19642)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19642)[0m   agg_primitives: ['count']
[2m[36m(pid=19642)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19642)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19629)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19629)[0m Instructions for updating:
[2m[36m(pid=19629)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19642)[0m LSTM is selected.
[2m[36m(pid=19642)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19642)[0m Instructions for updating:
[2m[36m(pid=19642)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19642)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19642)[0m Instructions for updating:
[2m[36m(pid=19642)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19629)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19629)[0m 2021-01-16 21:21:14.188725: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19629)[0m 2021-01-16 21:21:14.203192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19629)[0m 2021-01-16 21:21:14.207603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe48d102c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19629)[0m 2021-01-16 21:21:14.207650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19642)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19642)[0m 2021-01-16 21:21:15.009623: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19642)[0m 2021-01-16 21:21:15.021194: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19642)[0m 2021-01-16 21:21:15.025730: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f347d136900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19642)[0m 2021-01-16 21:21:15.025769: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19623)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19623)[0m   agg_primitives: ['count']
[2m[36m(pid=19623)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19623)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19628)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19628)[0m   agg_primitives: ['count']
[2m[36m(pid=19628)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19628)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19623)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19623)[0m Instructions for updating:
[2m[36m(pid=19623)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19623)[0m LSTM is selected.
[2m[36m(pid=19628)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19628)[0m Instructions for updating:
[2m[36m(pid=19628)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19628)[0m LSTM is selected.
[2m[36m(pid=19623)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19623)[0m Instructions for updating:
[2m[36m(pid=19623)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19628)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19628)[0m Instructions for updating:
[2m[36m(pid=19628)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 23 ({'TERMINATED': 6, 'ERROR': 8, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 2 not shown
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAK_2021-01-16_21-20-56f0p19apn/error_2021-01-16_21-21-11.txt
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAK_2021-01-16_21-20-5732ifxrab/error_2021-01-16_21-21-10.txt
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAKE(datetime)=0.86333,bayes_feature_IS_BUSY_HOURS(datetime)=0.4354,bayes_feature_IS_WEEKEND(datetime)=0.74762,bayes_feature_MONTH(datetime)=0.66727,bayes_feature_WEEKDAY(datetime)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAK_2021-01-16_21-20-583uo2cjtd/error_2021-01-16_21-21-08.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19651], 22 s, 3 iter
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=21422], 12 s, 3 iter
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=21413], 11 s, 3 iter
  ... 3 not shown
 - train_func_21_batch_size_log=6.5542,bayes_feature_DAY(datetime)=0.51789,bayes_feature_HOUR(datetime)=0.38767,bayes_feature_IS_AWAKE(datetime)=0.83361,bayes_feature_IS_BUSY_HOURS(datetime)=0.99462,bayes_feature_IS_WEEKEND(datetime)=0.72803,bayes_feature_MONTH(datetime)=0.60771,bayes_feature_WEEKDAY(datetime)=0.81755,dropout_1=0.35695,dropout_2=0.21205,epochs=5,lr=0.0029892,lstm_1_units_float=127.49,lstm_2_units_float=127.54,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19650], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19637], 8 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21400], 13 s, 5 iter
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21403], 16 s, 5 iter

[2m[36m(pid=19623)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19623)[0m 2021-01-16 21:21:17.524125: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19623)[0m 2021-01-16 21:21:17.533252: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19623)[0m 2021-01-16 21:21:17.535627: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f20c5103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19623)[0m 2021-01-16 21:21:17.535660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19629)[0m 2021-01-16 21:21:17,715	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19629)[0m Traceback (most recent call last):
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19629)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19629)[0m     param_dset[:] = val
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19629)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19629)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19629)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19629)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:17 2021
[2m[36m(pid=19629)[0m , filename = '/tmp/thalvari/4565627/automl_save_4u05hjj7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe48e22a808, total write size = 547660, bytes this sub-write = 547660, bytes actually written = 18446744073709551615, offset = 1384448)
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19629)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19629)[0m Traceback (most recent call last):
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19629)[0m     self._entrypoint()
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19629)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19629)[0m     output = train_func(config, reporter)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19629)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19629)[0m     config=config)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19629)[0m     model.save(model_path, config_path)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19629)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19629)[0m     self.model.save(model_path)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19629)[0m     signatures)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19629)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19629)[0m     f.close()
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19629)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19629)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:17 2021
[2m[36m(pid=19629)[0m , filename = '/tmp/thalvari/4565627/automl_save_4u05hjj7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe48e986040, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19629)[0m Exception in thread Thread-1:
[2m[36m(pid=19629)[0m Traceback (most recent call last):
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19629)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19629)[0m     param_dset[:] = val
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19629)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19629)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19629)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19629)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:17 2021
[2m[36m(pid=19629)[0m , filename = '/tmp/thalvari/4565627/automl_save_4u05hjj7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe48e22a808, total write size = 547660, bytes this sub-write = 547660, bytes actually written = 18446744073709551615, offset = 1384448)
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19629)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19629)[0m Traceback (most recent call last):
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19629)[0m     self._entrypoint()
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19629)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19629)[0m     output = train_func(config, reporter)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19629)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19629)[0m     config=config)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19629)[0m     model.save(model_path, config_path)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19629)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19629)[0m     self.model.save(model_path)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19629)[0m     signatures)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19629)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19629)[0m     f.close()
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19629)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19629)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19629)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:17 2021
[2m[36m(pid=19629)[0m , filename = '/tmp/thalvari/4565627/automl_save_4u05hjj7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe48e986040, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19628)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19628)[0m 2021-01-16 21:21:17.735761: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19628)[0m 2021-01-16 21:21:17.743932: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19628)[0m 2021-01-16 21:21:17.746203: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb8f511cfb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19628)[0m 2021-01-16 21:21:17.746234: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19629)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19629)[0m Traceback (most recent call last):
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19629)[0m     self.run()
[2m[36m(pid=19629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19629)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19629)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19630)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19630)[0m   agg_primitives: ['count']
[2m[36m(pid=19630)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19630)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19626)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19626)[0m   agg_primitives: ['count']
[2m[36m(pid=19626)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19626)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19630)[0m LSTM is selected.
[2m[36m(pid=19630)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19630)[0m Instructions for updating:
[2m[36m(pid=19630)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19626)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19626)[0m Instructions for updating:
[2m[36m(pid=19626)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19626)[0m LSTM is selected.
2021-01-16 21:21:18,737	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19629, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:18,741	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_18_batch_size_log=8.7464,bayes_feature_DAY(datetime)=0.912,bayes_feature_HOUR(datetime)=0.68056,bayes_feature_IS_AWAKE(datetime)=0.46688,bayes_feature_IS_BUSY_HOURS(datetime)=0.94813,bayes_feature_IS_WEEKEND(datetime)=0.75889,bayes_feature_MONTH(datetime)=0.85761,bayes_feature_WEEKDAY(datetime)=0.45109,dropout_1=0.48413,dropout_2=0.4848,epochs=5,lr=0.0027681,lstm_1_units_float=126.63,lstm_2_units_float=127.4,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19629)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19629)[0m 
[2m[36m(pid=19629)[0m Stack (most recent call first):
[2m[36m(pid=19630)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19630)[0m Instructions for updating:
[2m[36m(pid=19630)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19626)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19626)[0m Instructions for updating:
[2m[36m(pid=19626)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19626)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19626)[0m 2021-01-16 21:21:20.282401: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19626)[0m 2021-01-16 21:21:20.292510: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19626)[0m 2021-01-16 21:21:20.295450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7690cea70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19626)[0m 2021-01-16 21:21:20.295481: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19630)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19630)[0m 2021-01-16 21:21:20.354454: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19630)[0m 2021-01-16 21:21:20.363899: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19630)[0m 2021-01-16 21:21:20.370253: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f76f909aee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19630)[0m 2021-01-16 21:21:20.370298: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19623)[0m 2021-01-16 21:21:21,152	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19623)[0m Traceback (most recent call last):
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19623)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19623)[0m     param_dset[:] = val
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19623)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19623)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19623)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19623)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:21 2021
[2m[36m(pid=19623)[0m , filename = '/tmp/thalvari/4565627/automl_save_eku1ukgw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c6c05998, total write size = 547056, bytes this sub-write = 547056, bytes actually written = 18446744073709551615, offset = 1376256)
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19623)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19623)[0m Traceback (most recent call last):
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19623)[0m     self._entrypoint()
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19623)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19623)[0m     output = train_func(config, reporter)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19623)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19623)[0m     config=config)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19623)[0m     model.save(model_path, config_path)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19623)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19623)[0m     self.model.save(model_path)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19623)[0m     signatures)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19623)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19623)[0m     f.close()
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19623)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19623)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:21 2021
[2m[36m(pid=19623)[0m , filename = '/tmp/thalvari/4565627/automl_save_eku1ukgw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c55bf180, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19623)[0m Exception in thread Thread-1:
[2m[36m(pid=19623)[0m Traceback (most recent call last):
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19623)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19623)[0m     param_dset[:] = val
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19623)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19623)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19623)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19623)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:21 2021
[2m[36m(pid=19623)[0m , filename = '/tmp/thalvari/4565627/automl_save_eku1ukgw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c6c05998, total write size = 547056, bytes this sub-write = 547056, bytes actually written = 18446744073709551615, offset = 1376256)
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19623)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19623)[0m Traceback (most recent call last):
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19623)[0m     self._entrypoint()
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19623)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19623)[0m     output = train_func(config, reporter)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19623)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19623)[0m     config=config)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19623)[0m     model.save(model_path, config_path)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19623)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19623)[0m     self.model.save(model_path)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19623)[0m     signatures)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19623)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19623)[0m     f.close()
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19623)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19623)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19623)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:21 2021
[2m[36m(pid=19623)[0m , filename = '/tmp/thalvari/4565627/automl_save_eku1ukgw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c55bf180, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19623)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19623)[0m Traceback (most recent call last):
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19623)[0m     self.run()
[2m[36m(pid=19623)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19623)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19623)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19624)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19624)[0m   agg_primitives: ['count']
[2m[36m(pid=19624)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19624)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:21:22,195	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19623, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:22,200	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_20_batch_size_log=8.664,bayes_feature_DAY(datetime)=0.56827,bayes_feature_HOUR(datetime)=0.98575,bayes_feature_IS_AWAKE(datetime)=0.39403,bayes_feature_IS_BUSY_HOURS(datetime)=0.62621,bayes_feature_IS_WEEKEND(datetime)=0.95107,bayes_feature_MONTH(datetime)=0.33758,bayes_feature_WEEKDAY(datetime)=0.96781,dropout_1=0.24555,dropout_2=0.28327,epochs=5,lr=0.0029481,lstm_1_units_float=127.94,lstm_2_units_float=126.59,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 27 ({'TERMINATED': 8, 'ERROR': 10, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 4 not shown
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAKE(datetime)=0.86333,bayes_feature_IS_BUSY_HOURS(datetime)=0.4354,bayes_feature_IS_WEEKEND(datetime)=0.74762,bayes_feature_MONTH(datetime)=0.66727,bayes_feature_WEEKDAY(datetime)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_15_batch_size_log=8.7638,bayes_feature_DAY(datetime)=0.34658,bayes_feature_HOUR(datetime)=0.48222,bayes_feature_IS_AWAK_2021-01-16_21-20-583uo2cjtd/error_2021-01-16_21-21-08.txt
 - train_func_18_batch_size_log=8.7464,bayes_feature_DAY(datetime)=0.912,bayes_feature_HOUR(datetime)=0.68056,bayes_feature_IS_AWAKE(datetime)=0.46688,bayes_feature_IS_BUSY_HOURS(datetime)=0.94813,bayes_feature_IS_WEEKEND(datetime)=0.75889,bayes_feature_MONTH(datetime)=0.85761,bayes_feature_WEEKDAY(datetime)=0.45109,dropout_1=0.48413,dropout_2=0.4848,epochs=5,lr=0.0027681,lstm_1_units_float=126.63,lstm_2_units_float=127.4,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_18_batch_size_log=8.7464,bayes_feature_DAY(datetime)=0.912,bayes_feature_HOUR(datetime)=0.68056,bayes_feature_IS_AWAKE(_2021-01-16_21-21-07hmywv8i6/error_2021-01-16_21-21-18.txt
 - train_func_20_batch_size_log=8.664,bayes_feature_DAY(datetime)=0.56827,bayes_feature_HOUR(datetime)=0.98575,bayes_feature_IS_AWAKE(datetime)=0.39403,bayes_feature_IS_BUSY_HOURS(datetime)=0.62621,bayes_feature_IS_WEEKEND(datetime)=0.95107,bayes_feature_MONTH(datetime)=0.33758,bayes_feature_WEEKDAY(datetime)=0.96781,dropout_1=0.24555,dropout_2=0.28327,epochs=5,lr=0.0029481,lstm_1_units_float=127.94,lstm_2_units_float=126.59,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_20_batch_size_log=8.664,bayes_feature_DAY(datetime)=0.56827,bayes_feature_HOUR(datetime)=0.98575,bayes_feature_IS_AWAKE_2021-01-16_21-21-118fivatf0/error_2021-01-16_21-21-22.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19651], 28 s, 4 iter
 - train_func_19_batch_size_log=5.3437,bayes_feature_DAY(datetime)=0.86718,bayes_feature_HOUR(datetime)=0.86306,bayes_feature_IS_AWAKE(datetime)=0.58556,bayes_feature_IS_BUSY_HOURS(datetime)=0.96126,bayes_feature_IS_WEEKEND(datetime)=0.61999,bayes_feature_MONTH(datetime)=0.85166,bayes_feature_WEEKDAY(datetime)=0.95074,dropout_1=0.25837,dropout_2=0.31902,epochs=5,lr=0.0032245,lstm_1_units_float=127.61,lstm_2_units_float=127.21,past_seq_len=2:	RUNNING
 - train_func_21_batch_size_log=6.5542,bayes_feature_DAY(datetime)=0.51789,bayes_feature_HOUR(datetime)=0.38767,bayes_feature_IS_AWAKE(datetime)=0.83361,bayes_feature_IS_BUSY_HOURS(datetime)=0.99462,bayes_feature_IS_WEEKEND(datetime)=0.72803,bayes_feature_MONTH(datetime)=0.60771,bayes_feature_WEEKDAY(datetime)=0.81755,dropout_1=0.35695,dropout_2=0.21205,epochs=5,lr=0.0029892,lstm_1_units_float=127.49,lstm_2_units_float=127.54,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_25_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.054,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_26_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=85.949,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.573,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19650], 10 s, 5 iter
  ... 2 not shown
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21403], 16 s, 5 iter
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21422], 17 s, 5 iter
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter

[2m[36m(pid=19623)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19623)[0m 
[2m[36m(pid=19623)[0m Stack (most recent call first):
[2m[36m(pid=19624)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19624)[0m Instructions for updating:
[2m[36m(pid=19624)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19624)[0m LSTM is selected.
[2m[36m(pid=19624)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19624)[0m Instructions for updating:
[2m[36m(pid=19624)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19628)[0m 2021-01-16 21:21:23,208	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19628)[0m Traceback (most recent call last):
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19628)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19628)[0m     param_dset[:] = val
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19628)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19628)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19628)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19628)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:23 2021
[2m[36m(pid=19628)[0m , filename = '/tmp/thalvari/4565627/automl_save_pl8z1szk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb8f6afd338, total write size = 572252, bytes this sub-write = 572252, bytes actually written = 18446744073709551615, offset = 1368064)
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19628)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19628)[0m Traceback (most recent call last):
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19628)[0m     self._entrypoint()
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19628)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19628)[0m     output = train_func(config, reporter)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19628)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19628)[0m     config=config)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19628)[0m     model.save(model_path, config_path)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19628)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19628)[0m     self.model.save(model_path)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19628)[0m     signatures)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19628)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19628)[0m     f.close()
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19628)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19628)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:23 2021
[2m[36m(pid=19628)[0m , filename = '/tmp/thalvari/4565627/automl_save_pl8z1szk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb8f5564400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19628)[0m Exception in thread Thread-1:
[2m[36m(pid=19628)[0m Traceback (most recent call last):
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19628)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19628)[0m     param_dset[:] = val
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19628)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19628)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19628)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19628)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:23 2021
[2m[36m(pid=19628)[0m , filename = '/tmp/thalvari/4565627/automl_save_pl8z1szk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb8f6afd338, total write size = 572252, bytes this sub-write = 572252, bytes actually written = 18446744073709551615, offset = 1368064)
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19628)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19628)[0m Traceback (most recent call last):
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19628)[0m     self._entrypoint()
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19628)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19628)[0m     output = train_func(config, reporter)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19628)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19628)[0m     config=config)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19628)[0m     model.save(model_path, config_path)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19628)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19628)[0m     self.model.save(model_path)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19628)[0m     signatures)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19628)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19628)[0m     f.close()
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19628)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19628)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19628)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:23 2021
[2m[36m(pid=19628)[0m , filename = '/tmp/thalvari/4565627/automl_save_pl8z1szk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb8f5564400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19628)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19628)[0m Traceback (most recent call last):
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19628)[0m     self.run()
[2m[36m(pid=19628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19628)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19628)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19654)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19654)[0m   agg_primitives: ['count']
[2m[36m(pid=19654)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19654)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19642)[0m 2021-01-16 21:21:24,083	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19642)[0m Traceback (most recent call last):
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19642)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19642)[0m     param_dset[:] = val
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19642)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19642)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19642)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19642)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:24 2021
[2m[36m(pid=19642)[0m , filename = '/tmp/thalvari/4565627/automl_save_ko5i3vte/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f347e902878, total write size = 582476, bytes this sub-write = 582476, bytes actually written = 18446744073709551615, offset = 1359872)
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19642)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19642)[0m Traceback (most recent call last):
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19642)[0m     self._entrypoint()
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19642)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19642)[0m     output = train_func(config, reporter)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19642)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19642)[0m     config=config)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19642)[0m     model.save(model_path, config_path)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19642)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19642)[0m     self.model.save(model_path)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19642)[0m     signatures)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19642)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19642)[0m     f.close()
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19642)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19642)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:24 2021
[2m[36m(pid=19642)[0m , filename = '/tmp/thalvari/4565627/automl_save_ko5i3vte/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f347db59aa0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19642)[0m Exception in thread Thread-1:
[2m[36m(pid=19642)[0m Traceback (most recent call last):
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19642)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19642)[0m     param_dset[:] = val
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19642)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19642)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19642)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19642)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:24 2021
[2m[36m(pid=19642)[0m , filename = '/tmp/thalvari/4565627/automl_save_ko5i3vte/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f347e902878, total write size = 582476, bytes this sub-write = 582476, bytes actually written = 18446744073709551615, offset = 1359872)
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19642)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19642)[0m Traceback (most recent call last):
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19642)[0m     self._entrypoint()
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19642)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19642)[0m     output = train_func(config, reporter)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19642)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19642)[0m     config=config)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19642)[0m     model.save(model_path, config_path)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19642)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19642)[0m     self.model.save(model_path)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19642)[0m     signatures)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19642)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19642)[0m     f.close()
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19642)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19642)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19642)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:24 2021
[2m[36m(pid=19642)[0m , filename = '/tmp/thalvari/4565627/automl_save_ko5i3vte/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f347db59aa0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19642)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19642)[0m Traceback (most recent call last):
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19642)[0m     self.run()
[2m[36m(pid=19642)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19642)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19642)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19624)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19624)[0m 2021-01-16 21:21:24.140594: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19624)[0m 2021-01-16 21:21:24.149699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19624)[0m 2021-01-16 21:21:24.152199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb2d11d620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19624)[0m 2021-01-16 21:21:24.152235: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19654)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19654)[0m Instructions for updating:
[2m[36m(pid=19654)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19654)[0m LSTM is selected.
2021-01-16 21:21:24,316	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19628, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:24,321	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_21_batch_size_log=6.5542,bayes_feature_DAY(datetime)=0.51789,bayes_feature_HOUR(datetime)=0.38767,bayes_feature_IS_AWAKE(datetime)=0.83361,bayes_feature_IS_BUSY_HOURS(datetime)=0.99462,bayes_feature_IS_WEEKEND(datetime)=0.72803,bayes_feature_MONTH(datetime)=0.60771,bayes_feature_WEEKDAY(datetime)=0.81755,dropout_1=0.35695,dropout_2=0.21205,epochs=5,lr=0.0029892,lstm_1_units_float=127.49,lstm_2_units_float=127.54,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19628)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19628)[0m 
[2m[36m(pid=19628)[0m Stack (most recent call first):
[2m[36m(pid=19648)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19648)[0m   agg_primitives: ['count']
[2m[36m(pid=19648)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19648)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19619)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19619)[0m   agg_primitives: ['count']
[2m[36m(pid=19619)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19619)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19654)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19654)[0m Instructions for updating:
[2m[36m(pid=19654)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19648)[0m LSTM is selected.
[2m[36m(pid=19619)[0m LSTM is selected.
[2m[36m(pid=19648)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19648)[0m Instructions for updating:
[2m[36m(pid=19648)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19619)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19619)[0m Instructions for updating:
[2m[36m(pid=19619)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19648)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19648)[0m Instructions for updating:
[2m[36m(pid=19648)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19619)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19619)[0m Instructions for updating:
[2m[36m(pid=19619)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:21:25,853	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19642, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:25,857	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_19_batch_size_log=5.3437,bayes_feature_DAY(datetime)=0.86718,bayes_feature_HOUR(datetime)=0.86306,bayes_feature_IS_AWAKE(datetime)=0.58556,bayes_feature_IS_BUSY_HOURS(datetime)=0.96126,bayes_feature_IS_WEEKEND(datetime)=0.61999,bayes_feature_MONTH(datetime)=0.85166,bayes_feature_WEEKDAY(datetime)=0.95074,dropout_1=0.25837,dropout_2=0.31902,epochs=5,lr=0.0032245,lstm_1_units_float=127.61,lstm_2_units_float=127.21,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19654)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19654)[0m 2021-01-16 21:21:25.824623: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19654)[0m 2021-01-16 21:21:25.834392: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19654)[0m 2021-01-16 21:21:25.836730: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5af511d300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19654)[0m 2021-01-16 21:21:25.836751: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19642)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19642)[0m 
[2m[36m(pid=19642)[0m Stack (most recent call first):
[2m[36m(pid=19648)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19648)[0m 2021-01-16 21:21:26.726462: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19648)[0m 2021-01-16 21:21:26.734455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19648)[0m 2021-01-16 21:21:26.737439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3f790cf400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19648)[0m 2021-01-16 21:21:26.737472: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19619)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19619)[0m 2021-01-16 21:21:26.779322: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19619)[0m 2021-01-16 21:21:26.791628: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19619)[0m 2021-01-16 21:21:26.794342: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fce7911d400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19619)[0m 2021-01-16 21:21:26.794384: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19646)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19646)[0m   agg_primitives: ['count']
[2m[36m(pid=19646)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19646)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19624)[0m 2021-01-16 21:21:27,151	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19624)[0m Traceback (most recent call last):
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19624)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19624)[0m     param_dset[:] = val
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19624)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19624)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19624)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19624)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:27 2021
[2m[36m(pid=19624)[0m , filename = '/tmp/thalvari/4565627/automl_save_2setj8y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb2e87c7c8, total write size = 365592, bytes this sub-write = 365592, bytes actually written = 18446744073709551615, offset = 1351680)
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19624)[0m Traceback (most recent call last):
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19624)[0m     self._entrypoint()
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19624)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19624)[0m     output = train_func(config, reporter)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19624)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19624)[0m     config=config)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19624)[0m     model.save(model_path, config_path)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19624)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19624)[0m     self.model.save(model_path)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19624)[0m     signatures)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19624)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19624)[0m     f.close()
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19624)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19624)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:27 2021
[2m[36m(pid=19624)[0m , filename = '/tmp/thalvari/4565627/automl_save_2setj8y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb2d63d930, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19624)[0m Exception in thread Thread-1:
[2m[36m(pid=19624)[0m Traceback (most recent call last):
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19624)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19624)[0m     param_dset[:] = val
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19624)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19624)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19624)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19624)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:27 2021
[2m[36m(pid=19624)[0m , filename = '/tmp/thalvari/4565627/automl_save_2setj8y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb2e87c7c8, total write size = 365592, bytes this sub-write = 365592, bytes actually written = 18446744073709551615, offset = 1351680)
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19624)[0m Traceback (most recent call last):
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19624)[0m     self._entrypoint()
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19624)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19624)[0m     output = train_func(config, reporter)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19624)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19624)[0m     config=config)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19624)[0m     model.save(model_path, config_path)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19624)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19624)[0m     self.model.save(model_path)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19624)[0m     signatures)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19624)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19624)[0m     f.close()
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19624)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19624)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19624)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:27 2021
[2m[36m(pid=19624)[0m , filename = '/tmp/thalvari/4565627/automl_save_2setj8y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb2d63d930, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19624)[0m Traceback (most recent call last):
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19624)[0m     self.run()
[2m[36m(pid=19624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19624)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19624)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19646)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19646)[0m Instructions for updating:
[2m[36m(pid=19646)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19646)[0m LSTM is selected.
[2m[36m(pid=19646)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19646)[0m Instructions for updating:
[2m[36m(pid=19646)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:21:28,173	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19624, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:28,178	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_24_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.055,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 31 ({'TERMINATED': 9, 'ERROR': 13, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 7 not shown
 - train_func_20_batch_size_log=8.664,bayes_feature_DAY(datetime)=0.56827,bayes_feature_HOUR(datetime)=0.98575,bayes_feature_IS_AWAKE(datetime)=0.39403,bayes_feature_IS_BUSY_HOURS(datetime)=0.62621,bayes_feature_IS_WEEKEND(datetime)=0.95107,bayes_feature_MONTH(datetime)=0.33758,bayes_feature_WEEKDAY(datetime)=0.96781,dropout_1=0.24555,dropout_2=0.28327,epochs=5,lr=0.0029481,lstm_1_units_float=127.94,lstm_2_units_float=126.59,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_20_batch_size_log=8.664,bayes_feature_DAY(datetime)=0.56827,bayes_feature_HOUR(datetime)=0.98575,bayes_feature_IS_AWAKE_2021-01-16_21-21-118fivatf0/error_2021-01-16_21-21-22.txt
 - train_func_21_batch_size_log=6.5542,bayes_feature_DAY(datetime)=0.51789,bayes_feature_HOUR(datetime)=0.38767,bayes_feature_IS_AWAKE(datetime)=0.83361,bayes_feature_IS_BUSY_HOURS(datetime)=0.99462,bayes_feature_IS_WEEKEND(datetime)=0.72803,bayes_feature_MONTH(datetime)=0.60771,bayes_feature_WEEKDAY(datetime)=0.81755,dropout_1=0.35695,dropout_2=0.21205,epochs=5,lr=0.0029892,lstm_1_units_float=127.49,lstm_2_units_float=127.54,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_21_batch_size_log=6.5542,bayes_feature_DAY(datetime)=0.51789,bayes_feature_HOUR(datetime)=0.38767,bayes_feature_IS_AWAK_2021-01-16_21-21-12ag00t4l_/error_2021-01-16_21-21-24.txt
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.055,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_24_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-21-17hkpc6bdp/error_2021-01-16_21-21-28.txt
RUNNING trials:
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_25_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.054,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.59,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.774,lstm_2_units_float=118.94,past_seq_len=2:	RUNNING
 - train_func_31_batch_size_log=7.2672,bayes_feature_DAY(datetime)=0.9954,bayes_feature_HOUR(datetime)=0.32481,bayes_feature_IS_AWAKE(datetime)=0.53627,bayes_feature_IS_BUSY_HOURS(datetime)=0.67619,bayes_feature_IS_WEEKEND(datetime)=0.61211,bayes_feature_MONTH(datetime)=0.36325,bayes_feature_WEEKDAY(datetime)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 3 not shown
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21403], 16 s, 5 iter
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21422], 17 s, 5 iter
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter

[2m[36m(pid=19624)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19624)[0m 
[2m[36m(pid=19624)[0m Stack (most recent call first):
[2m[36m(pid=19654)[0m 2021-01-16 21:21:28,876	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19654)[0m Traceback (most recent call last):
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19654)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19654)[0m     param_dset[:] = val
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19654)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19654)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19654)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19654)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:28 2021
[2m[36m(pid=19654)[0m , filename = '/tmp/thalvari/4565627/automl_save_pvitbed8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5af6afc808, total write size = 373784, bytes this sub-write = 373784, bytes actually written = 18446744073709551615, offset = 1343488)
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19654)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19654)[0m Traceback (most recent call last):
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19654)[0m     self._entrypoint()
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19654)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19654)[0m     output = train_func(config, reporter)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19654)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19654)[0m     config=config)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19654)[0m     model.save(model_path, config_path)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19654)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19654)[0m     self.model.save(model_path)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19654)[0m     signatures)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19654)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19654)[0m     f.close()
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19654)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19654)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:28 2021
[2m[36m(pid=19654)[0m , filename = '/tmp/thalvari/4565627/automl_save_pvitbed8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5af6564990, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19654)[0m Exception in thread Thread-1:
[2m[36m(pid=19654)[0m Traceback (most recent call last):
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19654)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19654)[0m     param_dset[:] = val
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19654)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19654)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19654)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19654)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:28 2021
[2m[36m(pid=19654)[0m , filename = '/tmp/thalvari/4565627/automl_save_pvitbed8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5af6afc808, total write size = 373784, bytes this sub-write = 373784, bytes actually written = 18446744073709551615, offset = 1343488)
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19654)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19654)[0m Traceback (most recent call last):
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19654)[0m     self._entrypoint()
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19654)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19654)[0m     output = train_func(config, reporter)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19654)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19654)[0m     config=config)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19654)[0m     model.save(model_path, config_path)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19654)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19654)[0m     self.model.save(model_path)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19654)[0m     signatures)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19654)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19654)[0m     f.close()
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19654)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19654)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19654)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:28 2021
[2m[36m(pid=19654)[0m , filename = '/tmp/thalvari/4565627/automl_save_pvitbed8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5af6564990, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19654)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19654)[0m Traceback (most recent call last):
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19654)[0m     self.run()
[2m[36m(pid=19654)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19654)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19654)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19646)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19646)[0m 2021-01-16 21:21:29.068149: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19646)[0m 2021-01-16 21:21:29.081867: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19646)[0m 2021-01-16 21:21:29.085154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef49d0ce6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19646)[0m 2021-01-16 21:21:29.085189: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19625)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19625)[0m   agg_primitives: ['count']
[2m[36m(pid=19625)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19625)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19617)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19617)[0m   agg_primitives: ['count']
[2m[36m(pid=19617)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19617)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19649)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19649)[0m   agg_primitives: ['count']
[2m[36m(pid=19649)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19649)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19619)[0m 2021-01-16 21:21:29,680	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19619)[0m Traceback (most recent call last):
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19619)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19619)[0m     param_dset[:] = val
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19619)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19619)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19619)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19619)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:29 2021
[2m[36m(pid=19619)[0m , filename = '/tmp/thalvari/4565627/automl_save_qygoy4w6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fce7a8a8dd8, total write size = 386840, bytes this sub-write = 386840, bytes actually written = 18446744073709551615, offset = 1335296)
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19619)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19619)[0m Traceback (most recent call last):
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19619)[0m     self._entrypoint()
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19619)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19619)[0m     output = train_func(config, reporter)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19619)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19619)[0m     config=config)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19619)[0m     model.save(model_path, config_path)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19619)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19619)[0m     self.model.save(model_path)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19619)[0m     signatures)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19619)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19619)[0m     f.close()
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19619)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19619)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:29 2021
[2m[36m(pid=19619)[0m , filename = '/tmp/thalvari/4565627/automl_save_qygoy4w6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fce7a286220, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19619)[0m Exception in thread Thread-1:
[2m[36m(pid=19619)[0m Traceback (most recent call last):
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19619)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19619)[0m     param_dset[:] = val
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19619)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19619)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19619)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19619)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:29 2021
[2m[36m(pid=19619)[0m , filename = '/tmp/thalvari/4565627/automl_save_qygoy4w6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fce7a8a8dd8, total write size = 386840, bytes this sub-write = 386840, bytes actually written = 18446744073709551615, offset = 1335296)
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19619)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19619)[0m Traceback (most recent call last):
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19619)[0m     self._entrypoint()
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19619)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19619)[0m     output = train_func(config, reporter)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19619)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19619)[0m     config=config)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19619)[0m     model.save(model_path, config_path)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19619)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19619)[0m     self.model.save(model_path)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19619)[0m     signatures)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19619)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19619)[0m     f.close()
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19619)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19619)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19619)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:29 2021
[2m[36m(pid=19619)[0m , filename = '/tmp/thalvari/4565627/automl_save_qygoy4w6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fce7a286220, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19619)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19619)[0m Traceback (most recent call last):
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19619)[0m     self.run()
[2m[36m(pid=19619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19619)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19619)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19617)[0m LSTM is selected.
[2m[36m(pid=19625)[0m LSTM is selected.
[2m[36m(pid=19617)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19617)[0m Instructions for updating:
[2m[36m(pid=19617)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19625)[0m Instructions for updating:
[2m[36m(pid=19625)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19649)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19649)[0m Instructions for updating:
[2m[36m(pid=19649)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19649)[0m LSTM is selected.
2021-01-16 21:21:29,980	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19654, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:29,983	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_25_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.054,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19654)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19654)[0m 
[2m[36m(pid=19654)[0m Stack (most recent call first):
[2m[36m(pid=19625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19625)[0m Instructions for updating:
[2m[36m(pid=19625)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19617)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19617)[0m Instructions for updating:
[2m[36m(pid=19617)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19649)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19649)[0m Instructions for updating:
[2m[36m(pid=19649)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:21:30,817	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19619, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:30,821	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_26_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=85.949,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19619)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19619)[0m 
[2m[36m(pid=19619)[0m Stack (most recent call first):
[2m[36m(pid=19617)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19617)[0m 2021-01-16 21:21:31.394875: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19617)[0m 2021-01-16 21:21:31.405095: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19625)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19625)[0m 2021-01-16 21:21:31.397556: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19625)[0m 2021-01-16 21:21:31.407844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19617)[0m 2021-01-16 21:21:31.408862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7c5d1026c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19617)[0m 2021-01-16 21:21:31.408899: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19625)[0m 2021-01-16 21:21:31.412654: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef6950ce900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19625)[0m 2021-01-16 21:21:31.412693: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19649)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19649)[0m 2021-01-16 21:21:31.444137: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19649)[0m 2021-01-16 21:21:31.454027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19649)[0m 2021-01-16 21:21:31.457480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f993d0cea70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19649)[0m 2021-01-16 21:21:31.457512: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19626)[0m 2021-01-16 21:21:31,876	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19626)[0m Traceback (most recent call last):
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19626)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19626)[0m     param_dset[:] = val
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19626)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19626)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19626)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19626)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:31 2021
[2m[36m(pid=19626)[0m , filename = '/tmp/thalvari/4565627/automl_save_gpgs05tw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb76a9e2388, total write size = 636504, bytes this sub-write = 636504, bytes actually written = 18446744073709551615, offset = 1318912)
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19626)[0m Traceback (most recent call last):
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19626)[0m     self._entrypoint()
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19626)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19626)[0m     output = train_func(config, reporter)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19626)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19626)[0m     config=config)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19626)[0m     model.save(model_path, config_path)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19626)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19626)[0m     self.model.save(model_path)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19626)[0m     signatures)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19626)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19626)[0m     f.close()
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19626)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19626)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:31 2021
[2m[36m(pid=19626)[0m , filename = '/tmp/thalvari/4565627/automl_save_gpgs05tw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb76a5da460, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19626)[0m Exception in thread Thread-1:
[2m[36m(pid=19626)[0m Traceback (most recent call last):
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19626)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19626)[0m     param_dset[:] = val
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19626)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19626)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19626)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19626)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:31 2021
[2m[36m(pid=19626)[0m , filename = '/tmp/thalvari/4565627/automl_save_gpgs05tw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb76a9e2388, total write size = 636504, bytes this sub-write = 636504, bytes actually written = 18446744073709551615, offset = 1318912)
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19626)[0m Traceback (most recent call last):
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19626)[0m     self._entrypoint()
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19626)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19626)[0m     output = train_func(config, reporter)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19626)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19626)[0m     config=config)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19626)[0m     model.save(model_path, config_path)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19626)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19626)[0m     self.model.save(model_path)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19626)[0m     signatures)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19626)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19626)[0m     f.close()
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19626)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19626)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19626)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:31 2021
[2m[36m(pid=19626)[0m , filename = '/tmp/thalvari/4565627/automl_save_gpgs05tw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb76a5da460, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19626)[0m Traceback (most recent call last):
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19626)[0m     self.run()
[2m[36m(pid=19626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19626)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19626)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19630)[0m 2021-01-16 21:21:32,015	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19630)[0m Traceback (most recent call last):
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19630)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19630)[0m     param_dset[:] = val
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19630)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19630)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19630)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19630)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:32 2021
[2m[36m(pid=19630)[0m , filename = '/tmp/thalvari/4565627/automl_save_jm28ennc/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f76faa34c28, total write size = 632408, bytes this sub-write = 632408, bytes actually written = 18446744073709551615, offset = 1318912)
[2m[36m(pid=19630)[0m 
[2m[36m(pid=19630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19630)[0m 
[2m[36m(pid=19630)[0m Traceback (most recent call last):
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19630)[0m     self._entrypoint()
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19630)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19630)[0m     output = train_func(config, reporter)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19630)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19630)[0m     config=config)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19630)[0m     model.save(model_path, config_path)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19630)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19630)[0m     self.model.save(model_path)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19630)[0m     signatures)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19630)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19630)[0m     f.close()
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19630)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19630)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:32 2021
[2m[36m(pid=19630)[0m , filename = '/tmp/thalvari/4565627/automl_save_jm28ennc/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f76fa64c7f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19630)[0m Exception in thread Thread-1:
[2m[36m(pid=19630)[0m Traceback (most recent call last):
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19630)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19630)[0m     param_dset[:] = val
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19630)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19630)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19630)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19630)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:32 2021
[2m[36m(pid=19630)[0m , filename = '/tmp/thalvari/4565627/automl_save_jm28ennc/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f76faa34c28, total write size = 632408, bytes this sub-write = 632408, bytes actually written = 18446744073709551615, offset = 1318912)
[2m[36m(pid=19630)[0m 
[2m[36m(pid=19630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19630)[0m 
[2m[36m(pid=19630)[0m Traceback (most recent call last):
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19630)[0m     self._entrypoint()
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19630)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19630)[0m     output = train_func(config, reporter)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19630)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19630)[0m     config=config)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19630)[0m     model.save(model_path, config_path)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19630)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19630)[0m     self.model.save(model_path)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19630)[0m     signatures)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19630)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19630)[0m     f.close()
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19630)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19630)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19630)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:32 2021
[2m[36m(pid=19630)[0m , filename = '/tmp/thalvari/4565627/automl_save_jm28ennc/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f76fa64c7f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19630)[0m 
[2m[36m(pid=19630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19630)[0m 
[2m[36m(pid=19630)[0m Traceback (most recent call last):
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19630)[0m     self.run()
[2m[36m(pid=19630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19630)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19630)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19630)[0m 
[2m[36m(pid=21418)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21418)[0m   agg_primitives: ['count']
[2m[36m(pid=21418)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21418)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:21:32,920	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19626, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:32,928	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:21:33,114	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19630, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:33,117	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_23_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19626)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19626)[0m 
[2m[36m(pid=19626)[0m Stack (most recent call first):
[2m[36m(pid=21418)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21418)[0m Instructions for updating:
[2m[36m(pid=21418)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21418)[0m LSTM is selected.
[2m[36m(pid=19630)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19630)[0m 
[2m[36m(pid=19630)[0m Stack (most recent call first):
[2m[36m(pid=19641)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19641)[0m   agg_primitives: ['count']
[2m[36m(pid=19641)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19641)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 36 ({'TERMINATED': 9, 'ERROR': 17, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 11 not shown
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.055,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_24_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-21-17hkpc6bdp/error_2021-01-16_21-21-28.txt
 - train_func_25_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.054,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_25_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-21-194l5_tjuu/error_2021-01-16_21-21-29.txt
 - train_func_26_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=85.949,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_26_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-21-201zl8edh1/error_2021-01-16_21-21-30.txt
RUNNING trials:
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.573,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_28_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.536,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.59,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.756,lstm_2_units_float=118.94,past_seq_len=2:	RUNNING
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	RUNNING
 - train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.77,lstm_2_units_float=118.94,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 3 not shown
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21403], 16 s, 5 iter
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21422], 17 s, 5 iter
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter

[2m[36m(pid=21418)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21418)[0m Instructions for updating:
[2m[36m(pid=21418)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19641)[0m LSTM is selected.
[2m[36m(pid=19641)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19641)[0m Instructions for updating:
[2m[36m(pid=19641)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19641)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19641)[0m Instructions for updating:
[2m[36m(pid=19641)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21418)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21418)[0m 2021-01-16 21:21:34.865805: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21418)[0m 2021-01-16 21:21:34.874908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21418)[0m 2021-01-16 21:21:34.877411: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2dcd0ce530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21418)[0m 2021-01-16 21:21:34.877452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19621)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19621)[0m   agg_primitives: ['count']
[2m[36m(pid=19621)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19621)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19641)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19641)[0m 2021-01-16 21:21:35.576578: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19641)[0m 2021-01-16 21:21:35.588210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19641)[0m 2021-01-16 21:21:35.591589: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3291036c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19641)[0m 2021-01-16 21:21:35.591636: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19621)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19621)[0m Instructions for updating:
[2m[36m(pid=19621)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19621)[0m LSTM is selected.
[2m[36m(pid=19621)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19621)[0m Instructions for updating:
[2m[36m(pid=19621)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19633)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19633)[0m   agg_primitives: ['count']
[2m[36m(pid=19633)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19633)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19627)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19627)[0m   agg_primitives: ['count']
[2m[36m(pid=19627)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19627)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19648)[0m 2021-01-16 21:21:37,212	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19648)[0m Traceback (most recent call last):
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19648)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19648)[0m     param_dset[:] = val
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19648)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19648)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19648)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19648)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:37 2021
[2m[36m(pid=19648)[0m , filename = '/tmp/thalvari/4565627/automl_save_8f30wvrv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3f7aaa58f8, total write size = 412184, bytes this sub-write = 412184, bytes actually written = 18446744073709551615, offset = 1310720)
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19648)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19648)[0m Traceback (most recent call last):
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19648)[0m     self._entrypoint()
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19648)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19648)[0m     output = train_func(config, reporter)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19648)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19648)[0m     config=config)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19648)[0m     model.save(model_path, config_path)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19648)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19648)[0m     self.model.save(model_path)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19648)[0m     signatures)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19648)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19648)[0m     f.close()
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19648)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19648)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:37 2021
[2m[36m(pid=19648)[0m , filename = '/tmp/thalvari/4565627/automl_save_8f30wvrv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3f7a4eb990, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19648)[0m Exception in thread Thread-1:
[2m[36m(pid=19648)[0m Traceback (most recent call last):
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19648)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19648)[0m     param_dset[:] = val
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19648)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19648)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19648)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19648)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:37 2021
[2m[36m(pid=19648)[0m , filename = '/tmp/thalvari/4565627/automl_save_8f30wvrv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3f7aaa58f8, total write size = 412184, bytes this sub-write = 412184, bytes actually written = 18446744073709551615, offset = 1310720)
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19648)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19648)[0m Traceback (most recent call last):
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19648)[0m     self._entrypoint()
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19648)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19648)[0m     output = train_func(config, reporter)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19648)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19648)[0m     config=config)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19648)[0m     model.save(model_path, config_path)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19648)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19648)[0m     self.model.save(model_path)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19648)[0m     signatures)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19648)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19648)[0m     f.close()
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19648)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19648)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19648)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:37 2021
[2m[36m(pid=19648)[0m , filename = '/tmp/thalvari/4565627/automl_save_8f30wvrv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3f7a4eb990, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19648)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19648)[0m Traceback (most recent call last):
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19648)[0m     self.run()
[2m[36m(pid=19648)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19648)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19648)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19633)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19633)[0m Instructions for updating:
[2m[36m(pid=19633)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19633)[0m LSTM is selected.
[2m[36m(pid=19627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19627)[0m Instructions for updating:
[2m[36m(pid=19627)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19627)[0m LSTM is selected.
[2m[36m(pid=19621)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19621)[0m 2021-01-16 21:21:37.718925: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19621)[0m 2021-01-16 21:21:37.732227: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19621)[0m 2021-01-16 21:21:37.737542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d110cf400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19621)[0m 2021-01-16 21:21:37.737598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19633)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19633)[0m Instructions for updating:
[2m[36m(pid=19633)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19627)[0m Instructions for updating:
[2m[36m(pid=19627)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:21:38,420	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19648, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:38,426	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.573,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19648)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19648)[0m 
[2m[36m(pid=19648)[0m Stack (most recent call first):
[2m[36m(pid=19633)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19633)[0m 2021-01-16 21:21:39.395914: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19633)[0m 2021-01-16 21:21:39.406140: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19633)[0m 2021-01-16 21:21:39.409676: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eed450cf6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19633)[0m 2021-01-16 21:21:39.409722: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19627)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19627)[0m 2021-01-16 21:21:39.388866: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19627)[0m 2021-01-16 21:21:39.402134: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19627)[0m 2021-01-16 21:21:39.407630: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3d75100900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19627)[0m 2021-01-16 21:21:39.407659: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19646)[0m 2021-01-16 21:21:39,406	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19646)[0m Traceback (most recent call last):
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19646)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19646)[0m     param_dset[:] = val
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19646)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19646)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19646)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19646)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:39 2021
[2m[36m(pid=19646)[0m , filename = '/tmp/thalvari/4565627/automl_save_dhsfmxhp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef49eab2168, total write size = 420376, bytes this sub-write = 420376, bytes actually written = 18446744073709551615, offset = 1302528)
[2m[36m(pid=19646)[0m 
[2m[36m(pid=19646)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19646)[0m 
[2m[36m(pid=19646)[0m Traceback (most recent call last):
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19646)[0m     self._entrypoint()
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19646)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19646)[0m     output = train_func(config, reporter)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19646)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19646)[0m     config=config)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19646)[0m     model.save(model_path, config_path)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19646)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19646)[0m     self.model.save(model_path)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19646)[0m     signatures)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19646)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19646)[0m     f.close()
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19646)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19646)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:39 2021
[2m[36m(pid=19646)[0m , filename = '/tmp/thalvari/4565627/automl_save_dhsfmxhp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef49e4e9b90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19646)[0m Exception in thread Thread-1:
[2m[36m(pid=19646)[0m Traceback (most recent call last):
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19646)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19646)[0m     param_dset[:] = val
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19646)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19646)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19646)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19646)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:39 2021
[2m[36m(pid=19646)[0m , filename = '/tmp/thalvari/4565627/automl_save_dhsfmxhp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef49eab2168, total write size = 420376, bytes this sub-write = 420376, bytes actually written = 18446744073709551615, offset = 1302528)
[2m[36m(pid=19646)[0m 
[2m[36m(pid=19646)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19646)[0m 
[2m[36m(pid=19646)[0m Traceback (most recent call last):
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19646)[0m     self._entrypoint()
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19646)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19646)[0m     output = train_func(config, reporter)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19646)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19646)[0m     config=config)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19646)[0m     model.save(model_path, config_path)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19646)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19646)[0m     self.model.save(model_path)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19646)[0m     signatures)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19646)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19646)[0m     f.close()
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19646)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19646)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19646)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:39 2021
[2m[36m(pid=19646)[0m , filename = '/tmp/thalvari/4565627/automl_save_dhsfmxhp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef49e4e9b90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19646)[0m 
[2m[36m(pid=19646)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19646)[0m 
[2m[36m(pid=19646)[0m Traceback (most recent call last):
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19646)[0m     self.run()
[2m[36m(pid=19646)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19646)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19646)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19646)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 37 ({'TERMINATED': 9, 'ERROR': 18, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 12 not shown
 - train_func_25_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=84.054,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_25_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-21-194l5_tjuu/error_2021-01-16_21-21-29.txt
 - train_func_26_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=85.949,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_26_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-21-201zl8edh1/error_2021-01-16_21-21-30.txt
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.573,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-21556n2fbl/error_2021-01-16_21-21-38.txt
RUNNING trials:
 - train_func_28_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.536,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.59,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.774,lstm_2_units_float=118.94,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	RUNNING
 - train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.77,lstm_2_units_float=118.94,past_seq_len=2:	RUNNING
 - train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.771,lstm_2_units_float=118.93,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 3 not shown
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21403], 16 s, 5 iter
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21422], 17 s, 5 iter
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter

2021-01-16 21:21:40,480	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19646, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:40,484	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_28_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.536,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19646)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19646)[0m 
[2m[36m(pid=19646)[0m Stack (most recent call first):
[2m[36m(pid=19649)[0m 2021-01-16 21:21:42,211	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19649)[0m Traceback (most recent call last):
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19649)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19649)[0m     param_dset[:] = val
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19649)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19649)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19649)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19649)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19649)[0m , filename = '/tmp/thalvari/4565627/automl_save_lung_2w3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f993e849a78, total write size = 915992, bytes this sub-write = 915992, bytes actually written = 18446744073709551615, offset = 806912)
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19649)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19649)[0m Traceback (most recent call last):
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19649)[0m     self._entrypoint()
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19649)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19649)[0m     output = train_func(config, reporter)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19649)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19649)[0m     config=config)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19649)[0m     model.save(model_path, config_path)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19649)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19649)[0m     self.model.save(model_path)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19649)[0m     signatures)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19649)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19649)[0m     f.close()
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19649)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19649)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19649)[0m , filename = '/tmp/thalvari/4565627/automl_save_lung_2w3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f993d5888b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19649)[0m Exception in thread Thread-1:
[2m[36m(pid=19649)[0m Traceback (most recent call last):
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19649)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19649)[0m     param_dset[:] = val
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19649)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19649)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19649)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19649)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19649)[0m , filename = '/tmp/thalvari/4565627/automl_save_lung_2w3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f993e849a78, total write size = 915992, bytes this sub-write = 915992, bytes actually written = 18446744073709551615, offset = 806912)
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19649)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19649)[0m Traceback (most recent call last):
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19649)[0m     self._entrypoint()
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19649)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19649)[0m     output = train_func(config, reporter)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19649)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19649)[0m     config=config)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19649)[0m     model.save(model_path, config_path)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19649)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19649)[0m     self.model.save(model_path)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19649)[0m     signatures)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19649)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19649)[0m     f.close()
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19649)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19649)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19649)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19649)[0m , filename = '/tmp/thalvari/4565627/automl_save_lung_2w3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f993d5888b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19649)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19649)[0m Traceback (most recent call last):
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19649)[0m     self.run()
[2m[36m(pid=19649)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19649)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19649)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19625)[0m 2021-01-16 21:21:42,238	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19625)[0m Traceback (most recent call last):
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19625)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19625)[0m     param_dset[:] = val
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19625)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19625)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19625)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19625)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19625)[0m , filename = '/tmp/thalvari/4565627/automl_save_fl2wbbf5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef6968f2ea8, total write size = 253680, bytes this sub-write = 253680, bytes actually written = 18446744073709551615, offset = 1286144)
[2m[36m(pid=19625)[0m 
[2m[36m(pid=19625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19625)[0m 
[2m[36m(pid=19625)[0m Traceback (most recent call last):
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19625)[0m     self._entrypoint()
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19625)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19625)[0m     output = train_func(config, reporter)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19625)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19625)[0m     config=config)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19625)[0m     model.save(model_path, config_path)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19625)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19625)[0m     self.model.save(model_path)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19625)[0m     signatures)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19625)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19625)[0m     f.close()
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19625)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19625)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19625)[0m , filename = '/tmp/thalvari/4565627/automl_save_fl2wbbf5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef6965f1be0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19625)[0m Exception in thread Thread-1:
[2m[36m(pid=19625)[0m Traceback (most recent call last):
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19625)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19625)[0m     param_dset[:] = val
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19625)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19625)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19625)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19625)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19625)[0m , filename = '/tmp/thalvari/4565627/automl_save_fl2wbbf5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef6968f2ea8, total write size = 253680, bytes this sub-write = 253680, bytes actually written = 18446744073709551615, offset = 1286144)
[2m[36m(pid=19625)[0m 
[2m[36m(pid=19625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19625)[0m 
[2m[36m(pid=19625)[0m Traceback (most recent call last):
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19625)[0m     self._entrypoint()
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19625)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19625)[0m     output = train_func(config, reporter)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19625)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19625)[0m     config=config)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19625)[0m     model.save(model_path, config_path)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19625)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19625)[0m     self.model.save(model_path)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19625)[0m     signatures)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19625)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19625)[0m     f.close()
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19625)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19625)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19625)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:42 2021
[2m[36m(pid=19625)[0m , filename = '/tmp/thalvari/4565627/automl_save_fl2wbbf5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef6965f1be0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19625)[0m 
[2m[36m(pid=19625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19625)[0m 
[2m[36m(pid=19625)[0m Traceback (most recent call last):
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19625)[0m     self.run()
[2m[36m(pid=19625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19625)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19625)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19625)[0m 
2021-01-16 21:21:43,312	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19625, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:43,317	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.774,lstm_2_units_float=118.94,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:21:43,541	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19649, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:43,544	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.59,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19625)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19625)[0m 
[2m[36m(pid=19625)[0m Stack (most recent call first):
[2m[36m(pid=19649)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19649)[0m 
[2m[36m(pid=19649)[0m Stack (most recent call first):
[2m[36m(pid=19647)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19647)[0m   agg_primitives: ['count']
[2m[36m(pid=19647)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19647)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19618)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19618)[0m   agg_primitives: ['count']
[2m[36m(pid=19618)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19618)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19647)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19647)[0m Instructions for updating:
[2m[36m(pid=19647)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19647)[0m LSTM is selected.
[2m[36m(pid=19618)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19618)[0m Instructions for updating:
[2m[36m(pid=19618)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19618)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 40 ({'TERMINATED': 9, 'ERROR': 21, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 15 not shown
 - train_func_28_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.536,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_28_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-23a9eq06kj/error_2021-01-16_21-21-40.txt
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=86.59,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-25hi876p8r/error_2021-01-16_21-21-43.txt
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.774,lstm_2_units_float=118.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-259qytotl2/error_2021-01-16_21-21-43.txt
RUNNING trials:
 - train_func_31_batch_size_log=7.2672,bayes_feature_DAY(datetime)=0.9954,bayes_feature_HOUR(datetime)=0.32481,bayes_feature_IS_AWAKE(datetime)=0.53627,bayes_feature_IS_BUSY_HOURS(datetime)=0.67619,bayes_feature_IS_WEEKEND(datetime)=0.61211,bayes_feature_MONTH(datetime)=0.36325,bayes_feature_WEEKDAY(datetime)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19617], 14 s, 4 iter
 - train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.93,past_seq_len=2:	RUNNING
 - train_func_33_batch_size_log=5.2437,bayes_feature_DAY(datetime)=0.36903,bayes_feature_HOUR(datetime)=0.73775,bayes_feature_IS_AWAKE(datetime)=0.78004,bayes_feature_IS_BUSY_HOURS(datetime)=0.9004,bayes_feature_IS_WEEKEND(datetime)=0.39211,bayes_feature_MONTH(datetime)=0.76533,bayes_feature_WEEKDAY(datetime)=0.67767,dropout_1=0.37074,dropout_2=0.40503,epochs=5,lr=0.0053996,lstm_1_units_float=77.617,lstm_2_units_float=122.42,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_38_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.93,past_seq_len=2:	RUNNING
 - train_func_39_batch_size_log=6.0514,bayes_feature_DAY(datetime)=0.36066,bayes_feature_HOUR(datetime)=0.70954,bayes_feature_IS_AWAKE(datetime)=0.87719,bayes_feature_IS_BUSY_HOURS(datetime)=0.6499,bayes_feature_IS_WEEKEND(datetime)=0.37847,bayes_feature_MONTH(datetime)=0.93751,bayes_feature_WEEKDAY(datetime)=0.58144,dropout_1=0.32957,dropout_2=0.40117,epochs=5,lr=0.0035862,lstm_1_units_float=125.17,lstm_2_units_float=101.62,past_seq_len=2:	RUNNING
 - train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.92,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 3 not shown
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(datetime)=0.52215,bayes_feature_HOUR(datetime)=0.99203,bayes_feature_IS_AWAKE(datetime)=0.70582,bayes_feature_IS_BUSY_HOURS(datetime)=0.5661,bayes_feature_IS_WEEKEND(datetime)=0.68566,bayes_feature_MONTH(datetime)=0.82173,bayes_feature_WEEKDAY(datetime)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21403], 16 s, 5 iter
 - train_func_16_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21422], 17 s, 5 iter
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter

[2m[36m(pid=19647)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19647)[0m Instructions for updating:
[2m[36m(pid=19647)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19618)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19618)[0m Instructions for updating:
[2m[36m(pid=19618)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19641)[0m 2021-01-16 21:21:45,586	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19641)[0m Traceback (most recent call last):
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19641)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19641)[0m     param_dset[:] = val
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19641)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19641)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19641)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19641)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:45 2021
[2m[36m(pid=19641)[0m , filename = '/tmp/thalvari/4565627/automl_save_zxcs4ijv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd32a910e38, total write size = 320192, bytes this sub-write = 320192, bytes actually written = 18446744073709551615, offset = 1277952)
[2m[36m(pid=19641)[0m 
[2m[36m(pid=19641)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19641)[0m 
[2m[36m(pid=19641)[0m Traceback (most recent call last):
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19641)[0m     self._entrypoint()
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19641)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19641)[0m     output = train_func(config, reporter)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19641)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19641)[0m     config=config)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19641)[0m     model.save(model_path, config_path)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19641)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19641)[0m     self.model.save(model_path)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19641)[0m     signatures)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19641)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19641)[0m     f.close()
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19641)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19641)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:45 2021
[2m[36m(pid=19641)[0m , filename = '/tmp/thalvari/4565627/automl_save_zxcs4ijv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd32a4a9fb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19641)[0m Exception in thread Thread-1:
[2m[36m(pid=19641)[0m Traceback (most recent call last):
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19641)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19641)[0m     param_dset[:] = val
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19641)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19641)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19641)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19641)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:45 2021
[2m[36m(pid=19641)[0m , filename = '/tmp/thalvari/4565627/automl_save_zxcs4ijv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd32a910e38, total write size = 320192, bytes this sub-write = 320192, bytes actually written = 18446744073709551615, offset = 1277952)
[2m[36m(pid=19641)[0m 
[2m[36m(pid=19641)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19641)[0m 
[2m[36m(pid=19641)[0m Traceback (most recent call last):
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19641)[0m     self._entrypoint()
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19641)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19641)[0m     output = train_func(config, reporter)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19641)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19641)[0m     config=config)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19641)[0m     model.save(model_path, config_path)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19641)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19641)[0m     self.model.save(model_path)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19641)[0m     signatures)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19641)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19641)[0m     f.close()
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19641)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19641)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19641)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:45 2021
[2m[36m(pid=19641)[0m , filename = '/tmp/thalvari/4565627/automl_save_zxcs4ijv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd32a4a9fb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19641)[0m 
[2m[36m(pid=19641)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19641)[0m 
[2m[36m(pid=19641)[0m Traceback (most recent call last):
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19641)[0m     self.run()
[2m[36m(pid=19641)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19641)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19641)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19641)[0m 
[2m[36m(pid=21418)[0m 2021-01-16 21:21:46,120	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=21418)[0m Traceback (most recent call last):
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=21418)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=21418)[0m     param_dset[:] = val
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21418)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21418)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21418)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21418)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:46 2021
[2m[36m(pid=21418)[0m , filename = '/tmp/thalvari/4565627/automl_save_cgbh8mk0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dce8f5e38, total write size = 270064, bytes this sub-write = 270064, bytes actually written = 18446744073709551615, offset = 1269760)
[2m[36m(pid=21418)[0m 
[2m[36m(pid=21418)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21418)[0m 
[2m[36m(pid=21418)[0m Traceback (most recent call last):
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21418)[0m     self._entrypoint()
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21418)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21418)[0m     output = train_func(config, reporter)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21418)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21418)[0m     config=config)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21418)[0m     model.save(model_path, config_path)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21418)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21418)[0m     self.model.save(model_path)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21418)[0m     signatures)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21418)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21418)[0m     f.close()
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21418)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21418)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:46 2021
[2m[36m(pid=21418)[0m , filename = '/tmp/thalvari/4565627/automl_save_cgbh8mk0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dcd3c30e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21418)[0m Exception in thread Thread-1:
[2m[36m(pid=21418)[0m Traceback (most recent call last):
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=21418)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=21418)[0m     param_dset[:] = val
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=21418)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=21418)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=21418)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=21418)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:46 2021
[2m[36m(pid=21418)[0m , filename = '/tmp/thalvari/4565627/automl_save_cgbh8mk0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dce8f5e38, total write size = 270064, bytes this sub-write = 270064, bytes actually written = 18446744073709551615, offset = 1269760)
[2m[36m(pid=21418)[0m 
[2m[36m(pid=21418)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21418)[0m 
[2m[36m(pid=21418)[0m Traceback (most recent call last):
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=21418)[0m     self._entrypoint()
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=21418)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=21418)[0m     output = train_func(config, reporter)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=21418)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=21418)[0m     config=config)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=21418)[0m     model.save(model_path, config_path)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=21418)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=21418)[0m     self.model.save(model_path)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=21418)[0m     signatures)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=21418)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=21418)[0m     f.close()
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=21418)[0m     h5i.dec_ref(id_)
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=21418)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=21418)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:46 2021
[2m[36m(pid=21418)[0m , filename = '/tmp/thalvari/4565627/automl_save_cgbh8mk0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dcd3c30e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=21418)[0m 
[2m[36m(pid=21418)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=21418)[0m 
[2m[36m(pid=21418)[0m Traceback (most recent call last):
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=21418)[0m     self.run()
[2m[36m(pid=21418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=21418)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=21418)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=21418)[0m 
[2m[36m(pid=19647)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19647)[0m 2021-01-16 21:21:46.343460: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19647)[0m 2021-01-16 21:21:46.351832: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19647)[0m 2021-01-16 21:21:46.354758: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb5c90cf620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19647)[0m 2021-01-16 21:21:46.354786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19618)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19618)[0m 2021-01-16 21:21:46.329428: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19618)[0m 2021-01-16 21:21:46.337745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19618)[0m 2021-01-16 21:21:46.340717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f61f50cecb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19618)[0m 2021-01-16 21:21:46.340759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:21:46,792	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19641, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:46,795	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_33_batch_size_log=5.2437,bayes_feature_DAY(datetime)=0.36903,bayes_feature_HOUR(datetime)=0.73775,bayes_feature_IS_AWAKE(datetime)=0.78004,bayes_feature_IS_BUSY_HOURS(datetime)=0.9004,bayes_feature_IS_WEEKEND(datetime)=0.39211,bayes_feature_MONTH(datetime)=0.76533,bayes_feature_WEEKDAY(datetime)=0.67767,dropout_1=0.37074,dropout_2=0.40503,epochs=5,lr=0.0053996,lstm_1_units_float=77.617,lstm_2_units_float=122.42,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19641)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19641)[0m 
[2m[36m(pid=19641)[0m Stack (most recent call first):
2021-01-16 21:21:47,450	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=21418, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:47,453	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.93,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19615)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19615)[0m   agg_primitives: ['count']
[2m[36m(pid=19615)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19615)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19622)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19622)[0m   agg_primitives: ['count']
[2m[36m(pid=19622)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19622)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21418)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=21418)[0m 
[2m[36m(pid=21418)[0m Stack (most recent call first):
[2m[36m(pid=19621)[0m 2021-01-16 21:21:47,804	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19621)[0m Traceback (most recent call last):
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19621)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19621)[0m     param_dset[:] = val
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19621)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19621)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19621)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19621)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:47 2021
[2m[36m(pid=19621)[0m , filename = '/tmp/thalvari/4565627/automl_save_q0njv09k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9d128e0ca8, total write size = 278256, bytes this sub-write = 278256, bytes actually written = 18446744073709551615, offset = 1261568)
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19621)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19621)[0m Traceback (most recent call last):
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19621)[0m     self._entrypoint()
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19621)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19621)[0m     output = train_func(config, reporter)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19621)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19621)[0m     config=config)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19621)[0m     model.save(model_path, config_path)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19621)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19621)[0m     self.model.save(model_path)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19621)[0m     signatures)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19621)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19621)[0m     f.close()
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19621)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19621)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:47 2021
[2m[36m(pid=19621)[0m , filename = '/tmp/thalvari/4565627/automl_save_q0njv09k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9d1238af30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19621)[0m Exception in thread Thread-1:
[2m[36m(pid=19621)[0m Traceback (most recent call last):
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19621)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19621)[0m     param_dset[:] = val
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19621)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19621)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19621)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19621)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:47 2021
[2m[36m(pid=19621)[0m , filename = '/tmp/thalvari/4565627/automl_save_q0njv09k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9d128e0ca8, total write size = 278256, bytes this sub-write = 278256, bytes actually written = 18446744073709551615, offset = 1261568)
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19621)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19621)[0m Traceback (most recent call last):
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19621)[0m     self._entrypoint()
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19621)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19621)[0m     output = train_func(config, reporter)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19621)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19621)[0m     config=config)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19621)[0m     model.save(model_path, config_path)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19621)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19621)[0m     self.model.save(model_path)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19621)[0m     signatures)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19621)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19621)[0m     f.close()
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19621)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19621)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19621)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:47 2021
[2m[36m(pid=19621)[0m , filename = '/tmp/thalvari/4565627/automl_save_q0njv09k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9d1238af30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19621)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19621)[0m Traceback (most recent call last):
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19621)[0m     self.run()
[2m[36m(pid=19621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19621)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19621)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19622)[0m LSTM is selected.
[2m[36m(pid=19615)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19615)[0m Instructions for updating:
[2m[36m(pid=19615)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19615)[0m LSTM is selected.
[2m[36m(pid=19622)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19622)[0m Instructions for updating:
[2m[36m(pid=19622)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19622)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19622)[0m Instructions for updating:
[2m[36m(pid=19622)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19615)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19615)[0m Instructions for updating:
[2m[36m(pid=19615)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:21:48,942	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19621, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:48,948	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.756,lstm_2_units_float=118.94,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19621)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19621)[0m 
[2m[36m(pid=19621)[0m Stack (most recent call first):
[2m[36m(pid=19633)[0m 2021-01-16 21:21:49,395	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19633)[0m Traceback (most recent call last):
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19633)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19633)[0m     param_dset[:] = val
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19633)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19633)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19633)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19633)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:49 2021
[2m[36m(pid=19633)[0m , filename = '/tmp/thalvari/4565627/automl_save_cwkiidy5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eed46a7a488, total write size = 286448, bytes this sub-write = 286448, bytes actually written = 18446744073709551615, offset = 1253376)
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19633)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19633)[0m Traceback (most recent call last):
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19633)[0m     self._entrypoint()
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19633)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19633)[0m     output = train_func(config, reporter)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19633)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19633)[0m     config=config)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19633)[0m     model.save(model_path, config_path)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19633)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19633)[0m     self.model.save(model_path)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19633)[0m     signatures)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19633)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19633)[0m     f.close()
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19633)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19633)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:49 2021
[2m[36m(pid=19633)[0m , filename = '/tmp/thalvari/4565627/automl_save_cwkiidy5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eed46491700, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19633)[0m Exception in thread Thread-1:
[2m[36m(pid=19633)[0m Traceback (most recent call last):
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19633)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19633)[0m     param_dset[:] = val
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19633)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19633)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19633)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19633)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:49 2021
[2m[36m(pid=19633)[0m , filename = '/tmp/thalvari/4565627/automl_save_cwkiidy5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eed46a7a488, total write size = 286448, bytes this sub-write = 286448, bytes actually written = 18446744073709551615, offset = 1253376)
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19633)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19633)[0m Traceback (most recent call last):
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19633)[0m     self._entrypoint()
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19633)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19633)[0m     output = train_func(config, reporter)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19633)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19633)[0m     config=config)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19633)[0m     model.save(model_path, config_path)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19633)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19633)[0m     self.model.save(model_path)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19633)[0m     signatures)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19633)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19633)[0m     f.close()
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19633)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19633)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19633)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:49 2021
[2m[36m(pid=19633)[0m , filename = '/tmp/thalvari/4565627/automl_save_cwkiidy5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eed46491700, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19633)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19633)[0m Traceback (most recent call last):
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19633)[0m     self.run()
[2m[36m(pid=19633)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19633)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19633)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19622)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19622)[0m 2021-01-16 21:21:49.632395: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19622)[0m 2021-01-16 21:21:49.641696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19622)[0m 2021-01-16 21:21:49.644758: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f000d102860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19622)[0m 2021-01-16 21:21:49.644792: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19615)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19615)[0m 2021-01-16 21:21:49.674041: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19615)[0m 2021-01-16 21:21:49.683418: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19615)[0m 2021-01-16 21:21:49.686696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f78e50cec60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19615)[0m 2021-01-16 21:21:49.686743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19639)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19639)[0m   agg_primitives: ['count']
[2m[36m(pid=19639)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19639)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19639)[0m LSTM is selected.
[2m[36m(pid=19639)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19639)[0m Instructions for updating:
[2m[36m(pid=19639)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 45 ({'TERMINATED': 11, 'ERROR': 24, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 18 not shown
 - train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.93,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-28rja45pzx/error_2021-01-16_21-21-47.txt
 - train_func_33_batch_size_log=5.2437,bayes_feature_DAY(datetime)=0.36903,bayes_feature_HOUR(datetime)=0.73775,bayes_feature_IS_AWAKE(datetime)=0.78004,bayes_feature_IS_BUSY_HOURS(datetime)=0.9004,bayes_feature_IS_WEEKEND(datetime)=0.39211,bayes_feature_MONTH(datetime)=0.76533,bayes_feature_WEEKDAY(datetime)=0.67767,dropout_1=0.37074,dropout_2=0.40503,epochs=5,lr=0.0053996,lstm_1_units_float=77.617,lstm_2_units_float=122.42,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_33_batch_size_log=5.2437,bayes_feature_DAY(datetime)=0.36903,bayes_feature_HOUR(datetime)=0.73775,bayes_feature_IS_AWAK_2021-01-16_21-21-30paox0uld/error_2021-01-16_21-21-46.txt
 - train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.756,lstm_2_units_float=118.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-31kubn1ozr/error_2021-01-16_21-21-48.txt
RUNNING trials:
 - train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.77,lstm_2_units_float=118.94,past_seq_len=2:	RUNNING
 - train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.771,lstm_2_units_float=118.93,past_seq_len=2:	RUNNING
 - train_func_38_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.93,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAKE(datetime)=0.66537,bayes_feature_IS_BUSY_HOURS(datetime)=0.48774,bayes_feature_IS_WEEKEND(datetime)=0.56386,bayes_feature_MONTH(datetime)=0.43311,bayes_feature_WEEKDAY(datetime)=0.67913,dropout_1=0.37933,dropout_2=0.32591,epochs=5,lr=0.0038224,lstm_1_units_float=76.587,lstm_2_units_float=43.124,past_seq_len=2:	RUNNING
 - train_func_44_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=81.29,lstm_2_units_float=121.56,past_seq_len=2:	RUNNING
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.504,lstm_2_units_float=123.4,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 5 not shown
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter
 - train_func_31_batch_size_log=7.2672,bayes_feature_DAY(datetime)=0.9954,bayes_feature_HOUR(datetime)=0.32481,bayes_feature_IS_AWAKE(datetime)=0.53627,bayes_feature_IS_BUSY_HOURS(datetime)=0.67619,bayes_feature_IS_WEEKEND(datetime)=0.61211,bayes_feature_MONTH(datetime)=0.36325,bayes_feature_WEEKDAY(datetime)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19617], 17 s, 5 iter
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter

2021-01-16 21:21:50,588	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19633, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:50,591	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.77,lstm_2_units_float=118.94,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19633)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19633)[0m 
[2m[36m(pid=19633)[0m Stack (most recent call first):
[2m[36m(pid=21408)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21408)[0m   agg_primitives: ['count']
[2m[36m(pid=21408)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21408)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19643)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19643)[0m   agg_primitives: ['count']
[2m[36m(pid=19643)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19643)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19639)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19639)[0m Instructions for updating:
[2m[36m(pid=19639)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21408)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21408)[0m Instructions for updating:
[2m[36m(pid=21408)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21408)[0m LSTM is selected.
[2m[36m(pid=19643)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19643)[0m Instructions for updating:
[2m[36m(pid=19643)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19643)[0m LSTM is selected.
[2m[36m(pid=21408)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21408)[0m Instructions for updating:
[2m[36m(pid=21408)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19643)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19643)[0m Instructions for updating:
[2m[36m(pid=19643)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19639)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19639)[0m 2021-01-16 21:21:52.083911: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19639)[0m 2021-01-16 21:21:52.092704: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19639)[0m 2021-01-16 21:21:52.095706: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdfad137620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19639)[0m 2021-01-16 21:21:52.095761: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21408)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21408)[0m 2021-01-16 21:21:52.987540: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21408)[0m 2021-01-16 21:21:52.997076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21408)[0m 2021-01-16 21:21:53.000708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f46750e8c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21408)[0m 2021-01-16 21:21:53.000739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19643)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19643)[0m 2021-01-16 21:21:53.027956: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19643)[0m 2021-01-16 21:21:53.037343: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19643)[0m 2021-01-16 21:21:53.040480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f41e10cefb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19643)[0m 2021-01-16 21:21:53.040516: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19632)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19632)[0m   agg_primitives: ['count']
[2m[36m(pid=19632)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19632)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19632)[0m Instructions for updating:
[2m[36m(pid=19632)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19632)[0m LSTM is selected.
[2m[36m(pid=19616)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19616)[0m   agg_primitives: ['count']
[2m[36m(pid=19616)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19616)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19640)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19640)[0m   agg_primitives: ['count']
[2m[36m(pid=19640)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19640)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19632)[0m Instructions for updating:
[2m[36m(pid=19632)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19616)[0m LSTM is selected.
[2m[36m(pid=19640)[0m LSTM is selected.
[2m[36m(pid=19616)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19616)[0m Instructions for updating:
[2m[36m(pid=19616)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19640)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19640)[0m Instructions for updating:
[2m[36m(pid=19640)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19632)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19632)[0m 2021-01-16 21:21:55.291588: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19616)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19616)[0m Instructions for updating:
[2m[36m(pid=19616)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19632)[0m 2021-01-16 21:21:55.304911: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19632)[0m 2021-01-16 21:21:55.311228: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb3d0cf230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19632)[0m 2021-01-16 21:21:55.311283: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19640)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19640)[0m Instructions for updating:
[2m[36m(pid=19640)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19616)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19616)[0m 2021-01-16 21:21:56.366440: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19640)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19640)[0m 2021-01-16 21:21:56.369220: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19616)[0m 2021-01-16 21:21:56.375359: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19616)[0m 2021-01-16 21:21:56.378937: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f20c10cf530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19616)[0m 2021-01-16 21:21:56.378988: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19640)[0m 2021-01-16 21:21:56.380858: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19640)[0m 2021-01-16 21:21:56.384085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc2d10cea70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19640)[0m 2021-01-16 21:21:56.384136: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21408)[0m Traceback (most recent call last):
[2m[36m(pid=21408)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=21408)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=21408)[0m , filename = '/tmp/thalvari/4565627/automl_save_rfg7q6f4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f467665b440, total write size = 18664, bytes this sub-write = 18664, bytes actually written = 18446744073709551615, offset = 180224)
[2m[36m(pid=21408)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=21408)[0m Traceback (most recent call last):
[2m[36m(pid=21408)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=21408)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=21408)[0m , filename = '/tmp/thalvari/4565627/automl_save_rfg7q6f4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f467665b440, total write size = 18664, bytes this sub-write = 18664, bytes actually written = 18446744073709551615, offset = 180224)
[2m[36m(pid=19639)[0m Traceback (most recent call last):
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=19639)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19639)[0m , filename = '/tmp/thalvari/4565627/automl_save_t0alvyve/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfadf92978, total write size = 8832, bytes this sub-write = 8832, bytes actually written = 18446744073709551615, offset = 1062520)
[2m[36m(pid=19639)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=19639)[0m Traceback (most recent call last):
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=19639)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19639)[0m , filename = '/tmp/thalvari/4565627/automl_save_t0alvyve/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfadf92978, total write size = 8832, bytes this sub-write = 8832, bytes actually written = 18446744073709551615, offset = 1062520)
[2m[36m(pid=19639)[0m 2021-01-16 21:21:56,465	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19639)[0m Traceback (most recent call last):
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19639)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19639)[0m     param_dset[:] = val
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19639)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19639)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19639)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19639)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19639)[0m , filename = '/tmp/thalvari/4565627/automl_save_t0alvyve/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfadf770f0, total write size = 76176, bytes this sub-write = 76176, bytes actually written = 18446744073709551615, offset = 1073400)
[2m[36m(pid=19639)[0m 
[2m[36m(pid=19639)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19639)[0m 
[2m[36m(pid=19639)[0m Traceback (most recent call last):
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19639)[0m     self._entrypoint()
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19639)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19639)[0m     output = train_func(config, reporter)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19639)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19639)[0m     config=config)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19639)[0m     model.save(model_path, config_path)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19639)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19639)[0m     self.model.save(model_path)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19639)[0m     signatures)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19639)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19639)[0m     f.close()
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19639)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19639)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19639)[0m , filename = '/tmp/thalvari/4565627/automl_save_t0alvyve/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfade50b60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19639)[0m Exception in thread Thread-1:
[2m[36m(pid=19639)[0m Traceback (most recent call last):
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19639)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19639)[0m     param_dset[:] = val
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19639)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19639)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19639)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19639)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19639)[0m , filename = '/tmp/thalvari/4565627/automl_save_t0alvyve/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfadf770f0, total write size = 76176, bytes this sub-write = 76176, bytes actually written = 18446744073709551615, offset = 1073400)
[2m[36m(pid=19639)[0m 
[2m[36m(pid=19639)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19639)[0m 
[2m[36m(pid=19639)[0m Traceback (most recent call last):
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19639)[0m     self._entrypoint()
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19639)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19639)[0m     output = train_func(config, reporter)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19639)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19639)[0m     config=config)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19639)[0m     model.save(model_path, config_path)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19639)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19639)[0m     self.model.save(model_path)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19639)[0m     signatures)
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19639)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=21408)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=21408)[0m 
[2m[36m(pid=21408)[0m Stack (most recent call first):
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 439 in close
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114 in save_model_to_hdf5
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109 in save_model
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171 in save
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163 in save
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122 in save
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs03107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340 in train_func
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262 in _trainable_func
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143 in entrypoint
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92 in run
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916 in _bootstrap_inner
[2m[36m(pid=21408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 884 in _bootstrap
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19639)[0m     f.close()
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19639)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19639)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19639)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19639)[0m , filename = '/tmp/thalvari/4565627/automl_save_t0alvyve/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfade50b60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19639)[0m 
[2m[36m(pid=19639)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19639)[0m 
[2m[36m(pid=19639)[0m Traceback (most recent call last):
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19639)[0m     self.run()
[2m[36m(pid=19639)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19639)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19639)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19639)[0m 
2021-01-16 21:21:56,536	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2021-01-16 21:21:56,541	ERROR worker.py:1672 -- A worker died or was killed while executing task b48a01d784124f108ec0f4d2ea572e00.
2021-01-16 21:21:56,541	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAKE(datetime)=0.66537,bayes_feature_IS_BUSY_HOURS(datetime)=0.48774,bayes_feature_IS_WEEKEND(datetime)=0.56386,bayes_feature_MONTH(datetime)=0.43311,bayes_feature_WEEKDAY(datetime)=0.67913,dropout_1=0.37933,dropout_2=0.32591,epochs=5,lr=0.0038224,lstm_1_units_float=76.587,lstm_2_units_float=43.124,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 46 ({'TERMINATED': 11, 'ERROR': 26, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 20 not shown
 - train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.756,lstm_2_units_float=118.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-31kubn1ozr/error_2021-01-16_21-21-48.txt
 - train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.77,lstm_2_units_float=118.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-33bk5mui2q/error_2021-01-16_21-21-50.txt
 - train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAKE(datetime)=0.66537,bayes_feature_IS_BUSY_HOURS(datetime)=0.48774,bayes_feature_IS_WEEKEND(datetime)=0.56386,bayes_feature_MONTH(datetime)=0.43311,bayes_feature_WEEKDAY(datetime)=0.67913,dropout_1=0.37933,dropout_2=0.32591,epochs=5,lr=0.0038224,lstm_1_units_float=76.587,lstm_2_units_float=43.124,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAK_2021-01-16_21-21-47clyn2s78/error_2021-01-16_21-21-56.txt
RUNNING trials:
 - train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.771,lstm_2_units_float=118.93,past_seq_len=2:	RUNNING
 - train_func_38_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.93,past_seq_len=2:	RUNNING
 - train_func_39_batch_size_log=6.0514,bayes_feature_DAY(datetime)=0.36066,bayes_feature_HOUR(datetime)=0.70954,bayes_feature_IS_AWAKE(datetime)=0.87719,bayes_feature_IS_BUSY_HOURS(datetime)=0.6499,bayes_feature_IS_WEEKEND(datetime)=0.37847,bayes_feature_MONTH(datetime)=0.93751,bayes_feature_WEEKDAY(datetime)=0.58144,dropout_1=0.32957,dropout_2=0.40117,epochs=5,lr=0.0035862,lstm_1_units_float=125.17,lstm_2_units_float=101.62,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_44_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=81.29,lstm_2_units_float=121.56,past_seq_len=2:	RUNNING
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.504,lstm_2_units_float=123.4,past_seq_len=2:	RUNNING
 - train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.517,lstm_2_units_float=123.41,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 5 not shown
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter
 - train_func_31_batch_size_log=7.2672,bayes_feature_DAY(datetime)=0.9954,bayes_feature_HOUR(datetime)=0.32481,bayes_feature_IS_AWAKE(datetime)=0.53627,bayes_feature_IS_BUSY_HOURS(datetime)=0.67619,bayes_feature_IS_WEEKEND(datetime)=0.61211,bayes_feature_MONTH(datetime)=0.36325,bayes_feature_WEEKDAY(datetime)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19617], 17 s, 5 iter
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter

[2m[36m(pid=19647)[0m 2021-01-16 21:21:56,679	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19647)[0m Traceback (most recent call last):
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19647)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19647)[0m     param_dset[:] = val
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19647)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19647)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19647)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19647)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19647)[0m , filename = '/tmp/thalvari/4565627/automl_save_nolf8znj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5caa3de88, total write size = 507632, bytes this sub-write = 507632, bytes actually written = 18446744073709551615, offset = 1032192)
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19647)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19647)[0m Traceback (most recent call last):
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19647)[0m     self._entrypoint()
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19647)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19647)[0m     output = train_func(config, reporter)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19647)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19647)[0m     config=config)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19647)[0m     model.save(model_path, config_path)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19647)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19647)[0m     self.model.save(model_path)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19647)[0m     signatures)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19647)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19647)[0m     f.close()
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19647)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19647)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19647)[0m , filename = '/tmp/thalvari/4565627/automl_save_nolf8znj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5c9710580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19647)[0m Exception in thread Thread-1:
[2m[36m(pid=19647)[0m Traceback (most recent call last):
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19647)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19647)[0m     param_dset[:] = val
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19647)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19647)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19647)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19647)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19647)[0m , filename = '/tmp/thalvari/4565627/automl_save_nolf8znj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5caa3de88, total write size = 507632, bytes this sub-write = 507632, bytes actually written = 18446744073709551615, offset = 1032192)
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19647)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19647)[0m Traceback (most recent call last):
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19647)[0m     self._entrypoint()
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19647)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19647)[0m     output = train_func(config, reporter)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19647)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19647)[0m     config=config)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19647)[0m     model.save(model_path, config_path)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19647)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19647)[0m     self.model.save(model_path)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19647)[0m     signatures)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19647)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19647)[0m     f.close()
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19647)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19647)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19647)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19647)[0m , filename = '/tmp/thalvari/4565627/automl_save_nolf8znj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5c9710580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19647)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19647)[0m Traceback (most recent call last):
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19647)[0m     self.run()
[2m[36m(pid=19647)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19647)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19647)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19622)[0m 2021-01-16 21:21:56,861	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19622)[0m Traceback (most recent call last):
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19622)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19622)[0m     param_dset[:] = val
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19622)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19622)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19622)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19622)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19622)[0m , filename = '/tmp/thalvari/4565627/automl_save_xopqjouv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f000ea7b1c8, total write size = 515732, bytes this sub-write = 515732, bytes actually written = 18446744073709551615, offset = 1032192)
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19622)[0m Traceback (most recent call last):
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19622)[0m     self._entrypoint()
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19622)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19622)[0m     output = train_func(config, reporter)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19622)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19622)[0m     config=config)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19622)[0m     model.save(model_path, config_path)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19622)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19622)[0m     self.model.save(model_path)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19622)[0m     signatures)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19622)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19622)[0m     f.close()
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19622)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19622)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19622)[0m , filename = '/tmp/thalvari/4565627/automl_save_xopqjouv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f000e9ba540, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19622)[0m Exception in thread Thread-1:
[2m[36m(pid=19622)[0m Traceback (most recent call last):
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19622)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19622)[0m     param_dset[:] = val
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19622)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19622)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19622)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19622)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19622)[0m , filename = '/tmp/thalvari/4565627/automl_save_xopqjouv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f000ea7b1c8, total write size = 515732, bytes this sub-write = 515732, bytes actually written = 18446744073709551615, offset = 1032192)
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19622)[0m Traceback (most recent call last):
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19622)[0m     self._entrypoint()
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19622)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19622)[0m     output = train_func(config, reporter)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19622)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19622)[0m     config=config)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19622)[0m     model.save(model_path, config_path)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19622)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19622)[0m     self.model.save(model_path)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19622)[0m     signatures)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19622)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19622)[0m     f.close()
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19622)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19622)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19622)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19622)[0m , filename = '/tmp/thalvari/4565627/automl_save_xopqjouv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f000e9ba540, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19622)[0m Traceback (most recent call last):
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19622)[0m     self.run()
[2m[36m(pid=19622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19622)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19622)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19618)[0m 2021-01-16 21:21:56,957	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19618)[0m Traceback (most recent call last):
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19618)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19618)[0m     param_dset[:] = val
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19618)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19618)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19618)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19618)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19618)[0m , filename = '/tmp/thalvari/4565627/automl_save_gvck4jls/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f61f6884f78, total write size = 507632, bytes this sub-write = 507632, bytes actually written = 18446744073709551615, offset = 1032192)
[2m[36m(pid=19618)[0m 
[2m[36m(pid=19618)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19618)[0m 
[2m[36m(pid=19618)[0m Traceback (most recent call last):
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19618)[0m     self._entrypoint()
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19618)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19618)[0m     output = train_func(config, reporter)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19618)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19618)[0m     config=config)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19618)[0m     model.save(model_path, config_path)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19618)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19618)[0m     self.model.save(model_path)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19618)[0m     signatures)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19618)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19618)[0m     f.close()
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19618)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19618)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19618)[0m , filename = '/tmp/thalvari/4565627/automl_save_gvck4jls/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f61f55cc5e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19618)[0m Exception in thread Thread-1:
[2m[36m(pid=19618)[0m Traceback (most recent call last):
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19618)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19618)[0m     param_dset[:] = val
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19618)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19618)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19618)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19618)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19618)[0m , filename = '/tmp/thalvari/4565627/automl_save_gvck4jls/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f61f6884f78, total write size = 507632, bytes this sub-write = 507632, bytes actually written = 18446744073709551615, offset = 1032192)
[2m[36m(pid=19618)[0m 
[2m[36m(pid=19618)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19618)[0m 
[2m[36m(pid=19618)[0m Traceback (most recent call last):
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19618)[0m     self._entrypoint()
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19618)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19618)[0m     output = train_func(config, reporter)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19618)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19618)[0m     config=config)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19618)[0m     model.save(model_path, config_path)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19618)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19618)[0m     self.model.save(model_path)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19618)[0m     signatures)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19618)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19618)[0m     f.close()
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19618)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19618)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19618)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:21:56 2021
[2m[36m(pid=19618)[0m , filename = '/tmp/thalvari/4565627/automl_save_gvck4jls/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f61f55cc5e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19618)[0m 
[2m[36m(pid=19618)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19618)[0m 
[2m[36m(pid=19618)[0m Traceback (most recent call last):
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19618)[0m     self.run()
[2m[36m(pid=19618)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19618)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19618)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19618)[0m 
2021-01-16 21:21:57,551	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19639, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:57,555	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_41_batch_size_log=7.4803,bayes_feature_DAY(datetime)=0.99458,bayes_feature_HOUR(datetime)=0.88284,bayes_feature_IS_AWAKE(datetime)=0.90813,bayes_feature_IS_BUSY_HOURS(datetime)=0.96173,bayes_feature_IS_WEEKEND(datetime)=0.87772,bayes_feature_MONTH(datetime)=0.95349,bayes_feature_WEEKDAY(datetime)=0.79756,dropout_1=0.3714,dropout_2=0.46094,epochs=5,lr=0.0027408,lstm_1_units_float=69.182,lstm_2_units_float=83.325,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:21:57,785	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19647, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:57,789	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_38_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.93,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19647)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19647)[0m 
[2m[36m(pid=19647)[0m Stack (most recent call first):
2021-01-16 21:21:57,955	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19622, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:57,968	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_39_batch_size_log=6.0514,bayes_feature_DAY(datetime)=0.36066,bayes_feature_HOUR(datetime)=0.70954,bayes_feature_IS_AWAKE(datetime)=0.87719,bayes_feature_IS_BUSY_HOURS(datetime)=0.6499,bayes_feature_IS_WEEKEND(datetime)=0.37847,bayes_feature_MONTH(datetime)=0.93751,bayes_feature_WEEKDAY(datetime)=0.58144,dropout_1=0.32957,dropout_2=0.40117,epochs=5,lr=0.0035862,lstm_1_units_float=125.17,lstm_2_units_float=101.62,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19639)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19639)[0m 
[2m[36m(pid=19639)[0m Stack (most recent call first):
[2m[36m(pid=19622)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19622)[0m 
[2m[36m(pid=19622)[0m Stack (most recent call first):
2021-01-16 21:21:58,427	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19618, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:21:58,430	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.771,lstm_2_units_float=118.93,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19618)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19618)[0m 
[2m[36m(pid=19618)[0m Stack (most recent call first):
[2m[36m(pid=19615)[0m 2021-01-16 21:22:00,374	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19615)[0m Traceback (most recent call last):
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19615)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19615)[0m     param_dset[:] = val
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19615)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19615)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19615)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19615)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:00 2021
[2m[36m(pid=19615)[0m , filename = '/tmp/thalvari/4565627/automl_save_qf72y0bw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78e689d398, total write size = 515824, bytes this sub-write = 515824, bytes actually written = 18446744073709551615, offset = 1024000)
[2m[36m(pid=19615)[0m 
[2m[36m(pid=19615)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19615)[0m 
[2m[36m(pid=19615)[0m Traceback (most recent call last):
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19615)[0m     self._entrypoint()
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19615)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19615)[0m     output = train_func(config, reporter)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19615)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19615)[0m     config=config)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19615)[0m     model.save(model_path, config_path)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19615)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19615)[0m     self.model.save(model_path)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19615)[0m     signatures)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19615)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19615)[0m     f.close()
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19615)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19615)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:00 2021
[2m[36m(pid=19615)[0m , filename = '/tmp/thalvari/4565627/automl_save_qf72y0bw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78e67d6470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19615)[0m Exception in thread Thread-1:
[2m[36m(pid=19615)[0m Traceback (most recent call last):
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19615)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19615)[0m     param_dset[:] = val
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19615)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19615)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19615)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19615)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:00 2021
[2m[36m(pid=19615)[0m , filename = '/tmp/thalvari/4565627/automl_save_qf72y0bw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78e689d398, total write size = 515824, bytes this sub-write = 515824, bytes actually written = 18446744073709551615, offset = 1024000)
[2m[36m(pid=19615)[0m 
[2m[36m(pid=19615)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19615)[0m 
[2m[36m(pid=19615)[0m Traceback (most recent call last):
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19615)[0m     self._entrypoint()
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19615)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19615)[0m     output = train_func(config, reporter)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19615)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19615)[0m     config=config)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19615)[0m     model.save(model_path, config_path)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19615)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19615)[0m     self.model.save(model_path)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19615)[0m     signatures)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19615)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19615)[0m     f.close()
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19615)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19615)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19615)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:00 2021
[2m[36m(pid=19615)[0m , filename = '/tmp/thalvari/4565627/automl_save_qf72y0bw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78e67d6470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19615)[0m 
[2m[36m(pid=19615)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19615)[0m 
[2m[36m(pid=19615)[0m Traceback (most recent call last):
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19615)[0m     self.run()
[2m[36m(pid=19615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19615)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19615)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19615)[0m 
[2m[36m(pid=30124)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30124)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19638)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19638)[0m   agg_primitives: ['count']
[2m[36m(pid=19638)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19638)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19631)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19631)[0m   agg_primitives: ['count']
[2m[36m(pid=19631)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19631)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=21425)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=21425)[0m   agg_primitives: ['count']
[2m[36m(pid=21425)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=21425)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:22:01,535	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19615, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:01,539	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.92,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=30167)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30167)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=19631)[0m LSTM is selected.
[2m[36m(pid=21425)[0m LSTM is selected.
[2m[36m(pid=19631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19631)[0m Instructions for updating:
[2m[36m(pid=19631)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=21425)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=21425)[0m Instructions for updating:
[2m[36m(pid=21425)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19615)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19615)[0m 
[2m[36m(pid=19615)[0m Stack (most recent call first):
[2m[36m(pid=19638)[0m LSTM is selected.
[2m[36m(pid=19638)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19638)[0m Instructions for updating:
[2m[36m(pid=19638)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19634)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=19634)[0m   agg_primitives: ['count']
[2m[36m(pid=19634)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=19634)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=19631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19631)[0m Instructions for updating:
[2m[36m(pid=19631)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=21425)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=21425)[0m Instructions for updating:
[2m[36m(pid=21425)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19638)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19638)[0m Instructions for updating:
[2m[36m(pid=19638)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19634)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=19634)[0m Instructions for updating:
[2m[36m(pid=19634)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=19634)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 52 ({'TERMINATED': 11, 'ERROR': 31, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 25 not shown
 - train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=77.775,lstm_2_units_float=118.92,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-443kxcrg0p/error_2021-01-16_21-22-01.txt
 - train_func_41_batch_size_log=7.4803,bayes_feature_DAY(datetime)=0.99458,bayes_feature_HOUR(datetime)=0.88284,bayes_feature_IS_AWAKE(datetime)=0.90813,bayes_feature_IS_BUSY_HOURS(datetime)=0.96173,bayes_feature_IS_WEEKEND(datetime)=0.87772,bayes_feature_MONTH(datetime)=0.95349,bayes_feature_WEEKDAY(datetime)=0.79756,dropout_1=0.3714,dropout_2=0.46094,epochs=5,lr=0.0027408,lstm_1_units_float=69.182,lstm_2_units_float=83.325,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_41_batch_size_log=7.4803,bayes_feature_DAY(datetime)=0.99458,bayes_feature_HOUR(datetime)=0.88284,bayes_feature_IS_AWAK_2021-01-16_21-21-46mv0hldl9/error_2021-01-16_21-21-57.txt
 - train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAKE(datetime)=0.66537,bayes_feature_IS_BUSY_HOURS(datetime)=0.48774,bayes_feature_IS_WEEKEND(datetime)=0.56386,bayes_feature_MONTH(datetime)=0.43311,bayes_feature_WEEKDAY(datetime)=0.67913,dropout_1=0.37933,dropout_2=0.32591,epochs=5,lr=0.0038224,lstm_1_units_float=76.587,lstm_2_units_float=43.124,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAK_2021-01-16_21-21-47clyn2s78/error_2021-01-16_21-21-56.txt
RUNNING trials:
 - train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=81.292,lstm_2_units_float=121.58,past_seq_len=2:	RUNNING
 - train_func_44_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=81.29,lstm_2_units_float=121.56,past_seq_len=2:	RUNNING
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.504,lstm_2_units_float=123.4,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.503,lstm_2_units_float=123.42,past_seq_len=2:	RUNNING
 - train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.453,lstm_2_units_float=123.39,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.558,lstm_2_units_float=123.43,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 5 not shown
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter
 - train_func_31_batch_size_log=7.2672,bayes_feature_DAY(datetime)=0.9954,bayes_feature_HOUR(datetime)=0.32481,bayes_feature_IS_AWAKE(datetime)=0.53627,bayes_feature_IS_BUSY_HOURS(datetime)=0.67619,bayes_feature_IS_WEEKEND(datetime)=0.61211,bayes_feature_MONTH(datetime)=0.36325,bayes_feature_WEEKDAY(datetime)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19617], 17 s, 5 iter
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter

[2m[36m(pid=19634)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=19634)[0m Instructions for updating:
[2m[36m(pid=19634)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19631)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19631)[0m 2021-01-16 21:22:03.305918: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19631)[0m 2021-01-16 21:22:03.317295: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19631)[0m 2021-01-16 21:22:03.319491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f22d1136ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19631)[0m 2021-01-16 21:22:03.319516: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=21425)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=21425)[0m 2021-01-16 21:22:03.324590: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=21425)[0m 2021-01-16 21:22:03.333158: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=21425)[0m 2021-01-16 21:22:03.336732: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f939d0e5fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=21425)[0m 2021-01-16 21:22:03.336785: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19638)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19638)[0m 2021-01-16 21:22:03.385394: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19638)[0m 2021-01-16 21:22:03.394929: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19638)[0m 2021-01-16 21:22:03.397759: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f27290e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19638)[0m 2021-01-16 21:22:03.397794: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19643)[0m 2021-01-16 21:22:03,670	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19643)[0m Traceback (most recent call last):
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19643)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19643)[0m     param_dset[:] = val
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19643)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19643)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19643)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19643)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:03 2021
[2m[36m(pid=19643)[0m , filename = '/tmp/thalvari/4565627/automl_save_36nc5dtk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41e2a4a708, total write size = 600356, bytes this sub-write = 600356, bytes actually written = 18446744073709551615, offset = 999424)
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19643)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19643)[0m Traceback (most recent call last):
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19643)[0m     self._entrypoint()
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19643)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19643)[0m     output = train_func(config, reporter)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19643)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19643)[0m     config=config)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19643)[0m     model.save(model_path, config_path)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19643)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19643)[0m     self.model.save(model_path)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19643)[0m     signatures)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19643)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19643)[0m     f.close()
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19643)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19643)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:03 2021
[2m[36m(pid=19643)[0m , filename = '/tmp/thalvari/4565627/automl_save_36nc5dtk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41e2626400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19643)[0m Exception in thread Thread-1:
[2m[36m(pid=19643)[0m Traceback (most recent call last):
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19643)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19643)[0m     param_dset[:] = val
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19643)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19643)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19643)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19643)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:03 2021
[2m[36m(pid=19643)[0m , filename = '/tmp/thalvari/4565627/automl_save_36nc5dtk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41e2a4a708, total write size = 600356, bytes this sub-write = 600356, bytes actually written = 18446744073709551615, offset = 999424)
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19643)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19643)[0m Traceback (most recent call last):
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19643)[0m     self._entrypoint()
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19643)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19643)[0m     output = train_func(config, reporter)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19643)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19643)[0m     config=config)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19643)[0m     model.save(model_path, config_path)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19643)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19643)[0m     self.model.save(model_path)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19643)[0m     signatures)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19643)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19643)[0m     f.close()
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19643)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19643)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19643)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:03 2021
[2m[36m(pid=19643)[0m , filename = '/tmp/thalvari/4565627/automl_save_36nc5dtk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41e2626400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19643)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19643)[0m Traceback (most recent call last):
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19643)[0m     self.run()
[2m[36m(pid=19643)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19643)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19643)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19634)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=19634)[0m 2021-01-16 21:22:04.063284: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=19634)[0m 2021-01-16 21:22:04.071339: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=19634)[0m 2021-01-16 21:22:04.075579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f76e90ce620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=19634)[0m 2021-01-16 21:22:04.075606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:22:04,716	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19643, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:04,720	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=81.292,lstm_2_units_float=121.58,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19643)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19643)[0m 
[2m[36m(pid=19643)[0m Stack (most recent call first):
[2m[36m(pid=19640)[0m 2021-01-16 21:22:05,524	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19640)[0m Traceback (most recent call last):
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19640)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19640)[0m     param_dset[:] = val
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19640)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19640)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19640)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19640)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19640)[0m , filename = '/tmp/thalvari/4565627/automl_save_29eo590k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc2d2a402b8, total write size = 627548, bytes this sub-write = 627548, bytes actually written = 18446744073709551615, offset = 991232)
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19640)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19640)[0m Traceback (most recent call last):
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19640)[0m     self._entrypoint()
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19640)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19640)[0m     output = train_func(config, reporter)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19640)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19640)[0m     config=config)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19640)[0m     model.save(model_path, config_path)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19640)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19640)[0m     self.model.save(model_path)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19640)[0m     signatures)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19640)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19640)[0m     f.close()
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19640)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19640)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19640)[0m , filename = '/tmp/thalvari/4565627/automl_save_29eo590k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc2d2108280, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19640)[0m Exception in thread Thread-1:
[2m[36m(pid=19640)[0m Traceback (most recent call last):
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19640)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19640)[0m     param_dset[:] = val
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19640)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19640)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19640)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19640)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19640)[0m , filename = '/tmp/thalvari/4565627/automl_save_29eo590k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc2d2a402b8, total write size = 627548, bytes this sub-write = 627548, bytes actually written = 18446744073709551615, offset = 991232)
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19640)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19640)[0m Traceback (most recent call last):
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19640)[0m     self._entrypoint()
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19640)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19640)[0m     output = train_func(config, reporter)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19640)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19640)[0m     config=config)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19640)[0m     model.save(model_path, config_path)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19640)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19640)[0m     self.model.save(model_path)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19640)[0m     signatures)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19640)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19640)[0m     f.close()
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19640)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19640)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19640)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19640)[0m , filename = '/tmp/thalvari/4565627/automl_save_29eo590k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc2d2108280, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19640)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19640)[0m Traceback (most recent call last):
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19640)[0m     self.run()
[2m[36m(pid=19640)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19640)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19640)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19632)[0m 2021-01-16 21:22:05,841	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19632)[0m Traceback (most recent call last):
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19632)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19632)[0m     param_dset[:] = val
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19632)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19632)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19632)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19632)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19632)[0m , filename = '/tmp/thalvari/4565627/automl_save_z080j5mx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb3e8b6dc8, total write size = 616740, bytes this sub-write = 616740, bytes actually written = 18446744073709551615, offset = 983040)
[2m[36m(pid=19632)[0m 
[2m[36m(pid=19632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19632)[0m 
[2m[36m(pid=19632)[0m Traceback (most recent call last):
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19632)[0m     self._entrypoint()
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19632)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19632)[0m     output = train_func(config, reporter)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19632)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19632)[0m     config=config)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19632)[0m     model.save(model_path, config_path)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19632)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19632)[0m     self.model.save(model_path)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19632)[0m     signatures)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19632)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19632)[0m     f.close()
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19632)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19632)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19632)[0m , filename = '/tmp/thalvari/4565627/automl_save_z080j5mx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb3d4b88c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19632)[0m Exception in thread Thread-1:
[2m[36m(pid=19632)[0m Traceback (most recent call last):
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19632)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19632)[0m     param_dset[:] = val
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19632)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19632)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19632)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19632)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19632)[0m , filename = '/tmp/thalvari/4565627/automl_save_z080j5mx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb3e8b6dc8, total write size = 616740, bytes this sub-write = 616740, bytes actually written = 18446744073709551615, offset = 983040)
[2m[36m(pid=19632)[0m 
[2m[36m(pid=19632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19632)[0m 
[2m[36m(pid=19632)[0m Traceback (most recent call last):
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19632)[0m     self._entrypoint()
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19632)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19632)[0m     output = train_func(config, reporter)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19632)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19632)[0m     config=config)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19632)[0m     model.save(model_path, config_path)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19632)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19632)[0m     self.model.save(model_path)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19632)[0m     signatures)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19632)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19632)[0m     f.close()
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19632)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19632)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19632)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:05 2021
[2m[36m(pid=19632)[0m , filename = '/tmp/thalvari/4565627/automl_save_z080j5mx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb3d4b88c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19632)[0m 
[2m[36m(pid=19632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19632)[0m 
[2m[36m(pid=19632)[0m Traceback (most recent call last):
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19632)[0m     self.run()
[2m[36m(pid=19632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19632)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19632)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19632)[0m 
[2m[36m(pid=30124)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30124)[0m   agg_primitives: ['count']
[2m[36m(pid=30124)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30124)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30167)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30167)[0m   agg_primitives: ['count']
[2m[36m(pid=30167)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30167)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:22:06,611	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19640, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:06,614	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.504,lstm_2_units_float=123.4,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19616)[0m 2021-01-16 21:22:06,620	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19616)[0m Traceback (most recent call last):
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19616)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19616)[0m     param_dset[:] = val
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19616)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19616)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19616)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19616)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:06 2021
[2m[36m(pid=19616)[0m , filename = '/tmp/thalvari/4565627/automl_save_f9_ae_hg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c28aee58, total write size = 652124, bytes this sub-write = 652124, bytes actually written = 18446744073709551615, offset = 966656)
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19616)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19616)[0m Traceback (most recent call last):
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19616)[0m     self._entrypoint()
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19616)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19616)[0m     output = train_func(config, reporter)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19616)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19616)[0m     config=config)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19616)[0m     model.save(model_path, config_path)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19616)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19616)[0m     self.model.save(model_path)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19616)[0m     signatures)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19616)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19616)[0m     f.close()
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19616)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19616)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:06 2021
[2m[36m(pid=19616)[0m , filename = '/tmp/thalvari/4565627/automl_save_f9_ae_hg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c1f54480, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19616)[0m Exception in thread Thread-1:
[2m[36m(pid=19616)[0m Traceback (most recent call last):
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19616)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19616)[0m     param_dset[:] = val
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19616)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19616)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19616)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19616)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:06 2021
[2m[36m(pid=19616)[0m , filename = '/tmp/thalvari/4565627/automl_save_f9_ae_hg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c28aee58, total write size = 652124, bytes this sub-write = 652124, bytes actually written = 18446744073709551615, offset = 966656)
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19616)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19616)[0m Traceback (most recent call last):
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19616)[0m     self._entrypoint()
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19616)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19616)[0m     output = train_func(config, reporter)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19616)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19616)[0m     config=config)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19616)[0m     model.save(model_path, config_path)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19616)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19616)[0m     self.model.save(model_path)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19616)[0m     signatures)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19616)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19616)[0m     f.close()
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19616)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19616)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19616)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:06 2021
[2m[36m(pid=19616)[0m , filename = '/tmp/thalvari/4565627/automl_save_f9_ae_hg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20c1f54480, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19616)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19616)[0m Traceback (most recent call last):
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19616)[0m     self.run()
[2m[36m(pid=19616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19616)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19616)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19640)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19640)[0m 
[2m[36m(pid=19640)[0m Stack (most recent call first):
2021-01-16 21:22:07,010	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19632, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:07,018	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_44_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=81.29,lstm_2_units_float=121.56,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=30124)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30124)[0m Instructions for updating:
[2m[36m(pid=30124)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30124)[0m LSTM is selected.
[2m[36m(pid=19632)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19632)[0m 
[2m[36m(pid=19632)[0m Stack (most recent call first):
[2m[36m(pid=30815)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30815)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30858)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30858)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30857)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30857)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30938)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30938)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30167)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 55 ({'TERMINATED': 11, 'ERROR': 34, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 28 not shown
 - train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAKE(datetime)=0.66537,bayes_feature_IS_BUSY_HOURS(datetime)=0.48774,bayes_feature_IS_WEEKEND(datetime)=0.56386,bayes_feature_MONTH(datetime)=0.43311,bayes_feature_WEEKDAY(datetime)=0.67913,dropout_1=0.37933,dropout_2=0.32591,epochs=5,lr=0.0038224,lstm_1_units_float=76.587,lstm_2_units_float=43.124,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_43_batch_size_log=8.4515,bayes_feature_DAY(datetime)=0.84515,bayes_feature_HOUR(datetime)=0.46853,bayes_feature_IS_AWAK_2021-01-16_21-21-47clyn2s78/error_2021-01-16_21-21-56.txt
 - train_func_44_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=81.29,lstm_2_units_float=121.56,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_44_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-49us8z_z_z/error_2021-01-16_21-22-07.txt
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.504,lstm_2_units_float=123.4,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-502uvvohhc/error_2021-01-16_21-22-06.txt
RUNNING trials:
 - train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.517,lstm_2_units_float=123.41,past_seq_len=2:	RUNNING
 - train_func_47_batch_size_log=7.2738,bayes_feature_DAY(datetime)=0.57445,bayes_feature_HOUR(datetime)=0.95059,bayes_feature_IS_AWAKE(datetime)=0.79106,bayes_feature_IS_BUSY_HOURS(datetime)=0.75283,bayes_feature_IS_WEEKEND(datetime)=0.95195,bayes_feature_MONTH(datetime)=0.76368,bayes_feature_WEEKDAY(datetime)=0.68871,dropout_1=0.47076,dropout_2=0.28855,epochs=5,lr=0.0018596,lstm_1_units_float=68.792,lstm_2_units_float=33.37,past_seq_len=2:	RUNNING
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=19638], 6 s, 1 iter
  ... 4 not shown
 - train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.45858,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.532,lstm_2_units_float=123.42,past_seq_len=2:	RUNNING
 - train_func_54_batch_size_log=5.9374,bayes_feature_DAY(datetime)=0.97418,bayes_feature_HOUR(datetime)=0.45392,bayes_feature_IS_AWAKE(datetime)=0.86191,bayes_feature_IS_BUSY_HOURS(datetime)=0.73755,bayes_feature_IS_WEEKEND(datetime)=0.48815,bayes_feature_MONTH(datetime)=0.90272,bayes_feature_WEEKDAY(datetime)=0.81266,dropout_1=0.26873,dropout_2=0.44767,epochs=5,lr=0.0016327,lstm_1_units_float=67.286,lstm_2_units_float=33.272,past_seq_len=2:	RUNNING
 - train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.474,lstm_2_units_float=123.38,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 5 not shown
 - train_func_17_batch_size_log=7.0385,bayes_feature_DAY(datetime)=0.49371,bayes_feature_HOUR(datetime)=0.36149,bayes_feature_IS_AWAKE(datetime)=0.79074,bayes_feature_IS_BUSY_HOURS(datetime)=0.31,bayes_feature_IS_WEEKEND(datetime)=0.85478,bayes_feature_MONTH(datetime)=0.76993,bayes_feature_WEEKDAY(datetime)=0.74758,dropout_1=0.30161,dropout_2=0.49553,epochs=5,lr=0.0013278,lstm_1_units_float=78.222,lstm_2_units_float=20.291,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21413], 16 s, 5 iter
 - train_func_31_batch_size_log=7.2672,bayes_feature_DAY(datetime)=0.9954,bayes_feature_HOUR(datetime)=0.32481,bayes_feature_IS_AWAKE(datetime)=0.53627,bayes_feature_IS_BUSY_HOURS(datetime)=0.67619,bayes_feature_IS_WEEKEND(datetime)=0.61211,bayes_feature_MONTH(datetime)=0.36325,bayes_feature_WEEKDAY(datetime)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19617], 17 s, 5 iter
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter

[2m[36m(pid=30167)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30167)[0m Instructions for updating:
[2m[36m(pid=30167)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30124)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30124)[0m Instructions for updating:
[2m[36m(pid=30124)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:22:07,833	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19616, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:07,836	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.517,lstm_2_units_float=123.41,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19616)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19616)[0m 
[2m[36m(pid=19616)[0m Stack (most recent call first):
[2m[36m(pid=30985)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30985)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30984)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30984)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30983)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30983)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31104)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31104)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31105)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31105)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30167)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30167)[0m Instructions for updating:
[2m[36m(pid=30167)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31146)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31146)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31106)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31106)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31154)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31154)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31152)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31152)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31147)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31147)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31153)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31153)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31151)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31151)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31276)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31276)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31318)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31318)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31150)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31150)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=31155)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=31155)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30124)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30124)[0m 2021-01-16 21:22:08.969494: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30124)[0m 2021-01-16 21:22:08.979879: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30124)[0m 2021-01-16 21:22:08.986924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc1a90cf230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30124)[0m 2021-01-16 21:22:08.986966: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30167)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30167)[0m 2021-01-16 21:22:10.228372: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30167)[0m 2021-01-16 21:22:10.238141: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30167)[0m 2021-01-16 21:22:10.240265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb190cea90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30167)[0m 2021-01-16 21:22:10.240291: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=19631)[0m 2021-01-16 21:22:10,346	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19631)[0m Traceback (most recent call last):
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19631)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19631)[0m     param_dset[:] = val
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19631)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19631)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19631)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19631)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:10 2021
[2m[36m(pid=19631)[0m , filename = '/tmp/thalvari/4565627/automl_save_uh4l1gb9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22d2278850, total write size = 103948, bytes this sub-write = 103948, bytes actually written = 18446744073709551615, offset = 802816)
[2m[36m(pid=19631)[0m 
[2m[36m(pid=19631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19631)[0m 
[2m[36m(pid=19631)[0m Traceback (most recent call last):
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19631)[0m     self._entrypoint()
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19631)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19631)[0m     output = train_func(config, reporter)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19631)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19631)[0m     config=config)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19631)[0m     model.save(model_path, config_path)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19631)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19631)[0m     self.model.save(model_path)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19631)[0m     signatures)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19631)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19631)[0m     f.close()
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19631)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19631)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:10 2021
[2m[36m(pid=19631)[0m , filename = '/tmp/thalvari/4565627/automl_save_uh4l1gb9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22d24ea350, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19631)[0m Exception in thread Thread-1:
[2m[36m(pid=19631)[0m Traceback (most recent call last):
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=19631)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=19631)[0m     param_dset[:] = val
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19631)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19631)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19631)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19631)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:10 2021
[2m[36m(pid=19631)[0m , filename = '/tmp/thalvari/4565627/automl_save_uh4l1gb9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22d2278850, total write size = 103948, bytes this sub-write = 103948, bytes actually written = 18446744073709551615, offset = 802816)
[2m[36m(pid=19631)[0m 
[2m[36m(pid=19631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19631)[0m 
[2m[36m(pid=19631)[0m Traceback (most recent call last):
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19631)[0m     self._entrypoint()
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19631)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19631)[0m     output = train_func(config, reporter)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19631)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19631)[0m     config=config)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19631)[0m     model.save(model_path, config_path)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19631)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19631)[0m     self.model.save(model_path)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19631)[0m     signatures)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19631)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19631)[0m     f.close()
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19631)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19631)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19631)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:10 2021
[2m[36m(pid=19631)[0m , filename = '/tmp/thalvari/4565627/automl_save_uh4l1gb9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22d24ea350, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19631)[0m 
[2m[36m(pid=19631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19631)[0m 
[2m[36m(pid=19631)[0m Traceback (most recent call last):
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19631)[0m     self.run()
[2m[36m(pid=19631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19631)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19631)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19631)[0m 
2021-01-16 21:22:11,541	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19631, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:11,544	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_47_batch_size_log=7.2738,bayes_feature_DAY(datetime)=0.57445,bayes_feature_HOUR(datetime)=0.95059,bayes_feature_IS_AWAKE(datetime)=0.79106,bayes_feature_IS_BUSY_HOURS(datetime)=0.75283,bayes_feature_IS_WEEKEND(datetime)=0.95195,bayes_feature_MONTH(datetime)=0.76368,bayes_feature_WEEKDAY(datetime)=0.68871,dropout_1=0.47076,dropout_2=0.28855,epochs=5,lr=0.0018596,lstm_1_units_float=68.792,lstm_2_units_float=33.37,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=19631)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19631)[0m 
[2m[36m(pid=19631)[0m Stack (most recent call first):
[2m[36m(pid=30815)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30815)[0m   agg_primitives: ['count']
[2m[36m(pid=30815)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30815)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30858)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30858)[0m   agg_primitives: ['count']
[2m[36m(pid=30858)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30858)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30938)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30938)[0m   agg_primitives: ['count']
[2m[36m(pid=30938)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30938)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30985)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30985)[0m   agg_primitives: ['count']
[2m[36m(pid=30985)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30985)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 58 ({'TERMINATED': 13, 'ERROR': 36, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 30 not shown
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.504,lstm_2_units_float=123.4,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-502uvvohhc/error_2021-01-16_21-22-06.txt
 - train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.517,lstm_2_units_float=123.41,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-51ew01zvz7/error_2021-01-16_21-22-07.txt
 - train_func_47_batch_size_log=7.2738,bayes_feature_DAY(datetime)=0.57445,bayes_feature_HOUR(datetime)=0.95059,bayes_feature_IS_AWAKE(datetime)=0.79106,bayes_feature_IS_BUSY_HOURS(datetime)=0.75283,bayes_feature_IS_WEEKEND(datetime)=0.95195,bayes_feature_MONTH(datetime)=0.76368,bayes_feature_WEEKDAY(datetime)=0.68871,dropout_1=0.47076,dropout_2=0.28855,epochs=5,lr=0.0018596,lstm_1_units_float=68.792,lstm_2_units_float=33.37,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_47_batch_size_log=7.2738,bayes_feature_DAY(datetime)=0.57445,bayes_feature_HOUR(datetime)=0.95059,bayes_feature_IS_AWAK_2021-01-16_21-21-5672vnhjtq/error_2021-01-16_21-22-11.txt, [4 CPUs, 0 GPUs], [pid=19631], 7 s, 1 iter
RUNNING trials:
 - train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.503,lstm_2_units_float=123.42,past_seq_len=2:	RUNNING
 - train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.453,lstm_2_units_float=123.39,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.558,lstm_2_units_float=123.43,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_56_batch_size_log=9.4562,bayes_feature_DAY(datetime)=0.32836,bayes_feature_HOUR(datetime)=0.857,bayes_feature_IS_AWAKE(datetime)=0.70475,bayes_feature_IS_BUSY_HOURS(datetime)=0.58425,bayes_feature_IS_WEEKEND(datetime)=0.62085,bayes_feature_MONTH(datetime)=0.62028,bayes_feature_WEEKDAY(datetime)=0.33117,dropout_1=0.3251,dropout_2=0.37963,epochs=5,lr=0.0022808,lstm_1_units_float=14.904,lstm_2_units_float=54.106,past_seq_len=2:	RUNNING
 - train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=87.266,lstm_2_units_float=122.67,past_seq_len=2:	RUNNING
 - train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=87.267,lstm_2_units_float=122.64,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 7 not shown
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter

[2m[36m(pid=30938)[0m LSTM is selected.
[2m[36m(pid=30815)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30815)[0m Instructions for updating:
[2m[36m(pid=30815)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30815)[0m LSTM is selected.
[2m[36m(pid=30858)[0m LSTM is selected.
[2m[36m(pid=30938)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30938)[0m Instructions for updating:
[2m[36m(pid=30938)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30985)[0m LSTM is selected.
[2m[36m(pid=30858)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30858)[0m Instructions for updating:
[2m[36m(pid=30858)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30985)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30985)[0m Instructions for updating:
[2m[36m(pid=30985)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30815)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30815)[0m Instructions for updating:
[2m[36m(pid=30815)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=30938)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30938)[0m Instructions for updating:
[2m[36m(pid=30938)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=30858)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30858)[0m Instructions for updating:
[2m[36m(pid=30858)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=30985)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30985)[0m Instructions for updating:
[2m[36m(pid=30985)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19634)[0m 2021-01-16 21:22:15,134	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=19634)[0m Traceback (most recent call last):
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19634)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19634)[0m     param_dset[:] = val
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19634)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19634)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19634)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19634)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:15 2021
[2m[36m(pid=19634)[0m , filename = '/tmp/thalvari/4565627/automl_save_5gv2ksph/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f76ea819c38, total write size = 824156, bytes this sub-write = 824156, bytes actually written = 18446744073709551615, offset = 794624)
[2m[36m(pid=19634)[0m 
[2m[36m(pid=19634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19634)[0m 
[2m[36m(pid=19634)[0m Traceback (most recent call last):
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19634)[0m     self._entrypoint()
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19634)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19634)[0m     output = train_func(config, reporter)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19634)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19634)[0m     config=config)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19634)[0m     model.save(model_path, config_path)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19634)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19634)[0m     self.model.save(model_path)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19634)[0m     signatures)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19634)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19634)[0m     f.close()
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19634)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19634)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:15 2021
[2m[36m(pid=19634)[0m , filename = '/tmp/thalvari/4565627/automl_save_5gv2ksph/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f76e958ead0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19634)[0m Exception in thread Thread-1:
[2m[36m(pid=19634)[0m Traceback (most recent call last):
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=19634)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=19634)[0m     param_dset[:] = val
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=19634)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=19634)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=19634)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=19634)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:15 2021
[2m[36m(pid=19634)[0m , filename = '/tmp/thalvari/4565627/automl_save_5gv2ksph/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f76ea819c38, total write size = 824156, bytes this sub-write = 824156, bytes actually written = 18446744073709551615, offset = 794624)
[2m[36m(pid=19634)[0m 
[2m[36m(pid=19634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19634)[0m 
[2m[36m(pid=19634)[0m Traceback (most recent call last):
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=19634)[0m     self._entrypoint()
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=19634)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=19634)[0m     output = train_func(config, reporter)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=19634)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=19634)[0m     config=config)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=19634)[0m     model.save(model_path, config_path)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=19634)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=19634)[0m     self.model.save(model_path)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=19634)[0m     signatures)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=19634)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=19634)[0m     f.close()
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=19634)[0m     h5i.dec_ref(id_)
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=19634)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=19634)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:15 2021
[2m[36m(pid=19634)[0m , filename = '/tmp/thalvari/4565627/automl_save_5gv2ksph/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f76e958ead0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=19634)[0m 
[2m[36m(pid=19634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=19634)[0m 
[2m[36m(pid=19634)[0m Traceback (most recent call last):
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=19634)[0m     self.run()
[2m[36m(pid=19634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=19634)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=19634)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=19634)[0m 
[2m[36m(pid=31276)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31276)[0m   agg_primitives: ['count']
[2m[36m(pid=31276)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31276)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31155)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31155)[0m   agg_primitives: ['count']
[2m[36m(pid=31155)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31155)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30815)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30815)[0m 2021-01-16 21:22:15.341764: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30815)[0m 2021-01-16 21:22:15.349704: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30815)[0m 2021-01-16 21:22:15.352088: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbfd90ce400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30815)[0m 2021-01-16 21:22:15.352123: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30938)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30938)[0m 2021-01-16 21:22:15.405867: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30938)[0m 2021-01-16 21:22:15.414968: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30938)[0m 2021-01-16 21:22:15.417062: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f364d0cf230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30938)[0m 2021-01-16 21:22:15.417084: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30858)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30858)[0m 2021-01-16 21:22:15.435317: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30858)[0m 2021-01-16 21:22:15.444012: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30858)[0m 2021-01-16 21:22:15.446542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7fd103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30858)[0m 2021-01-16 21:22:15.446565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30985)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30985)[0m 2021-01-16 21:22:15.426394: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30985)[0m 2021-01-16 21:22:15.445038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30985)[0m 2021-01-16 21:22:15.447195: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efb7d0fd230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30985)[0m 2021-01-16 21:22:15.447218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31276)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31276)[0m Instructions for updating:
[2m[36m(pid=31276)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31276)[0m LSTM is selected.
[2m[36m(pid=31155)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31155)[0m Instructions for updating:
[2m[36m(pid=31155)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31155)[0m LSTM is selected.
2021-01-16 21:22:16,324	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=19634, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:16,327	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.503,lstm_2_units_float=123.42,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31155)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31155)[0m Instructions for updating:
[2m[36m(pid=31155)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31276)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31276)[0m Instructions for updating:
[2m[36m(pid=31276)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=19634)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=19634)[0m 
[2m[36m(pid=19634)[0m Stack (most recent call first):
[2m[36m(pid=31276)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31276)[0m 2021-01-16 21:22:17.370790: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31276)[0m 2021-01-16 21:22:17.384552: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31276)[0m 2021-01-16 21:22:17.387978: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd1f11036c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31276)[0m 2021-01-16 21:22:17.388027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31155)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31155)[0m 2021-01-16 21:22:17.385459: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31155)[0m 2021-01-16 21:22:17.396310: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31155)[0m 2021-01-16 21:22:17.399960: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efdcd102a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31155)[0m 2021-01-16 21:22:17.400000: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31151)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31151)[0m   agg_primitives: ['count']
[2m[36m(pid=31151)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31151)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30985)[0m 2021-01-16 21:22:18,153	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30985)[0m Traceback (most recent call last):
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=30985)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=30985)[0m     param_dset[:] = val
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30985)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30985)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30985)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30985)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30985)[0m , filename = '/tmp/thalvari/4565627/automl_save_df7rdhtc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb7e6dd314, total write size = 347236, bytes this sub-write = 347236, bytes actually written = 18446744073709551615, offset = 786432)
[2m[36m(pid=30985)[0m 
[2m[36m(pid=30985)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30985)[0m 
[2m[36m(pid=30985)[0m Traceback (most recent call last):
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30985)[0m     self._entrypoint()
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30985)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30985)[0m     output = train_func(config, reporter)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30985)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30985)[0m     config=config)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30985)[0m     model.save(model_path, config_path)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30985)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30985)[0m     self.model.save(model_path)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30985)[0m     signatures)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30985)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30985)[0m     f.close()
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30985)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30985)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30985)[0m , filename = '/tmp/thalvari/4565627/automl_save_df7rdhtc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb7e368470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30985)[0m Exception in thread Thread-1:
[2m[36m(pid=30985)[0m Traceback (most recent call last):
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=30985)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=30985)[0m     param_dset[:] = val
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30985)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30985)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30985)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30985)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30985)[0m , filename = '/tmp/thalvari/4565627/automl_save_df7rdhtc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb7e6dd314, total write size = 347236, bytes this sub-write = 347236, bytes actually written = 18446744073709551615, offset = 786432)
[2m[36m(pid=30985)[0m 
[2m[36m(pid=30985)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30985)[0m 
[2m[36m(pid=30985)[0m Traceback (most recent call last):
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30985)[0m     self._entrypoint()
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30985)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30985)[0m     output = train_func(config, reporter)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30985)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30985)[0m     config=config)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30985)[0m     model.save(model_path, config_path)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30985)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30985)[0m     self.model.save(model_path)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30985)[0m     signatures)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30985)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30985)[0m     f.close()
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30985)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30985)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30985)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30985)[0m , filename = '/tmp/thalvari/4565627/automl_save_df7rdhtc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb7e368470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30985)[0m 
[2m[36m(pid=30985)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30985)[0m 
[2m[36m(pid=30985)[0m Traceback (most recent call last):
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30985)[0m     self.run()
[2m[36m(pid=30985)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30985)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30985)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30985)[0m 
[2m[36m(pid=31151)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31151)[0m Instructions for updating:
[2m[36m(pid=31151)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31151)[0m LSTM is selected.
[2m[36m(pid=30124)[0m 2021-01-16 21:22:18,889	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30124)[0m Traceback (most recent call last):
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30124)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30124)[0m     param_dset[:] = val
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30124)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30124)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30124)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30124)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30124)[0m , filename = '/tmp/thalvari/4565627/automl_save_u9co8iok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc1aa83f638, total write size = 840540, bytes this sub-write = 840540, bytes actually written = 18446744073709551615, offset = 778240)
[2m[36m(pid=30124)[0m 
[2m[36m(pid=30124)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30124)[0m 
[2m[36m(pid=30124)[0m Traceback (most recent call last):
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30124)[0m     self._entrypoint()
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30124)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30124)[0m     output = train_func(config, reporter)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30124)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30124)[0m     config=config)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30124)[0m     model.save(model_path, config_path)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30124)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30124)[0m     self.model.save(model_path)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30124)[0m     signatures)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30124)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30124)[0m     f.close()
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30124)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30124)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30124)[0m , filename = '/tmp/thalvari/4565627/automl_save_u9co8iok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc1aa696670, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30124)[0m Exception in thread Thread-1:
[2m[36m(pid=30124)[0m Traceback (most recent call last):
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30124)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30124)[0m     param_dset[:] = val
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30124)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30124)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30124)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30124)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30124)[0m , filename = '/tmp/thalvari/4565627/automl_save_u9co8iok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc1aa83f638, total write size = 840540, bytes this sub-write = 840540, bytes actually written = 18446744073709551615, offset = 778240)
[2m[36m(pid=30124)[0m 
[2m[36m(pid=30124)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30124)[0m 
[2m[36m(pid=30124)[0m Traceback (most recent call last):
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30124)[0m     self._entrypoint()
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30124)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30124)[0m     output = train_func(config, reporter)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30124)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30124)[0m     config=config)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30124)[0m     model.save(model_path, config_path)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30124)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30124)[0m     self.model.save(model_path)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30124)[0m     signatures)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30124)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30124)[0m     f.close()
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30124)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30124)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30124)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:18 2021
[2m[36m(pid=30124)[0m , filename = '/tmp/thalvari/4565627/automl_save_u9co8iok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc1aa696670, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30124)[0m 
[2m[36m(pid=30124)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30124)[0m 
[2m[36m(pid=30124)[0m Traceback (most recent call last):
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30124)[0m     self.run()
[2m[36m(pid=30124)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30124)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30124)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30124)[0m 
[2m[36m(pid=31151)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31151)[0m Instructions for updating:
[2m[36m(pid=31151)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:22:19,229	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30985, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:19,234	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_56_batch_size_log=9.4562,bayes_feature_DAY(datetime)=0.32836,bayes_feature_HOUR(datetime)=0.857,bayes_feature_IS_AWAKE(datetime)=0.70475,bayes_feature_IS_BUSY_HOURS(datetime)=0.58425,bayes_feature_IS_WEEKEND(datetime)=0.62085,bayes_feature_MONTH(datetime)=0.62028,bayes_feature_WEEKDAY(datetime)=0.33117,dropout_1=0.3251,dropout_2=0.37963,epochs=5,lr=0.0022808,lstm_1_units_float=14.904,lstm_2_units_float=54.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 60 ({'TERMINATED': 13, 'ERROR': 38, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 32 not shown
 - train_func_47_batch_size_log=7.2738,bayes_feature_DAY(datetime)=0.57445,bayes_feature_HOUR(datetime)=0.95059,bayes_feature_IS_AWAKE(datetime)=0.79106,bayes_feature_IS_BUSY_HOURS(datetime)=0.75283,bayes_feature_IS_WEEKEND(datetime)=0.95195,bayes_feature_MONTH(datetime)=0.76368,bayes_feature_WEEKDAY(datetime)=0.68871,dropout_1=0.47076,dropout_2=0.28855,epochs=5,lr=0.0018596,lstm_1_units_float=68.792,lstm_2_units_float=33.37,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_47_batch_size_log=7.2738,bayes_feature_DAY(datetime)=0.57445,bayes_feature_HOUR(datetime)=0.95059,bayes_feature_IS_AWAK_2021-01-16_21-21-5672vnhjtq/error_2021-01-16_21-22-11.txt, [4 CPUs, 0 GPUs], [pid=19631], 7 s, 1 iter
 - train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.503,lstm_2_units_float=123.42,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-21-58nlkj5d6u/error_2021-01-16_21-22-16.txt
 - train_func_56_batch_size_log=9.4562,bayes_feature_DAY(datetime)=0.32836,bayes_feature_HOUR(datetime)=0.857,bayes_feature_IS_AWAKE(datetime)=0.70475,bayes_feature_IS_BUSY_HOURS(datetime)=0.58425,bayes_feature_IS_WEEKEND(datetime)=0.62085,bayes_feature_MONTH(datetime)=0.62028,bayes_feature_WEEKDAY(datetime)=0.33117,dropout_1=0.3251,dropout_2=0.37963,epochs=5,lr=0.0022808,lstm_1_units_float=14.904,lstm_2_units_float=54.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_56_batch_size_log=9.4562,bayes_feature_DAY(datetime)=0.32836,bayes_feature_HOUR(datetime)=0.857,bayes_feature_IS_AWAKE(_2021-01-16_21-22-08ws6f_0hr/error_2021-01-16_21-22-19.txt
RUNNING trials:
 - train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.453,lstm_2_units_float=123.39,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.558,lstm_2_units_float=123.43,past_seq_len=2:	RUNNING
 - train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.45858,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.532,lstm_2_units_float=123.42,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=87.267,lstm_2_units_float=122.64,past_seq_len=2:	RUNNING
 - train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.55,lstm_2_units_float=127.71,past_seq_len=2:	RUNNING
 - train_func_60_batch_size_log=7.0682,bayes_feature_DAY(datetime)=0.951,bayes_feature_HOUR(datetime)=0.30751,bayes_feature_IS_AWAKE(datetime)=0.87857,bayes_feature_IS_BUSY_HOURS(datetime)=0.39519,bayes_feature_IS_WEEKEND(datetime)=0.91974,bayes_feature_MONTH(datetime)=0.50449,bayes_feature_WEEKDAY(datetime)=0.56349,dropout_1=0.34346,dropout_2=0.36178,epochs=5,lr=0.0074656,lstm_1_units_float=101.3,lstm_2_units_float=116.01,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 7 not shown
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter

[2m[36m(pid=30985)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30985)[0m 
[2m[36m(pid=30985)[0m Stack (most recent call first):
[2m[36m(pid=30167)[0m 2021-01-16 21:22:19,683	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30167)[0m Traceback (most recent call last):
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30167)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30167)[0m     param_dset[:] = val
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30167)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30167)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30167)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30167)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:19 2021
[2m[36m(pid=30167)[0m , filename = '/tmp/thalvari/4565627/automl_save__82011y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb1a887158, total write size = 848732, bytes this sub-write = 848732, bytes actually written = 18446744073709551615, offset = 770048)
[2m[36m(pid=30167)[0m 
[2m[36m(pid=30167)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30167)[0m 
[2m[36m(pid=30167)[0m Traceback (most recent call last):
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30167)[0m     self._entrypoint()
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30167)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30167)[0m     output = train_func(config, reporter)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30167)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30167)[0m     config=config)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30167)[0m     model.save(model_path, config_path)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30167)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30167)[0m     self.model.save(model_path)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30167)[0m     signatures)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30167)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30167)[0m     f.close()
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30167)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30167)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:19 2021
[2m[36m(pid=30167)[0m , filename = '/tmp/thalvari/4565627/automl_save__82011y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb1a194f80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30167)[0m Exception in thread Thread-1:
[2m[36m(pid=30167)[0m Traceback (most recent call last):
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30167)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30167)[0m     param_dset[:] = val
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30167)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30167)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30167)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30167)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:19 2021
[2m[36m(pid=30167)[0m , filename = '/tmp/thalvari/4565627/automl_save__82011y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb1a887158, total write size = 848732, bytes this sub-write = 848732, bytes actually written = 18446744073709551615, offset = 770048)
[2m[36m(pid=30167)[0m 
[2m[36m(pid=30167)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30167)[0m 
[2m[36m(pid=30167)[0m Traceback (most recent call last):
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30167)[0m     self._entrypoint()
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30167)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30167)[0m     output = train_func(config, reporter)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30167)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30167)[0m     config=config)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30167)[0m     model.save(model_path, config_path)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30167)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30167)[0m     self.model.save(model_path)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30167)[0m     signatures)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30167)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30167)[0m     f.close()
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30167)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30167)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30167)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:19 2021
[2m[36m(pid=30167)[0m , filename = '/tmp/thalvari/4565627/automl_save__82011y4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb1a194f80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30167)[0m 
[2m[36m(pid=30167)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30167)[0m 
[2m[36m(pid=30167)[0m Traceback (most recent call last):
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30167)[0m     self.run()
[2m[36m(pid=30167)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30167)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30167)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30167)[0m 
2021-01-16 21:22:20,080	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30124, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:20,083	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.453,lstm_2_units_float=123.39,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31151)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31151)[0m 2021-01-16 21:22:20.130384: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31151)[0m 2021-01-16 21:22:20.146484: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31151)[0m 2021-01-16 21:22:20.150200: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9035102ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31151)[0m 2021-01-16 21:22:20.150226: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30124)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30124)[0m 
[2m[36m(pid=30124)[0m Stack (most recent call first):
2021-01-16 21:22:20,809	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30167, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:20,814	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.558,lstm_2_units_float=123.43,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31146)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31146)[0m   agg_primitives: ['count']
[2m[36m(pid=31146)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31146)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30167)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30167)[0m 
[2m[36m(pid=30167)[0m Stack (most recent call first):
[2m[36m(pid=31146)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31146)[0m Instructions for updating:
[2m[36m(pid=31146)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31146)[0m LSTM is selected.
[2m[36m(pid=30858)[0m 2021-01-16 21:22:21,701	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30858)[0m Traceback (most recent call last):
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=30858)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=30858)[0m     param_dset[:] = val
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30858)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30858)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30858)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30858)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:21 2021
[2m[36m(pid=30858)[0m , filename = '/tmp/thalvari/4565627/automl_save_1rdmm4wz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa7fd4c0210, total write size = 134988, bytes this sub-write = 134988, bytes actually written = 18446744073709551615, offset = 761856)
[2m[36m(pid=30858)[0m 
[2m[36m(pid=30858)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30858)[0m 
[2m[36m(pid=30858)[0m Traceback (most recent call last):
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30858)[0m     self._entrypoint()
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30858)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30858)[0m     output = train_func(config, reporter)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30858)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30858)[0m     config=config)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30858)[0m     model.save(model_path, config_path)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30858)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30858)[0m     self.model.save(model_path)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30858)[0m     signatures)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30858)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30858)[0m     f.close()
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30858)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30858)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:21 2021
[2m[36m(pid=30858)[0m , filename = '/tmp/thalvari/4565627/automl_save_1rdmm4wz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa7fe3d1360, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30858)[0m Exception in thread Thread-1:
[2m[36m(pid=30858)[0m Traceback (most recent call last):
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=30858)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=30858)[0m     param_dset[:] = val
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30858)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30858)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30858)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30858)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:21 2021
[2m[36m(pid=30858)[0m , filename = '/tmp/thalvari/4565627/automl_save_1rdmm4wz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa7fd4c0210, total write size = 134988, bytes this sub-write = 134988, bytes actually written = 18446744073709551615, offset = 761856)
[2m[36m(pid=30858)[0m 
[2m[36m(pid=30858)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30858)[0m 
[2m[36m(pid=30858)[0m Traceback (most recent call last):
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30858)[0m     self._entrypoint()
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30858)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30858)[0m     output = train_func(config, reporter)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30858)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30858)[0m     config=config)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30858)[0m     model.save(model_path, config_path)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30858)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30858)[0m     self.model.save(model_path)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30858)[0m     signatures)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30858)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30858)[0m     f.close()
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30858)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30858)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30858)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:21 2021
[2m[36m(pid=30858)[0m , filename = '/tmp/thalvari/4565627/automl_save_1rdmm4wz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa7fe3d1360, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30858)[0m 
[2m[36m(pid=30858)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30858)[0m 
[2m[36m(pid=30858)[0m Traceback (most recent call last):
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30858)[0m     self.run()
[2m[36m(pid=30858)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30858)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30858)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30858)[0m 
[2m[36m(pid=31146)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31146)[0m Instructions for updating:
[2m[36m(pid=31146)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:22:22,866	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30858, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:22,870	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_54_batch_size_log=5.9374,bayes_feature_DAY(datetime)=0.97418,bayes_feature_HOUR(datetime)=0.45392,bayes_feature_IS_AWAKE(datetime)=0.86191,bayes_feature_IS_BUSY_HOURS(datetime)=0.73755,bayes_feature_IS_WEEKEND(datetime)=0.48815,bayes_feature_MONTH(datetime)=0.90272,bayes_feature_WEEKDAY(datetime)=0.81266,dropout_1=0.26873,dropout_2=0.44767,epochs=5,lr=0.0016327,lstm_1_units_float=67.286,lstm_2_units_float=33.272,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=30858)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30858)[0m 
[2m[36m(pid=30858)[0m Stack (most recent call first):
[2m[36m(pid=31146)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31146)[0m 2021-01-16 21:22:23.296970: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31146)[0m 2021-01-16 21:22:23.307019: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31146)[0m 2021-01-16 21:22:23.309769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc475102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31146)[0m 2021-01-16 21:22:23.309800: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31106)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31106)[0m   agg_primitives: ['count']
[2m[36m(pid=31106)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31106)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31154)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31154)[0m   agg_primitives: ['count']
[2m[36m(pid=31154)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31154)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31106)[0m LSTM is selected.
[2m[36m(pid=31154)[0m LSTM is selected.
[2m[36m(pid=31106)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31106)[0m Instructions for updating:
[2m[36m(pid=31106)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31154)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31154)[0m Instructions for updating:
[2m[36m(pid=31154)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31106)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31106)[0m Instructions for updating:
[2m[36m(pid=31106)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31154)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31154)[0m Instructions for updating:
[2m[36m(pid=31154)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=30938)[0m 2021-01-16 21:22:25,354	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30938)[0m Traceback (most recent call last):
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30938)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30938)[0m     param_dset[:] = val
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30938)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30938)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30938)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30938)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:25 2021
[2m[36m(pid=30938)[0m , filename = '/tmp/thalvari/4565627/automl_save_dy0akokx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f364e7bff28, total write size = 869212, bytes this sub-write = 869212, bytes actually written = 18446744073709551615, offset = 749568)
[2m[36m(pid=30938)[0m 
[2m[36m(pid=30938)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30938)[0m 
[2m[36m(pid=30938)[0m Traceback (most recent call last):
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30938)[0m     self._entrypoint()
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30938)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30938)[0m     output = train_func(config, reporter)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30938)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30938)[0m     config=config)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30938)[0m     model.save(model_path, config_path)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30938)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30938)[0m     self.model.save(model_path)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30938)[0m     signatures)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30938)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30938)[0m     f.close()
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30938)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30938)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:25 2021
[2m[36m(pid=30938)[0m , filename = '/tmp/thalvari/4565627/automl_save_dy0akokx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f364d916530, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30938)[0m Exception in thread Thread-1:
[2m[36m(pid=30938)[0m Traceback (most recent call last):
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30938)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30938)[0m     param_dset[:] = val
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30938)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30938)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30938)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30938)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:25 2021
[2m[36m(pid=30938)[0m , filename = '/tmp/thalvari/4565627/automl_save_dy0akokx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f364e7bff28, total write size = 869212, bytes this sub-write = 869212, bytes actually written = 18446744073709551615, offset = 749568)
[2m[36m(pid=30938)[0m 
[2m[36m(pid=30938)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30938)[0m 
[2m[36m(pid=30938)[0m Traceback (most recent call last):
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30938)[0m     self._entrypoint()
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30938)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30938)[0m     output = train_func(config, reporter)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30938)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30938)[0m     config=config)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30938)[0m     model.save(model_path, config_path)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30938)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30938)[0m     self.model.save(model_path)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30938)[0m     signatures)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30938)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30938)[0m     f.close()
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30938)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30938)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30938)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:25 2021
[2m[36m(pid=30938)[0m , filename = '/tmp/thalvari/4565627/automl_save_dy0akokx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f364d916530, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30938)[0m 
[2m[36m(pid=30938)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30938)[0m 
[2m[36m(pid=30938)[0m Traceback (most recent call last):
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30938)[0m     self.run()
[2m[36m(pid=30938)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30938)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30938)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30938)[0m 
[2m[36m(pid=31152)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31152)[0m   agg_primitives: ['count']
[2m[36m(pid=31152)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31152)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30815)[0m 2021-01-16 21:22:26,017	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30815)[0m Traceback (most recent call last):
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30815)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30815)[0m     param_dset[:] = val
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30815)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30815)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30815)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30815)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:26 2021
[2m[36m(pid=30815)[0m , filename = '/tmp/thalvari/4565627/automl_save_0fyhzjr6/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbfdaa08dd8, total write size = 877404, bytes this sub-write = 877404, bytes actually written = 18446744073709551615, offset = 741376)
[2m[36m(pid=30815)[0m 
[2m[36m(pid=30815)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30815)[0m 
[2m[36m(pid=30815)[0m Traceback (most recent call last):
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30815)[0m     self._entrypoint()
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30815)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30815)[0m     output = train_func(config, reporter)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30815)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30815)[0m     config=config)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30815)[0m     model.save(model_path, config_path)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30815)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30815)[0m     self.model.save(model_path)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30815)[0m     signatures)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30815)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30815)[0m     f.close()
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30815)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30815)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:26 2021
[2m[36m(pid=30815)[0m , filename = '/tmp/thalvari/4565627/automl_save_0fyhzjr6/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbfda377df0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30815)[0m Exception in thread Thread-1:
[2m[36m(pid=30815)[0m Traceback (most recent call last):
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30815)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30815)[0m     param_dset[:] = val
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30815)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30815)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30815)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30815)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:26 2021
[2m[36m(pid=30815)[0m , filename = '/tmp/thalvari/4565627/automl_save_0fyhzjr6/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbfdaa08dd8, total write size = 877404, bytes this sub-write = 877404, bytes actually written = 18446744073709551615, offset = 741376)
[2m[36m(pid=30815)[0m 
[2m[36m(pid=30815)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30815)[0m 
[2m[36m(pid=30815)[0m Traceback (most recent call last):
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30815)[0m     self._entrypoint()
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30815)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30815)[0m     output = train_func(config, reporter)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30815)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30815)[0m     config=config)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30815)[0m     model.save(model_path, config_path)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30815)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30815)[0m     self.model.save(model_path)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30815)[0m     signatures)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30815)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30815)[0m     f.close()
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30815)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30815)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30815)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:26 2021
[2m[36m(pid=30815)[0m , filename = '/tmp/thalvari/4565627/automl_save_0fyhzjr6/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbfda377df0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31152)[0m LSTM is selected.
[2m[36m(pid=30815)[0m 
[2m[36m(pid=30815)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30815)[0m 
[2m[36m(pid=30815)[0m Traceback (most recent call last):
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30815)[0m     self.run()
[2m[36m(pid=30815)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30815)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30815)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30815)[0m 
[2m[36m(pid=31152)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31152)[0m Instructions for updating:
[2m[36m(pid=31152)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31106)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31106)[0m 2021-01-16 21:22:26.125299: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31106)[0m 2021-01-16 21:22:26.134405: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31106)[0m 2021-01-16 21:22:26.138812: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f549511da90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31106)[0m 2021-01-16 21:22:26.138848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31154)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31154)[0m 2021-01-16 21:22:26.134641: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31154)[0m 2021-01-16 21:22:26.143188: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31154)[0m 2021-01-16 21:22:26.147423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd69102ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31154)[0m 2021-01-16 21:22:26.147472: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:22:26,444	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30938, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:26,449	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.474,lstm_2_units_float=123.38,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 64 ({'TERMINATED': 13, 'ERROR': 42, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 36 not shown
 - train_func_54_batch_size_log=5.9374,bayes_feature_DAY(datetime)=0.97418,bayes_feature_HOUR(datetime)=0.45392,bayes_feature_IS_AWAKE(datetime)=0.86191,bayes_feature_IS_BUSY_HOURS(datetime)=0.73755,bayes_feature_IS_WEEKEND(datetime)=0.48815,bayes_feature_MONTH(datetime)=0.90272,bayes_feature_WEEKDAY(datetime)=0.81266,dropout_1=0.26873,dropout_2=0.44767,epochs=5,lr=0.0016327,lstm_1_units_float=67.286,lstm_2_units_float=33.272,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_54_batch_size_log=5.9374,bayes_feature_DAY(datetime)=0.97418,bayes_feature_HOUR(datetime)=0.45392,bayes_feature_IS_AWAK_2021-01-16_21-22-063e25lvtd/error_2021-01-16_21-22-22.txt
 - train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.474,lstm_2_units_float=123.38,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-07fukyo3di/error_2021-01-16_21-22-26.txt
 - train_func_56_batch_size_log=9.4562,bayes_feature_DAY(datetime)=0.32836,bayes_feature_HOUR(datetime)=0.857,bayes_feature_IS_AWAKE(datetime)=0.70475,bayes_feature_IS_BUSY_HOURS(datetime)=0.58425,bayes_feature_IS_WEEKEND(datetime)=0.62085,bayes_feature_MONTH(datetime)=0.62028,bayes_feature_WEEKDAY(datetime)=0.33117,dropout_1=0.3251,dropout_2=0.37963,epochs=5,lr=0.0022808,lstm_1_units_float=14.904,lstm_2_units_float=54.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_56_batch_size_log=9.4562,bayes_feature_DAY(datetime)=0.32836,bayes_feature_HOUR(datetime)=0.857,bayes_feature_IS_AWAKE(_2021-01-16_21-22-08ws6f_0hr/error_2021-01-16_21-22-19.txt
RUNNING trials:
 - train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.45858,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.532,lstm_2_units_float=123.42,past_seq_len=2:	RUNNING
 - train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=87.266,lstm_2_units_float=122.67,past_seq_len=2:	RUNNING
 - train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=87.267,lstm_2_units_float=122.64,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_62_batch_size_log=8.3886,bayes_feature_DAY(datetime)=0.49591,bayes_feature_HOUR(datetime)=0.6659,bayes_feature_IS_AWAKE(datetime)=0.6775,bayes_feature_IS_BUSY_HOURS(datetime)=0.84863,bayes_feature_IS_WEEKEND(datetime)=0.87559,bayes_feature_MONTH(datetime)=0.38292,bayes_feature_WEEKDAY(datetime)=0.9981,dropout_1=0.28915,dropout_2=0.38574,epochs=5,lr=0.0041109,lstm_1_units_float=104.57,lstm_2_units_float=91.759,past_seq_len=2:	RUNNING
 - train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.78,past_seq_len=2:	RUNNING
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 7 not shown
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter

[2m[36m(pid=30938)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30938)[0m 
[2m[36m(pid=30938)[0m Stack (most recent call first):
[2m[36m(pid=31152)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31152)[0m Instructions for updating:
[2m[36m(pid=31152)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:22:27,229	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30815, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:27,233	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.45858,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=79.532,lstm_2_units_float=123.42,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31153)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31153)[0m   agg_primitives: ['count']
[2m[36m(pid=31153)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31153)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31276)[0m 2021-01-16 21:22:27,256	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31276)[0m Traceback (most recent call last):
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31276)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31276)[0m     param_dset[:] = val
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31276)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31276)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31276)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31276)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:27 2021
[2m[36m(pid=31276)[0m , filename = '/tmp/thalvari/4565627/automl_save_j0uzsqj9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd1f2a42ef8, total write size = 911680, bytes this sub-write = 911680, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=31276)[0m 
[2m[36m(pid=31276)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31276)[0m 
[2m[36m(pid=31276)[0m Traceback (most recent call last):
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31276)[0m     self._entrypoint()
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31276)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31276)[0m     output = train_func(config, reporter)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31276)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31276)[0m     config=config)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31276)[0m     model.save(model_path, config_path)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31276)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31276)[0m     self.model.save(model_path)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31276)[0m     signatures)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31276)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31276)[0m     f.close()
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31276)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31276)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:27 2021
[2m[36m(pid=31276)[0m , filename = '/tmp/thalvari/4565627/automl_save_j0uzsqj9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd1f252aac0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31276)[0m Exception in thread Thread-1:
[2m[36m(pid=31276)[0m Traceback (most recent call last):
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31276)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31276)[0m     param_dset[:] = val
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31276)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31276)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31276)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31276)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:27 2021
[2m[36m(pid=31276)[0m , filename = '/tmp/thalvari/4565627/automl_save_j0uzsqj9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd1f2a42ef8, total write size = 911680, bytes this sub-write = 911680, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=31276)[0m 
[2m[36m(pid=31276)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31276)[0m 
[2m[36m(pid=31276)[0m Traceback (most recent call last):
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31276)[0m     self._entrypoint()
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31276)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31276)[0m     output = train_func(config, reporter)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31276)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31276)[0m     config=config)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31276)[0m     model.save(model_path, config_path)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31276)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31276)[0m     self.model.save(model_path)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31276)[0m     signatures)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31276)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31276)[0m     f.close()
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31276)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31276)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31276)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:27 2021
[2m[36m(pid=31276)[0m , filename = '/tmp/thalvari/4565627/automl_save_j0uzsqj9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd1f252aac0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31276)[0m 
[2m[36m(pid=31276)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31276)[0m 
[2m[36m(pid=31276)[0m Traceback (most recent call last):
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31276)[0m     self.run()
[2m[36m(pid=31276)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31276)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31276)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31276)[0m 
[2m[36m(pid=30815)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30815)[0m 
[2m[36m(pid=30815)[0m Stack (most recent call first):
[2m[36m(pid=31153)[0m LSTM is selected.
[2m[36m(pid=31152)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31152)[0m 2021-01-16 21:22:27.799553: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31152)[0m 2021-01-16 21:22:27.812064: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31152)[0m 2021-01-16 21:22:27.817910: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83bd102a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31152)[0m 2021-01-16 21:22:27.817960: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31153)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31153)[0m Instructions for updating:
[2m[36m(pid=31153)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31146)[0m 2021-01-16 21:22:28,197	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31146)[0m Traceback (most recent call last):
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31146)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31146)[0m     param_dset[:] = val
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31146)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31146)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31146)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31146)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31146)[0m , filename = '/tmp/thalvari/4565627/automl_save_zu5yzljk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc47629de58, total write size = 17352, bytes this sub-write = 17352, bytes actually written = 18446744073709551615, offset = 167936)
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31146)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31146)[0m Traceback (most recent call last):
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31146)[0m     self._entrypoint()
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31146)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31146)[0m     output = train_func(config, reporter)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31146)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31146)[0m     config=config)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31146)[0m     model.save(model_path, config_path)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31146)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31146)[0m     self.model.save(model_path)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31146)[0m     signatures)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31146)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31146)[0m     f.close()
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31146)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31146)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31146)[0m , filename = '/tmp/thalvari/4565627/automl_save_zu5yzljk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc4769c4130, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31146)[0m Exception in thread Thread-1:
[2m[36m(pid=31146)[0m Traceback (most recent call last):
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31146)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31146)[0m     param_dset[:] = val
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31146)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31146)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31146)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31146)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31146)[0m , filename = '/tmp/thalvari/4565627/automl_save_zu5yzljk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc47629de58, total write size = 17352, bytes this sub-write = 17352, bytes actually written = 18446744073709551615, offset = 167936)
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31146)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31146)[0m Traceback (most recent call last):
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31146)[0m     self._entrypoint()
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31146)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31146)[0m     output = train_func(config, reporter)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31146)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31146)[0m     config=config)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31146)[0m     model.save(model_path, config_path)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31146)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31146)[0m     self.model.save(model_path)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31146)[0m     signatures)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31146)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31146)[0m     f.close()
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31146)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31146)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31146)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31146)[0m , filename = '/tmp/thalvari/4565627/automl_save_zu5yzljk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc4769c4130, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31155)[0m 2021-01-16 21:22:28,219	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31155)[0m Traceback (most recent call last):
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31155)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31155)[0m     param_dset[:] = val
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31155)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31155)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31155)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31155)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31155)[0m , filename = '/tmp/thalvari/4565627/automl_save_lpt_92da/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efdcea3de88, total write size = 928064, bytes this sub-write = 928064, bytes actually written = 18446744073709551615, offset = 716800)
[2m[36m(pid=31155)[0m 
[2m[36m(pid=31155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31155)[0m 
[2m[36m(pid=31155)[0m Traceback (most recent call last):
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31155)[0m     self._entrypoint()
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31155)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31155)[0m     output = train_func(config, reporter)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31155)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31155)[0m     config=config)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31155)[0m     model.save(model_path, config_path)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31155)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31155)[0m     self.model.save(model_path)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31155)[0m     signatures)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31155)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31155)[0m     f.close()
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31155)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31155)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31155)[0m , filename = '/tmp/thalvari/4565627/automl_save_lpt_92da/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efdce516340, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31155)[0m Exception in thread Thread-1:
[2m[36m(pid=31155)[0m Traceback (most recent call last):
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31155)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31155)[0m     param_dset[:] = val
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31155)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31155)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31155)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31155)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31155)[0m , filename = '/tmp/thalvari/4565627/automl_save_lpt_92da/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efdcea3de88, total write size = 928064, bytes this sub-write = 928064, bytes actually written = 18446744073709551615, offset = 716800)
[2m[36m(pid=31155)[0m 
[2m[36m(pid=31155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31155)[0m 
[2m[36m(pid=31155)[0m Traceback (most recent call last):
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31155)[0m     self._entrypoint()
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31155)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31155)[0m     output = train_func(config, reporter)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31155)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31155)[0m     config=config)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31155)[0m     model.save(model_path, config_path)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31155)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31155)[0m     self.model.save(model_path)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31155)[0m     signatures)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31155)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31155)[0m     f.close()
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31155)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31155)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31155)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:28 2021
[2m[36m(pid=31155)[0m , filename = '/tmp/thalvari/4565627/automl_save_lpt_92da/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efdce516340, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31146)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31146)[0m Traceback (most recent call last):
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31146)[0m     self.run()
[2m[36m(pid=31146)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31146)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31146)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31155)[0m 
[2m[36m(pid=31155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31155)[0m 
[2m[36m(pid=31155)[0m Traceback (most recent call last):
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31155)[0m     self.run()
[2m[36m(pid=31155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31155)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31155)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31155)[0m 
2021-01-16 21:22:28,320	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31276, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:28,322	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=87.266,lstm_2_units_float=122.67,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31153)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31153)[0m Instructions for updating:
[2m[36m(pid=31153)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31276)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31276)[0m 
[2m[36m(pid=31276)[0m Stack (most recent call first):
2021-01-16 21:22:29,336	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31155, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:29,339	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=87.267,lstm_2_units_float=122.64,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31153)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31153)[0m 2021-01-16 21:22:29.373428: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31153)[0m 2021-01-16 21:22:29.387136: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31153)[0m 2021-01-16 21:22:29.392983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6acd0cc080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31153)[0m 2021-01-16 21:22:29.393025: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31155)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31155)[0m 
[2m[36m(pid=31155)[0m Stack (most recent call first):
[2m[36m(pid=31106)[0m 2021-01-16 21:22:29,527	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31106)[0m Traceback (most recent call last):
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31106)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31106)[0m     param_dset[:] = val
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31106)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31106)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31106)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31106)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31106)[0m , filename = '/tmp/thalvari/4565627/automl_save_v_67wa09/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f549643ec48, total write size = 848556, bytes this sub-write = 848556, bytes actually written = 18446744073709551615, offset = 708608)
[2m[36m(pid=31106)[0m 
[2m[36m(pid=31106)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31106)[0m 
[2m[36m(pid=31106)[0m Traceback (most recent call last):
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31106)[0m     self._entrypoint()
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31106)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31106)[0m     output = train_func(config, reporter)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31106)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31106)[0m     config=config)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31106)[0m     model.save(model_path, config_path)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31106)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31106)[0m     self.model.save(model_path)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31106)[0m     signatures)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31106)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31106)[0m     f.close()
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31106)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31106)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31106)[0m , filename = '/tmp/thalvari/4565627/automl_save_v_67wa09/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5496739f30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31106)[0m Exception in thread Thread-1:
[2m[36m(pid=31106)[0m Traceback (most recent call last):
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31106)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31106)[0m     param_dset[:] = val
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31106)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31106)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31106)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31106)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31106)[0m , filename = '/tmp/thalvari/4565627/automl_save_v_67wa09/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f549643ec48, total write size = 848556, bytes this sub-write = 848556, bytes actually written = 18446744073709551615, offset = 708608)
[2m[36m(pid=31106)[0m 
[2m[36m(pid=31106)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31106)[0m 
[2m[36m(pid=31106)[0m Traceback (most recent call last):
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31106)[0m     self._entrypoint()
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31106)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31106)[0m     output = train_func(config, reporter)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31106)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31106)[0m     config=config)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31106)[0m     model.save(model_path, config_path)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31106)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31106)[0m     self.model.save(model_path)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31106)[0m     signatures)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31106)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31106)[0m     f.close()
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31106)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31106)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31106)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31106)[0m , filename = '/tmp/thalvari/4565627/automl_save_v_67wa09/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5496739f30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31106)[0m 
[2m[36m(pid=31106)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31106)[0m 
[2m[36m(pid=31106)[0m Traceback (most recent call last):
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31106)[0m     self.run()
[2m[36m(pid=31106)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31106)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31106)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31106)[0m 
2021-01-16 21:22:29,582	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31146, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:29,585	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_60_batch_size_log=7.0682,bayes_feature_DAY(datetime)=0.951,bayes_feature_HOUR(datetime)=0.30751,bayes_feature_IS_AWAKE(datetime)=0.87857,bayes_feature_IS_BUSY_HOURS(datetime)=0.39519,bayes_feature_IS_WEEKEND(datetime)=0.91974,bayes_feature_MONTH(datetime)=0.50449,bayes_feature_WEEKDAY(datetime)=0.56349,dropout_1=0.34346,dropout_2=0.36178,epochs=5,lr=0.0074656,lstm_1_units_float=101.3,lstm_2_units_float=116.01,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31146)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31146)[0m 
[2m[36m(pid=31146)[0m Stack (most recent call first):
[2m[36m(pid=31154)[0m 2021-01-16 21:22:29,997	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31154)[0m Traceback (most recent call last):
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31154)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31154)[0m     param_dset[:] = val
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31154)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31154)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31154)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31154)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31154)[0m , filename = '/tmp/thalvari/4565627/automl_save_8s5r3ocu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd6a1b1068, total write size = 598332, bytes this sub-write = 598332, bytes actually written = 18446744073709551615, offset = 700416)
[2m[36m(pid=31154)[0m 
[2m[36m(pid=31154)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31154)[0m 
[2m[36m(pid=31154)[0m Traceback (most recent call last):
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31154)[0m     self._entrypoint()
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31154)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31154)[0m     output = train_func(config, reporter)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31154)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31154)[0m     config=config)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31154)[0m     model.save(model_path, config_path)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31154)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31154)[0m     self.model.save(model_path)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31154)[0m     signatures)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31154)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31154)[0m     f.close()
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31154)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31154)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31154)[0m , filename = '/tmp/thalvari/4565627/automl_save_8s5r3ocu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd6a841b50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31154)[0m Exception in thread Thread-1:
[2m[36m(pid=31154)[0m Traceback (most recent call last):
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31154)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31154)[0m     param_dset[:] = val
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31154)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31154)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31154)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31154)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31154)[0m , filename = '/tmp/thalvari/4565627/automl_save_8s5r3ocu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd6a1b1068, total write size = 598332, bytes this sub-write = 598332, bytes actually written = 18446744073709551615, offset = 700416)
[2m[36m(pid=31154)[0m 
[2m[36m(pid=31154)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31154)[0m 
[2m[36m(pid=31154)[0m Traceback (most recent call last):
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31154)[0m     self._entrypoint()
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31154)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31154)[0m     output = train_func(config, reporter)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31154)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31154)[0m     config=config)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31154)[0m     model.save(model_path, config_path)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31154)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31154)[0m     self.model.save(model_path)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31154)[0m     signatures)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31154)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31154)[0m     f.close()
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31154)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31154)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31154)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:29 2021
[2m[36m(pid=31154)[0m , filename = '/tmp/thalvari/4565627/automl_save_8s5r3ocu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd6a841b50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31154)[0m 
[2m[36m(pid=31154)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31154)[0m 
[2m[36m(pid=31154)[0m Traceback (most recent call last):
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31154)[0m     self.run()
[2m[36m(pid=31154)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31154)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31154)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31154)[0m 
2021-01-16 21:22:30,560	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31106, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:30,563	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_61_batch_size_log=8.7072,bayes_feature_DAY(datetime)=0.38393,bayes_feature_HOUR(datetime)=0.52062,bayes_feature_IS_AWAKE(datetime)=0.92977,bayes_feature_IS_BUSY_HOURS(datetime)=0.51154,bayes_feature_IS_WEEKEND(datetime)=0.55061,bayes_feature_MONTH(datetime)=0.93264,bayes_feature_WEEKDAY(datetime)=0.77364,dropout_1=0.4035,dropout_2=0.34525,epochs=5,lr=0.0088355,lstm_1_units_float=50.042,lstm_2_units_float=127.27,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31106)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31106)[0m 
[2m[36m(pid=31106)[0m Stack (most recent call first):
[2m[36m(pid=31105)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31105)[0m   agg_primitives: ['count']
[2m[36m(pid=31105)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31105)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31150)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31150)[0m   agg_primitives: ['count']
[2m[36m(pid=31150)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31150)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:22:31,165	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31154, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:31,168	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_62_batch_size_log=8.3886,bayes_feature_DAY(datetime)=0.49591,bayes_feature_HOUR(datetime)=0.6659,bayes_feature_IS_AWAKE(datetime)=0.6775,bayes_feature_IS_BUSY_HOURS(datetime)=0.84863,bayes_feature_IS_WEEKEND(datetime)=0.87559,bayes_feature_MONTH(datetime)=0.38292,bayes_feature_WEEKDAY(datetime)=0.9981,dropout_1=0.28915,dropout_2=0.38574,epochs=5,lr=0.0041109,lstm_1_units_float=104.57,lstm_2_units_float=91.759,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31154)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31154)[0m 
[2m[36m(pid=31154)[0m Stack (most recent call first):
[2m[36m(pid=31150)[0m LSTM is selected.
[2m[36m(pid=31105)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31105)[0m Instructions for updating:
[2m[36m(pid=31105)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31105)[0m LSTM is selected.
[2m[36m(pid=31150)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31150)[0m Instructions for updating:
[2m[36m(pid=31150)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31151)[0m 2021-01-16 21:22:31,635	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31151)[0m Traceback (most recent call last):
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31151)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31151)[0m     param_dset[:] = val
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31151)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31151)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31151)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31151)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:31 2021
[2m[36m(pid=31151)[0m , filename = '/tmp/thalvari/4565627/automl_save_s9cucze1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f90368a57c8, total write size = 1090540, bytes this sub-write = 1090540, bytes actually written = 18446744073709551615, offset = 692224)
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31151)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31151)[0m Traceback (most recent call last):
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31151)[0m     self._entrypoint()
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31151)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31151)[0m     output = train_func(config, reporter)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31151)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31151)[0m     config=config)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31151)[0m     model.save(model_path, config_path)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31151)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31151)[0m     self.model.save(model_path)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31151)[0m     signatures)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31151)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31151)[0m     f.close()
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31151)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31151)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:31 2021
[2m[36m(pid=31151)[0m , filename = '/tmp/thalvari/4565627/automl_save_s9cucze1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9036576550, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31151)[0m Exception in thread Thread-1:
[2m[36m(pid=31151)[0m Traceback (most recent call last):
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31151)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31151)[0m     param_dset[:] = val
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31151)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31151)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31151)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31151)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:31 2021
[2m[36m(pid=31151)[0m , filename = '/tmp/thalvari/4565627/automl_save_s9cucze1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f90368a57c8, total write size = 1090540, bytes this sub-write = 1090540, bytes actually written = 18446744073709551615, offset = 692224)
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31151)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31151)[0m Traceback (most recent call last):
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31151)[0m     self._entrypoint()
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31151)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31151)[0m     output = train_func(config, reporter)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31151)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31151)[0m     config=config)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31151)[0m     model.save(model_path, config_path)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31151)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31151)[0m     self.model.save(model_path)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31151)[0m     signatures)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31151)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31151)[0m     f.close()
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31151)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31151)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31151)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:31 2021
[2m[36m(pid=31151)[0m , filename = '/tmp/thalvari/4565627/automl_save_s9cucze1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9036576550, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31151)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31151)[0m Traceback (most recent call last):
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31151)[0m     self.run()
[2m[36m(pid=31151)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31151)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31151)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31105)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31105)[0m Instructions for updating:
[2m[36m(pid=31105)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31150)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31150)[0m Instructions for updating:
[2m[36m(pid=31150)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 71 ({'TERMINATED': 13, 'ERROR': 48, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 42 not shown
 - train_func_60_batch_size_log=7.0682,bayes_feature_DAY(datetime)=0.951,bayes_feature_HOUR(datetime)=0.30751,bayes_feature_IS_AWAKE(datetime)=0.87857,bayes_feature_IS_BUSY_HOURS(datetime)=0.39519,bayes_feature_IS_WEEKEND(datetime)=0.91974,bayes_feature_MONTH(datetime)=0.50449,bayes_feature_WEEKDAY(datetime)=0.56349,dropout_1=0.34346,dropout_2=0.36178,epochs=5,lr=0.0074656,lstm_1_units_float=101.3,lstm_2_units_float=116.01,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_60_batch_size_log=7.0682,bayes_feature_DAY(datetime)=0.951,bayes_feature_HOUR(datetime)=0.30751,bayes_feature_IS_AWAKE(_2021-01-16_21-22-16iaz536f0/error_2021-01-16_21-22-29.txt
 - train_func_61_batch_size_log=8.7072,bayes_feature_DAY(datetime)=0.38393,bayes_feature_HOUR(datetime)=0.52062,bayes_feature_IS_AWAKE(datetime)=0.92977,bayes_feature_IS_BUSY_HOURS(datetime)=0.51154,bayes_feature_IS_WEEKEND(datetime)=0.55061,bayes_feature_MONTH(datetime)=0.93264,bayes_feature_WEEKDAY(datetime)=0.77364,dropout_1=0.4035,dropout_2=0.34525,epochs=5,lr=0.0088355,lstm_1_units_float=50.042,lstm_2_units_float=127.27,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_61_batch_size_log=8.7072,bayes_feature_DAY(datetime)=0.38393,bayes_feature_HOUR(datetime)=0.52062,bayes_feature_IS_AWAK_2021-01-16_21-22-19k459gprm/error_2021-01-16_21-22-30.txt
 - train_func_62_batch_size_log=8.3886,bayes_feature_DAY(datetime)=0.49591,bayes_feature_HOUR(datetime)=0.6659,bayes_feature_IS_AWAKE(datetime)=0.6775,bayes_feature_IS_BUSY_HOURS(datetime)=0.84863,bayes_feature_IS_WEEKEND(datetime)=0.87559,bayes_feature_MONTH(datetime)=0.38292,bayes_feature_WEEKDAY(datetime)=0.9981,dropout_1=0.28915,dropout_2=0.38574,epochs=5,lr=0.0041109,lstm_1_units_float=104.57,lstm_2_units_float=91.759,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_62_batch_size_log=8.3886,bayes_feature_DAY(datetime)=0.49591,bayes_feature_HOUR(datetime)=0.6659,bayes_feature_IS_AWAKE_2021-01-16_21-22-20yvy2_o0b/error_2021-01-16_21-22-31.txt
RUNNING trials:
 - train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.55,lstm_2_units_float=127.71,past_seq_len=2:	RUNNING
 - train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.78,past_seq_len=2:	RUNNING
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_69_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.52,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING
 - train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAKE(datetime)=0.30567,bayes_feature_IS_BUSY_HOURS(datetime)=0.52893,bayes_feature_IS_WEEKEND(datetime)=0.51649,bayes_feature_MONTH(datetime)=0.85243,bayes_feature_WEEKDAY(datetime)=0.84011,dropout_1=0.41935,dropout_2=0.23883,epochs=5,lr=0.0041175,lstm_1_units_float=74.972,lstm_2_units_float=79.941,past_seq_len=2:	RUNNING
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.56,lstm_2_units_float=127.71,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 7 not shown
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter

[2m[36m(pid=30983)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30983)[0m   agg_primitives: ['count']
[2m[36m(pid=30983)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30983)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31104)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31104)[0m   agg_primitives: ['count']
[2m[36m(pid=31104)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31104)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:22:32,822	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31151, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:32,825	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.55,lstm_2_units_float=127.71,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31150)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31150)[0m 2021-01-16 21:22:32.917651: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31104)[0m LSTM is selected.
[2m[36m(pid=31105)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31105)[0m 2021-01-16 21:22:32.954434: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31105)[0m 2021-01-16 21:22:32.969335: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31105)[0m 2021-01-16 21:22:32.972461: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef0750e8f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31105)[0m 2021-01-16 21:22:32.972494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31150)[0m 2021-01-16 21:22:32.927888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31150)[0m 2021-01-16 21:22:32.931244: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9de9102a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31150)[0m 2021-01-16 21:22:32.931268: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30983)[0m LSTM is selected.
[2m[36m(pid=31104)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31104)[0m Instructions for updating:
[2m[36m(pid=31104)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30983)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30983)[0m Instructions for updating:
[2m[36m(pid=30983)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31151)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31151)[0m 
[2m[36m(pid=31151)[0m Stack (most recent call first):
[2m[36m(pid=31104)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31104)[0m Instructions for updating:
[2m[36m(pid=31104)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=30983)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30983)[0m Instructions for updating:
[2m[36m(pid=30983)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=30984)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30984)[0m   agg_primitives: ['count']
[2m[36m(pid=30984)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30984)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31318)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31318)[0m   agg_primitives: ['count']
[2m[36m(pid=31318)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31318)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30984)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30984)[0m Instructions for updating:
[2m[36m(pid=30984)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30984)[0m LSTM is selected.
[2m[36m(pid=31318)[0m LSTM is selected.
[2m[36m(pid=31318)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31318)[0m Instructions for updating:
[2m[36m(pid=31318)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31104)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31104)[0m 2021-01-16 21:22:34.498521: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31104)[0m 2021-01-16 21:22:34.510233: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31104)[0m 2021-01-16 21:22:34.513031: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9c9103080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31104)[0m 2021-01-16 21:22:34.513073: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30983)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30983)[0m 2021-01-16 21:22:34.556737: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30983)[0m 2021-01-16 21:22:34.567766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30983)[0m 2021-01-16 21:22:34.571369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd0150e5ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30983)[0m 2021-01-16 21:22:34.571405: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30984)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30984)[0m Instructions for updating:
[2m[36m(pid=30984)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31318)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31318)[0m Instructions for updating:
[2m[36m(pid=31318)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31147)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=31147)[0m   agg_primitives: ['count']
[2m[36m(pid=31147)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=31147)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=30984)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30984)[0m 2021-01-16 21:22:35.751702: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30984)[0m 2021-01-16 21:22:35.760422: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30984)[0m 2021-01-16 21:22:35.763893: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb551103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30984)[0m 2021-01-16 21:22:35.763934: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31318)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31318)[0m 2021-01-16 21:22:35.774097: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31318)[0m 2021-01-16 21:22:35.782662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31318)[0m 2021-01-16 21:22:35.786033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faacd102a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31318)[0m 2021-01-16 21:22:35.786077: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30857)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=30857)[0m   agg_primitives: ['count']
[2m[36m(pid=30857)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=30857)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=31105)[0m 2021-01-16 21:22:35,908	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31105)[0m Traceback (most recent call last):
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31105)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31105)[0m     param_dset[:] = val
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31105)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31105)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31105)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31105)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:35 2021
[2m[36m(pid=31105)[0m , filename = '/tmp/thalvari/4565627/automl_save_jpk71s3o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef075407448, total write size = 110296, bytes this sub-write = 110296, bytes actually written = 18446744073709551615, offset = 122880)
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31105)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31105)[0m Traceback (most recent call last):
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31105)[0m     self._entrypoint()
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31105)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31105)[0m     output = train_func(config, reporter)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31105)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31105)[0m     config=config)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31105)[0m     model.save(model_path, config_path)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31105)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31105)[0m     self.model.save(model_path)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31105)[0m     signatures)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31105)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31105)[0m     f.close()
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31105)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31105)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:35 2021
[2m[36m(pid=31105)[0m , filename = '/tmp/thalvari/4565627/automl_save_jpk71s3o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef075454e10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31105)[0m Exception in thread Thread-1:
[2m[36m(pid=31105)[0m Traceback (most recent call last):
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31105)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31105)[0m     param_dset[:] = val
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31105)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31105)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31105)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31105)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:35 2021
[2m[36m(pid=31105)[0m , filename = '/tmp/thalvari/4565627/automl_save_jpk71s3o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef075407448, total write size = 110296, bytes this sub-write = 110296, bytes actually written = 18446744073709551615, offset = 122880)
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31105)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31105)[0m Traceback (most recent call last):
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31105)[0m     self._entrypoint()
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31105)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31105)[0m     output = train_func(config, reporter)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31105)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31105)[0m     config=config)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31105)[0m     model.save(model_path, config_path)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31105)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31105)[0m     self.model.save(model_path)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31105)[0m     signatures)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31105)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31105)[0m     f.close()
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31105)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31105)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31105)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:35 2021
[2m[36m(pid=31105)[0m , filename = '/tmp/thalvari/4565627/automl_save_jpk71s3o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef075454e10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31105)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31105)[0m Traceback (most recent call last):
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31105)[0m     self.run()
[2m[36m(pid=31105)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31105)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31105)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31147)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=31147)[0m Instructions for updating:
[2m[36m(pid=31147)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=31147)[0m LSTM is selected.
[2m[36m(pid=30857)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=30857)[0m Instructions for updating:
[2m[36m(pid=30857)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=30857)[0m LSTM is selected.
[2m[36m(pid=31147)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=31147)[0m Instructions for updating:
[2m[36m(pid=31147)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=30857)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=30857)[0m Instructions for updating:
[2m[36m(pid=30857)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:22:37,096	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31105, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:37,102	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_65_batch_size_log=9.2307,bayes_feature_DAY(datetime)=0.70852,bayes_feature_HOUR(datetime)=0.43291,bayes_feature_IS_AWAKE(datetime)=0.65102,bayes_feature_IS_BUSY_HOURS(datetime)=0.755,bayes_feature_IS_WEEKEND(datetime)=0.43111,bayes_feature_MONTH(datetime)=0.63965,bayes_feature_WEEKDAY(datetime)=0.32764,dropout_1=0.24414,dropout_2=0.28165,epochs=5,lr=0.0023158,lstm_1_units_float=115.16,lstm_2_units_float=99.765,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 72 ({'TERMINATED': 13, 'ERROR': 50, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 44 not shown
 - train_func_61_batch_size_log=8.7072,bayes_feature_DAY(datetime)=0.38393,bayes_feature_HOUR(datetime)=0.52062,bayes_feature_IS_AWAKE(datetime)=0.92977,bayes_feature_IS_BUSY_HOURS(datetime)=0.51154,bayes_feature_IS_WEEKEND(datetime)=0.55061,bayes_feature_MONTH(datetime)=0.93264,bayes_feature_WEEKDAY(datetime)=0.77364,dropout_1=0.4035,dropout_2=0.34525,epochs=5,lr=0.0088355,lstm_1_units_float=50.042,lstm_2_units_float=127.27,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_61_batch_size_log=8.7072,bayes_feature_DAY(datetime)=0.38393,bayes_feature_HOUR(datetime)=0.52062,bayes_feature_IS_AWAK_2021-01-16_21-22-19k459gprm/error_2021-01-16_21-22-30.txt
 - train_func_62_batch_size_log=8.3886,bayes_feature_DAY(datetime)=0.49591,bayes_feature_HOUR(datetime)=0.6659,bayes_feature_IS_AWAKE(datetime)=0.6775,bayes_feature_IS_BUSY_HOURS(datetime)=0.84863,bayes_feature_IS_WEEKEND(datetime)=0.87559,bayes_feature_MONTH(datetime)=0.38292,bayes_feature_WEEKDAY(datetime)=0.9981,dropout_1=0.28915,dropout_2=0.38574,epochs=5,lr=0.0041109,lstm_1_units_float=104.57,lstm_2_units_float=91.759,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_62_batch_size_log=8.3886,bayes_feature_DAY(datetime)=0.49591,bayes_feature_HOUR(datetime)=0.6659,bayes_feature_IS_AWAKE_2021-01-16_21-22-20yvy2_o0b/error_2021-01-16_21-22-31.txt
 - train_func_65_batch_size_log=9.2307,bayes_feature_DAY(datetime)=0.70852,bayes_feature_HOUR(datetime)=0.43291,bayes_feature_IS_AWAKE(datetime)=0.65102,bayes_feature_IS_BUSY_HOURS(datetime)=0.755,bayes_feature_IS_WEEKEND(datetime)=0.43111,bayes_feature_MONTH(datetime)=0.63965,bayes_feature_WEEKDAY(datetime)=0.32764,dropout_1=0.24414,dropout_2=0.28165,epochs=5,lr=0.0023158,lstm_1_units_float=115.16,lstm_2_units_float=99.765,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_65_batch_size_log=9.2307,bayes_feature_DAY(datetime)=0.70852,bayes_feature_HOUR(datetime)=0.43291,bayes_feature_IS_AWAK_2021-01-16_21-22-26hrqc6wbo/error_2021-01-16_21-22-37.txt
RUNNING trials:
 - train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.78,past_seq_len=2:	RUNNING
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=31153], 9 s, 3 iter
 - train_func_66_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.48,lstm_2_units_float=127.74,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAKE(datetime)=0.30567,bayes_feature_IS_BUSY_HOURS(datetime)=0.52893,bayes_feature_IS_WEEKEND(datetime)=0.51649,bayes_feature_MONTH(datetime)=0.85243,bayes_feature_WEEKDAY(datetime)=0.84011,dropout_1=0.41935,dropout_2=0.23883,epochs=5,lr=0.0041175,lstm_1_units_float=74.972,lstm_2_units_float=79.941,past_seq_len=2:	RUNNING
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.56,lstm_2_units_float=127.71,past_seq_len=2:	RUNNING
 - train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAKE(datetime)=0.51343,bayes_feature_IS_BUSY_HOURS(datetime)=0.58628,bayes_feature_IS_WEEKEND(datetime)=0.34766,bayes_feature_MONTH(datetime)=0.39863,bayes_feature_WEEKDAY(datetime)=0.38765,dropout_1=0.26776,dropout_2=0.28822,epochs=5,lr=0.007196,lstm_1_units_float=87.392,lstm_2_units_float=125.67,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 7 not shown
 - train_func_35_batch_size_log=7.637,bayes_feature_DAY(datetime)=0.81525,bayes_feature_HOUR(datetime)=0.82653,bayes_feature_IS_AWAKE(datetime)=0.49408,bayes_feature_IS_BUSY_HOURS(datetime)=0.73195,bayes_feature_IS_WEEKEND(datetime)=0.70097,bayes_feature_MONTH(datetime)=0.83118,bayes_feature_WEEKDAY(datetime)=0.43948,dropout_1=0.29191,dropout_2=0.42087,epochs=5,lr=0.008338,lstm_1_units_float=29.667,lstm_2_units_float=24.318,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19627], 13 s, 5 iter
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter

[2m[36m(pid=31105)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31105)[0m 
[2m[36m(pid=31105)[0m Stack (most recent call first):
[2m[36m(pid=31147)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=31147)[0m 2021-01-16 21:22:37.935996: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=31147)[0m 2021-01-16 21:22:37.945858: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=31147)[0m 2021-01-16 21:22:37.950405: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda85102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=31147)[0m 2021-01-16 21:22:37.950448: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=30857)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=30857)[0m 2021-01-16 21:22:37.998418: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=30857)[0m 2021-01-16 21:22:38.006858: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=30857)[0m 2021-01-16 21:22:38.013054: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fae810e9220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=30857)[0m 2021-01-16 21:22:38.013110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31152)[0m 2021-01-16 21:22:38,026	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31152)[0m Traceback (most recent call last):
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31152)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31152)[0m     param_dset[:] = val
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31152)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31152)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31152)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31152)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=31152)[0m , filename = '/tmp/thalvari/4565627/automl_save_pwnjl_mq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f83bea565d8, total write size = 1106924, bytes this sub-write = 1106924, bytes actually written = 18446744073709551615, offset = 675840)
[2m[36m(pid=31152)[0m 
[2m[36m(pid=31152)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31152)[0m 
[2m[36m(pid=31152)[0m Traceback (most recent call last):
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31152)[0m     self._entrypoint()
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31152)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31152)[0m     output = train_func(config, reporter)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31152)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31152)[0m     config=config)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31152)[0m     model.save(model_path, config_path)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31152)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31152)[0m     self.model.save(model_path)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31152)[0m     signatures)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31152)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31152)[0m     f.close()
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31152)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31152)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=31152)[0m , filename = '/tmp/thalvari/4565627/automl_save_pwnjl_mq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f83bd6e28b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31152)[0m Exception in thread Thread-1:
[2m[36m(pid=31152)[0m Traceback (most recent call last):
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31152)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31152)[0m     param_dset[:] = val
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31152)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31152)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31152)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31152)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=31152)[0m , filename = '/tmp/thalvari/4565627/automl_save_pwnjl_mq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f83bea565d8, total write size = 1106924, bytes this sub-write = 1106924, bytes actually written = 18446744073709551615, offset = 675840)
[2m[36m(pid=31152)[0m 
[2m[36m(pid=31152)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31152)[0m 
[2m[36m(pid=31152)[0m Traceback (most recent call last):
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31152)[0m     self._entrypoint()
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31152)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31152)[0m     output = train_func(config, reporter)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31152)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31152)[0m     config=config)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31152)[0m     model.save(model_path, config_path)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31152)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31152)[0m     self.model.save(model_path)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31152)[0m     signatures)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31152)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31152)[0m     f.close()
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31152)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31152)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31152)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=31152)[0m , filename = '/tmp/thalvari/4565627/automl_save_pwnjl_mq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f83bd6e28b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31152)[0m 
[2m[36m(pid=31152)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31152)[0m 
[2m[36m(pid=31152)[0m Traceback (most recent call last):
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31152)[0m     self.run()
[2m[36m(pid=31152)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31152)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31152)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31152)[0m 
[2m[36m(pid=30984)[0m 2021-01-16 21:22:38,943	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30984)[0m Traceback (most recent call last):
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30984)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30984)[0m     param_dset[:] = val
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30984)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30984)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30984)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30984)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=30984)[0m , filename = '/tmp/thalvari/4565627/automl_save_zy2fx2l3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb55278e4d8, total write size = 345548, bytes this sub-write = 345548, bytes actually written = 18446744073709551615, offset = 667648)
[2m[36m(pid=30984)[0m 
[2m[36m(pid=30984)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30984)[0m 
[2m[36m(pid=30984)[0m Traceback (most recent call last):
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30984)[0m     self._entrypoint()
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30984)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30984)[0m     output = train_func(config, reporter)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30984)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30984)[0m     config=config)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30984)[0m     model.save(model_path, config_path)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30984)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30984)[0m     self.model.save(model_path)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30984)[0m     signatures)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30984)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30984)[0m     f.close()
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30984)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30984)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=30984)[0m , filename = '/tmp/thalvari/4565627/automl_save_zy2fx2l3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5521ffbd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30984)[0m Exception in thread Thread-1:
[2m[36m(pid=30984)[0m Traceback (most recent call last):
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30984)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30984)[0m     param_dset[:] = val
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30984)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30984)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30984)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30984)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=30984)[0m , filename = '/tmp/thalvari/4565627/automl_save_zy2fx2l3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb55278e4d8, total write size = 345548, bytes this sub-write = 345548, bytes actually written = 18446744073709551615, offset = 667648)
[2m[36m(pid=30984)[0m 
[2m[36m(pid=30984)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30984)[0m 
[2m[36m(pid=30984)[0m Traceback (most recent call last):
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30984)[0m     self._entrypoint()
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30984)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30984)[0m     output = train_func(config, reporter)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30984)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30984)[0m     config=config)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30984)[0m     model.save(model_path, config_path)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30984)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30984)[0m     self.model.save(model_path)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30984)[0m     signatures)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30984)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30984)[0m     f.close()
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30984)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30984)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30984)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:38 2021
[2m[36m(pid=30984)[0m , filename = '/tmp/thalvari/4565627/automl_save_zy2fx2l3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5521ffbd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30984)[0m 
[2m[36m(pid=30984)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30984)[0m 
[2m[36m(pid=30984)[0m Traceback (most recent call last):
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30984)[0m     self.run()
[2m[36m(pid=30984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30984)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30984)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30984)[0m 
2021-01-16 21:22:39,159	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31152, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:39,163	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.78,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31152)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31152)[0m 
[2m[36m(pid=31152)[0m Stack (most recent call first):
[2m[36m(pid=35395)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35395)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30983)[0m 2021-01-16 21:22:40,410	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30983)[0m Traceback (most recent call last):
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30983)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30983)[0m     param_dset[:] = val
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30983)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30983)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30983)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30983)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:40 2021
[2m[36m(pid=30983)[0m , filename = '/tmp/thalvari/4565627/automl_save_p_u46qka/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd015eb1e98, total write size = 30284, bytes this sub-write = 30284, bytes actually written = 18446744073709551615, offset = 634880)
[2m[36m(pid=30983)[0m 
[2m[36m(pid=30983)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30983)[0m 
[2m[36m(pid=30983)[0m Traceback (most recent call last):
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30983)[0m     self._entrypoint()
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30983)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30983)[0m     output = train_func(config, reporter)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30983)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30983)[0m     config=config)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30983)[0m     model.save(model_path, config_path)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30983)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30983)[0m     self.model.save(model_path)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30983)[0m     signatures)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30983)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30983)[0m     f.close()
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30983)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30983)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:40 2021
[2m[36m(pid=30983)[0m , filename = '/tmp/thalvari/4565627/automl_save_p_u46qka/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd0155183a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30983)[0m Exception in thread Thread-1:
[2m[36m(pid=30983)[0m Traceback (most recent call last):
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30983)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30983)[0m     param_dset[:] = val
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30983)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30983)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30983)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30983)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:40 2021
[2m[36m(pid=30983)[0m , filename = '/tmp/thalvari/4565627/automl_save_p_u46qka/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd015eb1e98, total write size = 30284, bytes this sub-write = 30284, bytes actually written = 18446744073709551615, offset = 634880)
[2m[36m(pid=30983)[0m 
[2m[36m(pid=30983)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30983)[0m 
[2m[36m(pid=30983)[0m Traceback (most recent call last):
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30983)[0m     self._entrypoint()
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30983)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30983)[0m     output = train_func(config, reporter)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30983)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30983)[0m     config=config)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30983)[0m     model.save(model_path, config_path)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30983)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30983)[0m     self.model.save(model_path)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30983)[0m     signatures)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30983)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30983)[0m     f.close()
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30983)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30983)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30983)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:40 2021
[2m[36m(pid=30983)[0m , filename = '/tmp/thalvari/4565627/automl_save_p_u46qka/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd0155183a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35438)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35438)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30983)[0m 
[2m[36m(pid=30983)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30983)[0m 
[2m[36m(pid=30983)[0m Traceback (most recent call last):
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30983)[0m     self.run()
[2m[36m(pid=30983)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30983)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30983)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30983)[0m 
[2m[36m(pid=35440)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35440)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35439)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35439)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35520)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35520)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35561)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35561)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-16 21:22:40,760	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30984, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:40,764	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAKE(datetime)=0.30567,bayes_feature_IS_BUSY_HOURS(datetime)=0.52893,bayes_feature_IS_WEEKEND(datetime)=0.51649,bayes_feature_MONTH(datetime)=0.85243,bayes_feature_WEEKDAY(datetime)=0.84011,dropout_1=0.41935,dropout_2=0.23883,epochs=5,lr=0.0041175,lstm_1_units_float=74.972,lstm_2_units_float=79.941,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35562)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35562)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35564)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=30984)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30984)[0m 
[2m[36m(pid=30984)[0m Stack (most recent call first):
[2m[36m(pid=35564)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35724)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35724)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35769)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35769)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-16 21:22:41,533	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30983, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:41,537	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_68_batch_size_log=6.1462,bayes_feature_DAY(datetime)=0.56842,bayes_feature_HOUR(datetime)=0.45803,bayes_feature_IS_AWAKE(datetime)=0.87729,bayes_feature_IS_BUSY_HOURS(datetime)=0.41303,bayes_feature_IS_WEEKEND(datetime)=0.55707,bayes_feature_MONTH(datetime)=0.4986,bayes_feature_WEEKDAY(datetime)=0.76831,dropout_1=0.21953,dropout_2=0.33516,epochs=5,lr=0.0070224,lstm_1_units_float=39.727,lstm_2_units_float=59.818,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=30857)[0m 2021-01-16 21:22:41,530	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=30857)[0m Traceback (most recent call last):
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30857)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30857)[0m     param_dset[:] = val
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30857)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30857)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30857)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30857)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:41 2021
[2m[36m(pid=30857)[0m , filename = '/tmp/thalvari/4565627/automl_save_o8wxrbm8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae8146c3f8, total write size = 9432, bytes this sub-write = 9432, bytes actually written = 18446744073709551615, offset = 561152)
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30857)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30857)[0m Traceback (most recent call last):
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30857)[0m     self._entrypoint()
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30857)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30857)[0m     output = train_func(config, reporter)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30857)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30857)[0m     config=config)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30857)[0m     model.save(model_path, config_path)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30857)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30857)[0m     self.model.save(model_path)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30857)[0m     signatures)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30857)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30857)[0m     f.close()
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30857)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30857)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:41 2021
[2m[36m(pid=30857)[0m , filename = '/tmp/thalvari/4565627/automl_save_o8wxrbm8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae816ea070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=30857)[0m Exception in thread Thread-1:
[2m[36m(pid=30857)[0m Traceback (most recent call last):
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=30857)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=30857)[0m     param_dset[:] = val
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=30857)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=30857)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=30857)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=30857)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:41 2021
[2m[36m(pid=30857)[0m , filename = '/tmp/thalvari/4565627/automl_save_o8wxrbm8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae8146c3f8, total write size = 9432, bytes this sub-write = 9432, bytes actually written = 18446744073709551615, offset = 561152)
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30857)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30857)[0m Traceback (most recent call last):
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=30857)[0m     self._entrypoint()
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=30857)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=30857)[0m     output = train_func(config, reporter)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=30857)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=30857)[0m     config=config)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=30857)[0m     model.save(model_path, config_path)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=30857)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=30857)[0m     self.model.save(model_path)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=30857)[0m     signatures)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=30857)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=30857)[0m     f.close()
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=30857)[0m     h5i.dec_ref(id_)
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=30857)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=30857)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:41 2021
[2m[36m(pid=30857)[0m , filename = '/tmp/thalvari/4565627/automl_save_o8wxrbm8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae816ea070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35811)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=35811)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30857)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30857)[0m Traceback (most recent call last):
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=30857)[0m     self.run()
[2m[36m(pid=30857)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=30857)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=30857)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30983)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30983)[0m 
[2m[36m(pid=30983)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 77 ({'TERMINATED': 14, 'ERROR': 53, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 47 not shown
 - train_func_65_batch_size_log=9.2307,bayes_feature_DAY(datetime)=0.70852,bayes_feature_HOUR(datetime)=0.43291,bayes_feature_IS_AWAKE(datetime)=0.65102,bayes_feature_IS_BUSY_HOURS(datetime)=0.755,bayes_feature_IS_WEEKEND(datetime)=0.43111,bayes_feature_MONTH(datetime)=0.63965,bayes_feature_WEEKDAY(datetime)=0.32764,dropout_1=0.24414,dropout_2=0.28165,epochs=5,lr=0.0023158,lstm_1_units_float=115.16,lstm_2_units_float=99.765,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_65_batch_size_log=9.2307,bayes_feature_DAY(datetime)=0.70852,bayes_feature_HOUR(datetime)=0.43291,bayes_feature_IS_AWAK_2021-01-16_21-22-26hrqc6wbo/error_2021-01-16_21-22-37.txt
 - train_func_68_batch_size_log=6.1462,bayes_feature_DAY(datetime)=0.56842,bayes_feature_HOUR(datetime)=0.45803,bayes_feature_IS_AWAKE(datetime)=0.87729,bayes_feature_IS_BUSY_HOURS(datetime)=0.41303,bayes_feature_IS_WEEKEND(datetime)=0.55707,bayes_feature_MONTH(datetime)=0.4986,bayes_feature_WEEKDAY(datetime)=0.76831,dropout_1=0.21953,dropout_2=0.33516,epochs=5,lr=0.0070224,lstm_1_units_float=39.727,lstm_2_units_float=59.818,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_68_batch_size_log=6.1462,bayes_feature_DAY(datetime)=0.56842,bayes_feature_HOUR(datetime)=0.45803,bayes_feature_IS_AWAK_2021-01-16_21-22-29pk34kwls/error_2021-01-16_21-22-41.txt
 - train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAKE(datetime)=0.30567,bayes_feature_IS_BUSY_HOURS(datetime)=0.52893,bayes_feature_IS_WEEKEND(datetime)=0.51649,bayes_feature_MONTH(datetime)=0.85243,bayes_feature_WEEKDAY(datetime)=0.84011,dropout_1=0.41935,dropout_2=0.23883,epochs=5,lr=0.0041175,lstm_1_units_float=74.972,lstm_2_units_float=79.941,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAK_2021-01-16_21-22-30yinlmpr3/error_2021-01-16_21-22-40.txt
RUNNING trials:
 - train_func_66_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.48,lstm_2_units_float=127.74,past_seq_len=2:	RUNNING
 - train_func_67_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.58,lstm_2_units_float=127.74,past_seq_len=2:	RUNNING
 - train_func_69_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.52,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_75_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.44636,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.072,lstm_2_units_float=69.302,past_seq_len=2:	RUNNING
 - train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.72036,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.033,lstm_2_units_float=69.313,past_seq_len=2:	RUNNING
 - train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.6852,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84567,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.069,lstm_2_units_float=69.31,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 8 not shown
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter

2021-01-16 21:22:42,736	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=30857, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:42,739	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAKE(datetime)=0.51343,bayes_feature_IS_BUSY_HOURS(datetime)=0.58628,bayes_feature_IS_WEEKEND(datetime)=0.34766,bayes_feature_MONTH(datetime)=0.39863,bayes_feature_WEEKDAY(datetime)=0.38765,dropout_1=0.26776,dropout_2=0.28822,epochs=5,lr=0.007196,lstm_1_units_float=87.392,lstm_2_units_float=125.67,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=30857)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=30857)[0m 
[2m[36m(pid=30857)[0m Stack (most recent call first):
[2m[36m(pid=31150)[0m 2021-01-16 21:22:43,770	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31150)[0m Traceback (most recent call last):
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31150)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31150)[0m     param_dset[:] = val
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31150)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31150)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31150)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31150)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:43 2021
[2m[36m(pid=31150)[0m , filename = '/tmp/thalvari/4565627/automl_save_rutue20e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9dea13f328, total write size = 96424, bytes this sub-write = 96424, bytes actually written = 18446744073709551615, offset = 552960)
[2m[36m(pid=31150)[0m 
[2m[36m(pid=31150)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31150)[0m 
[2m[36m(pid=31150)[0m Traceback (most recent call last):
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31150)[0m     self._entrypoint()
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31150)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31150)[0m     output = train_func(config, reporter)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31150)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31150)[0m     config=config)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31150)[0m     model.save(model_path, config_path)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31150)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31150)[0m     self.model.save(model_path)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31150)[0m     signatures)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31150)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31150)[0m     f.close()
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31150)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31150)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:43 2021
[2m[36m(pid=31150)[0m , filename = '/tmp/thalvari/4565627/automl_save_rutue20e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9dea7e6fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31150)[0m Exception in thread Thread-1:
[2m[36m(pid=31150)[0m Traceback (most recent call last):
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31150)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31150)[0m     param_dset[:] = val
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31150)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31150)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31150)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31150)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:43 2021
[2m[36m(pid=31150)[0m , filename = '/tmp/thalvari/4565627/automl_save_rutue20e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9dea13f328, total write size = 96424, bytes this sub-write = 96424, bytes actually written = 18446744073709551615, offset = 552960)
[2m[36m(pid=31150)[0m 
[2m[36m(pid=31150)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31150)[0m 
[2m[36m(pid=31150)[0m Traceback (most recent call last):
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31150)[0m     self._entrypoint()
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31150)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31150)[0m     output = train_func(config, reporter)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31150)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31150)[0m     config=config)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31150)[0m     model.save(model_path, config_path)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31150)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31150)[0m     self.model.save(model_path)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31150)[0m     signatures)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31150)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31150)[0m     f.close()
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31150)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31150)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31150)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:43 2021
[2m[36m(pid=31150)[0m , filename = '/tmp/thalvari/4565627/automl_save_rutue20e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9dea7e6fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31150)[0m 
[2m[36m(pid=31150)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31150)[0m 
[2m[36m(pid=31150)[0m Traceback (most recent call last):
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31150)[0m     self.run()
[2m[36m(pid=31150)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31150)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31150)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31150)[0m 
2021-01-16 21:22:44,899	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31150, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:44,902	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_66_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.48,lstm_2_units_float=127.74,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31150)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31150)[0m 
[2m[36m(pid=31150)[0m Stack (most recent call first):
[2m[36m(pid=31104)[0m 2021-01-16 21:22:45,716	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31104)[0m Traceback (most recent call last):
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31104)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31104)[0m     param_dset[:] = val
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31104)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31104)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31104)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31104)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:45 2021
[2m[36m(pid=31104)[0m , filename = '/tmp/thalvari/4565627/automl_save_1b3rdc3a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9ca797578, total write size = 104616, bytes this sub-write = 104616, bytes actually written = 18446744073709551615, offset = 544768)
[2m[36m(pid=31104)[0m 
[2m[36m(pid=31104)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31104)[0m 
[2m[36m(pid=31104)[0m Traceback (most recent call last):
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31104)[0m     self._entrypoint()
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31104)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31104)[0m     output = train_func(config, reporter)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31104)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31104)[0m     config=config)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31104)[0m     model.save(model_path, config_path)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31104)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31104)[0m     self.model.save(model_path)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31104)[0m     signatures)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31104)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31104)[0m     f.close()
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31104)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31104)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:45 2021
[2m[36m(pid=31104)[0m , filename = '/tmp/thalvari/4565627/automl_save_1b3rdc3a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9ca424a40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31104)[0m Exception in thread Thread-1:
[2m[36m(pid=31104)[0m Traceback (most recent call last):
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31104)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31104)[0m     param_dset[:] = val
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31104)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31104)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31104)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31104)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:45 2021
[2m[36m(pid=31104)[0m , filename = '/tmp/thalvari/4565627/automl_save_1b3rdc3a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9ca797578, total write size = 104616, bytes this sub-write = 104616, bytes actually written = 18446744073709551615, offset = 544768)
[2m[36m(pid=31104)[0m 
[2m[36m(pid=31104)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31104)[0m 
[2m[36m(pid=31104)[0m Traceback (most recent call last):
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31104)[0m     self._entrypoint()
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31104)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31104)[0m     output = train_func(config, reporter)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31104)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31104)[0m     config=config)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31104)[0m     model.save(model_path, config_path)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31104)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31104)[0m     self.model.save(model_path)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31104)[0m     signatures)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31104)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31104)[0m     f.close()
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31104)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31104)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31104)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:45 2021
[2m[36m(pid=31104)[0m , filename = '/tmp/thalvari/4565627/automl_save_1b3rdc3a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9ca424a40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31104)[0m 
[2m[36m(pid=31104)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31104)[0m 
[2m[36m(pid=31104)[0m Traceback (most recent call last):
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31104)[0m     self.run()
[2m[36m(pid=31104)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31104)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31104)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31104)[0m 
[2m[36m(pid=35395)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35395)[0m   agg_primitives: ['count']
[2m[36m(pid=35395)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35395)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35438)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35438)[0m   agg_primitives: ['count']
[2m[36m(pid=35438)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35438)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35562)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35562)[0m   agg_primitives: ['count']
[2m[36m(pid=35562)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35562)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35564)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35564)[0m   agg_primitives: ['count']
[2m[36m(pid=35564)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35564)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35724)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35724)[0m   agg_primitives: ['count']
[2m[36m(pid=35724)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35724)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35395)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35395)[0m Instructions for updating:
[2m[36m(pid=35395)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35395)[0m LSTM is selected.
[2m[36m(pid=35438)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35438)[0m Instructions for updating:
[2m[36m(pid=35438)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35438)[0m LSTM is selected.
[2m[36m(pid=35562)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35562)[0m Instructions for updating:
[2m[36m(pid=35562)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35562)[0m LSTM is selected.
[2m[36m(pid=35564)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35564)[0m Instructions for updating:
[2m[36m(pid=35564)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35564)[0m LSTM is selected.
[2m[36m(pid=35724)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35724)[0m Instructions for updating:
[2m[36m(pid=35724)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35724)[0m LSTM is selected.
[2m[36m(pid=35520)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35520)[0m   agg_primitives: ['count']
[2m[36m(pid=35520)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35520)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:22:46,894	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31104, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:46,897	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_67_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.58,lstm_2_units_float=127.74,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35395)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35395)[0m Instructions for updating:
[2m[36m(pid=35395)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35562)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35562)[0m Instructions for updating:
[2m[36m(pid=35562)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35724)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35724)[0m Instructions for updating:
[2m[36m(pid=35724)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35438)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35438)[0m Instructions for updating:
[2m[36m(pid=35438)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35564)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35564)[0m Instructions for updating:
[2m[36m(pid=35564)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=31104)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31104)[0m 
[2m[36m(pid=31104)[0m Stack (most recent call first):
[2m[36m(pid=31318)[0m 2021-01-16 21:22:47,062	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31318)[0m Traceback (most recent call last):
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31318)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31318)[0m     param_dset[:] = val
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31318)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31318)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31318)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31318)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:47 2021
[2m[36m(pid=31318)[0m , filename = '/tmp/thalvari/4565627/automl_save_g81ltt_w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7faace98dc58, total write size = 112808, bytes this sub-write = 112808, bytes actually written = 18446744073709551615, offset = 536576)
[2m[36m(pid=31318)[0m 
[2m[36m(pid=31318)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31318)[0m 
[2m[36m(pid=31318)[0m Traceback (most recent call last):
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31318)[0m     self._entrypoint()
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31318)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31318)[0m     output = train_func(config, reporter)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31318)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31318)[0m     config=config)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31318)[0m     model.save(model_path, config_path)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31318)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31318)[0m     self.model.save(model_path)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31318)[0m     signatures)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31318)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31318)[0m     f.close()
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31318)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31318)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:47 2021
[2m[36m(pid=31318)[0m , filename = '/tmp/thalvari/4565627/automl_save_g81ltt_w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7faace121320, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31318)[0m Exception in thread Thread-1:
[2m[36m(pid=31318)[0m Traceback (most recent call last):
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31318)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31318)[0m     param_dset[:] = val
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31318)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31318)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31318)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31318)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:47 2021
[2m[36m(pid=31318)[0m , filename = '/tmp/thalvari/4565627/automl_save_g81ltt_w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7faace98dc58, total write size = 112808, bytes this sub-write = 112808, bytes actually written = 18446744073709551615, offset = 536576)
[2m[36m(pid=31318)[0m 
[2m[36m(pid=31318)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31318)[0m 
[2m[36m(pid=31318)[0m Traceback (most recent call last):
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31318)[0m     self._entrypoint()
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31318)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31318)[0m     output = train_func(config, reporter)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31318)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31318)[0m     config=config)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31318)[0m     model.save(model_path, config_path)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31318)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31318)[0m     self.model.save(model_path)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31318)[0m     signatures)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31318)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31318)[0m     f.close()
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31318)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31318)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31318)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:47 2021
[2m[36m(pid=31318)[0m , filename = '/tmp/thalvari/4565627/automl_save_g81ltt_w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7faace121320, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31318)[0m 
[2m[36m(pid=31318)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31318)[0m 
[2m[36m(pid=31318)[0m Traceback (most recent call last):
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31318)[0m     self.run()
[2m[36m(pid=31318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31318)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31318)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31318)[0m 
[2m[36m(pid=35520)[0m LSTM is selected.
[2m[36m(pid=35520)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35520)[0m Instructions for updating:
[2m[36m(pid=35520)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 80 ({'TERMINATED': 14, 'ERROR': 56, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 50 not shown
 - train_func_68_batch_size_log=6.1462,bayes_feature_DAY(datetime)=0.56842,bayes_feature_HOUR(datetime)=0.45803,bayes_feature_IS_AWAKE(datetime)=0.87729,bayes_feature_IS_BUSY_HOURS(datetime)=0.41303,bayes_feature_IS_WEEKEND(datetime)=0.55707,bayes_feature_MONTH(datetime)=0.4986,bayes_feature_WEEKDAY(datetime)=0.76831,dropout_1=0.21953,dropout_2=0.33516,epochs=5,lr=0.0070224,lstm_1_units_float=39.727,lstm_2_units_float=59.818,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_68_batch_size_log=6.1462,bayes_feature_DAY(datetime)=0.56842,bayes_feature_HOUR(datetime)=0.45803,bayes_feature_IS_AWAK_2021-01-16_21-22-29pk34kwls/error_2021-01-16_21-22-41.txt
 - train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAKE(datetime)=0.30567,bayes_feature_IS_BUSY_HOURS(datetime)=0.52893,bayes_feature_IS_WEEKEND(datetime)=0.51649,bayes_feature_MONTH(datetime)=0.85243,bayes_feature_WEEKDAY(datetime)=0.84011,dropout_1=0.41935,dropout_2=0.23883,epochs=5,lr=0.0041175,lstm_1_units_float=74.972,lstm_2_units_float=79.941,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAK_2021-01-16_21-22-30yinlmpr3/error_2021-01-16_21-22-40.txt
 - train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAKE(datetime)=0.51343,bayes_feature_IS_BUSY_HOURS(datetime)=0.58628,bayes_feature_IS_WEEKEND(datetime)=0.34766,bayes_feature_MONTH(datetime)=0.39863,bayes_feature_WEEKDAY(datetime)=0.38765,dropout_1=0.26776,dropout_2=0.28822,epochs=5,lr=0.007196,lstm_1_units_float=87.392,lstm_2_units_float=125.67,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAK_2021-01-16_21-22-323mpabqky/error_2021-01-16_21-22-42.txt
RUNNING trials:
 - train_func_69_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.52,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.56,lstm_2_units_float=127.71,past_seq_len=2:	RUNNING
 - train_func_73_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.72,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.31845,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.01,lstm_2_units_float=69.327,past_seq_len=2:	RUNNING
 - train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33972,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.044,lstm_2_units_float=69.343,past_seq_len=2:	RUNNING
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37612,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.54941,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.068,lstm_2_units_float=69.301,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 8 not shown
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter

[2m[36m(pid=35520)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35520)[0m Instructions for updating:
[2m[36m(pid=35520)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35564)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35564)[0m 2021-01-16 21:22:47.913467: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35564)[0m 2021-01-16 21:22:47.921511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35564)[0m 2021-01-16 21:22:47.923700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f74710e9860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35564)[0m 2021-01-16 21:22:47.923731: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35395)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35395)[0m 2021-01-16 21:22:47.958094: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35395)[0m 2021-01-16 21:22:47.965689: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35395)[0m 2021-01-16 21:22:47.967872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85c1102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35395)[0m 2021-01-16 21:22:47.967893: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35438)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35438)[0m 2021-01-16 21:22:47.941365: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35438)[0m 2021-01-16 21:22:47.949399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35438)[0m 2021-01-16 21:22:47.952146: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6ae90e3860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35438)[0m 2021-01-16 21:22:47.952179: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35562)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35562)[0m 2021-01-16 21:22:47.950349: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35562)[0m 2021-01-16 21:22:47.958443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35562)[0m 2021-01-16 21:22:47.960556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f886511d230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35562)[0m 2021-01-16 21:22:47.960576: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35724)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35724)[0m 2021-01-16 21:22:47.947835: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35724)[0m 2021-01-16 21:22:47.955444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35724)[0m 2021-01-16 21:22:47.957610: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb691103900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35724)[0m 2021-01-16 21:22:47.957633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:22:48,120	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31318, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:48,123	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_69_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.52,lstm_2_units_float=127.7,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31318)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31318)[0m 
[2m[36m(pid=31318)[0m Stack (most recent call first):
[2m[36m(pid=35811)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35811)[0m   agg_primitives: ['count']
[2m[36m(pid=35811)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35811)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35520)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35520)[0m 2021-01-16 21:22:48.779395: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35520)[0m 2021-01-16 21:22:48.787389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35520)[0m 2021-01-16 21:22:48.789606: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f25111036c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35520)[0m 2021-01-16 21:22:48.789628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=31147)[0m 2021-01-16 21:22:49,018	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=31147)[0m Traceback (most recent call last):
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31147)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31147)[0m     param_dset[:] = val
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31147)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31147)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31147)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31147)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:49 2021
[2m[36m(pid=31147)[0m , filename = '/tmp/thalvari/4565627/automl_save_7_7hw60g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fda85f57a18, total write size = 121000, bytes this sub-write = 121000, bytes actually written = 18446744073709551615, offset = 528384)
[2m[36m(pid=31147)[0m 
[2m[36m(pid=31147)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31147)[0m 
[2m[36m(pid=31147)[0m Traceback (most recent call last):
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31147)[0m     self._entrypoint()
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31147)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31147)[0m     output = train_func(config, reporter)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31147)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31147)[0m     config=config)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31147)[0m     model.save(model_path, config_path)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31147)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31147)[0m     self.model.save(model_path)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31147)[0m     signatures)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31147)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31147)[0m     f.close()
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31147)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31147)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:49 2021
[2m[36m(pid=31147)[0m , filename = '/tmp/thalvari/4565627/automl_save_7_7hw60g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fda8608c1d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31147)[0m Exception in thread Thread-1:
[2m[36m(pid=31147)[0m Traceback (most recent call last):
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=31147)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=31147)[0m     param_dset[:] = val
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=31147)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=31147)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=31147)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=31147)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:49 2021
[2m[36m(pid=31147)[0m , filename = '/tmp/thalvari/4565627/automl_save_7_7hw60g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fda85f57a18, total write size = 121000, bytes this sub-write = 121000, bytes actually written = 18446744073709551615, offset = 528384)
[2m[36m(pid=31147)[0m 
[2m[36m(pid=31147)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31147)[0m 
[2m[36m(pid=31147)[0m Traceback (most recent call last):
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=31147)[0m     self._entrypoint()
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=31147)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=31147)[0m     output = train_func(config, reporter)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=31147)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=31147)[0m     config=config)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=31147)[0m     model.save(model_path, config_path)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=31147)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=31147)[0m     self.model.save(model_path)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=31147)[0m     signatures)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=31147)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=31147)[0m     f.close()
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=31147)[0m     h5i.dec_ref(id_)
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=31147)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=31147)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:49 2021
[2m[36m(pid=31147)[0m , filename = '/tmp/thalvari/4565627/automl_save_7_7hw60g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fda8608c1d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=31147)[0m 
[2m[36m(pid=31147)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=31147)[0m 
[2m[36m(pid=31147)[0m Traceback (most recent call last):
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=31147)[0m     self.run()
[2m[36m(pid=31147)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=31147)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=31147)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=31147)[0m 
[2m[36m(pid=35811)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35811)[0m Instructions for updating:
[2m[36m(pid=35811)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35811)[0m LSTM is selected.
[2m[36m(pid=35811)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35811)[0m Instructions for updating:
[2m[36m(pid=35811)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:22:50,148	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=31147, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:50,151	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.56,lstm_2_units_float=127.71,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=31147)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=31147)[0m 
[2m[36m(pid=31147)[0m Stack (most recent call first):
[2m[36m(pid=35811)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35811)[0m 2021-01-16 21:22:50.746493: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35811)[0m 2021-01-16 21:22:50.758743: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35811)[0m 2021-01-16 21:22:50.762715: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5b71102e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35811)[0m 2021-01-16 21:22:50.762763: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35561)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35561)[0m   agg_primitives: ['count']
[2m[36m(pid=35561)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35561)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35561)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35561)[0m Instructions for updating:
[2m[36m(pid=35561)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35561)[0m LSTM is selected.
[2m[36m(pid=35561)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35561)[0m Instructions for updating:
[2m[36m(pid=35561)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35769)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35769)[0m   agg_primitives: ['count']
[2m[36m(pid=35769)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35769)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35769)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35769)[0m Instructions for updating:
[2m[36m(pid=35769)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35769)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 82 ({'TERMINATED': 14, 'ERROR': 58, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 52 not shown
 - train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAKE(datetime)=0.30567,bayes_feature_IS_BUSY_HOURS(datetime)=0.52893,bayes_feature_IS_WEEKEND(datetime)=0.51649,bayes_feature_MONTH(datetime)=0.85243,bayes_feature_WEEKDAY(datetime)=0.84011,dropout_1=0.41935,dropout_2=0.23883,epochs=5,lr=0.0041175,lstm_1_units_float=74.972,lstm_2_units_float=79.941,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAK_2021-01-16_21-22-30yinlmpr3/error_2021-01-16_21-22-40.txt
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.56,lstm_2_units_float=127.71,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-3159kfreh5/error_2021-01-16_21-22-50.txt
 - train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAKE(datetime)=0.51343,bayes_feature_IS_BUSY_HOURS(datetime)=0.58628,bayes_feature_IS_WEEKEND(datetime)=0.34766,bayes_feature_MONTH(datetime)=0.39863,bayes_feature_WEEKDAY(datetime)=0.38765,dropout_1=0.26776,dropout_2=0.28822,epochs=5,lr=0.007196,lstm_1_units_float=87.392,lstm_2_units_float=125.67,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAK_2021-01-16_21-22-323mpabqky/error_2021-01-16_21-22-42.txt
RUNNING trials:
 - train_func_73_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.72,past_seq_len=2:	RUNNING
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=35438], 7 s, 2 iter
 - train_func_75_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.44636,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.072,lstm_2_units_float=69.302,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37612,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.54941,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.068,lstm_2_units_float=69.301,past_seq_len=2:	RUNNING
 - train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.66664,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.054,lstm_2_units_float=69.319,past_seq_len=2:	RUNNING
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.80469,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.998,lstm_2_units_float=69.294,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 8 not shown
 - train_func_48_batch_size_log=8.3682,bayes_feature_DAY(datetime)=0.36335,bayes_feature_HOUR(datetime)=0.53357,bayes_feature_IS_AWAKE(datetime)=0.9348,bayes_feature_IS_BUSY_HOURS(datetime)=0.70554,bayes_feature_IS_WEEKEND(datetime)=0.60583,bayes_feature_MONTH(datetime)=0.44756,bayes_feature_WEEKDAY(datetime)=0.41664,dropout_1=0.40897,dropout_2=0.27372,epochs=5,lr=0.0095167,lstm_1_units_float=51.41,lstm_2_units_float=31.833,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19638], 12 s, 5 iter
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter

[2m[36m(pid=35561)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35561)[0m 2021-01-16 21:22:53.321140: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35561)[0m 2021-01-16 21:22:53.331415: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35561)[0m 2021-01-16 21:22:53.336245: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f88cd103530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35561)[0m 2021-01-16 21:22:53.336286: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35769)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35769)[0m Instructions for updating:
[2m[36m(pid=35769)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35769)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35769)[0m 2021-01-16 21:22:54.456048: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35769)[0m 2021-01-16 21:22:54.468716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35769)[0m 2021-01-16 21:22:54.471899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd0b9103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35769)[0m 2021-01-16 21:22:54.471943: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35439)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35439)[0m   agg_primitives: ['count']
[2m[36m(pid=35439)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35439)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=35439)[0m LSTM is selected.
[2m[36m(pid=35439)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35439)[0m Instructions for updating:
[2m[36m(pid=35439)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35439)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35439)[0m Instructions for updating:
[2m[36m(pid=35439)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35564)[0m 2021-01-16 21:22:57,928	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35564)[0m Traceback (most recent call last):
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35564)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35564)[0m     param_dset[:] = val
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35564)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35564)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35564)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35564)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35564)[0m , filename = '/tmp/thalvari/4565627/automl_save_r3uqoa9l/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f747277fad8, total write size = 363844, bytes this sub-write = 363844, bytes actually written = 18446744073709551615, offset = 520192)
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35564)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35564)[0m Traceback (most recent call last):
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35564)[0m     self._entrypoint()
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35564)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35564)[0m     output = train_func(config, reporter)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35564)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35564)[0m     config=config)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35564)[0m     model.save(model_path, config_path)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35564)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35564)[0m     self.model.save(model_path)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35564)[0m     signatures)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35564)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35564)[0m     f.close()
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35564)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35564)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35564)[0m , filename = '/tmp/thalvari/4565627/automl_save_r3uqoa9l/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f7471bb4be0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35564)[0m Exception in thread Thread-1:
[2m[36m(pid=35564)[0m Traceback (most recent call last):
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35564)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35564)[0m     param_dset[:] = val
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35564)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35564)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35564)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35564)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35564)[0m , filename = '/tmp/thalvari/4565627/automl_save_r3uqoa9l/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f747277fad8, total write size = 363844, bytes this sub-write = 363844, bytes actually written = 18446744073709551615, offset = 520192)
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35564)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35564)[0m Traceback (most recent call last):
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35564)[0m     self._entrypoint()
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35564)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35564)[0m     output = train_func(config, reporter)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35564)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35564)[0m     config=config)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35564)[0m     model.save(model_path, config_path)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35564)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35564)[0m     self.model.save(model_path)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35564)[0m     signatures)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35564)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35564)[0m     f.close()
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35564)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35564)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35564)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35564)[0m , filename = '/tmp/thalvari/4565627/automl_save_r3uqoa9l/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f7471bb4be0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35724)[0m 2021-01-16 21:22:57,921	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35724)[0m Traceback (most recent call last):
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35724)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35724)[0m     param_dset[:] = val
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35724)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35724)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35724)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35724)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35724)[0m , filename = '/tmp/thalvari/4565627/automl_save_i_a8ei68/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb691eedd68, total write size = 17704, bytes this sub-write = 17704, bytes actually written = 18446744073709551615, offset = 249856)
[2m[36m(pid=35724)[0m 
[2m[36m(pid=35724)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35724)[0m 
[2m[36m(pid=35724)[0m Traceback (most recent call last):
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35724)[0m     self._entrypoint()
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35724)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35724)[0m     output = train_func(config, reporter)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35724)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35724)[0m     config=config)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35724)[0m     model.save(model_path, config_path)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35724)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35724)[0m     self.model.save(model_path)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35724)[0m     signatures)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35724)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35724)[0m     f.close()
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35724)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35724)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35724)[0m , filename = '/tmp/thalvari/4565627/automl_save_i_a8ei68/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb691842900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35724)[0m Exception in thread Thread-1:
[2m[36m(pid=35724)[0m Traceback (most recent call last):
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35724)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35724)[0m     param_dset[:] = val
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35724)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35724)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35724)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35724)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35724)[0m , filename = '/tmp/thalvari/4565627/automl_save_i_a8ei68/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb691eedd68, total write size = 17704, bytes this sub-write = 17704, bytes actually written = 18446744073709551615, offset = 249856)
[2m[36m(pid=35724)[0m 
[2m[36m(pid=35724)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35724)[0m 
[2m[36m(pid=35724)[0m Traceback (most recent call last):
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35724)[0m     self._entrypoint()
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35724)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35724)[0m     output = train_func(config, reporter)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35724)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35724)[0m     config=config)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35724)[0m     model.save(model_path, config_path)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35724)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35724)[0m     self.model.save(model_path)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35724)[0m     signatures)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35724)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35724)[0m     f.close()
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35724)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35724)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35724)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:57 2021
[2m[36m(pid=35724)[0m , filename = '/tmp/thalvari/4565627/automl_save_i_a8ei68/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb691842900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35564)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35564)[0m Traceback (most recent call last):
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35564)[0m     self.run()
[2m[36m(pid=35564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35564)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35564)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35724)[0m 
[2m[36m(pid=35724)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35724)[0m 
[2m[36m(pid=35724)[0m Traceback (most recent call last):
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35724)[0m     self.run()
[2m[36m(pid=35724)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35724)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35724)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35724)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 83 ({'TERMINATED': 15, 'ERROR': 58, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 52 not shown
 - train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAKE(datetime)=0.30567,bayes_feature_IS_BUSY_HOURS(datetime)=0.52893,bayes_feature_IS_WEEKEND(datetime)=0.51649,bayes_feature_MONTH(datetime)=0.85243,bayes_feature_WEEKDAY(datetime)=0.84011,dropout_1=0.41935,dropout_2=0.23883,epochs=5,lr=0.0041175,lstm_1_units_float=74.972,lstm_2_units_float=79.941,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_70_batch_size_log=9.5114,bayes_feature_DAY(datetime)=0.50923,bayes_feature_HOUR(datetime)=0.44769,bayes_feature_IS_AWAK_2021-01-16_21-22-30yinlmpr3/error_2021-01-16_21-22-40.txt
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.56,lstm_2_units_float=127.71,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-3159kfreh5/error_2021-01-16_21-22-50.txt
 - train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAKE(datetime)=0.51343,bayes_feature_IS_BUSY_HOURS(datetime)=0.58628,bayes_feature_IS_WEEKEND(datetime)=0.34766,bayes_feature_MONTH(datetime)=0.39863,bayes_feature_WEEKDAY(datetime)=0.38765,dropout_1=0.26776,dropout_2=0.28822,epochs=5,lr=0.007196,lstm_1_units_float=87.392,lstm_2_units_float=125.67,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_72_batch_size_log=9.1886,bayes_feature_DAY(datetime)=0.96533,bayes_feature_HOUR(datetime)=0.72218,bayes_feature_IS_AWAK_2021-01-16_21-22-323mpabqky/error_2021-01-16_21-22-42.txt
RUNNING trials:
 - train_func_73_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.72,past_seq_len=2:	RUNNING
 - train_func_75_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.44636,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.072,lstm_2_units_float=69.302,past_seq_len=2:	RUNNING
 - train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.72036,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.033,lstm_2_units_float=69.313,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.66664,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.054,lstm_2_units_float=69.319,past_seq_len=2:	RUNNING
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.80469,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.998,lstm_2_units_float=69.294,past_seq_len=2:	RUNNING
 - train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.567,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=35439)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35439)[0m 2021-01-16 21:22:58.009275: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35439)[0m 2021-01-16 21:22:58.020114: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35439)[0m 2021-01-16 21:22:58.023598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f460d103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35439)[0m 2021-01-16 21:22:58.023637: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35562)[0m 2021-01-16 21:22:58,343	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35562)[0m Traceback (most recent call last):
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35562)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35562)[0m     param_dset[:] = val
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35562)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35562)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35562)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35562)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35562)[0m , filename = '/tmp/thalvari/4565627/automl_save_uqkajts7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88661bda88, total write size = 382564, bytes this sub-write = 382564, bytes actually written = 18446744073709551615, offset = 503808)
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35562)[0m Traceback (most recent call last):
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35562)[0m     self._entrypoint()
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35562)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35562)[0m     output = train_func(config, reporter)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35562)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35562)[0m     config=config)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35562)[0m     model.save(model_path, config_path)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35562)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35562)[0m     self.model.save(model_path)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35562)[0m     signatures)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35562)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35562)[0m     f.close()
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35562)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35562)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35562)[0m , filename = '/tmp/thalvari/4565627/automl_save_uqkajts7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88654cb560, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35562)[0m Exception in thread Thread-1:
[2m[36m(pid=35562)[0m Traceback (most recent call last):
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35562)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35562)[0m     param_dset[:] = val
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35562)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35562)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35562)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35562)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35562)[0m , filename = '/tmp/thalvari/4565627/automl_save_uqkajts7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88661bda88, total write size = 382564, bytes this sub-write = 382564, bytes actually written = 18446744073709551615, offset = 503808)
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35562)[0m Traceback (most recent call last):
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35562)[0m     self._entrypoint()
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35562)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35562)[0m     output = train_func(config, reporter)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35562)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35562)[0m     config=config)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35562)[0m     model.save(model_path, config_path)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35562)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35562)[0m     self.model.save(model_path)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35562)[0m     signatures)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35562)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35562)[0m     f.close()
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35562)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35562)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35562)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35562)[0m , filename = '/tmp/thalvari/4565627/automl_save_uqkajts7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88654cb560, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35562)[0m Traceback (most recent call last):
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35562)[0m     self.run()
[2m[36m(pid=35562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35562)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35562)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35520)[0m 2021-01-16 21:22:58,943	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35520)[0m Traceback (most recent call last):
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35520)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35520)[0m     param_dset[:] = val
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35520)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35520)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35520)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35520)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35520)[0m , filename = '/tmp/thalvari/4565627/automl_save_ekobrf4d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f25127da098, total write size = 573908, bytes this sub-write = 573908, bytes actually written = 18446744073709551615, offset = 311296)
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35520)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35520)[0m Traceback (most recent call last):
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35520)[0m     self._entrypoint()
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35520)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35520)[0m     output = train_func(config, reporter)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35520)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35520)[0m     config=config)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35520)[0m     model.save(model_path, config_path)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35520)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35520)[0m     self.model.save(model_path)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35520)[0m     signatures)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35520)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35520)[0m     f.close()
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35520)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35520)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35520)[0m , filename = '/tmp/thalvari/4565627/automl_save_ekobrf4d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f25118a6590, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35520)[0m Exception in thread Thread-1:
[2m[36m(pid=35520)[0m Traceback (most recent call last):
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35520)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35520)[0m     param_dset[:] = val
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35520)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35520)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35520)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35520)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35520)[0m , filename = '/tmp/thalvari/4565627/automl_save_ekobrf4d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f25127da098, total write size = 573908, bytes this sub-write = 573908, bytes actually written = 18446744073709551615, offset = 311296)
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35520)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35520)[0m Traceback (most recent call last):
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35520)[0m     self._entrypoint()
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35520)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35520)[0m     output = train_func(config, reporter)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35520)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35520)[0m     config=config)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35520)[0m     model.save(model_path, config_path)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35520)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35520)[0m     self.model.save(model_path)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35520)[0m     signatures)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35520)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35520)[0m     f.close()
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35520)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35520)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35520)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35520)[0m , filename = '/tmp/thalvari/4565627/automl_save_ekobrf4d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f25118a6590, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35520)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35520)[0m Traceback (most recent call last):
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35520)[0m     self.run()
[2m[36m(pid=35520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35520)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35520)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35395)[0m 2021-01-16 21:22:58,968	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35395)[0m Traceback (most recent call last):
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35395)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35395)[0m     param_dset[:] = val
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35395)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35395)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35395)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35395)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35395)[0m , filename = '/tmp/thalvari/4565627/automl_save_jk7x4h03/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f85c1d31258, total write size = 161960, bytes this sub-write = 161960, bytes actually written = 18446744073709551615, offset = 487424)
[2m[36m(pid=35395)[0m 
[2m[36m(pid=35395)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35395)[0m 
[2m[36m(pid=35395)[0m Traceback (most recent call last):
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35395)[0m     self._entrypoint()
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35395)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35395)[0m     output = train_func(config, reporter)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35395)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35395)[0m     config=config)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35395)[0m     model.save(model_path, config_path)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35395)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35395)[0m     self.model.save(model_path)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35395)[0m     signatures)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35395)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35395)[0m     f.close()
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35395)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35395)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35395)[0m , filename = '/tmp/thalvari/4565627/automl_save_jk7x4h03/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f85c29ca0a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35395)[0m Exception in thread Thread-1:
[2m[36m(pid=35395)[0m Traceback (most recent call last):
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35395)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35395)[0m     param_dset[:] = val
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35395)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35395)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35395)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35395)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35395)[0m , filename = '/tmp/thalvari/4565627/automl_save_jk7x4h03/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f85c1d31258, total write size = 161960, bytes this sub-write = 161960, bytes actually written = 18446744073709551615, offset = 487424)
[2m[36m(pid=35395)[0m 
[2m[36m(pid=35395)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35395)[0m 
[2m[36m(pid=35395)[0m Traceback (most recent call last):
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35395)[0m     self._entrypoint()
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35395)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35395)[0m     output = train_func(config, reporter)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35395)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35395)[0m     config=config)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35395)[0m     model.save(model_path, config_path)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35395)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35395)[0m     self.model.save(model_path)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35395)[0m     signatures)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35395)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35395)[0m     f.close()
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35395)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35395)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35395)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:22:58 2021
[2m[36m(pid=35395)[0m , filename = '/tmp/thalvari/4565627/automl_save_jk7x4h03/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f85c29ca0a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35395)[0m 
[2m[36m(pid=35395)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35395)[0m 
[2m[36m(pid=35395)[0m Traceback (most recent call last):
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35395)[0m     self.run()
[2m[36m(pid=35395)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35395)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35395)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35395)[0m 
2021-01-16 21:22:59,088	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35564, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:59,091	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_75_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.44636,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.072,lstm_2_units_float=69.302,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35564)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35564)[0m 
[2m[36m(pid=35564)[0m Stack (most recent call first):
2021-01-16 21:22:59,624	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35562, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:22:59,627	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.6852,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84567,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.069,lstm_2_units_float=69.31,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35562)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35562)[0m 
[2m[36m(pid=35562)[0m Stack (most recent call first):
2021-01-16 21:23:00,681	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35724, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:00,684	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.72036,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.033,lstm_2_units_float=69.313,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37651)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37651)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37652)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37653)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37652)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37653)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35724)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35724)[0m 
[2m[36m(pid=35724)[0m Stack (most recent call first):
[2m[36m(pid=37775)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37775)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37774)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37774)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=35811)[0m 2021-01-16 21:23:01,349	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35811)[0m Traceback (most recent call last):
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35811)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35811)[0m     param_dset[:] = val
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35811)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35811)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35811)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35811)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:01 2021
[2m[36m(pid=35811)[0m , filename = '/tmp/thalvari/4565627/automl_save_yjtybrqa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b71e8b508, total write size = 446932, bytes this sub-write = 446932, bytes actually written = 18446744073709551615, offset = 438272)
[2m[36m(pid=35811)[0m 
[2m[36m(pid=35811)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35811)[0m 
[2m[36m(pid=35811)[0m Traceback (most recent call last):
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35811)[0m     self._entrypoint()
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35811)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35811)[0m     output = train_func(config, reporter)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35811)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35811)[0m     config=config)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35811)[0m     model.save(model_path, config_path)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35811)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35811)[0m     self.model.save(model_path)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35811)[0m     signatures)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35811)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35811)[0m     f.close()
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35811)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35811)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:01 2021
[2m[36m(pid=35811)[0m , filename = '/tmp/thalvari/4565627/automl_save_yjtybrqa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b725605e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35811)[0m Exception in thread Thread-1:
[2m[36m(pid=35811)[0m Traceback (most recent call last):
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35811)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35811)[0m     param_dset[:] = val
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35811)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35811)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35811)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35811)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:01 2021
[2m[36m(pid=35811)[0m , filename = '/tmp/thalvari/4565627/automl_save_yjtybrqa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b71e8b508, total write size = 446932, bytes this sub-write = 446932, bytes actually written = 18446744073709551615, offset = 438272)
[2m[36m(pid=35811)[0m 
[2m[36m(pid=35811)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35811)[0m 
[2m[36m(pid=35811)[0m Traceback (most recent call last):
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35811)[0m     self._entrypoint()
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35811)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35811)[0m     output = train_func(config, reporter)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35811)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35811)[0m     config=config)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35811)[0m     model.save(model_path, config_path)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35811)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35811)[0m     self.model.save(model_path)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35811)[0m     signatures)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35811)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35811)[0m     f.close()
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35811)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35811)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35811)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:01 2021
[2m[36m(pid=35811)[0m , filename = '/tmp/thalvari/4565627/automl_save_yjtybrqa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b725605e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35811)[0m 
[2m[36m(pid=35811)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35811)[0m 
[2m[36m(pid=35811)[0m Traceback (most recent call last):
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35811)[0m     self.run()
[2m[36m(pid=35811)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35811)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35811)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35811)[0m 
[2m[36m(pid=37871)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37863)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37863)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37859)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37859)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37861)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37861)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37860)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37860)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37862)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37862)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37876)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37873)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37873)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37871)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37867)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37874)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37874)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37876)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37869)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37869)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37867)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37875)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=37875)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-16 21:23:02,019	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35395, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:02,024	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_73_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=100.5,lstm_2_units_float=127.72,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35395)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35395)[0m 
[2m[36m(pid=35395)[0m Stack (most recent call first):
[2m[36m(pid=35440)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=35440)[0m   agg_primitives: ['count']
[2m[36m(pid=35440)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=35440)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 87 ({'TERMINATED': 15, 'ERROR': 62, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 56 not shown
 - train_func_75_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.44636,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.072,lstm_2_units_float=69.302,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_75_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-40yr99z3k3/error_2021-01-16_21-22-59.txt
 - train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.72036,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.033,lstm_2_units_float=69.313,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-41arft66sd/error_2021-01-16_21-23-00.txt
 - train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.6852,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84567,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.069,lstm_2_units_float=69.31,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.6852,bayes_feature_IS_AWAKE(dateti_2021-01-16_21-22-42hvfuaeoi/error_2021-01-16_21-22-59.txt
RUNNING trials:
 - train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.31845,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.01,lstm_2_units_float=69.327,past_seq_len=2:	RUNNING
 - train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33972,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.044,lstm_2_units_float=69.343,past_seq_len=2:	RUNNING
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37612,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.54941,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.068,lstm_2_units_float=69.301,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34382,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.7094,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.572,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.5848,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.926,lstm_2_units_float=67.545,past_seq_len=2:	RUNNING
 - train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.79005,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.562,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

2021-01-16 21:23:03,001	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35811, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:03,037	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33972,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.044,lstm_2_units_float=69.343,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35561)[0m 2021-01-16 21:23:03,228	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35561)[0m Traceback (most recent call last):
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35561)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35561)[0m     param_dset[:] = val
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35561)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35561)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35561)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35561)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:03 2021
[2m[36m(pid=35561)[0m , filename = '/tmp/thalvari/4565627/automl_save_ygwv052p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88ce7a4248, total write size = 553428, bytes this sub-write = 553428, bytes actually written = 18446744073709551615, offset = 331776)
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35561)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35561)[0m Traceback (most recent call last):
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35561)[0m     self._entrypoint()
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35561)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35561)[0m     output = train_func(config, reporter)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35561)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35561)[0m     config=config)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35561)[0m     model.save(model_path, config_path)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35561)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35561)[0m     self.model.save(model_path)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35561)[0m     signatures)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35561)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35561)[0m     f.close()
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35561)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35561)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:03 2021
[2m[36m(pid=35561)[0m , filename = '/tmp/thalvari/4565627/automl_save_ygwv052p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88cd947200, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35561)[0m Exception in thread Thread-1:
[2m[36m(pid=35561)[0m Traceback (most recent call last):
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35561)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35561)[0m     param_dset[:] = val
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35561)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35561)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35561)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35561)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:03 2021
[2m[36m(pid=35561)[0m , filename = '/tmp/thalvari/4565627/automl_save_ygwv052p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88ce7a4248, total write size = 553428, bytes this sub-write = 553428, bytes actually written = 18446744073709551615, offset = 331776)
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35561)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35561)[0m Traceback (most recent call last):
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35561)[0m     self._entrypoint()
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35561)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35561)[0m     output = train_func(config, reporter)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35561)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35561)[0m     config=config)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35561)[0m     model.save(model_path, config_path)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35561)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35561)[0m     self.model.save(model_path)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35561)[0m     signatures)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35561)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35561)[0m     f.close()
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35561)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35561)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35561)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:03 2021
[2m[36m(pid=35561)[0m , filename = '/tmp/thalvari/4565627/automl_save_ygwv052p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f88cd947200, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35811)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35811)[0m 
[2m[36m(pid=35811)[0m Stack (most recent call first):
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35561)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35561)[0m Traceback (most recent call last):
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35561)[0m     self.run()
[2m[36m(pid=35561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35561)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35561)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35440)[0m LSTM is selected.
[2m[36m(pid=35440)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=35440)[0m Instructions for updating:
[2m[36m(pid=35440)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=35440)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=35440)[0m Instructions for updating:
[2m[36m(pid=35440)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:23:04,010	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35520, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:04,013	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.31845,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.01,lstm_2_units_float=69.327,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35769)[0m 2021-01-16 21:23:04,048	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35769)[0m Traceback (most recent call last):
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35769)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35769)[0m     param_dset[:] = val
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35769)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35769)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35769)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35769)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:04 2021
[2m[36m(pid=35769)[0m , filename = '/tmp/thalvari/4565627/automl_save_sirlq37q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd0ba7d03a8, total write size = 561620, bytes this sub-write = 561620, bytes actually written = 18446744073709551615, offset = 323584)
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35769)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35769)[0m Traceback (most recent call last):
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35769)[0m     self._entrypoint()
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35769)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35769)[0m     output = train_func(config, reporter)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35769)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35769)[0m     config=config)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35769)[0m     model.save(model_path, config_path)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35769)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35769)[0m     self.model.save(model_path)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35769)[0m     signatures)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35769)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35769)[0m     f.close()
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35769)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35769)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:04 2021
[2m[36m(pid=35769)[0m , filename = '/tmp/thalvari/4565627/automl_save_sirlq37q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd0ba4e23d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35769)[0m Exception in thread Thread-1:
[2m[36m(pid=35769)[0m Traceback (most recent call last):
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35769)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35769)[0m     param_dset[:] = val
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35769)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35769)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35769)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35769)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:04 2021
[2m[36m(pid=35769)[0m , filename = '/tmp/thalvari/4565627/automl_save_sirlq37q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd0ba7d03a8, total write size = 561620, bytes this sub-write = 561620, bytes actually written = 18446744073709551615, offset = 323584)
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35769)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35769)[0m Traceback (most recent call last):
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35769)[0m     self._entrypoint()
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35769)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35769)[0m     output = train_func(config, reporter)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35769)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35769)[0m     config=config)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35769)[0m     model.save(model_path, config_path)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35769)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35769)[0m     self.model.save(model_path)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35769)[0m     signatures)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35769)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35769)[0m     f.close()
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35769)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35769)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35769)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:04 2021
[2m[36m(pid=35769)[0m , filename = '/tmp/thalvari/4565627/automl_save_sirlq37q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd0ba4e23d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35769)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35769)[0m Traceback (most recent call last):
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35769)[0m     self.run()
[2m[36m(pid=35769)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35769)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35769)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35520)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35520)[0m 
[2m[36m(pid=35520)[0m Stack (most recent call first):
2021-01-16 21:23:04,731	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35561, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:04,733	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37612,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.54941,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.068,lstm_2_units_float=69.301,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35440)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=35440)[0m 2021-01-16 21:23:04.841058: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=35440)[0m 2021-01-16 21:23:04.850687: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=35440)[0m 2021-01-16 21:23:04.855341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f24991039c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=35440)[0m 2021-01-16 21:23:04.855373: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=35561)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35561)[0m 
[2m[36m(pid=35561)[0m Stack (most recent call first):
2021-01-16 21:23:05,489	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35769, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:05,492	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.66664,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.054,lstm_2_units_float=69.319,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=35769)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35769)[0m 
[2m[36m(pid=35769)[0m Stack (most recent call first):
[2m[36m(pid=37651)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37651)[0m   agg_primitives: ['count']
[2m[36m(pid=37651)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37651)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37653)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37653)[0m   agg_primitives: ['count']
[2m[36m(pid=37653)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37653)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37875)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37875)[0m   agg_primitives: ['count']
[2m[36m(pid=37875)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37875)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37869)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37869)[0m   agg_primitives: ['count']
[2m[36m(pid=37869)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37869)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37651)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37651)[0m Instructions for updating:
[2m[36m(pid=37651)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37651)[0m LSTM is selected.
[2m[36m(pid=37653)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37653)[0m Instructions for updating:
[2m[36m(pid=37653)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37653)[0m LSTM is selected.
[2m[36m(pid=37875)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37875)[0m Instructions for updating:
[2m[36m(pid=37875)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37875)[0m LSTM is selected.
[2m[36m(pid=37869)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37869)[0m Instructions for updating:
[2m[36m(pid=37869)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37869)[0m LSTM is selected.
[2m[36m(pid=35439)[0m 2021-01-16 21:23:06,776	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35439)[0m Traceback (most recent call last):
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35439)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35439)[0m     param_dset[:] = val
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35439)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35439)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35439)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35439)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:06 2021
[2m[36m(pid=35439)[0m , filename = '/tmp/thalvari/4565627/automl_save_zg1nxqfx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f460e6e8238, total write size = 566292, bytes this sub-write = 566292, bytes actually written = 18446744073709551615, offset = 315392)
[2m[36m(pid=35439)[0m 
[2m[36m(pid=35439)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35439)[0m 
[2m[36m(pid=35439)[0m Traceback (most recent call last):
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35439)[0m     self._entrypoint()
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35439)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35439)[0m     output = train_func(config, reporter)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35439)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35439)[0m     config=config)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35439)[0m     model.save(model_path, config_path)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35439)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35439)[0m     self.model.save(model_path)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35439)[0m     signatures)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35439)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35439)[0m     f.close()
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35439)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35439)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:06 2021
[2m[36m(pid=35439)[0m , filename = '/tmp/thalvari/4565627/automl_save_zg1nxqfx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f460e91ad40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35439)[0m Exception in thread Thread-1:
[2m[36m(pid=35439)[0m Traceback (most recent call last):
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35439)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35439)[0m     param_dset[:] = val
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35439)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35439)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35439)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35439)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:06 2021
[2m[36m(pid=35439)[0m , filename = '/tmp/thalvari/4565627/automl_save_zg1nxqfx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f460e6e8238, total write size = 566292, bytes this sub-write = 566292, bytes actually written = 18446744073709551615, offset = 315392)
[2m[36m(pid=35439)[0m 
[2m[36m(pid=35439)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35439)[0m 
[2m[36m(pid=35439)[0m Traceback (most recent call last):
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35439)[0m     self._entrypoint()
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35439)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35439)[0m     output = train_func(config, reporter)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35439)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35439)[0m     config=config)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35439)[0m     model.save(model_path, config_path)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35439)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35439)[0m     self.model.save(model_path)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35439)[0m     signatures)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35439)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35439)[0m     f.close()
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35439)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35439)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35439)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:06 2021
[2m[36m(pid=35439)[0m , filename = '/tmp/thalvari/4565627/automl_save_zg1nxqfx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f460e91ad40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35439)[0m 
[2m[36m(pid=35439)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35439)[0m 
[2m[36m(pid=35439)[0m Traceback (most recent call last):
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35439)[0m     self.run()
[2m[36m(pid=35439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35439)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35439)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35439)[0m 
[2m[36m(pid=37867)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37867)[0m   agg_primitives: ['count']
[2m[36m(pid=37867)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37867)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37651)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37651)[0m Instructions for updating:
[2m[36m(pid=37651)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37653)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37653)[0m Instructions for updating:
[2m[36m(pid=37653)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37875)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37875)[0m Instructions for updating:
[2m[36m(pid=37875)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37869)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37869)[0m Instructions for updating:
[2m[36m(pid=37869)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37867)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37867)[0m Instructions for updating:
[2m[36m(pid=37867)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37867)[0m LSTM is selected.
[2m[36m(pid=37876)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37876)[0m   agg_primitives: ['count']
[2m[36m(pid=37876)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37876)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:23:07,816	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35439, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:07,818	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.80469,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.998,lstm_2_units_float=69.294,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37867)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37867)[0m Instructions for updating:
[2m[36m(pid=37867)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35439)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35439)[0m 
[2m[36m(pid=35439)[0m Stack (most recent call first):
[2m[36m(pid=37876)[0m LSTM is selected.
[2m[36m(pid=37653)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37653)[0m 2021-01-16 21:23:08.152927: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37653)[0m 2021-01-16 21:23:08.160635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37875)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37875)[0m 2021-01-16 21:23:08.145080: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37875)[0m 2021-01-16 21:23:08.152572: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37875)[0m 2021-01-16 21:23:08.154679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6349103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37875)[0m 2021-01-16 21:23:08.154707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37869)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37869)[0m 2021-01-16 21:23:08.160528: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37876)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37876)[0m Instructions for updating:
[2m[36m(pid=37876)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37653)[0m 2021-01-16 21:23:08.162675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efb3d103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37653)[0m 2021-01-16 21:23:08.162695: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37869)[0m 2021-01-16 21:23:08.168109: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37869)[0m 2021-01-16 21:23:08.170313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f341d103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37869)[0m 2021-01-16 21:23:08.170331: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37651)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37651)[0m 2021-01-16 21:23:08.206600: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37651)[0m 2021-01-16 21:23:08.214683: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37651)[0m 2021-01-16 21:23:08.216502: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdac11035a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37651)[0m 2021-01-16 21:23:08.216524: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37863)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37863)[0m   agg_primitives: ['count']
[2m[36m(pid=37863)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37863)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37873)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37873)[0m   agg_primitives: ['count']
[2m[36m(pid=37873)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37873)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 92 ({'TERMINATED': 15, 'ERROR': 67, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 61 not shown
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37612,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.54941,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.068,lstm_2_units_float=69.301,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37612,bayes_feature_IS_AWAKE(datet_2021-01-16_21-22-47tbfj_ttt/error_2021-01-16_21-23-04.txt
 - train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.66664,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.054,lstm_2_units_float=69.319,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-48itu3z4jy/error_2021-01-16_21-23-05.txt
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.80469,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.998,lstm_2_units_float=69.294,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-51c7r8gxb5/error_2021-01-16_21-23-07.txt
RUNNING trials:
 - train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.567,past_seq_len=2:	RUNNING
 - train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.875,lstm_2_units_float=67.599,past_seq_len=2:	RUNNING
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34382,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.7094,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.572,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.851,lstm_2_units_float=67.594,past_seq_len=2:	RUNNING
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.36336,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.601,past_seq_len=2:	RUNNING
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.934,lstm_2_units_float=67.555,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=37876)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37876)[0m Instructions for updating:
[2m[36m(pid=37876)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37863)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37863)[0m Instructions for updating:
[2m[36m(pid=37863)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37863)[0m LSTM is selected.
[2m[36m(pid=37873)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37873)[0m Instructions for updating:
[2m[36m(pid=37873)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37873)[0m LSTM is selected.
[2m[36m(pid=37867)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37867)[0m 2021-01-16 21:23:08.842643: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37867)[0m 2021-01-16 21:23:08.850166: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37867)[0m 2021-01-16 21:23:08.852422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0859102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37867)[0m 2021-01-16 21:23:08.852454: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37863)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37863)[0m Instructions for updating:
[2m[36m(pid=37863)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37873)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37873)[0m Instructions for updating:
[2m[36m(pid=37873)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37876)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37876)[0m 2021-01-16 21:23:09.608263: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37876)[0m 2021-01-16 21:23:09.618483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37876)[0m 2021-01-16 21:23:09.621542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fadc90e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37876)[0m 2021-01-16 21:23:09.621581: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37863)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37863)[0m 2021-01-16 21:23:10.255496: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37873)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37873)[0m 2021-01-16 21:23:10.308669: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37873)[0m 2021-01-16 21:23:10.320211: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37863)[0m 2021-01-16 21:23:10.265891: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37863)[0m 2021-01-16 21:23:10.270297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6c90e8c40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37863)[0m 2021-01-16 21:23:10.270346: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37873)[0m 2021-01-16 21:23:10.324643: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efbdd102a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37873)[0m 2021-01-16 21:23:10.324684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37859)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37859)[0m   agg_primitives: ['count']
[2m[36m(pid=37859)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37859)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37859)[0m LSTM is selected.
[2m[36m(pid=37859)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37859)[0m Instructions for updating:
[2m[36m(pid=37859)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37859)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37859)[0m Instructions for updating:
[2m[36m(pid=37859)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=35440)[0m 2021-01-16 21:23:14,155	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=35440)[0m Traceback (most recent call last):
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35440)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35440)[0m     param_dset[:] = val
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35440)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35440)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35440)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35440)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:14 2021
[2m[36m(pid=35440)[0m , filename = '/tmp/thalvari/4565627/automl_save_mht5izhg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f249a6fb968, total write size = 550044, bytes this sub-write = 550044, bytes actually written = 18446744073709551615, offset = 307200)
[2m[36m(pid=35440)[0m 
[2m[36m(pid=35440)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35440)[0m 
[2m[36m(pid=35440)[0m Traceback (most recent call last):
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35440)[0m     self._entrypoint()
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35440)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35440)[0m     output = train_func(config, reporter)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35440)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35440)[0m     config=config)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35440)[0m     model.save(model_path, config_path)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35440)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35440)[0m     self.model.save(model_path)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35440)[0m     signatures)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35440)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35440)[0m     f.close()
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35440)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35440)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:14 2021
[2m[36m(pid=35440)[0m , filename = '/tmp/thalvari/4565627/automl_save_mht5izhg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f24995e66c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35440)[0m Exception in thread Thread-1:
[2m[36m(pid=35440)[0m Traceback (most recent call last):
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=35440)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=35440)[0m     param_dset[:] = val
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=35440)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=35440)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=35440)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=35440)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:14 2021
[2m[36m(pid=35440)[0m , filename = '/tmp/thalvari/4565627/automl_save_mht5izhg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f249a6fb968, total write size = 550044, bytes this sub-write = 550044, bytes actually written = 18446744073709551615, offset = 307200)
[2m[36m(pid=35440)[0m 
[2m[36m(pid=35440)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35440)[0m 
[2m[36m(pid=35440)[0m Traceback (most recent call last):
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=35440)[0m     self._entrypoint()
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=35440)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=35440)[0m     output = train_func(config, reporter)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=35440)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=35440)[0m     config=config)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=35440)[0m     model.save(model_path, config_path)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=35440)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=35440)[0m     self.model.save(model_path)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=35440)[0m     signatures)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=35440)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=35440)[0m     f.close()
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=35440)[0m     h5i.dec_ref(id_)
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=35440)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=35440)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:14 2021
[2m[36m(pid=35440)[0m , filename = '/tmp/thalvari/4565627/automl_save_mht5izhg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f24995e66c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=35440)[0m 
[2m[36m(pid=35440)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=35440)[0m 
[2m[36m(pid=35440)[0m Traceback (most recent call last):
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=35440)[0m     self.run()
[2m[36m(pid=35440)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=35440)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=35440)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=35440)[0m 
[2m[36m(pid=37859)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37859)[0m 2021-01-16 21:23:14.696980: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37859)[0m 2021-01-16 21:23:14.708995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37859)[0m 2021-01-16 21:23:14.712742: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2de5102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37859)[0m 2021-01-16 21:23:14.712793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:23:15,343	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=35440, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:15,347	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.567,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 92 ({'TERMINATED': 15, 'ERROR': 68, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 62 not shown
 - train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.66664,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=73.054,lstm_2_units_float=69.319,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-48itu3z4jy/error_2021-01-16_21-23-05.txt
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.80469,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.998,lstm_2_units_float=69.294,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-51c7r8gxb5/error_2021-01-16_21-23-07.txt
 - train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.567,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-578bm2ov_z/error_2021-01-16_21-23-15.txt
RUNNING trials:
 - train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.875,lstm_2_units_float=67.599,past_seq_len=2:	RUNNING
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34382,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.7094,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.572,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.5848,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.926,lstm_2_units_float=67.545,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.851,lstm_2_units_float=67.594,past_seq_len=2:	RUNNING
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.36336,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.601,past_seq_len=2:	RUNNING
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.934,lstm_2_units_float=67.555,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=35440)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=35440)[0m 
[2m[36m(pid=35440)[0m Stack (most recent call first):
[2m[36m(pid=37875)[0m 2021-01-16 21:23:18,296	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37875)[0m Traceback (most recent call last):
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37875)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37875)[0m     param_dset[:] = val
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37875)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37875)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37875)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37875)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37875)[0m , filename = '/tmp/thalvari/4565627/automl_save_xsalprh0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63494e63a8, total write size = 16216, bytes this sub-write = 16216, bytes actually written = 18446744073709551615, offset = 86016)
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37875)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37875)[0m Traceback (most recent call last):
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37875)[0m     self._entrypoint()
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37875)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37875)[0m     output = train_func(config, reporter)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37875)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37875)[0m     config=config)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37875)[0m     model.save(model_path, config_path)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37875)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37875)[0m     self.model.save(model_path)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37875)[0m     signatures)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37875)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37875)[0m     f.close()
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37875)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37875)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37875)[0m , filename = '/tmp/thalvari/4565627/automl_save_xsalprh0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6349f77610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37875)[0m Exception in thread Thread-1:
[2m[36m(pid=37875)[0m Traceback (most recent call last):
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37875)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37875)[0m     param_dset[:] = val
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37875)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37875)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37875)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37875)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37875)[0m , filename = '/tmp/thalvari/4565627/automl_save_xsalprh0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63494e63a8, total write size = 16216, bytes this sub-write = 16216, bytes actually written = 18446744073709551615, offset = 86016)
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37875)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37875)[0m Traceback (most recent call last):
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37875)[0m     self._entrypoint()
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37875)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37875)[0m     output = train_func(config, reporter)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37875)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37875)[0m     config=config)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37875)[0m     model.save(model_path, config_path)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37875)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37875)[0m     self.model.save(model_path)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37875)[0m     signatures)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37875)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37875)[0m     f.close()
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37875)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37875)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37875)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37875)[0m , filename = '/tmp/thalvari/4565627/automl_save_xsalprh0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6349f77610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37869)[0m 2021-01-16 21:23:18,310	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37869)[0m Traceback (most recent call last):
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37869)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37869)[0m     param_dset[:] = val
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37869)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37869)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37869)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37869)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37869)[0m , filename = '/tmp/thalvari/4565627/automl_save_zp4u0wuq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f341ddbe2d8, total write size = 3288, bytes this sub-write = 3288, bytes actually written = 18446744073709551615, offset = 180224)
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37869)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37869)[0m Traceback (most recent call last):
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37869)[0m     self._entrypoint()
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37869)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37869)[0m     output = train_func(config, reporter)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37869)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37869)[0m     config=config)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37869)[0m     model.save(model_path, config_path)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37869)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37869)[0m     self.model.save(model_path)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37869)[0m     signatures)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37869)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37869)[0m     f.close()
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37869)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37869)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37869)[0m , filename = '/tmp/thalvari/4565627/automl_save_zp4u0wuq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f341d8ae100, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37869)[0m Exception in thread Thread-1:
[2m[36m(pid=37869)[0m Traceback (most recent call last):
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37869)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37869)[0m     param_dset[:] = val
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37869)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37869)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37869)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37869)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37869)[0m , filename = '/tmp/thalvari/4565627/automl_save_zp4u0wuq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f341ddbe2d8, total write size = 3288, bytes this sub-write = 3288, bytes actually written = 18446744073709551615, offset = 180224)
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37869)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37869)[0m Traceback (most recent call last):
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37869)[0m     self._entrypoint()
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37869)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37869)[0m     output = train_func(config, reporter)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37869)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37869)[0m     config=config)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37869)[0m     model.save(model_path, config_path)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37869)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37869)[0m     self.model.save(model_path)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37869)[0m     signatures)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37869)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37869)[0m     f.close()
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37869)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37869)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37869)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37869)[0m , filename = '/tmp/thalvari/4565627/automl_save_zp4u0wuq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f341d8ae100, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37875)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37875)[0m Traceback (most recent call last):
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37875)[0m     self.run()
[2m[36m(pid=37875)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37875)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37875)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37869)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37869)[0m Traceback (most recent call last):
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37869)[0m     self.run()
[2m[36m(pid=37869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37869)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37869)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37651)[0m 2021-01-16 21:23:18,360	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37651)[0m Traceback (most recent call last):
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37651)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37651)[0m     param_dset[:] = val
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37651)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37651)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37651)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37651)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37651)[0m , filename = '/tmp/thalvari/4565627/automl_save_wvmnr0lt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdac27cca38, total write size = 582812, bytes this sub-write = 582812, bytes actually written = 18446744073709551615, offset = 274432)
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37651)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37651)[0m Traceback (most recent call last):
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37651)[0m     self._entrypoint()
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37651)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37651)[0m     output = train_func(config, reporter)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37651)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37651)[0m     config=config)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37651)[0m     model.save(model_path, config_path)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37651)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37651)[0m     self.model.save(model_path)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37651)[0m     signatures)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37651)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37651)[0m     f.close()
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37651)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37651)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37651)[0m , filename = '/tmp/thalvari/4565627/automl_save_wvmnr0lt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdac2135570, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37651)[0m Exception in thread Thread-1:
[2m[36m(pid=37651)[0m Traceback (most recent call last):
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37651)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37651)[0m     param_dset[:] = val
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37651)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37651)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37651)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37651)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37651)[0m , filename = '/tmp/thalvari/4565627/automl_save_wvmnr0lt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdac27cca38, total write size = 582812, bytes this sub-write = 582812, bytes actually written = 18446744073709551615, offset = 274432)
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37651)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37651)[0m Traceback (most recent call last):
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37651)[0m     self._entrypoint()
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37651)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37651)[0m     output = train_func(config, reporter)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37651)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37651)[0m     config=config)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37651)[0m     model.save(model_path, config_path)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37651)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37651)[0m     self.model.save(model_path)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37651)[0m     signatures)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37651)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37651)[0m     f.close()
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37651)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37651)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37651)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37651)[0m , filename = '/tmp/thalvari/4565627/automl_save_wvmnr0lt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdac2135570, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37651)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37651)[0m Traceback (most recent call last):
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37651)[0m     self.run()
[2m[36m(pid=37651)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37651)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37651)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37653)[0m 2021-01-16 21:23:18,450	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37653)[0m Traceback (most recent call last):
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37653)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37653)[0m     param_dset[:] = val
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37653)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37653)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37653)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37653)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37653)[0m , filename = '/tmp/thalvari/4565627/automl_save_hr9ocao8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb3e6dc058, total write size = 582812, bytes this sub-write = 582812, bytes actually written = 18446744073709551615, offset = 274432)
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37653)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37653)[0m Traceback (most recent call last):
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37653)[0m     self._entrypoint()
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37653)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37653)[0m     output = train_func(config, reporter)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37653)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37653)[0m     config=config)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37653)[0m     model.save(model_path, config_path)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37653)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37653)[0m     self.model.save(model_path)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37653)[0m     signatures)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37653)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37653)[0m     f.close()
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37653)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37653)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37653)[0m , filename = '/tmp/thalvari/4565627/automl_save_hr9ocao8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb3d517460, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37653)[0m Exception in thread Thread-1:
[2m[36m(pid=37653)[0m Traceback (most recent call last):
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37653)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37653)[0m     param_dset[:] = val
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37653)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37653)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37653)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37653)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37653)[0m , filename = '/tmp/thalvari/4565627/automl_save_hr9ocao8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb3e6dc058, total write size = 582812, bytes this sub-write = 582812, bytes actually written = 18446744073709551615, offset = 274432)
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37653)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37653)[0m Traceback (most recent call last):
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37653)[0m     self._entrypoint()
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37653)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37653)[0m     output = train_func(config, reporter)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37653)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37653)[0m     config=config)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37653)[0m     model.save(model_path, config_path)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37653)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37653)[0m     self.model.save(model_path)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37653)[0m     signatures)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37653)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37653)[0m     f.close()
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37653)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37653)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37653)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:18 2021
[2m[36m(pid=37653)[0m , filename = '/tmp/thalvari/4565627/automl_save_hr9ocao8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efb3d517460, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37653)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37653)[0m Traceback (most recent call last):
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37653)[0m     self.run()
[2m[36m(pid=37653)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37653)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37653)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37867)[0m 2021-01-16 21:23:19,127	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37867)[0m Traceback (most recent call last):
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37867)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37867)[0m     param_dset[:] = val
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37867)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37867)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37867)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37867)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37867)[0m , filename = '/tmp/thalvari/4565627/automl_save_t14_oy9q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0859dce568, total write size = 591004, bytes this sub-write = 591004, bytes actually written = 18446744073709551615, offset = 266240)
[2m[36m(pid=37867)[0m 
[2m[36m(pid=37867)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37867)[0m 
[2m[36m(pid=37867)[0m Traceback (most recent call last):
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37867)[0m     self._entrypoint()
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37867)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37867)[0m     output = train_func(config, reporter)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37867)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37867)[0m     config=config)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37867)[0m     model.save(model_path, config_path)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37867)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37867)[0m     self.model.save(model_path)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37867)[0m     signatures)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37867)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37867)[0m     f.close()
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37867)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37867)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37867)[0m , filename = '/tmp/thalvari/4565627/automl_save_t14_oy9q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f08595f29b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37867)[0m Exception in thread Thread-1:
[2m[36m(pid=37867)[0m Traceback (most recent call last):
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37867)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37867)[0m     param_dset[:] = val
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37867)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37867)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37867)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37867)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37867)[0m , filename = '/tmp/thalvari/4565627/automl_save_t14_oy9q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0859dce568, total write size = 591004, bytes this sub-write = 591004, bytes actually written = 18446744073709551615, offset = 266240)
[2m[36m(pid=37867)[0m 
[2m[36m(pid=37867)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37867)[0m 
[2m[36m(pid=37867)[0m Traceback (most recent call last):
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37867)[0m     self._entrypoint()
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37867)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37867)[0m     output = train_func(config, reporter)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37867)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37867)[0m     config=config)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37867)[0m     model.save(model_path, config_path)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37867)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37867)[0m     self.model.save(model_path)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37867)[0m     signatures)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37867)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37867)[0m     f.close()
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37867)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37867)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37867)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37867)[0m , filename = '/tmp/thalvari/4565627/automl_save_t14_oy9q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f08595f29b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37867)[0m 
[2m[36m(pid=37867)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37867)[0m 
[2m[36m(pid=37867)[0m Traceback (most recent call last):
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37867)[0m     self.run()
[2m[36m(pid=37867)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37867)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37867)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37867)[0m 
2021-01-16 21:23:19,347	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37869, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:19,352	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.79005,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.562,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37869)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37869)[0m 
[2m[36m(pid=37869)[0m Stack (most recent call first):
[2m[36m(pid=37876)[0m 2021-01-16 21:23:19,904	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37876)[0m Traceback (most recent call last):
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37876)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37876)[0m     param_dset[:] = val
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37876)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37876)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37876)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37876)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37876)[0m , filename = '/tmp/thalvari/4565627/automl_save_1w9vrqcu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fadca8218b0, total write size = 595764, bytes this sub-write = 595764, bytes actually written = 18446744073709551615, offset = 260328)
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37876)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37876)[0m Traceback (most recent call last):
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37876)[0m     self._entrypoint()
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37876)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37876)[0m     output = train_func(config, reporter)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37876)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37876)[0m     config=config)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37876)[0m     model.save(model_path, config_path)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37876)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37876)[0m     self.model.save(model_path)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37876)[0m     signatures)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37876)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37876)[0m     f.close()
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37876)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37876)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37876)[0m , filename = '/tmp/thalvari/4565627/automl_save_1w9vrqcu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fadca6ebbb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37876)[0m Exception in thread Thread-1:
[2m[36m(pid=37876)[0m Traceback (most recent call last):
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37876)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37876)[0m     param_dset[:] = val
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37876)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37876)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37876)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37876)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37876)[0m , filename = '/tmp/thalvari/4565627/automl_save_1w9vrqcu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fadca8218b0, total write size = 595764, bytes this sub-write = 595764, bytes actually written = 18446744073709551615, offset = 260328)
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37876)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37876)[0m Traceback (most recent call last):
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37876)[0m     self._entrypoint()
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37876)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37876)[0m     output = train_func(config, reporter)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37876)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37876)[0m     config=config)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37876)[0m     model.save(model_path, config_path)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37876)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37876)[0m     self.model.save(model_path)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37876)[0m     signatures)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37876)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37876)[0m     f.close()
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37876)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37876)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37876)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:19 2021
[2m[36m(pid=37876)[0m , filename = '/tmp/thalvari/4565627/automl_save_1w9vrqcu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fadca6ebbb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37876)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37876)[0m Traceback (most recent call last):
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37876)[0m     self.run()
[2m[36m(pid=37876)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37876)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37876)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37861)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37861)[0m   agg_primitives: ['count']
[2m[36m(pid=37861)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37861)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37873)[0m 2021-01-16 21:23:20,221	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37873)[0m Traceback (most recent call last):
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37873)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37873)[0m     param_dset[:] = val
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37873)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37873)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37873)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37873)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37873)[0m , filename = '/tmp/thalvari/4565627/automl_save_o85f7t9h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efbde4e0988, total write size = 15720, bytes this sub-write = 15720, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37873)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37873)[0m Traceback (most recent call last):
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37873)[0m     self._entrypoint()
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37873)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37873)[0m     output = train_func(config, reporter)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37873)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37873)[0m     config=config)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37873)[0m     model.save(model_path, config_path)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37873)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37873)[0m     self.model.save(model_path)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37873)[0m     signatures)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37873)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37873)[0m     f.close()
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37873)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37873)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37873)[0m , filename = '/tmp/thalvari/4565627/automl_save_o85f7t9h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efbdd56ba80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37873)[0m Exception in thread Thread-1:
[2m[36m(pid=37873)[0m Traceback (most recent call last):
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37873)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37873)[0m     param_dset[:] = val
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37873)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37873)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37873)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37873)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37873)[0m , filename = '/tmp/thalvari/4565627/automl_save_o85f7t9h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efbde4e0988, total write size = 15720, bytes this sub-write = 15720, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37873)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37873)[0m Traceback (most recent call last):
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37873)[0m     self._entrypoint()
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37873)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37873)[0m     output = train_func(config, reporter)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37873)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37873)[0m     config=config)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37873)[0m     model.save(model_path, config_path)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37873)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37873)[0m     self.model.save(model_path)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37873)[0m     signatures)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37873)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37873)[0m     f.close()
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37873)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37873)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37873)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37873)[0m , filename = '/tmp/thalvari/4565627/automl_save_o85f7t9h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efbdd56ba80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37863)[0m 2021-01-16 21:23:20,258	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37863)[0m Traceback (most recent call last):
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37863)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37863)[0m     param_dset[:] = val
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37863)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37863)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37863)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37863)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37863)[0m , filename = '/tmp/thalvari/4565627/automl_save_1u65pi0w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa6ca3753c8, total write size = 14568, bytes this sub-write = 14568, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37863)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37863)[0m Traceback (most recent call last):
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37863)[0m     self._entrypoint()
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37863)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37863)[0m     output = train_func(config, reporter)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37863)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37863)[0m     config=config)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37863)[0m     model.save(model_path, config_path)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37863)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37863)[0m     self.model.save(model_path)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37863)[0m     signatures)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37863)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37863)[0m     f.close()
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37863)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37863)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37863)[0m , filename = '/tmp/thalvari/4565627/automl_save_1u65pi0w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa6ca43c270, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37863)[0m Exception in thread Thread-1:
[2m[36m(pid=37863)[0m Traceback (most recent call last):
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37863)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37863)[0m     param_dset[:] = val
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37863)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37863)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37863)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37863)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37863)[0m , filename = '/tmp/thalvari/4565627/automl_save_1u65pi0w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa6ca3753c8, total write size = 14568, bytes this sub-write = 14568, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37863)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37863)[0m Traceback (most recent call last):
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37863)[0m     self._entrypoint()
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37863)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37863)[0m     output = train_func(config, reporter)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37863)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37863)[0m     config=config)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37863)[0m     model.save(model_path, config_path)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37863)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37863)[0m     self.model.save(model_path)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37863)[0m     signatures)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37863)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37863)[0m     f.close()
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37863)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37863)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37863)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:20 2021
[2m[36m(pid=37863)[0m , filename = '/tmp/thalvari/4565627/automl_save_1u65pi0w/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa6ca43c270, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37873)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37873)[0m Traceback (most recent call last):
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37873)[0m     self.run()
[2m[36m(pid=37873)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37873)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37873)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37863)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37863)[0m Traceback (most recent call last):
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37863)[0m     self.run()
[2m[36m(pid=37863)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37863)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37863)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37861)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37861)[0m Instructions for updating:
[2m[36m(pid=37861)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37861)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 94 ({'TERMINATED': 15, 'ERROR': 69, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 63 not shown
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.80469,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.998,lstm_2_units_float=69.294,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-51c7r8gxb5/error_2021-01-16_21-23-07.txt
 - train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.567,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-22-578bm2ov_z/error_2021-01-16_21-23-15.txt
 - train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.79005,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.562,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-020oeqqx_a/error_2021-01-16_21-23-19.txt
RUNNING trials:
 - train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.875,lstm_2_units_float=67.599,past_seq_len=2:	RUNNING
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34382,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.7094,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.572,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.5848,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.926,lstm_2_units_float=67.545,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.934,lstm_2_units_float=67.555,past_seq_len=2:	RUNNING
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.59084,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.847,lstm_2_units_float=67.575,past_seq_len=2:	RUNNING
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.58872,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.571,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

2021-01-16 21:23:20,708	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37653, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:20,710	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.875,lstm_2_units_float=67.599,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37653)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37653)[0m 
[2m[36m(pid=37653)[0m Stack (most recent call first):
2021-01-16 21:23:21,238	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37876, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:21,241	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.49518,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.572,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37861)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37861)[0m Instructions for updating:
[2m[36m(pid=37861)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37876)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37876)[0m 
[2m[36m(pid=37876)[0m Stack (most recent call first):
2021-01-16 21:23:21,939	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37863, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:21,941	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.36336,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.601,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37863)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37863)[0m 
[2m[36m(pid=37863)[0m Stack (most recent call first):
[2m[36m(pid=37861)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37861)[0m 2021-01-16 21:23:22.227180: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37861)[0m 2021-01-16 21:23:22.234952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37861)[0m 2021-01-16 21:23:22.237215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0845103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37861)[0m 2021-01-16 21:23:22.237243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:23:22,612	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37875, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:22,615	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.5848,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.926,lstm_2_units_float=67.545,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37875)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37875)[0m 
[2m[36m(pid=37875)[0m Stack (most recent call first):
2021-01-16 21:23:23,463	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37651, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:23,465	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34382,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.7094,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.572,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37651)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37651)[0m 
[2m[36m(pid=37651)[0m Stack (most recent call first):
[2m[36m(pid=37859)[0m 2021-01-16 21:23:23,672	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37859)[0m Traceback (most recent call last):
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37859)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37859)[0m     param_dset[:] = val
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37859)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37859)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37859)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37859)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:23 2021
[2m[36m(pid=37859)[0m , filename = '/tmp/thalvari/4565627/automl_save_l_91gki_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2de6555828, total write size = 23912, bytes this sub-write = 23912, bytes actually written = 18446744073709551615, offset = 233472)
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37859)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37859)[0m Traceback (most recent call last):
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37859)[0m     self._entrypoint()
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37859)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37859)[0m     output = train_func(config, reporter)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37859)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37859)[0m     config=config)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37859)[0m     model.save(model_path, config_path)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37859)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37859)[0m     self.model.save(model_path)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37859)[0m     signatures)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37859)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37859)[0m     f.close()
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37859)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37859)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:23 2021
[2m[36m(pid=37859)[0m , filename = '/tmp/thalvari/4565627/automl_save_l_91gki_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2de6289d20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37859)[0m Exception in thread Thread-1:
[2m[36m(pid=37859)[0m Traceback (most recent call last):
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37859)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37859)[0m     param_dset[:] = val
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37859)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37859)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37859)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37859)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:23 2021
[2m[36m(pid=37859)[0m , filename = '/tmp/thalvari/4565627/automl_save_l_91gki_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2de6555828, total write size = 23912, bytes this sub-write = 23912, bytes actually written = 18446744073709551615, offset = 233472)
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37859)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37859)[0m Traceback (most recent call last):
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37859)[0m     self._entrypoint()
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37859)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37859)[0m     output = train_func(config, reporter)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37859)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37859)[0m     config=config)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37859)[0m     model.save(model_path, config_path)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37859)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37859)[0m     self.model.save(model_path)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37859)[0m     signatures)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37859)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37859)[0m     f.close()
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37859)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37859)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37859)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:23 2021
[2m[36m(pid=37859)[0m , filename = '/tmp/thalvari/4565627/automl_save_l_91gki_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2de6289d20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37859)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37859)[0m Traceback (most recent call last):
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37859)[0m     self.run()
[2m[36m(pid=37859)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37859)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37859)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37860)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37860)[0m   agg_primitives: ['count']
[2m[36m(pid=37860)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37860)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37874)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37874)[0m   agg_primitives: ['count']
[2m[36m(pid=37874)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37874)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:23:24,154	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37873, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:24,156	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.851,lstm_2_units_float=67.594,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37860)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37860)[0m Instructions for updating:
[2m[36m(pid=37860)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37860)[0m LSTM is selected.
[2m[36m(pid=37874)[0m LSTM is selected.
[2m[36m(pid=37874)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37874)[0m Instructions for updating:
[2m[36m(pid=37874)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37873)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37873)[0m 
[2m[36m(pid=37873)[0m Stack (most recent call first):
[2m[36m(pid=37862)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37862)[0m   agg_primitives: ['count']
[2m[36m(pid=37862)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37862)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37860)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37860)[0m Instructions for updating:
[2m[36m(pid=37860)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37874)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37874)[0m Instructions for updating:
[2m[36m(pid=37874)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37862)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37862)[0m Instructions for updating:
[2m[36m(pid=37862)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37862)[0m LSTM is selected.
2021-01-16 21:23:25,335	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37867, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:25,338	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_88_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.58387,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.569,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37774)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37774)[0m   agg_primitives: ['count']
[2m[36m(pid=37774)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37774)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37867)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37867)[0m 
[2m[36m(pid=37867)[0m Stack (most recent call first):
[2m[36m(pid=37862)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37862)[0m Instructions for updating:
[2m[36m(pid=37862)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37774)[0m LSTM is selected.
[2m[36m(pid=37860)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37860)[0m 2021-01-16 21:23:25.823400: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37860)[0m 2021-01-16 21:23:25.831383: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37860)[0m 2021-01-16 21:23:25.833781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac39103a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37860)[0m 2021-01-16 21:23:25.833803: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37874)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37874)[0m 2021-01-16 21:23:25.856168: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37874)[0m 2021-01-16 21:23:25.864189: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37874)[0m 2021-01-16 21:23:25.866219: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eef15103a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37874)[0m 2021-01-16 21:23:25.866240: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 101 ({'TERMINATED': 15, 'ERROR': 76, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 70 not shown
 - train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.49518,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.572,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-04e6_1s_ce/error_2021-01-16_21-23-21.txt
 - train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.851,lstm_2_units_float=67.594,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-05svd3e8k3/error_2021-01-16_21-23-24.txt
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.36336,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.601,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-05bulg0s0o/error_2021-01-16_21-23-21.txt
RUNNING trials:
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.934,lstm_2_units_float=67.555,past_seq_len=2:	RUNNING
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.59084,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.847,lstm_2_units_float=67.575,past_seq_len=2:	RUNNING
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.58872,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.571,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_99_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.98346,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.915,lstm_2_units_float=67.571,past_seq_len=2:	RUNNING
 - train_func_100_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.592,past_seq_len=2:	RUNNING
 - train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34831,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.893,lstm_2_units_float=67.575,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=37774)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
2021-01-16 21:23:25,936	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37859, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.
[2m[36m(pid=37774)[0m Instructions for updating:
[2m[36m(pid=37774)[0m If using Keras pass *_constraint arguments to layers.

2021-01-16 21:23:25,938	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.934,lstm_2_units_float=67.555,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37859)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37859)[0m 
[2m[36m(pid=37859)[0m Stack (most recent call first):
[2m[36m(pid=37775)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37775)[0m   agg_primitives: ['count']
[2m[36m(pid=37775)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37775)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37774)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37774)[0m Instructions for updating:
[2m[36m(pid=37774)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37775)[0m LSTM is selected.
[2m[36m(pid=37775)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37775)[0m Instructions for updating:
[2m[36m(pid=37775)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37862)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37862)[0m 2021-01-16 21:23:26.845280: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37862)[0m 2021-01-16 21:23:26.866327: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37862)[0m 2021-01-16 21:23:26.870284: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8189103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37862)[0m 2021-01-16 21:23:26.870313: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37871)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37871)[0m   agg_primitives: ['count']
[2m[36m(pid=37871)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37871)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=40816)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=40818)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=40819)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=40818)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=40819)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=40816)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=40943)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=40943)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37775)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37775)[0m Instructions for updating:
[2m[36m(pid=37775)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37774)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37774)[0m 2021-01-16 21:23:27.509661: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37774)[0m 2021-01-16 21:23:27.521312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37774)[0m 2021-01-16 21:23:27.523819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa755103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37774)[0m 2021-01-16 21:23:27.523858: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37871)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37871)[0m Instructions for updating:
[2m[36m(pid=37871)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37871)[0m LSTM is selected.
[2m[36m(pid=40984)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=40984)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=41160)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=41160)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=41153)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=41153)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=41161)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=41159)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=41155)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=41161)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=41159)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=41155)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=41158)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=41158)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=37871)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37871)[0m Instructions for updating:
[2m[36m(pid=37871)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37775)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37775)[0m 2021-01-16 21:23:28.508516: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37775)[0m 2021-01-16 21:23:28.518953: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37775)[0m 2021-01-16 21:23:28.521340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd049102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37775)[0m 2021-01-16 21:23:28.521366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37871)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37871)[0m 2021-01-16 21:23:29.151095: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37871)[0m 2021-01-16 21:23:29.159842: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37871)[0m 2021-01-16 21:23:29.162250: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a39103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37871)[0m 2021-01-16 21:23:29.162279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37652)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=37652)[0m   agg_primitives: ['count']
[2m[36m(pid=37652)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=37652)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=37652)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=37652)[0m Instructions for updating:
[2m[36m(pid=37652)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=37652)[0m LSTM is selected.
[2m[36m(pid=37652)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=37652)[0m Instructions for updating:
[2m[36m(pid=37652)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=37861)[0m 2021-01-16 21:23:30,497	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37861)[0m Traceback (most recent call last):
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37861)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37861)[0m     param_dset[:] = val
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37861)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37861)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37861)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37861)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=37861)[0m , filename = '/tmp/thalvari/4565627/automl_save_tut75uk5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f08464cf348, total write size = 48344, bytes this sub-write = 48344, bytes actually written = 18446744073709551615, offset = 135168)
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37861)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37861)[0m Traceback (most recent call last):
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37861)[0m     self._entrypoint()
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37861)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37861)[0m     output = train_func(config, reporter)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37861)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37861)[0m     config=config)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37861)[0m     model.save(model_path, config_path)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37861)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37861)[0m     self.model.save(model_path)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37861)[0m     signatures)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37861)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37861)[0m     f.close()
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37861)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37861)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=37861)[0m , filename = '/tmp/thalvari/4565627/automl_save_tut75uk5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f084542bb80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37861)[0m Exception in thread Thread-1:
[2m[36m(pid=37861)[0m Traceback (most recent call last):
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37861)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37861)[0m     param_dset[:] = val
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37861)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37861)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37861)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37861)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=37861)[0m , filename = '/tmp/thalvari/4565627/automl_save_tut75uk5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f08464cf348, total write size = 48344, bytes this sub-write = 48344, bytes actually written = 18446744073709551615, offset = 135168)
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37861)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37861)[0m Traceback (most recent call last):
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37861)[0m     self._entrypoint()
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37861)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37861)[0m     output = train_func(config, reporter)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37861)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37861)[0m     config=config)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37861)[0m     model.save(model_path, config_path)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37861)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37861)[0m     self.model.save(model_path)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37861)[0m     signatures)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37861)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37861)[0m     f.close()
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37861)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37861)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37861)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=37861)[0m , filename = '/tmp/thalvari/4565627/automl_save_tut75uk5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f084542bb80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37861)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37861)[0m Traceback (most recent call last):
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37861)[0m     self.run()
[2m[36m(pid=37861)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37861)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37861)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37652)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=37652)[0m 2021-01-16 21:23:31.404213: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=37652)[0m 2021-01-16 21:23:31.415472: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=37652)[0m 2021-01-16 21:23:31.418906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f867d102ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=37652)[0m 2021-01-16 21:23:31.418946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:23:31,609	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37861, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:31,614	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.59084,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.847,lstm_2_units_float=67.575,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 102 ({'TERMINATED': 15, 'ERROR': 78, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 72 not shown
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.36336,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.601,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-05bulg0s0o/error_2021-01-16_21-23-21.txt
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.934,lstm_2_units_float=67.555,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-08zmoyw6xh/error_2021-01-16_21-23-25.txt
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.59084,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.847,lstm_2_units_float=67.575,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-152ctpmbys/error_2021-01-16_21-23-31.txt
RUNNING trials:
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.58872,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.571,past_seq_len=2:	RUNNING
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.899,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.68587,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.896,lstm_2_units_float=67.57,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_100_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.592,past_seq_len=2:	RUNNING
 - train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34831,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.893,lstm_2_units_float=67.575,past_seq_len=2:	RUNNING
 - train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84961,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.557,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=37861)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37861)[0m 
[2m[36m(pid=37861)[0m Stack (most recent call first):
[2m[36m(pid=40818)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=40818)[0m   agg_primitives: ['count']
[2m[36m(pid=40818)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=40818)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=40816)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=40816)[0m   agg_primitives: ['count']
[2m[36m(pid=40816)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=40816)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=40818)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=40818)[0m Instructions for updating:
[2m[36m(pid=40818)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=40818)[0m LSTM is selected.
[2m[36m(pid=40816)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=40816)[0m Instructions for updating:
[2m[36m(pid=40816)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=40816)[0m LSTM is selected.
[2m[36m(pid=40818)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=40818)[0m Instructions for updating:
[2m[36m(pid=40818)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=40816)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=40816)[0m Instructions for updating:
[2m[36m(pid=40816)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=40818)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=40818)[0m 2021-01-16 21:23:34.971211: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=40818)[0m 2021-01-16 21:23:34.983155: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=40818)[0m 2021-01-16 21:23:34.987756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f65e1103860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=40818)[0m 2021-01-16 21:23:34.987799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=40816)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=40816)[0m 2021-01-16 21:23:35.008183: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=40816)[0m 2021-01-16 21:23:35.018697: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=40816)[0m 2021-01-16 21:23:35.023872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4ead103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=40816)[0m 2021-01-16 21:23:35.023909: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37860)[0m 2021-01-16 21:23:35,604	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37860)[0m Traceback (most recent call last):
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37860)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37860)[0m     param_dset[:] = val
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37860)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37860)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37860)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37860)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37860)[0m , filename = '/tmp/thalvari/4565627/automl_save_kgybvp6y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac3a1728e8, total write size = 64728, bytes this sub-write = 64728, bytes actually written = 18446744073709551615, offset = 118784)
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37860)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37860)[0m Traceback (most recent call last):
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37860)[0m     self._entrypoint()
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37860)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37860)[0m     output = train_func(config, reporter)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37860)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37860)[0m     config=config)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37860)[0m     model.save(model_path, config_path)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37860)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37860)[0m     self.model.save(model_path)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37860)[0m     signatures)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37860)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37860)[0m     f.close()
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37860)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37860)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37860)[0m , filename = '/tmp/thalvari/4565627/automl_save_kgybvp6y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac3a4e03b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37860)[0m Exception in thread Thread-1:
[2m[36m(pid=37860)[0m Traceback (most recent call last):
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37860)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37860)[0m     param_dset[:] = val
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37860)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37860)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37860)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37860)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37860)[0m , filename = '/tmp/thalvari/4565627/automl_save_kgybvp6y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac3a1728e8, total write size = 64728, bytes this sub-write = 64728, bytes actually written = 18446744073709551615, offset = 118784)
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37860)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37860)[0m Traceback (most recent call last):
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37860)[0m     self._entrypoint()
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37860)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37860)[0m     output = train_func(config, reporter)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37860)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37860)[0m     config=config)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37860)[0m     model.save(model_path, config_path)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37860)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37860)[0m     self.model.save(model_path)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37860)[0m     signatures)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37860)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37860)[0m     f.close()
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37860)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37860)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37860)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37860)[0m , filename = '/tmp/thalvari/4565627/automl_save_kgybvp6y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac3a4e03b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37860)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37860)[0m Traceback (most recent call last):
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37860)[0m     self.run()
[2m[36m(pid=37860)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37860)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37860)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37874)[0m 2021-01-16 21:23:35,712	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37874)[0m Traceback (most recent call last):
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37874)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37874)[0m     param_dset[:] = val
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37874)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37874)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37874)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37874)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37874)[0m , filename = '/tmp/thalvari/4565627/automl_save_vw07l12c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eef1672ebf8, total write size = 64728, bytes this sub-write = 64728, bytes actually written = 18446744073709551615, offset = 118784)
[2m[36m(pid=37874)[0m 
[2m[36m(pid=37874)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37874)[0m 
[2m[36m(pid=37874)[0m Traceback (most recent call last):
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37874)[0m     self._entrypoint()
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37874)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37874)[0m     output = train_func(config, reporter)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37874)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37874)[0m     config=config)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37874)[0m     model.save(model_path, config_path)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37874)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37874)[0m     self.model.save(model_path)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37874)[0m     signatures)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37874)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37874)[0m     f.close()
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37874)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37874)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37874)[0m , filename = '/tmp/thalvari/4565627/automl_save_vw07l12c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eef1568e180, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37874)[0m Exception in thread Thread-1:
[2m[36m(pid=37874)[0m Traceback (most recent call last):
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37874)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37874)[0m     param_dset[:] = val
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37874)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37874)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37874)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37874)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37874)[0m , filename = '/tmp/thalvari/4565627/automl_save_vw07l12c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eef1672ebf8, total write size = 64728, bytes this sub-write = 64728, bytes actually written = 18446744073709551615, offset = 118784)
[2m[36m(pid=37874)[0m 
[2m[36m(pid=37874)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37874)[0m 
[2m[36m(pid=37874)[0m Traceback (most recent call last):
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37874)[0m     self._entrypoint()
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37874)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37874)[0m     output = train_func(config, reporter)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37874)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37874)[0m     config=config)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37874)[0m     model.save(model_path, config_path)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37874)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37874)[0m     self.model.save(model_path)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37874)[0m     signatures)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37874)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37874)[0m     f.close()
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37874)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37874)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37874)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:35 2021
[2m[36m(pid=37874)[0m , filename = '/tmp/thalvari/4565627/automl_save_vw07l12c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eef1568e180, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37874)[0m 
[2m[36m(pid=37874)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37874)[0m 
[2m[36m(pid=37874)[0m Traceback (most recent call last):
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37874)[0m     self.run()
[2m[36m(pid=37874)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37874)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37874)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37874)[0m 
[2m[36m(pid=41158)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=41158)[0m   agg_primitives: ['count']
[2m[36m(pid=41158)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=41158)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:23:36,709	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37860, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:36,721	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.899,lstm_2_units_float=67.568,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 103 ({'TERMINATED': 15, 'ERROR': 79, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 73 not shown
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.934,lstm_2_units_float=67.555,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-08zmoyw6xh/error_2021-01-16_21-23-25.txt
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.59084,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.847,lstm_2_units_float=67.575,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-152ctpmbys/error_2021-01-16_21-23-31.txt
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.899,lstm_2_units_float=67.568,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-21m1iljgix/error_2021-01-16_21-23-36.txt
RUNNING trials:
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.58872,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.571,past_seq_len=2:	RUNNING
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.68587,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.896,lstm_2_units_float=67.57,past_seq_len=2:	RUNNING
 - train_func_97_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.8899,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.937,lstm_2_units_float=67.562,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34831,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.893,lstm_2_units_float=67.575,past_seq_len=2:	RUNNING
 - train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84961,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.557,past_seq_len=2:	RUNNING
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.906,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=41158)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=41158)[0m Instructions for updating:
[2m[36m(pid=41158)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=41158)[0m LSTM is selected.
[2m[36m(pid=37860)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37860)[0m 
[2m[36m(pid=37860)[0m Stack (most recent call first):
[2m[36m(pid=37862)[0m Traceback (most recent call last):
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=37862)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37862)[0m , filename = '/tmp/thalvari/4565627/automl_save_j9nf44zy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f818a3c5a20, total write size = 984, bytes this sub-write = 984, bytes actually written = 18446744073709551615, offset = 102400)
[2m[36m(pid=37862)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=37862)[0m Traceback (most recent call last):
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=37862)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37862)[0m , filename = '/tmp/thalvari/4565627/automl_save_j9nf44zy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f818a3c5a20, total write size = 984, bytes this sub-write = 984, bytes actually written = 18446744073709551615, offset = 102400)
[2m[36m(pid=37862)[0m 2021-01-16 21:23:37,061	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37862)[0m Traceback (most recent call last):
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37862)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37862)[0m     param_dset[:] = val
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37862)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37862)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37862)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37862)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37862)[0m , filename = '/tmp/thalvari/4565627/automl_save_j9nf44zy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f818a2e36a0, total write size = 77184, bytes this sub-write = 77184, bytes actually written = 18446744073709551615, offset = 106328)
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37862)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37862)[0m Traceback (most recent call last):
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37862)[0m     self._entrypoint()
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37862)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37862)[0m     output = train_func(config, reporter)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37862)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37862)[0m     config=config)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37862)[0m     model.save(model_path, config_path)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37862)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37862)[0m     self.model.save(model_path)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37862)[0m     signatures)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37862)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37862)[0m     f.close()
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37862)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37862)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37862)[0m , filename = '/tmp/thalvari/4565627/automl_save_j9nf44zy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f818a2f6c30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37862)[0m Exception in thread Thread-1:
[2m[36m(pid=37862)[0m Traceback (most recent call last):
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37862)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37862)[0m     param_dset[:] = val
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37862)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37862)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37862)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37862)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37862)[0m , filename = '/tmp/thalvari/4565627/automl_save_j9nf44zy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f818a2e36a0, total write size = 77184, bytes this sub-write = 77184, bytes actually written = 18446744073709551615, offset = 106328)
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37862)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37862)[0m Traceback (most recent call last):
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37862)[0m     self._entrypoint()
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37862)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37862)[0m     output = train_func(config, reporter)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37862)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37862)[0m     config=config)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37862)[0m     model.save(model_path, config_path)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37862)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37862)[0m     self.model.save(model_path)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37862)[0m     signatures)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37862)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37862)[0m     f.close()
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37862)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37862)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37862)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37862)[0m , filename = '/tmp/thalvari/4565627/automl_save_j9nf44zy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f818a2f6c30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37862)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37862)[0m Traceback (most recent call last):
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37862)[0m     self.run()
[2m[36m(pid=37862)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37862)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37862)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37774)[0m 2021-01-16 21:23:37,164	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37774)[0m Traceback (most recent call last):
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37774)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37774)[0m     param_dset[:] = val
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37774)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37774)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37774)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37774)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37774)[0m , filename = '/tmp/thalvari/4565627/automl_save_5asvj23d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa756336388, total write size = 3928, bytes this sub-write = 3928, bytes actually written = 18446744073709551615, offset = 98304)
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37774)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37774)[0m Traceback (most recent call last):
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37774)[0m     self._entrypoint()
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37774)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37774)[0m     output = train_func(config, reporter)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37774)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37774)[0m     config=config)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37774)[0m     model.save(model_path, config_path)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37774)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37774)[0m     self.model.save(model_path)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37774)[0m     signatures)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37774)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37774)[0m     f.close()
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37774)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37774)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37774)[0m , filename = '/tmp/thalvari/4565627/automl_save_5asvj23d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7558a4620, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37774)[0m Exception in thread Thread-1:
[2m[36m(pid=37774)[0m Traceback (most recent call last):
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37774)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37774)[0m     param_dset[:] = val
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37774)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37774)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37774)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37774)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37774)[0m , filename = '/tmp/thalvari/4565627/automl_save_5asvj23d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa756336388, total write size = 3928, bytes this sub-write = 3928, bytes actually written = 18446744073709551615, offset = 98304)
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37774)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37774)[0m Traceback (most recent call last):
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37774)[0m     self._entrypoint()
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37774)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37774)[0m     output = train_func(config, reporter)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37774)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37774)[0m     config=config)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37774)[0m     model.save(model_path, config_path)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37774)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37774)[0m     self.model.save(model_path)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37774)[0m     signatures)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37774)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37774)[0m     f.close()
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37774)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37774)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37774)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37774)[0m , filename = '/tmp/thalvari/4565627/automl_save_5asvj23d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7558a4620, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37774)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37774)[0m Traceback (most recent call last):
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37774)[0m     self.run()
[2m[36m(pid=37774)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37774)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37774)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37775)[0m 2021-01-16 21:23:37,447	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37775)[0m Traceback (most recent call last):
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37775)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37775)[0m     param_dset[:] = val
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37775)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37775)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37775)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37775)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37775)[0m , filename = '/tmp/thalvari/4565627/automl_save_nlsmwf52/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd04a7aa1d8, total write size = 12120, bytes this sub-write = 12120, bytes actually written = 18446744073709551615, offset = 90112)
[2m[36m(pid=37775)[0m 
[2m[36m(pid=37775)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37775)[0m 
[2m[36m(pid=37775)[0m Traceback (most recent call last):
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37775)[0m     self._entrypoint()
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37775)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37775)[0m     output = train_func(config, reporter)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37775)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37775)[0m     config=config)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37775)[0m     model.save(model_path, config_path)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37775)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37775)[0m     self.model.save(model_path)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37775)[0m     signatures)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37775)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37775)[0m     f.close()
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37775)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37775)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37775)[0m , filename = '/tmp/thalvari/4565627/automl_save_nlsmwf52/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd049dba860, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37775)[0m Exception in thread Thread-1:
[2m[36m(pid=37775)[0m Traceback (most recent call last):
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37775)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37775)[0m     param_dset[:] = val
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37775)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37775)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37775)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37775)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37775)[0m , filename = '/tmp/thalvari/4565627/automl_save_nlsmwf52/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd04a7aa1d8, total write size = 12120, bytes this sub-write = 12120, bytes actually written = 18446744073709551615, offset = 90112)
[2m[36m(pid=37775)[0m 
[2m[36m(pid=37775)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37775)[0m 
[2m[36m(pid=37775)[0m Traceback (most recent call last):
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37775)[0m     self._entrypoint()
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37775)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37775)[0m     output = train_func(config, reporter)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37775)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37775)[0m     config=config)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37775)[0m     model.save(model_path, config_path)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37775)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37775)[0m     self.model.save(model_path)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37775)[0m     signatures)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37775)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37775)[0m     f.close()
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37775)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37775)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37775)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:37 2021
[2m[36m(pid=37775)[0m , filename = '/tmp/thalvari/4565627/automl_save_nlsmwf52/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd049dba860, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37775)[0m 
[2m[36m(pid=37775)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37775)[0m 
[2m[36m(pid=37775)[0m Traceback (most recent call last):
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37775)[0m     self.run()
[2m[36m(pid=37775)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37775)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37775)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37775)[0m 
2021-01-16 21:23:37,565	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37874, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

[2m[36m(pid=41158)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=41158)[0m Instructions for updating:
[2m[36m(pid=41158)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:23:37,569	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.58872,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.895,lstm_2_units_float=67.571,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37874)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37874)[0m 
[2m[36m(pid=37874)[0m Stack (most recent call first):
2021-01-16 21:23:38,379	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37774, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:38,382	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_97_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.8899,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.937,lstm_2_units_float=67.562,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37871)[0m 2021-01-16 21:23:38,362	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37871)[0m Traceback (most recent call last):
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37871)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37871)[0m     param_dset[:] = val
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37871)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37871)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37871)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37871)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:38 2021
[2m[36m(pid=37871)[0m , filename = '/tmp/thalvari/4565627/automl_save_c8txjiyg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8a394a37a8, total write size = 20312, bytes this sub-write = 20312, bytes actually written = 18446744073709551615, offset = 81920)
[2m[36m(pid=37871)[0m 
[2m[36m(pid=37871)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37871)[0m 
[2m[36m(pid=37871)[0m Traceback (most recent call last):
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37871)[0m     self._entrypoint()
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37871)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37871)[0m     output = train_func(config, reporter)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37871)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37871)[0m     config=config)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37871)[0m     model.save(model_path, config_path)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37871)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37871)[0m     self.model.save(model_path)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37871)[0m     signatures)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37871)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37871)[0m     f.close()
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37871)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37871)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:38 2021
[2m[36m(pid=37871)[0m , filename = '/tmp/thalvari/4565627/automl_save_c8txjiyg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8a3a3f9040, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37871)[0m Exception in thread Thread-1:
[2m[36m(pid=37871)[0m Traceback (most recent call last):
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37871)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37871)[0m     param_dset[:] = val
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37871)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37871)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37871)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37871)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:38 2021
[2m[36m(pid=37871)[0m , filename = '/tmp/thalvari/4565627/automl_save_c8txjiyg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8a394a37a8, total write size = 20312, bytes this sub-write = 20312, bytes actually written = 18446744073709551615, offset = 81920)
[2m[36m(pid=37871)[0m 
[2m[36m(pid=37871)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37871)[0m 
[2m[36m(pid=37871)[0m Traceback (most recent call last):
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37871)[0m     self._entrypoint()
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37871)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37871)[0m     output = train_func(config, reporter)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37871)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37871)[0m     config=config)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37871)[0m     model.save(model_path, config_path)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37871)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37871)[0m     self.model.save(model_path)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37871)[0m     signatures)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37871)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37871)[0m     f.close()
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37871)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37871)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37871)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:38 2021
[2m[36m(pid=37871)[0m , filename = '/tmp/thalvari/4565627/automl_save_c8txjiyg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8a3a3f9040, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37871)[0m 
[2m[36m(pid=37871)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37871)[0m 
[2m[36m(pid=37871)[0m Traceback (most recent call last):
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37871)[0m     self.run()
[2m[36m(pid=37871)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37871)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37871)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37871)[0m 
[2m[36m(pid=41158)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=41158)[0m 2021-01-16 21:23:38.544046: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=41158)[0m 2021-01-16 21:23:38.555027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=41158)[0m 2021-01-16 21:23:38.560810: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f946d103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=41158)[0m 2021-01-16 21:23:38.560844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=37774)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37774)[0m 
[2m[36m(pid=37774)[0m Stack (most recent call first):
2021-01-16 21:23:39,170	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37862, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:39,173	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.68587,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.896,lstm_2_units_float=67.57,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37862)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37862)[0m 
[2m[36m(pid=37862)[0m Stack (most recent call first):
2021-01-16 21:23:39,743	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37775, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:39,746	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_98_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37724,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.83972,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.954,lstm_2_units_float=67.574,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37775)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37775)[0m 
[2m[36m(pid=37775)[0m Stack (most recent call first):
2021-01-16 21:23:40,555	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37871, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:40,558	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_99_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.98346,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.915,lstm_2_units_float=67.571,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37652)[0m 2021-01-16 21:23:40,629	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=37652)[0m Traceback (most recent call last):
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37652)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37652)[0m     param_dset[:] = val
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37652)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37652)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37652)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37652)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:40 2021
[2m[36m(pid=37652)[0m , filename = '/tmp/thalvari/4565627/automl_save_5unzlx_1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f867e1d7228, total write size = 28504, bytes this sub-write = 28504, bytes actually written = 18446744073709551615, offset = 73728)
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37652)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37652)[0m Traceback (most recent call last):
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37652)[0m     self._entrypoint()
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37652)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37652)[0m     output = train_func(config, reporter)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37652)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37652)[0m     config=config)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37652)[0m     model.save(model_path, config_path)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37652)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37652)[0m     self.model.save(model_path)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37652)[0m     signatures)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37652)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37652)[0m     f.close()
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37652)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37652)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:40 2021
[2m[36m(pid=37652)[0m , filename = '/tmp/thalvari/4565627/automl_save_5unzlx_1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f867ddb87d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37652)[0m Exception in thread Thread-1:
[2m[36m(pid=37652)[0m Traceback (most recent call last):
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=37652)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=37652)[0m     param_dset[:] = val
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=37652)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=37652)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=37652)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=37652)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:40 2021
[2m[36m(pid=37652)[0m , filename = '/tmp/thalvari/4565627/automl_save_5unzlx_1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f867e1d7228, total write size = 28504, bytes this sub-write = 28504, bytes actually written = 18446744073709551615, offset = 73728)
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37652)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37652)[0m Traceback (most recent call last):
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=37652)[0m     self._entrypoint()
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=37652)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=37652)[0m     output = train_func(config, reporter)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=37652)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=37652)[0m     config=config)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=37652)[0m     model.save(model_path, config_path)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=37652)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=37652)[0m     self.model.save(model_path)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=37652)[0m     signatures)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=37652)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=37652)[0m     f.close()
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=37652)[0m     h5i.dec_ref(id_)
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=37652)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=37652)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:40 2021
[2m[36m(pid=37652)[0m , filename = '/tmp/thalvari/4565627/automl_save_5unzlx_1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f867ddb87d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37652)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37652)[0m Traceback (most recent call last):
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=37652)[0m     self.run()
[2m[36m(pid=37652)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=37652)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=37652)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37871)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37871)[0m 
[2m[36m(pid=37871)[0m Stack (most recent call first):
[2m[36m(pid=41159)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=41159)[0m   agg_primitives: ['count']
[2m[36m(pid=41159)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=41159)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=41161)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=41161)[0m   agg_primitives: ['count']
[2m[36m(pid=41161)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=41161)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:23:41,694	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=37652, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:41,697	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_100_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.592,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=37652)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=37652)[0m 
[2m[36m(pid=37652)[0m Stack (most recent call first):
[2m[36m(pid=41161)[0m LSTM is selected.
[2m[36m(pid=41161)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=41161)[0m Instructions for updating:
[2m[36m(pid=41161)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=41159)[0m LSTM is selected.
[2m[36m(pid=41159)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=41159)[0m Instructions for updating:
[2m[36m(pid=41159)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=41155)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=41155)[0m   agg_primitives: ['count']
[2m[36m(pid=41155)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=41155)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=41161)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=41161)[0m Instructions for updating:
[2m[36m(pid=41161)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 110 ({'TERMINATED': 15, 'ERROR': 85, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 79 not shown
 - train_func_98_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37724,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.83972,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.954,lstm_2_units_float=67.574,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_98_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.37724,bayes_feature_IS_AWAKE(datet_2021-01-16_21-23-23vqb08w4w/error_2021-01-16_21-23-39.txt
 - train_func_99_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.98346,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.915,lstm_2_units_float=67.571,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_99_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-249fynr_9g/error_2021-01-16_21-23-40.txt
 - train_func_100_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.946,lstm_2_units_float=67.592,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_100_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-25zsf2ydgf/error_2021-01-16_21-23-41.txt
RUNNING trials:
 - train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34831,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.893,lstm_2_units_float=67.575,past_seq_len=2:	RUNNING
 - train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84961,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.557,past_seq_len=2:	RUNNING
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.906,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_108_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.96505,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.877,lstm_2_units_float=67.599,past_seq_len=2:	RUNNING
 - train_func_109_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.902,lstm_2_units_float=67.583,past_seq_len=2:	RUNNING
 - train_func_110_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.38102,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.63477,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=41159)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=41159)[0m Instructions for updating:
[2m[36m(pid=41159)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=41160)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=41160)[0m   agg_primitives: ['count']
[2m[36m(pid=41160)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=41160)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=41155)[0m LSTM is selected.
[2m[36m(pid=40818)[0m 2021-01-16 21:23:43,017	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=40818)[0m Traceback (most recent call last):
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=40818)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=40818)[0m     param_dset[:] = val
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=40818)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=40818)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=40818)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=40818)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40818)[0m , filename = '/tmp/thalvari/4565627/automl_save__xj_7d98/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f65e25873c8, total write size = 44888, bytes this sub-write = 44888, bytes actually written = 18446744073709551615, offset = 57344)
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40818)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40818)[0m Traceback (most recent call last):
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=40818)[0m     self._entrypoint()
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=40818)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=40818)[0m     output = train_func(config, reporter)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=40818)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=40818)[0m     config=config)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=40818)[0m     model.save(model_path, config_path)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=40818)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=40818)[0m     self.model.save(model_path)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=40818)[0m     signatures)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=40818)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=40818)[0m     f.close()
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=40818)[0m     h5i.dec_ref(id_)
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=40818)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40818)[0m , filename = '/tmp/thalvari/4565627/automl_save__xj_7d98/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f65e22ce350, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=40818)[0m Exception in thread Thread-1:
[2m[36m(pid=40818)[0m Traceback (most recent call last):
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=40818)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=40818)[0m     param_dset[:] = val
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=40818)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=40818)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=40818)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=40818)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40818)[0m , filename = '/tmp/thalvari/4565627/automl_save__xj_7d98/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f65e25873c8, total write size = 44888, bytes this sub-write = 44888, bytes actually written = 18446744073709551615, offset = 57344)
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40818)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40818)[0m Traceback (most recent call last):
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=40818)[0m     self._entrypoint()
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=40818)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=40818)[0m     output = train_func(config, reporter)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=40818)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=40818)[0m     config=config)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=40818)[0m     model.save(model_path, config_path)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=40818)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=40818)[0m     self.model.save(model_path)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=40818)[0m     signatures)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=40818)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=40818)[0m     f.close()
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=40818)[0m     h5i.dec_ref(id_)
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40818)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=40818)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40818)[0m , filename = '/tmp/thalvari/4565627/automl_save__xj_7d98/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f65e22ce350, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=41155)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=41155)[0m Instructions for updating:
[2m[36m(pid=41155)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40818)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40818)[0m Traceback (most recent call last):
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=40818)[0m     self.run()
[2m[36m(pid=40818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=40818)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=40818)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40816)[0m 2021-01-16 21:23:43,074	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=40816)[0m Traceback (most recent call last):
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=40816)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=40816)[0m     param_dset[:] = val
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=40816)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=40816)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=40816)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=40816)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40816)[0m , filename = '/tmp/thalvari/4565627/automl_save_i60lkbxt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4ead5bfc58, total write size = 44888, bytes this sub-write = 44888, bytes actually written = 18446744073709551615, offset = 57344)
[2m[36m(pid=40816)[0m 
[2m[36m(pid=40816)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40816)[0m 
[2m[36m(pid=40816)[0m Traceback (most recent call last):
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=40816)[0m     self._entrypoint()
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=40816)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=40816)[0m     output = train_func(config, reporter)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=40816)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=40816)[0m     config=config)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=40816)[0m     model.save(model_path, config_path)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=40816)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=40816)[0m     self.model.save(model_path)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=40816)[0m     signatures)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=40816)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=40816)[0m     f.close()
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=40816)[0m     h5i.dec_ref(id_)
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=40816)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40816)[0m , filename = '/tmp/thalvari/4565627/automl_save_i60lkbxt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4eae340580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=40816)[0m Exception in thread Thread-1:
[2m[36m(pid=40816)[0m Traceback (most recent call last):
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=40816)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=40816)[0m     param_dset[:] = val
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=40816)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=40816)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=40816)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=40816)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40816)[0m , filename = '/tmp/thalvari/4565627/automl_save_i60lkbxt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4ead5bfc58, total write size = 44888, bytes this sub-write = 44888, bytes actually written = 18446744073709551615, offset = 57344)
[2m[36m(pid=40816)[0m 
[2m[36m(pid=40816)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40816)[0m 
[2m[36m(pid=40816)[0m Traceback (most recent call last):
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=40816)[0m     self._entrypoint()
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=40816)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=40816)[0m     output = train_func(config, reporter)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=40816)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=40816)[0m     config=config)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=40816)[0m     model.save(model_path, config_path)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=40816)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=40816)[0m     self.model.save(model_path)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=40816)[0m     signatures)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=40816)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=40816)[0m     f.close()
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=40816)[0m     h5i.dec_ref(id_)
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=40816)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=40816)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:43 2021
[2m[36m(pid=40816)[0m , filename = '/tmp/thalvari/4565627/automl_save_i60lkbxt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4eae340580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=40816)[0m 
[2m[36m(pid=40816)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40816)[0m 
[2m[36m(pid=40816)[0m Traceback (most recent call last):
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=40816)[0m     self.run()
[2m[36m(pid=40816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=40816)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=40816)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=40816)[0m 
[2m[36m(pid=41160)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=41160)[0m Instructions for updating:
[2m[36m(pid=41160)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=41160)[0m LSTM is selected.
[2m[36m(pid=41161)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=41161)[0m 2021-01-16 21:23:43.486669: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=41161)[0m 2021-01-16 21:23:43.494417: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=41161)[0m 2021-01-16 21:23:43.496698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9601103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=41161)[0m 2021-01-16 21:23:43.496726: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=41155)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=41155)[0m Instructions for updating:
[2m[36m(pid=41155)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=41159)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=41159)[0m 2021-01-16 21:23:43.550355: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=41159)[0m 2021-01-16 21:23:43.557905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=41159)[0m 2021-01-16 21:23:43.560104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1f29103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=41159)[0m 2021-01-16 21:23:43.560133: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=41153)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=41153)[0m   agg_primitives: ['count']
[2m[36m(pid=41153)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=41153)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=41160)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=41160)[0m Instructions for updating:
[2m[36m(pid=41160)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:23:44,073	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=40818, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:44,076	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84961,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.557,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=40943)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=40943)[0m   agg_primitives: ['count']
[2m[36m(pid=40943)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=40943)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=40818)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=40818)[0m 
[2m[36m(pid=40818)[0m Stack (most recent call first):
[2m[36m(pid=41155)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=41155)[0m 2021-01-16 21:23:44.443776: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=41153)[0m LSTM is selected.
[2m[36m(pid=41155)[0m 2021-01-16 21:23:44.451153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=41155)[0m 2021-01-16 21:23:44.453278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faf9d103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=41155)[0m 2021-01-16 21:23:44.453306: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=41153)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=41153)[0m Instructions for updating:
[2m[36m(pid=41153)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=40943)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=40943)[0m Instructions for updating:
[2m[36m(pid=40943)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=40943)[0m LSTM is selected.
[2m[36m(pid=41160)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=41160)[0m 2021-01-16 21:23:44.854264: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=41160)[0m 2021-01-16 21:23:44.861927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=41160)[0m 2021-01-16 21:23:44.865085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe939103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=41160)[0m 2021-01-16 21:23:44.865141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=41153)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=41153)[0m Instructions for updating:
[2m[36m(pid=41153)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:23:45,066	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=40816, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:45,069	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34831,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.893,lstm_2_units_float=67.575,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=40816)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=40816)[0m 
[2m[36m(pid=40816)[0m Stack (most recent call first):
[2m[36m(pid=40943)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=40943)[0m Instructions for updating:
[2m[36m(pid=40943)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=40984)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=40984)[0m   agg_primitives: ['count']
[2m[36m(pid=40984)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=40984)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=41153)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=41153)[0m 2021-01-16 21:23:46.075980: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=41153)[0m 2021-01-16 21:23:46.084066: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=41153)[0m 2021-01-16 21:23:46.087713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcbd103220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=41153)[0m 2021-01-16 21:23:46.087740: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=40984)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=40984)[0m Instructions for updating:
[2m[36m(pid=40984)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=40984)[0m LSTM is selected.
[2m[36m(pid=40943)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=40943)[0m 2021-01-16 21:23:46.322061: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=40943)[0m 2021-01-16 21:23:46.332337: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=40943)[0m 2021-01-16 21:23:46.336188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f40f5103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=40943)[0m 2021-01-16 21:23:46.336219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=40984)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=40984)[0m Instructions for updating:
[2m[36m(pid=40984)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=43329)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=43329)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=41158)[0m 2021-01-16 21:23:47,305	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=41158)[0m Traceback (most recent call last):
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=41158)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=41158)[0m     param_dset[:] = val
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=41158)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=41158)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=41158)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=41158)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:47 2021
[2m[36m(pid=41158)[0m , filename = '/tmp/thalvari/4565627/automl_save_n58neg89/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f946dda7bc8, total write size = 61272, bytes this sub-write = 61272, bytes actually written = 18446744073709551615, offset = 40960)
[2m[36m(pid=41158)[0m 
[2m[36m(pid=41158)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41158)[0m 
[2m[36m(pid=41158)[0m Traceback (most recent call last):
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41158)[0m     self._entrypoint()
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41158)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41158)[0m     output = train_func(config, reporter)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41158)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41158)[0m     config=config)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=41158)[0m     model.save(model_path, config_path)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=41158)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=41158)[0m     self.model.save(model_path)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=41158)[0m     signatures)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=41158)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=41158)[0m     f.close()
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=41158)[0m     h5i.dec_ref(id_)
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=41158)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:47 2021
[2m[36m(pid=41158)[0m , filename = '/tmp/thalvari/4565627/automl_save_n58neg89/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f946e62f360, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=41158)[0m Exception in thread Thread-1:
[2m[36m(pid=41158)[0m Traceback (most recent call last):
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=41158)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=41158)[0m     param_dset[:] = val
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=41158)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=41158)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=41158)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=41158)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:47 2021
[2m[36m(pid=41158)[0m , filename = '/tmp/thalvari/4565627/automl_save_n58neg89/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f946dda7bc8, total write size = 61272, bytes this sub-write = 61272, bytes actually written = 18446744073709551615, offset = 40960)
[2m[36m(pid=41158)[0m 
[2m[36m(pid=41158)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41158)[0m 
[2m[36m(pid=41158)[0m Traceback (most recent call last):
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41158)[0m     self._entrypoint()
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41158)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41158)[0m     output = train_func(config, reporter)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41158)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41158)[0m     config=config)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=41158)[0m     model.save(model_path, config_path)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=41158)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=41158)[0m     self.model.save(model_path)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=41158)[0m     signatures)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=41158)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=41158)[0m     f.close()
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=41158)[0m     h5i.dec_ref(id_)
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41158)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=41158)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:47 2021
[2m[36m(pid=41158)[0m , filename = '/tmp/thalvari/4565627/automl_save_n58neg89/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f946e62f360, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=41158)[0m 
[2m[36m(pid=41158)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41158)[0m 
[2m[36m(pid=41158)[0m Traceback (most recent call last):
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=41158)[0m     self.run()
[2m[36m(pid=41158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=41158)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=41158)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=41158)[0m 
[2m[36m(pid=40984)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=40984)[0m 2021-01-16 21:23:47.785046: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=40984)[0m 2021-01-16 21:23:47.795371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=40984)[0m 2021-01-16 21:23:47.798712: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1071103080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=40984)[0m 2021-01-16 21:23:47.798750: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=43622)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=43622)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-16 21:23:48,364	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=41158, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:48,369	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.906,lstm_2_units_float=67.568,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 112 ({'TERMINATED': 15, 'ERROR': 88, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 82 not shown
 - train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34831,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.893,lstm_2_units_float=67.575,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34831,bayes_feature_IS_AWAKE(date_2021-01-16_21-23-25uszzt47a/error_2021-01-16_21-23-45.txt
 - train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84961,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.557,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-26iofwgqzq/error_2021-01-16_21-23-44.txt
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.906,lstm_2_units_float=67.568,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-32b76kkc05/error_2021-01-16_21-23-48.txt
RUNNING trials:
 - train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.89778,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.9,lstm_2_units_float=67.571,past_seq_len=2:	RUNNING
 - train_func_105_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.48614,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.86188,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.903,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
 - train_func_106_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.36348,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.919,lstm_2_units_float=67.563,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_110_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.38102,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.63477,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
 - train_func_111_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.593,past_seq_len=2:	RUNNING
 - train_func_112_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33241,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.78056,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.559,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=41158)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=41158)[0m 
[2m[36m(pid=41158)[0m Stack (most recent call first):
[2m[36m(pid=40819)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=40819)[0m   agg_primitives: ['count']
[2m[36m(pid=40819)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=40819)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=40819)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=40819)[0m Instructions for updating:
[2m[36m(pid=40819)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=40819)[0m LSTM is selected.
[2m[36m(pid=40819)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=40819)[0m Instructions for updating:
[2m[36m(pid=40819)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=40819)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=40819)[0m 2021-01-16 21:23:51.360568: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=40819)[0m 2021-01-16 21:23:51.373975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=40819)[0m 2021-01-16 21:23:51.378330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f22ad103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=40819)[0m 2021-01-16 21:23:51.378380: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=41161)[0m Traceback (most recent call last):
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=41161)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41161)[0m , filename = '/tmp/thalvari/4565627/automl_save__v0jnyu9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f960219bda0, total write size = 856, bytes this sub-write = 856, bytes actually written = 18446744073709551615, offset = 16384)
[2m[36m(pid=41161)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=41161)[0m Traceback (most recent call last):
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=41161)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41161)[0m , filename = '/tmp/thalvari/4565627/automl_save__v0jnyu9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f960219bda0, total write size = 856, bytes this sub-write = 856, bytes actually written = 18446744073709551615, offset = 16384)
[2m[36m(pid=41161)[0m 2021-01-16 21:23:52,629	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=41161)[0m Traceback (most recent call last):
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=41161)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=41161)[0m     param_dset[:] = val
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=41161)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=41161)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=41161)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=41161)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41161)[0m , filename = '/tmp/thalvari/4565627/automl_save__v0jnyu9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f960148dfe0, total write size = 82944, bytes this sub-write = 82944, bytes actually written = 18446744073709551615, offset = 19288)
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41161)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41161)[0m Traceback (most recent call last):
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41161)[0m     self._entrypoint()
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41161)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41161)[0m     output = train_func(config, reporter)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41161)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41161)[0m     config=config)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=41161)[0m     model.save(model_path, config_path)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=41161)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=41161)[0m     self.model.save(model_path)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=41161)[0m     signatures)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=41161)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=41161)[0m     f.close()
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=41161)[0m     h5i.dec_ref(id_)
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=41161)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41161)[0m , filename = '/tmp/thalvari/4565627/automl_save__v0jnyu9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f960219dac0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=41161)[0m Exception in thread Thread-1:
[2m[36m(pid=41161)[0m Traceback (most recent call last):
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=41161)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=41161)[0m     param_dset[:] = val
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=41161)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=41161)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=41161)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=41161)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41161)[0m , filename = '/tmp/thalvari/4565627/automl_save__v0jnyu9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f960148dfe0, total write size = 82944, bytes this sub-write = 82944, bytes actually written = 18446744073709551615, offset = 19288)
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41161)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41161)[0m Traceback (most recent call last):
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41161)[0m     self._entrypoint()
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41161)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41161)[0m     output = train_func(config, reporter)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41161)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41161)[0m     config=config)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=41161)[0m     model.save(model_path, config_path)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=41161)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=41161)[0m     self.model.save(model_path)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=41161)[0m     signatures)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=41161)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=41161)[0m     f.close()
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=41161)[0m     h5i.dec_ref(id_)
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41161)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=41161)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41161)[0m , filename = '/tmp/thalvari/4565627/automl_save__v0jnyu9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f960219dac0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41161)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41161)[0m Traceback (most recent call last):
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=41161)[0m     self.run()
[2m[36m(pid=41161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=41161)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=41161)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41159)[0m Traceback (most recent call last):
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=41159)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41159)[0m , filename = '/tmp/thalvari/4565627/automl_save_ccd8k3kx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1f2a041670, total write size = 4952, bytes this sub-write = 4952, bytes actually written = 18446744073709551615, offset = 12288)
[2m[36m(pid=41159)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=41159)[0m Traceback (most recent call last):
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=41159)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41159)[0m , filename = '/tmp/thalvari/4565627/automl_save_ccd8k3kx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1f2a041670, total write size = 4952, bytes this sub-write = 4952, bytes actually written = 18446744073709551615, offset = 12288)
[2m[36m(pid=41159)[0m 2021-01-16 21:23:52,782	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=41159)[0m Traceback (most recent call last):
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=41159)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=41159)[0m     param_dset[:] = val
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=41159)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=41159)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=41159)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=41159)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41159)[0m , filename = '/tmp/thalvari/4565627/automl_save_ccd8k3kx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1f293db680, total write size = 82944, bytes this sub-write = 82944, bytes actually written = 18446744073709551615, offset = 19288)
[2m[36m(pid=41159)[0m 
[2m[36m(pid=41159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41159)[0m 
[2m[36m(pid=41159)[0m Traceback (most recent call last):
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41159)[0m     self._entrypoint()
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41159)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41159)[0m     output = train_func(config, reporter)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41159)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41159)[0m     config=config)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=41159)[0m     model.save(model_path, config_path)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=41159)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=41159)[0m     self.model.save(model_path)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=41159)[0m     signatures)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=41159)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=41159)[0m     f.close()
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=41159)[0m     h5i.dec_ref(id_)
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=41159)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41159)[0m , filename = '/tmp/thalvari/4565627/automl_save_ccd8k3kx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1f2a0431d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=41159)[0m Exception in thread Thread-1:
[2m[36m(pid=41159)[0m Traceback (most recent call last):
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=41159)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=41159)[0m     param_dset[:] = val
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=41159)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=41159)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=41159)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=41159)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41159)[0m , filename = '/tmp/thalvari/4565627/automl_save_ccd8k3kx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1f293db680, total write size = 82944, bytes this sub-write = 82944, bytes actually written = 18446744073709551615, offset = 19288)
[2m[36m(pid=41159)[0m 
[2m[36m(pid=41159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41159)[0m 
[2m[36m(pid=41159)[0m Traceback (most recent call last):
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41159)[0m     self._entrypoint()
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41159)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41159)[0m     output = train_func(config, reporter)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41159)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41159)[0m     config=config)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=41159)[0m     model.save(model_path, config_path)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=41159)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=41159)[0m     self.model.save(model_path)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=41159)[0m     signatures)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=41159)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=41159)[0m     f.close()
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=41159)[0m     h5i.dec_ref(id_)
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=41159)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=41159)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:52 2021
[2m[36m(pid=41159)[0m , filename = '/tmp/thalvari/4565627/automl_save_ccd8k3kx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1f2a0431d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=41159)[0m 
[2m[36m(pid=41159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41159)[0m 
[2m[36m(pid=41159)[0m Traceback (most recent call last):
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=41159)[0m     self.run()
[2m[36m(pid=41159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=41159)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=41159)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=41159)[0m 
[2m[36m(pid=43329)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=43329)[0m   agg_primitives: ['count']
[2m[36m(pid=43329)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=43329)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=43622)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=43622)[0m   agg_primitives: ['count']
[2m[36m(pid=43622)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=43622)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=41155)[0m 2021-01-16 21:23:53,281	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=41155)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41155)[0m 
[2m[36m(pid=41155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41155)[0m 
[2m[36m(pid=41155)[0m Traceback (most recent call last):
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41155)[0m     self._entrypoint()
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41155)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41155)[0m     output = train_func(config, reporter)
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41155)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41155)[0m     config=config)
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=41155)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=41155)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=41155)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=41155)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41155)[0m Exception in thread Thread-1:
[2m[36m(pid=41155)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41155)[0m 
[2m[36m(pid=41155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41155)[0m 
[2m[36m(pid=41155)[0m Traceback (most recent call last):
[2m[36m(pid=41155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=43329)[0m LSTM is selected.
[2m[36m(pid=43622)[0m LSTM is selected.
2021-01-16 21:23:53,660	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=41161, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:53,668	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.89778,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.9,lstm_2_units_float=67.571,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=43329)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=43329)[0m Instructions for updating:
[2m[36m(pid=43329)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=43622)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=43622)[0m Instructions for updating:
[2m[36m(pid=43622)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 113 ({'TERMINATED': 15, 'ERROR': 89, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 83 not shown
 - train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.84961,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.557,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-26iofwgqzq/error_2021-01-16_21-23-44.txt
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.906,lstm_2_units_float=67.568,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-32b76kkc05/error_2021-01-16_21-23-48.txt
 - train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.89778,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.9,lstm_2_units_float=67.571,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-373f92910b/error_2021-01-16_21-23-53.txt
RUNNING trials:
 - train_func_105_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.48614,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.86188,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.903,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
 - train_func_106_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.36348,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.919,lstm_2_units_float=67.563,past_seq_len=2:	RUNNING
 - train_func_107_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.566,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_111_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.593,past_seq_len=2:	RUNNING
 - train_func_112_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33241,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.78056,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.559,past_seq_len=2:	RUNNING
 - train_func_113_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.904,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

[2m[36m(pid=41161)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=41161)[0m 
[2m[36m(pid=41161)[0m Stack (most recent call first):
[2m[36m(pid=43329)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=43329)[0m Instructions for updating:
[2m[36m(pid=43329)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=43622)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=43622)[0m Instructions for updating:
[2m[36m(pid=43622)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=41160)[0m 2021-01-16 21:23:54,221	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=41160)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41160)[0m 
[2m[36m(pid=41160)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41160)[0m 
[2m[36m(pid=41160)[0m Traceback (most recent call last):
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41160)[0m     self._entrypoint()
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41160)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41160)[0m     output = train_func(config, reporter)
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41160)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41160)[0m     config=config)
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=41160)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=41160)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=41160)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=41160)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41160)[0m Exception in thread Thread-1:
[2m[36m(pid=41160)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41160)[0m 
[2m[36m(pid=41160)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41160)[0m 
[2m[36m(pid=41160)[0m Traceback (most recent call last):
[2m[36m(pid=41160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
2021-01-16 21:23:54,760	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=41155, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:54,763	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_106_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.36348,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.919,lstm_2_units_float=67.563,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=43622)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=43622)[0m 2021-01-16 21:23:55.239466: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=43622)[0m 2021-01-16 21:23:55.248521: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=43622)[0m 2021-01-16 21:23:55.251126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4a691036c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=43622)[0m 2021-01-16 21:23:55.251159: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=41153)[0m 2021-01-16 21:23:55,236	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=41153)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41153)[0m 
[2m[36m(pid=41153)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41153)[0m 
[2m[36m(pid=41153)[0m Traceback (most recent call last):
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=41153)[0m     self._entrypoint()
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=41153)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=41153)[0m     output = train_func(config, reporter)
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=41153)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=41153)[0m     config=config)
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=41153)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=41153)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=41153)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=41153)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41153)[0m Exception in thread Thread-1:
[2m[36m(pid=41153)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=41153)[0m 
[2m[36m(pid=41153)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=41153)[0m 
[2m[36m(pid=41153)[0m Traceback (most recent call last):
[2m[36m(pid=41153)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=43329)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=43329)[0m 2021-01-16 21:23:55.332514: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=43329)[0m 2021-01-16 21:23:55.340902: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=43329)[0m 2021-01-16 21:23:55.344417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8779103220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=43329)[0m 2021-01-16 21:23:55.344452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:23:55,571	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=41160, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:55,574	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_107_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.566,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=40943)[0m 2021-01-16 21:23:55,622	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=40943)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40943)[0m 
[2m[36m(pid=40943)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40943)[0m 
[2m[36m(pid=40943)[0m Traceback (most recent call last):
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=40943)[0m     self._entrypoint()
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=40943)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=40943)[0m     output = train_func(config, reporter)
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=40943)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=40943)[0m     config=config)
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=40943)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=40943)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=40943)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=40943)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40943)[0m Exception in thread Thread-1:
[2m[36m(pid=40943)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40943)[0m 
[2m[36m(pid=40943)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40943)[0m 
[2m[36m(pid=40943)[0m Traceback (most recent call last):
[2m[36m(pid=40943)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
2021-01-16 21:23:56,430	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=41159, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:56,433	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_105_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.48614,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.86188,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.903,lstm_2_units_float=67.568,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=41159)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=41159)[0m 
[2m[36m(pid=41159)[0m Stack (most recent call first):
[2m[36m(pid=40984)[0m 2021-01-16 21:23:57,052	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=40984)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40984)[0m 
[2m[36m(pid=40984)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40984)[0m 
[2m[36m(pid=40984)[0m Traceback (most recent call last):
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=40984)[0m     self._entrypoint()
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=40984)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=40984)[0m     output = train_func(config, reporter)
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=40984)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=40984)[0m     config=config)
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=40984)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=40984)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=40984)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=40984)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40984)[0m Exception in thread Thread-1:
[2m[36m(pid=40984)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40984)[0m 
[2m[36m(pid=40984)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40984)[0m 
[2m[36m(pid=40984)[0m Traceback (most recent call last):
[2m[36m(pid=40984)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
2021-01-16 21:23:57,327	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=40943, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:57,330	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_109_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.902,lstm_2_units_float=67.583,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:23:58,015	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=41153, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:58,018	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_108_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.96505,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.877,lstm_2_units_float=67.599,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 13.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 119 ({'TERMINATED': 15, 'ERROR': 94, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 88 not shown
 - train_func_107_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.566,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_107_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-39kgxukqj1/error_2021-01-16_21-23-55.txt
 - train_func_108_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.96505,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.877,lstm_2_units_float=67.599,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_108_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-40wc8xayv9/error_2021-01-16_21-23-58.txt
 - train_func_109_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.902,lstm_2_units_float=67.583,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_109_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-41bzaitolz/error_2021-01-16_21-23-57.txt
RUNNING trials:
 - train_func_110_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.38102,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.63477,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.568,past_seq_len=2:	RUNNING
 - train_func_111_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.593,past_seq_len=2:	RUNNING
 - train_func_112_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33241,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.78056,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.559,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_117_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.567,past_seq_len=2:	RUNNING
 - train_func_118_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.93958,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.567,past_seq_len=2:	RUNNING
 - train_func_119_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.898,lstm_2_units_float=67.566,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

2021-01-16 21:23:58,923	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=40984, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:58,927	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_110_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.38102,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.63477,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.568,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=40819)[0m 2021-01-16 21:24:00,171	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=40819)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40819)[0m 
[2m[36m(pid=40819)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40819)[0m 
[2m[36m(pid=40819)[0m Traceback (most recent call last):
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=40819)[0m     self._entrypoint()
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=40819)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=40819)[0m     output = train_func(config, reporter)
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=40819)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=40819)[0m     config=config)
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=40819)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=40819)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=40819)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=40819)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40819)[0m Exception in thread Thread-1:
[2m[36m(pid=40819)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=40819)[0m 
[2m[36m(pid=40819)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=40819)[0m 
[2m[36m(pid=40819)[0m Traceback (most recent call last):
[2m[36m(pid=40819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
2021-01-16 21:24:01,248	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=40819, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:01,251	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_111_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.593,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=43622)[0m 2021-01-16 21:24:03,697	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=43622)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=43622)[0m 
[2m[36m(pid=43622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=43622)[0m 
[2m[36m(pid=43622)[0m Traceback (most recent call last):
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=43622)[0m     self._entrypoint()
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=43622)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=43622)[0m     output = train_func(config, reporter)
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=43622)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=43622)[0m     config=config)
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=43622)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=43622)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=43622)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=43622)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=43622)[0m Exception in thread Thread-1:
[2m[36m(pid=43622)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=43622)[0m 
[2m[36m(pid=43622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=43622)[0m 
[2m[36m(pid=43622)[0m Traceback (most recent call last):
[2m[36m(pid=43622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=43329)[0m 2021-01-16 21:24:04,320	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=43329)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=43329)[0m 
[2m[36m(pid=43329)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=43329)[0m 
[2m[36m(pid=43329)[0m Traceback (most recent call last):
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=43329)[0m     self._entrypoint()
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=43329)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=43329)[0m     output = train_func(config, reporter)
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=43329)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=43329)[0m     config=config)
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=43329)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=43329)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=43329)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=43329)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=43329)[0m Exception in thread Thread-1:
[2m[36m(pid=43329)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=43329)[0m 
[2m[36m(pid=43329)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=43329)[0m 
[2m[36m(pid=43329)[0m Traceback (most recent call last):
[2m[36m(pid=43329)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
2021-01-16 21:24:04,712	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=43622, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:04,714	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_113_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.904,lstm_2_units_float=67.568,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_qxprf6nj/automl
Number of trials: 121 ({'TERMINATED': 15, 'ERROR': 97, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-20-43pp8cpn53/error_2021-01-16_21-20-57.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(_2021-01-16_21-20-43dmm63zzi/error_2021-01-16_21-20-57.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE_2021-01-16_21-20-43gkdc0ll8/error_2021-01-16_21-20-58.txt
  ... 91 not shown
 - train_func_110_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.38102,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.63477,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.897,lstm_2_units_float=67.568,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_110_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.38102,bayes_feature_IS_AWAKE(date_2021-01-16_21-23-42alcga_as/error_2021-01-16_21-23-58.txt
 - train_func_111_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.914,lstm_2_units_float=67.593,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_111_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-45jc9c85u1/error_2021-01-16_21-24-01.txt
 - train_func_113_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.904,lstm_2_units_float=67.568,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_qxprf6nj/automl/train_func_113_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-4935zt552y/error_2021-01-16_21-24-04.txt
RUNNING trials:
 - train_func_112_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33241,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.78056,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.559,past_seq_len=2:	RUNNING
 - train_func_114_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.34659,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.80467,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.912,lstm_2_units_float=67.562,past_seq_len=2:	RUNNING
 - train_func_115_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.892,lstm_2_units_float=67.602,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_119_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.898,lstm_2_units_float=67.566,past_seq_len=2:	RUNNING
 - train_func_120_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.893,lstm_2_units_float=67.596,past_seq_len=2:	RUNNING
 - train_func_121_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.883,lstm_2_units_float=67.56,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19620], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19651], 34 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=19653], 23 s, 5 iter
  ... 9 not shown
 - train_func_49_batch_size_log=9.9445,bayes_feature_DAY(datetime)=0.5446,bayes_feature_HOUR(datetime)=0.49206,bayes_feature_IS_AWAKE(datetime)=0.52466,bayes_feature_IS_BUSY_HOURS(datetime)=0.65152,bayes_feature_IS_WEEKEND(datetime)=0.38586,bayes_feature_MONTH(datetime)=0.34603,bayes_feature_WEEKDAY(datetime)=0.55513,dropout_1=0.25102,dropout_2=0.32516,epochs=5,lr=0.0038662,lstm_1_units_float=40.57,lstm_2_units_float=22.627,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=21425], 10 s, 5 iter
 - train_func_64_batch_size_log=7.7091,bayes_feature_DAY(datetime)=0.89132,bayes_feature_HOUR(datetime)=0.92813,bayes_feature_IS_AWAKE(datetime)=0.31957,bayes_feature_IS_BUSY_HOURS(datetime)=0.3483,bayes_feature_IS_WEEKEND(datetime)=0.77001,bayes_feature_MONTH(datetime)=0.32818,bayes_feature_WEEKDAY(datetime)=0.46059,dropout_1=0.34204,dropout_2=0.22242,epochs=5,lr=0.0052931,lstm_1_units_float=29.163,lstm_2_units_float=24.168,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=31153], 12 s, 5 iter
 - train_func_74_batch_size_log=8.0234,bayes_feature_DAY(datetime)=0.61156,bayes_feature_HOUR(datetime)=0.49637,bayes_feature_IS_AWAKE(datetime)=0.4923,bayes_feature_IS_BUSY_HOURS(datetime)=0.41317,bayes_feature_IS_WEEKEND(datetime)=0.89295,bayes_feature_MONTH(datetime)=0.77945,bayes_feature_WEEKDAY(datetime)=0.59708,dropout_1=0.34608,dropout_2=0.20902,epochs=5,lr=0.0081178,lstm_1_units_float=24.498,lstm_2_units_float=15.482,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=35438], 11 s, 5 iter

2021-01-16 21:24:05,365	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=43329, host=r02c14.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:05,367	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_112_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.33241,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.78056,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=72.918,lstm_2_units_float=67.559,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-17 04:25:01,423	ERROR worker.py:1672 -- The reporter on node r02c14.bullx failed with the following error:
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/78808/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 176, in run
    self.perform_iteration()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 165, in perform_iteration
    stats = self.get_all_stats()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 156, in get_all_stats
    "workers": self.get_workers(),
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in get_workers
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in <listcomp>
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/__init__.py", line 634, in name
    name = self._proc.name()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1610, in name
    name = self._parse_stat_file()['name']
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=78808)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 218, in <module>
    reporter.run()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 178, in run
    traceback.print_exc()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 105, in print_exception
    print(line, file=file, end="")
OSError: [Errno 28] No space left on device

