Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
Adding /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.8.1-jar-with-dependencies.jar to BIGDL_JARS
Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
Current pyspark location is : /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/__init__.py
Start to getOrCreate SparkContext
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.11-2.4.3.jar) to method java.nio.Bits.unaligned()
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2021-01-16 21:23:14 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).

User settings:

   KMP_AFFINITY=granularity=fine,compact,1,0
   KMP_BLOCKTIME=0
   KMP_DUPLICATE_LIB_OK=True
   KMP_INIT_AT_FORK=FALSE
   KMP_SETTINGS=1
   OMP_NUM_THREADS=40

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=160
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=0
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_HAND_THREAD=false
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=true
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_FORKJOIN_FRAMES=true
   KMP_FORKJOIN_FRAMES_MODE=3
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_INIT_WAIT=2048
   KMP_ITT_PREPARE_DELAY=0
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NEXT_WAIT=1024
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=4M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=40
   KMP_TOPOLOGY_METHOD=all
   KMP_USER_LEVEL_MWAIT=false
   KMP_VERSION=false
   KMP_WARNINGS=true
   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'
   OMP_ALLOCATOR=omp_default_mem_alloc
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_AFFINITY=false
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=2147483647
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED=false
   OMP_NUM_THREADS='40'
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='intel'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=4M
   OMP_TARGET_OFFLOAD=DEFAULT
   OMP_THREAD_LIMIT=2147483647
   OMP_TOOL=enabled
   OMP_TOOL_LIBRARIES: value is not defined
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'

cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
Successfully got a SparkContext
2021-01-16 21:23:16,764	WARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.
2021-01-16 21:23:16,765	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2021-01-16_21-23-16_765033_234088/logs.
2021-01-16 21:23:16,879	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:48787 to respond...
2021-01-16 21:23:16,994	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:17375 to respond...
2021-01-16 21:23:16,995	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2021-01-16 21:23:17,017	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2021-01-16_21-23-16_765033_234088/logs.
2021-01-16 21:23:17,018	WARNING services.py:1298 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2021-01-16 21:23:17,018	INFO services.py:1446 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2021-01-16 21:23:17,472	WARNING bayesopt.py:69 -- `reward_attr` is deprecated and will be removed in a future version of Tune. Setting `metric=reward_metric` and `mode=max`.
2021-01-16 21:23:17,565	INFO tune.py:65 -- Did not find checkpoint file in /scratch/project_2003107/ray_results_1xd7p0gv/automl.
2021-01-16 21:23:17,565	INFO tune.py:233 -- Starting a new experiment.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.2/200.9 GB

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 10 ({'RUNNING': 1, 'PENDING': 9})
PENDING trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	PENDING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	PENDING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	PENDING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	PENDING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	PENDING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	PENDING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	PENDING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	PENDING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	PENDING
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING

[2m[36m(pid=234431)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234426)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234434)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234442)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234409)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234406)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234408)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234433)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234417)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234411)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234415)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234420)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234424)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234431)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234426)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234434)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234430)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234441)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234437)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234436)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234436)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234442)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234409)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234406)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234408)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234433)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234417)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234411)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234415)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234420)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234424)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234429)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234402)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234430)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234422)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234422)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234410)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234405)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234419)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234419)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234423)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234423)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234439)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234425)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234425)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234432)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234414)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234414)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234421)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234421)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234413)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234413)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234428)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234404)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234427)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234403)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234418)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234418)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234441)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234416)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234407)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234435)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234438)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234438)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234437)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234429)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234402)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234407)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234404)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234410)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234405)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234439)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234432)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234428)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234412)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=234412)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234427)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234403)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234416)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234435)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236208)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236215)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236194)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236187)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236203)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236205)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236185)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236185)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236208)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236215)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236194)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236187)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236203)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236214)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236214)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236205)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236201)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236199)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236201)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236199)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=236190)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=236190)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234431)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234431)[0m   agg_primitives: ['count']
[2m[36m(pid=234431)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234431)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234426)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234426)[0m   agg_primitives: ['count']
[2m[36m(pid=234426)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234426)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234434)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234434)[0m   agg_primitives: ['count']
[2m[36m(pid=234434)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234434)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234406)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234406)[0m   agg_primitives: ['count']
[2m[36m(pid=234406)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234406)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234433)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234433)[0m   agg_primitives: ['count']
[2m[36m(pid=234433)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234433)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234417)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234417)[0m   agg_primitives: ['count']
[2m[36m(pid=234417)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234417)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234411)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234411)[0m   agg_primitives: ['count']
[2m[36m(pid=234411)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234411)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234415)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234415)[0m   agg_primitives: ['count']
[2m[36m(pid=234415)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234415)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234420)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234420)[0m   agg_primitives: ['count']
[2m[36m(pid=234420)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234420)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234424)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234424)[0m   agg_primitives: ['count']
[2m[36m(pid=234424)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234424)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234431)[0m LSTM is selected.
[2m[36m(pid=234433)[0m LSTM is selected.
[2m[36m(pid=234417)[0m LSTM is selected.
[2m[36m(pid=234411)[0m LSTM is selected.
[2m[36m(pid=234415)[0m LSTM is selected.
[2m[36m(pid=234424)[0m LSTM is selected.
[2m[36m(pid=234426)[0m LSTM is selected.
[2m[36m(pid=234434)[0m LSTM is selected.
[2m[36m(pid=234406)[0m LSTM is selected.
[2m[36m(pid=234420)[0m LSTM is selected.
[2m[36m(pid=234431)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234431)[0m Instructions for updating:
[2m[36m(pid=234431)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234426)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234426)[0m Instructions for updating:
[2m[36m(pid=234426)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234434)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234434)[0m Instructions for updating:
[2m[36m(pid=234434)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234406)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234406)[0m Instructions for updating:
[2m[36m(pid=234406)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234433)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234433)[0m Instructions for updating:
[2m[36m(pid=234433)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234417)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234417)[0m Instructions for updating:
[2m[36m(pid=234417)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234411)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234411)[0m Instructions for updating:
[2m[36m(pid=234411)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234415)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234415)[0m Instructions for updating:
[2m[36m(pid=234415)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234420)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234420)[0m Instructions for updating:
[2m[36m(pid=234420)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234424)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234424)[0m Instructions for updating:
[2m[36m(pid=234424)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234431)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234431)[0m Instructions for updating:
[2m[36m(pid=234431)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234426)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234426)[0m Instructions for updating:
[2m[36m(pid=234426)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234434)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234434)[0m Instructions for updating:
[2m[36m(pid=234434)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234406)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234406)[0m Instructions for updating:
[2m[36m(pid=234406)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234433)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234433)[0m Instructions for updating:
[2m[36m(pid=234433)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234417)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234417)[0m Instructions for updating:
[2m[36m(pid=234417)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234411)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234411)[0m Instructions for updating:
[2m[36m(pid=234411)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234415)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234415)[0m Instructions for updating:
[2m[36m(pid=234415)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234420)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234420)[0m Instructions for updating:
[2m[36m(pid=234420)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234424)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234424)[0m Instructions for updating:
[2m[36m(pid=234424)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234411)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234424)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234431)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234434)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234406)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234433)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234417)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234417)[0m 2021-01-16 21:23:26.846410: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234411)[0m 2021-01-16 21:23:26.846417: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234415)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234415)[0m 2021-01-16 21:23:26.846415: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234420)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234420)[0m 2021-01-16 21:23:26.846412: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234424)[0m 2021-01-16 21:23:26.846424: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234431)[0m 2021-01-16 21:23:26.846413: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234434)[0m 2021-01-16 21:23:26.846420: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234406)[0m 2021-01-16 21:23:26.846421: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234433)[0m 2021-01-16 21:23:26.846421: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234431)[0m 2021-01-16 21:23:26.867444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234431)[0m 2021-01-16 21:23:26.869463: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f94ad0e65a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234431)[0m 2021-01-16 21:23:26.869484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234426)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234426)[0m 2021-01-16 21:23:26.874816: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234426)[0m 2021-01-16 21:23:26.883096: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234426)[0m 2021-01-16 21:23:26.885477: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3fe10e8620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234426)[0m 2021-01-16 21:23:26.885500: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234434)[0m 2021-01-16 21:23:26.867451: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234434)[0m 2021-01-16 21:23:26.869551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8b10ceee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234434)[0m 2021-01-16 21:23:26.869573: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234406)[0m 2021-01-16 21:23:26.867661: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234406)[0m 2021-01-16 21:23:26.869703: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f08910b1c40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234406)[0m 2021-01-16 21:23:26.869726: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234433)[0m 2021-01-16 21:23:26.867443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234433)[0m 2021-01-16 21:23:26.869380: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f339d0e8900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234433)[0m 2021-01-16 21:23:26.869401: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234417)[0m 2021-01-16 21:23:26.867440: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234417)[0m 2021-01-16 21:23:26.869468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcbc9102300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234417)[0m 2021-01-16 21:23:26.869489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234411)[0m 2021-01-16 21:23:26.867476: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234411)[0m 2021-01-16 21:23:26.869612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3ae911cee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234411)[0m 2021-01-16 21:23:26.869633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234415)[0m 2021-01-16 21:23:26.867448: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234415)[0m 2021-01-16 21:23:26.869388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f327d103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234415)[0m 2021-01-16 21:23:26.869406: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234420)[0m 2021-01-16 21:23:26.867443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234420)[0m 2021-01-16 21:23:26.869420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f41050e5fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234420)[0m 2021-01-16 21:23:26.869441: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234424)[0m 2021-01-16 21:23:26.867447: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234424)[0m 2021-01-16 21:23:26.869612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f81050fdc60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234424)[0m 2021-01-16 21:23:26.869632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:119: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 21.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 10 ({'RUNNING': 10})
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	RUNNING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	RUNNING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	RUNNING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	RUNNING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	RUNNING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234406], 6 s, 1 iter

[2m[36m(pid=234426)[0m 2021-01-16 21:23:30,488	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234426)[0m Traceback (most recent call last):
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234426)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234426)[0m     param_dset[:] = val
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234426)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234426)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234426)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234426)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234426)[0m , filename = '/tmp/thalvari/4565628/automl_save_371mep13/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3fe28ccd88, total write size = 420588, bytes this sub-write = 420588, bytes actually written = 18446744073709551615, offset = 1257472)
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234426)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234426)[0m Traceback (most recent call last):
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234426)[0m     self._entrypoint()
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234426)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234426)[0m     output = train_func(config, reporter)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234426)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234426)[0m     config=config)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234426)[0m     model.save(model_path, config_path)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234426)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234426)[0m     self.model.save(model_path)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234426)[0m     signatures)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234426)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234426)[0m     f.close()
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234426)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234426)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234426)[0m , filename = '/tmp/thalvari/4565628/automl_save_371mep13/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3fe1768f70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234426)[0m Exception in thread Thread-1:
[2m[36m(pid=234426)[0m Traceback (most recent call last):
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234426)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234426)[0m     param_dset[:] = val
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234426)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234426)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234426)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234426)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234426)[0m , filename = '/tmp/thalvari/4565628/automl_save_371mep13/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3fe28ccd88, total write size = 420588, bytes this sub-write = 420588, bytes actually written = 18446744073709551615, offset = 1257472)
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234426)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234426)[0m Traceback (most recent call last):
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234426)[0m     self._entrypoint()
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234426)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234426)[0m     output = train_func(config, reporter)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234426)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234426)[0m     config=config)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234426)[0m     model.save(model_path, config_path)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234426)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234426)[0m     self.model.save(model_path)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234426)[0m     signatures)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234426)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234426)[0m     f.close()
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234426)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234426)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234426)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234426)[0m , filename = '/tmp/thalvari/4565628/automl_save_371mep13/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3fe1768f70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234426)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234426)[0m Traceback (most recent call last):
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234426)[0m     self.run()
[2m[36m(pid=234426)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234426)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234426)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234433)[0m 2021-01-16 21:23:30,581	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234433)[0m Traceback (most recent call last):
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234433)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234433)[0m     param_dset[:] = val
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234433)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234433)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234433)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234433)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234433)[0m , filename = '/tmp/thalvari/4565628/automl_save_294lze2y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f339e894f74, total write size = 172452, bytes this sub-write = 172452, bytes actually written = 18446744073709551615, offset = 2560000)
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234433)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234433)[0m Traceback (most recent call last):
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234433)[0m     self._entrypoint()
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234433)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234433)[0m     output = train_func(config, reporter)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234433)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234433)[0m     config=config)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234433)[0m     model.save(model_path, config_path)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234433)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234433)[0m     self.model.save(model_path)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234433)[0m     signatures)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234433)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234433)[0m     f.close()
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234433)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234433)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234433)[0m , filename = '/tmp/thalvari/4565628/automl_save_294lze2y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f339dd8c760, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234433)[0m Exception in thread Thread-1:
[2m[36m(pid=234433)[0m Traceback (most recent call last):
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234433)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234433)[0m     param_dset[:] = val
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234433)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234433)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234433)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234433)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234433)[0m , filename = '/tmp/thalvari/4565628/automl_save_294lze2y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f339e894f74, total write size = 172452, bytes this sub-write = 172452, bytes actually written = 18446744073709551615, offset = 2560000)
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234433)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234433)[0m Traceback (most recent call last):
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234433)[0m     self._entrypoint()
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234433)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234433)[0m     output = train_func(config, reporter)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234433)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234433)[0m     config=config)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234433)[0m     model.save(model_path, config_path)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234433)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234433)[0m     self.model.save(model_path)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234433)[0m     signatures)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234433)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234433)[0m     f.close()
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234433)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234433)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234433)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234433)[0m , filename = '/tmp/thalvari/4565628/automl_save_294lze2y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f339dd8c760, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234417)[0m 2021-01-16 21:23:30,548	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234417)[0m Traceback (most recent call last):
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234417)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234417)[0m     param_dset[:] = val
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234417)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234417)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234417)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234417)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234417)[0m , filename = '/tmp/thalvari/4565628/automl_save_3xyuih8h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbca70aec4, total write size = 443236, bytes this sub-write = 443236, bytes actually written = 18446744073709551615, offset = 1196032)
[2m[36m(pid=234417)[0m 
[2m[36m(pid=234417)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234417)[0m 
[2m[36m(pid=234417)[0m Traceback (most recent call last):
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234417)[0m     self._entrypoint()
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234417)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234417)[0m     output = train_func(config, reporter)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234417)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234417)[0m     config=config)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234417)[0m     model.save(model_path, config_path)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234417)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234417)[0m     self.model.save(model_path)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234417)[0m     signatures)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234417)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234417)[0m     f.close()
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234417)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234417)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234417)[0m , filename = '/tmp/thalvari/4565628/automl_save_3xyuih8h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbc95eae80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234417)[0m Exception in thread Thread-1:
[2m[36m(pid=234417)[0m Traceback (most recent call last):
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234417)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234417)[0m     param_dset[:] = val
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234417)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234417)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234417)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234417)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234417)[0m , filename = '/tmp/thalvari/4565628/automl_save_3xyuih8h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbca70aec4, total write size = 443236, bytes this sub-write = 443236, bytes actually written = 18446744073709551615, offset = 1196032)
[2m[36m(pid=234417)[0m 
[2m[36m(pid=234417)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234417)[0m 
[2m[36m(pid=234417)[0m Traceback (most recent call last):
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234417)[0m     self._entrypoint()
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234417)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234417)[0m     output = train_func(config, reporter)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234417)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234417)[0m     config=config)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234417)[0m     model.save(model_path, config_path)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234417)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234417)[0m     self.model.save(model_path)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234417)[0m     signatures)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234417)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234417)[0m     f.close()
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234417)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234417)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234417)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:30 2021
[2m[36m(pid=234417)[0m , filename = '/tmp/thalvari/4565628/automl_save_3xyuih8h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbc95eae80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234433)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234433)[0m Traceback (most recent call last):
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234433)[0m     self.run()
[2m[36m(pid=234433)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234433)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234433)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234417)[0m 
[2m[36m(pid=234417)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234417)[0m 
[2m[36m(pid=234417)[0m Traceback (most recent call last):
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234417)[0m     self.run()
[2m[36m(pid=234417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234417)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234417)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234417)[0m 
2021-01-16 21:23:31,601	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234426, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:31,627	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:23:31,662	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234417, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:31,666	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234426)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234426)[0m 
[2m[36m(pid=234426)[0m Stack (most recent call first):
2021-01-16 21:23:31,797	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234433, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:31,802	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234417)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234417)[0m 
[2m[36m(pid=234417)[0m Stack (most recent call first):
[2m[36m(pid=234433)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234433)[0m 
[2m[36m(pid=234433)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 19.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 14 ({'RUNNING': 9, 'ERROR': 3, 'TERMINATED': 2})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234434], 10 s, 2 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234424], 10 s, 4 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234420], 10 s, 1 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234415], 10 s, 2 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234411], 11 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234406], 9 s, 5 iter

[2m[36m(pid=236215)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236215)[0m   agg_primitives: ['count']
[2m[36m(pid=236215)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236215)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236194)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236194)[0m   agg_primitives: ['count']
[2m[36m(pid=236194)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236194)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236214)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236214)[0m   agg_primitives: ['count']
[2m[36m(pid=236214)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236214)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236215)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236215)[0m Instructions for updating:
[2m[36m(pid=236215)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236215)[0m LSTM is selected.
[2m[36m(pid=236194)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236194)[0m Instructions for updating:
[2m[36m(pid=236194)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236194)[0m LSTM is selected.
[2m[36m(pid=236214)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236214)[0m Instructions for updating:
[2m[36m(pid=236214)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236214)[0m LSTM is selected.
[2m[36m(pid=236215)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236215)[0m Instructions for updating:
[2m[36m(pid=236215)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=236194)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236194)[0m Instructions for updating:
[2m[36m(pid=236194)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=236214)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236214)[0m Instructions for updating:
[2m[36m(pid=236214)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=236199)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236199)[0m   agg_primitives: ['count']
[2m[36m(pid=236199)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236199)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236215)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236215)[0m 2021-01-16 21:23:38.120900: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236215)[0m 2021-01-16 21:23:38.130122: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236215)[0m 2021-01-16 21:23:38.133449: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcafd0fdee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236215)[0m 2021-01-16 21:23:38.133483: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236194)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236194)[0m 2021-01-16 21:23:38.129762: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236194)[0m 2021-01-16 21:23:38.139901: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236194)[0m 2021-01-16 21:23:38.143663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f05550b1900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236194)[0m 2021-01-16 21:23:38.143694: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236214)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236214)[0m 2021-01-16 21:23:38.150492: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236214)[0m 2021-01-16 21:23:38.162221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236214)[0m 2021-01-16 21:23:38.166221: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc11911c6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236214)[0m 2021-01-16 21:23:38.166265: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236199)[0m LSTM is selected.
[2m[36m(pid=236199)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236199)[0m Instructions for updating:
[2m[36m(pid=236199)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236205)[0m 2021-01-16 21:23:38,710	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=236205)[0m Traceback (most recent call last):
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236205)[0m     self._entrypoint()
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236205)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236205)[0m     output = train_func(config, reporter)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 307, in train_func
[2m[36m(pid=236205)[0m     (x_train, y_train) = trial_ft.fit_transform(trial_input_df, **config)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 112, in fit_transform
[2m[36m(pid=236205)[0m     self.config = self._get_feat_config(**config)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 348, in _get_feat_config
[2m[36m(pid=236205)[0m     self._check_config(**config)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/abstract.py", line 92, in _check_config
[2m[36m(pid=236205)[0m     "Required parameters are: " + str(self._get_required_parameters()))
[2m[36m(pid=236205)[0m ValueError: Missing required parameters in configuration. Required parameters are: {'selected_features'}
[2m[36m(pid=236205)[0m Exception in thread Thread-1:
[2m[36m(pid=236205)[0m Traceback (most recent call last):
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236205)[0m     self._entrypoint()
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236205)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236205)[0m     output = train_func(config, reporter)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 307, in train_func
[2m[36m(pid=236205)[0m     (x_train, y_train) = trial_ft.fit_transform(trial_input_df, **config)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 112, in fit_transform
[2m[36m(pid=236205)[0m     self.config = self._get_feat_config(**config)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 348, in _get_feat_config
[2m[36m(pid=236205)[0m     self._check_config(**config)
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/abstract.py", line 92, in _check_config
[2m[36m(pid=236205)[0m     "Required parameters are: " + str(self._get_required_parameters()))
[2m[36m(pid=236205)[0m ValueError: Missing required parameters in configuration. Required parameters are: {'selected_features'}
[2m[36m(pid=236205)[0m 
[2m[36m(pid=236205)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236205)[0m 
[2m[36m(pid=236205)[0m Traceback (most recent call last):
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=236205)[0m     self.run()
[2m[36m(pid=236205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=236205)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=236205)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=236205)[0m 
[2m[36m(pid=236199)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236199)[0m Instructions for updating:
[2m[36m(pid=236199)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=236208)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236208)[0m   agg_primitives: ['count']
[2m[36m(pid=236208)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236208)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236208)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236208)[0m Instructions for updating:
[2m[36m(pid=236208)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236208)[0m LSTM is selected.
2021-01-16 21:23:39,916	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=236205, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:39,921	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=236199)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236199)[0m 2021-01-16 21:23:40.065192: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236199)[0m 2021-01-16 21:23:40.082338: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236199)[0m 2021-01-16 21:23:40.089020: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f01f90dd620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236199)[0m 2021-01-16 21:23:40.089073: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236208)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236208)[0m Instructions for updating:
[2m[36m(pid=236208)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 17 ({'RUNNING': 10, 'ERROR': 4, 'TERMINATED': 3})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
 - train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-36gvgxq35n/error_2021-01-16_21-23-39.txt
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234434], 15 s, 4 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234431], 12 s, 1 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234420], 13 s, 2 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234415], 14 s, 4 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	RUNNING
 - train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234411], 11 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234406], 9 s, 5 iter

[2m[36m(pid=236208)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236208)[0m 2021-01-16 21:23:41.448983: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236208)[0m 2021-01-16 21:23:41.459762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236208)[0m 2021-01-16 21:23:41.463826: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f03510e56c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236208)[0m 2021-01-16 21:23:41.463879: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236203)[0m 2021-01-16 21:23:44,342	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=236203)[0m Traceback (most recent call last):
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236203)[0m     self._entrypoint()
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236203)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236203)[0m     output = train_func(config, reporter)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 307, in train_func
[2m[36m(pid=236203)[0m     (x_train, y_train) = trial_ft.fit_transform(trial_input_df, **config)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 112, in fit_transform
[2m[36m(pid=236203)[0m     self.config = self._get_feat_config(**config)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 348, in _get_feat_config
[2m[36m(pid=236203)[0m     self._check_config(**config)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/abstract.py", line 92, in _check_config
[2m[36m(pid=236203)[0m     "Required parameters are: " + str(self._get_required_parameters()))
[2m[36m(pid=236203)[0m ValueError: Missing required parameters in configuration. Required parameters are: {'selected_features'}
[2m[36m(pid=236203)[0m Exception in thread Thread-1:
[2m[36m(pid=236203)[0m Traceback (most recent call last):
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236203)[0m     self._entrypoint()
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236203)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236203)[0m     output = train_func(config, reporter)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 307, in train_func
[2m[36m(pid=236203)[0m     (x_train, y_train) = trial_ft.fit_transform(trial_input_df, **config)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 112, in fit_transform
[2m[36m(pid=236203)[0m     self.config = self._get_feat_config(**config)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 348, in _get_feat_config
[2m[36m(pid=236203)[0m     self._check_config(**config)
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/abstract.py", line 92, in _check_config
[2m[36m(pid=236203)[0m     "Required parameters are: " + str(self._get_required_parameters()))
[2m[36m(pid=236203)[0m ValueError: Missing required parameters in configuration. Required parameters are: {'selected_features'}
[2m[36m(pid=236203)[0m 
[2m[36m(pid=236203)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236203)[0m 
[2m[36m(pid=236203)[0m Traceback (most recent call last):
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=236203)[0m     self.run()
[2m[36m(pid=236203)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=236203)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=236203)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=236203)[0m 
[2m[36m(pid=234429)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234429)[0m   agg_primitives: ['count']
[2m[36m(pid=234429)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234429)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234429)[0m LSTM is selected.
[2m[36m(pid=234429)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234429)[0m Instructions for updating:
[2m[36m(pid=234429)[0m If using Keras pass *_constraint arguments to layers.
2021-01-16 21:23:45,546	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=236203, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:45,551	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234429)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234429)[0m Instructions for updating:
[2m[36m(pid=234429)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 20 ({'TERMINATED': 5, 'ERROR': 5, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
 - train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-36gvgxq35n/error_2021-01-16_21-23-39.txt
 - train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-406ltyj0aq/error_2021-01-16_21-23-45.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234431], 18 s, 2 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234420], 21 s, 4 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236215], 9 s, 3 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236194], 9 s, 1 iter
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236214], 8 s, 1 iter
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236199], 7 s, 2 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236208], 5 s, 1 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	RUNNING
 - train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAKE(datetime)=0.64722,bayes_feature_IS_BUSY_HOURS(datetime)=0.8443,bayes_feature_IS_WEEKEND(datetime)=0.30295,bayes_feature_MONTH(datetime)=0.86154,bayes_feature_WEEKDAY(datetime)=0.76226,dropout_1=0.49104,dropout_2=0.27218,epochs=5,lr=0.008127,lstm_1_units_float=75.835,lstm_2_units_float=127.91,past_seq_len=2:	RUNNING
 - train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAKE(datetime)=0.34674,bayes_feature_IS_BUSY_HOURS(datetime)=0.61846,bayes_feature_IS_WEEKEND(datetime)=0.55889,bayes_feature_MONTH(datetime)=0.42832,bayes_feature_WEEKDAY(datetime)=0.85407,dropout_1=0.28051,dropout_2=0.49745,epochs=5,lr=0.00201,lstm_1_units_float=81.137,lstm_2_units_float=127.95,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234415], 16 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234411], 11 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234406], 9 s, 5 iter

[2m[36m(pid=234429)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234429)[0m 2021-01-16 21:23:46.913235: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234429)[0m 2021-01-16 21:23:46.925825: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234429)[0m 2021-01-16 21:23:46.932272: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8cdd117c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234429)[0m 2021-01-16 21:23:46.932319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234430)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234430)[0m   agg_primitives: ['count']
[2m[36m(pid=234430)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234430)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234430)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234430)[0m Instructions for updating:
[2m[36m(pid=234430)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234430)[0m LSTM is selected.
[2m[36m(pid=234430)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234430)[0m Instructions for updating:
[2m[36m(pid=234430)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234430)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234430)[0m 2021-01-16 21:23:49.732594: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234430)[0m 2021-01-16 21:23:49.747796: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234430)[0m 2021-01-16 21:23:49.755974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef53111d530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234430)[0m 2021-01-16 21:23:49.756027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236187)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236187)[0m   agg_primitives: ['count']
[2m[36m(pid=236187)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236187)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236187)[0m LSTM is selected.
[2m[36m(pid=236187)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236187)[0m Instructions for updating:
[2m[36m(pid=236187)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 24 ({'TERMINATED': 9, 'ERROR': 5, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
 - train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-36gvgxq35n/error_2021-01-16_21-23-39.txt
 - train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-406ltyj0aq/error_2021-01-16_21-23-45.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234431], 25 s, 3 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236194], 9 s, 1 iter
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236214], 13 s, 2 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234429], 6 s, 1 iter
  ... 2 not shown
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0040673,lstm_1_units_float=116.96,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=78.263,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=78.687,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234420], 25 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234415], 16 s, 5 iter
  ... 1 not shown
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234406], 9 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236215], 12 s, 5 iter
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter

[2m[36m(pid=236187)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236187)[0m Instructions for updating:
[2m[36m(pid=236187)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234430)[0m 2021-01-16 21:23:53,009	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234430)[0m Traceback (most recent call last):
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234430)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234430)[0m     param_dset[:] = val
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234430)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234430)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234430)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234430)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:53 2021
[2m[36m(pid=234430)[0m , filename = '/tmp/thalvari/4565628/automl_save_6vfmo52o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef532885d38, total write size = 776444, bytes this sub-write = 776444, bytes actually written = 18446744073709551615, offset = 2551808)
[2m[36m(pid=234430)[0m 
[2m[36m(pid=234430)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234430)[0m 
[2m[36m(pid=234430)[0m Traceback (most recent call last):
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234430)[0m     self._entrypoint()
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234430)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234430)[0m     output = train_func(config, reporter)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234430)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234430)[0m     config=config)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234430)[0m     model.save(model_path, config_path)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234430)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234430)[0m     self.model.save(model_path)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234430)[0m     signatures)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234430)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234430)[0m     f.close()
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234430)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234430)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:53 2021
[2m[36m(pid=234430)[0m , filename = '/tmp/thalvari/4565628/automl_save_6vfmo52o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef532a32090, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234430)[0m Exception in thread Thread-1:
[2m[36m(pid=234430)[0m Traceback (most recent call last):
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234430)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234430)[0m     param_dset[:] = val
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234430)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234430)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234430)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234430)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:53 2021
[2m[36m(pid=234430)[0m , filename = '/tmp/thalvari/4565628/automl_save_6vfmo52o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef532885d38, total write size = 776444, bytes this sub-write = 776444, bytes actually written = 18446744073709551615, offset = 2551808)
[2m[36m(pid=234430)[0m 
[2m[36m(pid=234430)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234430)[0m 
[2m[36m(pid=234430)[0m Traceback (most recent call last):
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234430)[0m     self._entrypoint()
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234430)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234430)[0m     output = train_func(config, reporter)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234430)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234430)[0m     config=config)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234430)[0m     model.save(model_path, config_path)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234430)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234430)[0m     self.model.save(model_path)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234430)[0m     signatures)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234430)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234430)[0m     f.close()
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234430)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234430)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234430)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:53 2021
[2m[36m(pid=234430)[0m , filename = '/tmp/thalvari/4565628/automl_save_6vfmo52o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef532a32090, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234430)[0m 
[2m[36m(pid=234430)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234430)[0m 
[2m[36m(pid=234430)[0m Traceback (most recent call last):
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234430)[0m     self.run()
[2m[36m(pid=234430)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234430)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234430)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234430)[0m 
[2m[36m(pid=236185)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236185)[0m   agg_primitives: ['count']
[2m[36m(pid=236185)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236185)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236187)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236187)[0m 2021-01-16 21:23:53.229427: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236187)[0m 2021-01-16 21:23:53.238077: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236187)[0m 2021-01-16 21:23:53.242131: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8b1102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236187)[0m 2021-01-16 21:23:53.242169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236185)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236185)[0m Instructions for updating:
[2m[36m(pid=236185)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236185)[0m LSTM is selected.
2021-01-16 21:23:54,167	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234430, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:54,170	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAKE(datetime)=0.64722,bayes_feature_IS_BUSY_HOURS(datetime)=0.8443,bayes_feature_IS_WEEKEND(datetime)=0.30295,bayes_feature_MONTH(datetime)=0.86154,bayes_feature_WEEKDAY(datetime)=0.76226,dropout_1=0.49104,dropout_2=0.27218,epochs=5,lr=0.008127,lstm_1_units_float=75.835,lstm_2_units_float=127.91,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=236185)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236185)[0m Instructions for updating:
[2m[36m(pid=236185)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234402)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234402)[0m   agg_primitives: ['count']
[2m[36m(pid=234402)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234402)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234430)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234430)[0m 
[2m[36m(pid=234430)[0m Stack (most recent call first):
[2m[36m(pid=234419)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234419)[0m   agg_primitives: ['count']
[2m[36m(pid=234419)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234419)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234402)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234402)[0m Instructions for updating:
[2m[36m(pid=234402)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234402)[0m LSTM is selected.
[2m[36m(pid=234419)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234419)[0m Instructions for updating:
[2m[36m(pid=234419)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234419)[0m LSTM is selected.
[2m[36m(pid=236185)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236185)[0m 2021-01-16 21:23:55.257331: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236185)[0m 2021-01-16 21:23:55.269797: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236185)[0m 2021-01-16 21:23:55.275999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80b90b4c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236185)[0m 2021-01-16 21:23:55.276049: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234402)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234402)[0m Instructions for updating:
[2m[36m(pid=234402)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234410)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234410)[0m   agg_primitives: ['count']
[2m[36m(pid=234410)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234410)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234419)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234419)[0m Instructions for updating:
[2m[36m(pid=234419)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234410)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234410)[0m Instructions for updating:
[2m[36m(pid=234410)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234410)[0m LSTM is selected.
[2m[36m(pid=234402)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234402)[0m 2021-01-16 21:23:56.378011: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234402)[0m 2021-01-16 21:23:56.386724: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234402)[0m 2021-01-16 21:23:56.389329: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9e109ac60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234402)[0m 2021-01-16 21:23:56.389352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236187)[0m 2021-01-16 21:23:56,387	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=236187)[0m Traceback (most recent call last):
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236187)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236187)[0m     param_dset[:] = val
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236187)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236187)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236187)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236187)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:56 2021
[2m[36m(pid=236187)[0m , filename = '/tmp/thalvari/4565628/automl_save_dlcwewrv/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd8b2a6fb48, total write size = 841820, bytes this sub-write = 841820, bytes actually written = 18446744073709551615, offset = 2539520)
[2m[36m(pid=236187)[0m 
[2m[36m(pid=236187)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236187)[0m 
[2m[36m(pid=236187)[0m Traceback (most recent call last):
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236187)[0m     self._entrypoint()
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236187)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236187)[0m     output = train_func(config, reporter)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236187)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236187)[0m     config=config)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236187)[0m     model.save(model_path, config_path)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236187)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236187)[0m     self.model.save(model_path)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236187)[0m     signatures)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236187)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236187)[0m     f.close()
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236187)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236187)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:56 2021
[2m[36m(pid=236187)[0m , filename = '/tmp/thalvari/4565628/automl_save_dlcwewrv/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd8b24395c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236187)[0m Exception in thread Thread-1:
[2m[36m(pid=236187)[0m Traceback (most recent call last):
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236187)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236187)[0m     param_dset[:] = val
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236187)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236187)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236187)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236187)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:23:56 2021
[2m[36m(pid=236187)[0m , filename = '/tmp/thalvari/4565628/automl_save_dlcwewrv/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd8b2a6fb48, total write size = 841820, bytes this sub-write = 841820, bytes actually written = 18446744073709551615, offset = 2539520)
[2m[36m(pid=236187)[0m 
[2m[36m(pid=236187)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236187)[0m 
[2m[36m(pid=236187)[0m Traceback (most recent call last):
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236187)[0m     self._entrypoint()
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236187)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236187)[0m     output = train_func(config, reporter)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236187)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236187)[0m     config=config)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236187)[0m     model.save(model_path, config_path)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236187)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236187)[0m     self.model.save(model_path)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236187)[0m     signatures)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236187)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236187)[0m     f.close()
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236187)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236187)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236187)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:23:56 2021
[2m[36m(pid=236187)[0m , filename = '/tmp/thalvari/4565628/automl_save_dlcwewrv/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd8b24395c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236187)[0m 
[2m[36m(pid=236187)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236187)[0m 
[2m[36m(pid=236187)[0m Traceback (most recent call last):
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=236187)[0m     self.run()
[2m[36m(pid=236187)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=236187)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=236187)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=236187)[0m 
[2m[36m(pid=234419)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234419)[0m 2021-01-16 21:23:56.607178: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234419)[0m 2021-01-16 21:23:56.615283: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234419)[0m 2021-01-16 21:23:56.618456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f27790e8a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234419)[0m 2021-01-16 21:23:56.618486: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234410)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234410)[0m Instructions for updating:
[2m[36m(pid=234410)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:23:57,510	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=236187, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:23:57,515	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAKE(datetime)=0.34674,bayes_feature_IS_BUSY_HOURS(datetime)=0.61846,bayes_feature_IS_WEEKEND(datetime)=0.55889,bayes_feature_MONTH(datetime)=0.42832,bayes_feature_WEEKDAY(datetime)=0.85407,dropout_1=0.28051,dropout_2=0.49745,epochs=5,lr=0.00201,lstm_1_units_float=81.137,lstm_2_units_float=127.95,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 26 ({'TERMINATED': 10, 'ERROR': 7, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
 - train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-36gvgxq35n/error_2021-01-16_21-23-39.txt
 - train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-406ltyj0aq/error_2021-01-16_21-23-45.txt
 - train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAKE(datetime)=0.64722,bayes_feature_IS_BUSY_HOURS(datetime)=0.8443,bayes_feature_IS_WEEKEND(datetime)=0.30295,bayes_feature_MONTH(datetime)=0.86154,bayes_feature_WEEKDAY(datetime)=0.76226,dropout_1=0.49104,dropout_2=0.27218,epochs=5,lr=0.008127,lstm_1_units_float=75.835,lstm_2_units_float=127.91,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAK_2021-01-16_21-23-43c0p7saxk/error_2021-01-16_21-23-54.txt
 - train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAKE(datetime)=0.34674,bayes_feature_IS_BUSY_HOURS(datetime)=0.61846,bayes_feature_IS_WEEKEND(datetime)=0.55889,bayes_feature_MONTH(datetime)=0.42832,bayes_feature_WEEKDAY(datetime)=0.85407,dropout_1=0.28051,dropout_2=0.49745,epochs=5,lr=0.00201,lstm_1_units_float=81.137,lstm_2_units_float=127.95,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAK_2021-01-16_21-23-4660jdm0et/error_2021-01-16_21-23-57.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234431], 31 s, 4 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236194], 15 s, 2 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=234429], 12 s, 4 iter
  ... 3 not shown
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=78.687,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234420], 25 s, 5 iter
  ... 4 not shown
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(datetime)=0.70695,bayes_feature_HOUR(datetime)=0.97901,bayes_feature_IS_AWAKE(datetime)=0.89278,bayes_feature_IS_BUSY_HOURS(datetime)=0.46789,bayes_feature_IS_WEEKEND(datetime)=0.64564,bayes_feature_MONTH(datetime)=0.73397,bayes_feature_WEEKDAY(datetime)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236214], 17 s, 3 iter
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter

[2m[36m(pid=236187)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=236187)[0m 
[2m[36m(pid=236187)[0m Stack (most recent call first):
[2m[36m(pid=234410)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234410)[0m 2021-01-16 21:23:57.700554: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234410)[0m 2021-01-16 21:23:57.709655: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234410)[0m 2021-01-16 21:23:57.713500: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9be10e8a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234410)[0m 2021-01-16 21:23:57.713537: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234405)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234405)[0m   agg_primitives: ['count']
[2m[36m(pid=234405)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234405)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236201)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236201)[0m   agg_primitives: ['count']
[2m[36m(pid=236201)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236201)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234405)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234405)[0m Instructions for updating:
[2m[36m(pid=234405)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234405)[0m LSTM is selected.
[2m[36m(pid=236201)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236201)[0m Instructions for updating:
[2m[36m(pid=236201)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236201)[0m LSTM is selected.
[2m[36m(pid=234405)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234405)[0m Instructions for updating:
[2m[36m(pid=234405)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=236201)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236201)[0m Instructions for updating:
[2m[36m(pid=236201)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234405)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234405)[0m 2021-01-16 21:23:59.867870: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234405)[0m 2021-01-16 21:23:59.880164: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234405)[0m 2021-01-16 21:23:59.888409: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efc59103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234405)[0m 2021-01-16 21:23:59.888444: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236201)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236201)[0m 2021-01-16 21:23:59.987446: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236201)[0m 2021-01-16 21:23:59.998809: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236201)[0m 2021-01-16 21:24:00.002442: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1c590e9080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236201)[0m 2021-01-16 21:24:00.002486: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 29 ({'TERMINATED': 12, 'ERROR': 7, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
 - train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_16_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-36gvgxq35n/error_2021-01-16_21-23-39.txt
 - train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=0.3,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_17_batch_size_log=10.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-406ltyj0aq/error_2021-01-16_21-23-45.txt
 - train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAKE(datetime)=0.64722,bayes_feature_IS_BUSY_HOURS(datetime)=0.8443,bayes_feature_IS_WEEKEND(datetime)=0.30295,bayes_feature_MONTH(datetime)=0.86154,bayes_feature_WEEKDAY(datetime)=0.76226,dropout_1=0.49104,dropout_2=0.27218,epochs=5,lr=0.008127,lstm_1_units_float=75.835,lstm_2_units_float=127.91,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAK_2021-01-16_21-23-43c0p7saxk/error_2021-01-16_21-23-54.txt
 - train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAKE(datetime)=0.34674,bayes_feature_IS_BUSY_HOURS(datetime)=0.61846,bayes_feature_IS_WEEKEND(datetime)=0.55889,bayes_feature_MONTH(datetime)=0.42832,bayes_feature_WEEKDAY(datetime)=0.85407,dropout_1=0.28051,dropout_2=0.49745,epochs=5,lr=0.00201,lstm_1_units_float=81.137,lstm_2_units_float=127.95,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAK_2021-01-16_21-23-4660jdm0et/error_2021-01-16_21-23-57.txt
RUNNING trials:
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236194], 21 s, 3 iter
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0040673,lstm_1_units_float=116.96,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_28_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.117,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 6 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=234418)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234418)[0m   agg_primitives: ['count']
[2m[36m(pid=234418)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234418)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234435)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234435)[0m   agg_primitives: ['count']
[2m[36m(pid=234435)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234435)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234418)[0m LSTM is selected.
[2m[36m(pid=234435)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234435)[0m Instructions for updating:
[2m[36m(pid=234435)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234435)[0m LSTM is selected.
[2m[36m(pid=234418)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234418)[0m Instructions for updating:
[2m[36m(pid=234418)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234418)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234418)[0m Instructions for updating:
[2m[36m(pid=234418)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234435)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234435)[0m Instructions for updating:
[2m[36m(pid=234435)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234418)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234418)[0m 2021-01-16 21:24:05.050669: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234418)[0m 2021-01-16 21:24:05.063255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234418)[0m 2021-01-16 21:24:05.067302: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3c850cefb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234418)[0m 2021-01-16 21:24:05.067345: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234435)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234435)[0m 2021-01-16 21:24:05.043936: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234435)[0m 2021-01-16 21:24:05.057546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234435)[0m 2021-01-16 21:24:05.063713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3590e6620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234435)[0m 2021-01-16 21:24:05.063758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=236185)[0m 2021-01-16 21:24:07,219	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=236185)[0m Traceback (most recent call last):
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236185)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236185)[0m     param_dset[:] = val
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236185)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236185)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236185)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236185)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:07 2021
[2m[36m(pid=236185)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lrq2kcn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f80ba8441ac, total write size = 95860, bytes this sub-write = 95860, bytes actually written = 18446744073709551615, offset = 2531328)
[2m[36m(pid=236185)[0m 
[2m[36m(pid=236185)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236185)[0m 
[2m[36m(pid=236185)[0m Traceback (most recent call last):
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236185)[0m     self._entrypoint()
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236185)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236185)[0m     output = train_func(config, reporter)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236185)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236185)[0m     config=config)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236185)[0m     model.save(model_path, config_path)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236185)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236185)[0m     self.model.save(model_path)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236185)[0m     signatures)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236185)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236185)[0m     f.close()
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236185)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236185)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:07 2021
[2m[36m(pid=236185)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lrq2kcn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f80ba4ba010, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236185)[0m Exception in thread Thread-1:
[2m[36m(pid=236185)[0m Traceback (most recent call last):
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236185)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236185)[0m     param_dset[:] = val
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236185)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236185)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236185)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236185)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:07 2021
[2m[36m(pid=236185)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lrq2kcn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f80ba8441ac, total write size = 95860, bytes this sub-write = 95860, bytes actually written = 18446744073709551615, offset = 2531328)
[2m[36m(pid=236185)[0m 
[2m[36m(pid=236185)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236185)[0m 
[2m[36m(pid=236185)[0m Traceback (most recent call last):
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236185)[0m     self._entrypoint()
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236185)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236185)[0m     output = train_func(config, reporter)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236185)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236185)[0m     config=config)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236185)[0m     model.save(model_path, config_path)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236185)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236185)[0m     self.model.save(model_path)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236185)[0m     signatures)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236185)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236185)[0m     f.close()
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236185)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236185)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236185)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:07 2021
[2m[36m(pid=236185)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lrq2kcn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f80ba4ba010, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236185)[0m 
[2m[36m(pid=236185)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236185)[0m 
[2m[36m(pid=236185)[0m Traceback (most recent call last):
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=236185)[0m     self.run()
[2m[36m(pid=236185)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=236185)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=236185)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=236185)[0m 
[2m[36m(pid=234407)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234407)[0m   agg_primitives: ['count']
[2m[36m(pid=234407)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234407)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234407)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234407)[0m Instructions for updating:
[2m[36m(pid=234407)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234407)[0m LSTM is selected.
2021-01-16 21:24:08,311	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=236185, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:08,316	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0040673,lstm_1_units_float=116.96,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 19.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 29 ({'TERMINATED': 12, 'ERROR': 8, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 2 not shown
 - train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAKE(datetime)=0.64722,bayes_feature_IS_BUSY_HOURS(datetime)=0.8443,bayes_feature_IS_WEEKEND(datetime)=0.30295,bayes_feature_MONTH(datetime)=0.86154,bayes_feature_WEEKDAY(datetime)=0.76226,dropout_1=0.49104,dropout_2=0.27218,epochs=5,lr=0.008127,lstm_1_units_float=75.835,lstm_2_units_float=127.91,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_19_batch_size_log=9.1153,bayes_feature_DAY(datetime)=0.65996,bayes_feature_HOUR(datetime)=0.70262,bayes_feature_IS_AWAK_2021-01-16_21-23-43c0p7saxk/error_2021-01-16_21-23-54.txt
 - train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAKE(datetime)=0.34674,bayes_feature_IS_BUSY_HOURS(datetime)=0.61846,bayes_feature_IS_WEEKEND(datetime)=0.55889,bayes_feature_MONTH(datetime)=0.42832,bayes_feature_WEEKDAY(datetime)=0.85407,dropout_1=0.28051,dropout_2=0.49745,epochs=5,lr=0.00201,lstm_1_units_float=81.137,lstm_2_units_float=127.95,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_20_batch_size_log=9.2462,bayes_feature_DAY(datetime)=0.85976,bayes_feature_HOUR(datetime)=0.93672,bayes_feature_IS_AWAK_2021-01-16_21-23-4660jdm0et/error_2021-01-16_21-23-57.txt
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0040673,lstm_1_units_float=116.96,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-48er_2pudu/error_2021-01-16_21-24-08.txt
RUNNING trials:
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=236194], 29 s, 4 iter
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=78.263,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_28_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.117,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 6 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=234419)[0m 2021-01-16 21:24:08,286	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234419)[0m Traceback (most recent call last):
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234419)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234419)[0m     param_dset[:] = val
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234419)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234419)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234419)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234419)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234419)[0m , filename = '/tmp/thalvari/4565628/automl_save_6u1i0x5j/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f277aaaa3cc, total write size = 868404, bytes this sub-write = 868404, bytes actually written = 18446744073709551615, offset = 2510848)
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234419)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234419)[0m Traceback (most recent call last):
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234419)[0m     self._entrypoint()
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234419)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234419)[0m     output = train_func(config, reporter)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234419)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234419)[0m     config=config)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234419)[0m     model.save(model_path, config_path)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234419)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234419)[0m     self.model.save(model_path)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234419)[0m     signatures)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234419)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234419)[0m     f.close()
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234419)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234419)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234419)[0m , filename = '/tmp/thalvari/4565628/automl_save_6u1i0x5j/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f277aa045d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234419)[0m Exception in thread Thread-1:
[2m[36m(pid=234419)[0m Traceback (most recent call last):
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234419)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234419)[0m     param_dset[:] = val
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234419)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234419)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234419)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234419)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234419)[0m , filename = '/tmp/thalvari/4565628/automl_save_6u1i0x5j/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f277aaaa3cc, total write size = 868404, bytes this sub-write = 868404, bytes actually written = 18446744073709551615, offset = 2510848)
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234419)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234419)[0m Traceback (most recent call last):
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234419)[0m     self._entrypoint()
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234419)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234419)[0m     output = train_func(config, reporter)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234419)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234419)[0m     config=config)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234419)[0m     model.save(model_path, config_path)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234419)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234419)[0m     self.model.save(model_path)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234419)[0m     signatures)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234419)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234419)[0m     f.close()
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234419)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234419)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234419)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234419)[0m , filename = '/tmp/thalvari/4565628/automl_save_6u1i0x5j/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f277aa045d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234419)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234419)[0m Traceback (most recent call last):
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234419)[0m     self.run()
[2m[36m(pid=234419)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234419)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234419)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234402)[0m 2021-01-16 21:24:08,440	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234402)[0m Traceback (most recent call last):
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234402)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234402)[0m     param_dset[:] = val
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234402)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234402)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234402)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234402)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234402)[0m , filename = '/tmp/thalvari/4565628/automl_save_da8s1y8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9e29dcb48, total write size = 968280, bytes this sub-write = 968280, bytes actually written = 18446744073709551615, offset = 983040)
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234402)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234402)[0m Traceback (most recent call last):
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234402)[0m     self._entrypoint()
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234402)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234402)[0m     output = train_func(config, reporter)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234402)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234402)[0m     config=config)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234402)[0m     model.save(model_path, config_path)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234402)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234402)[0m     self.model.save(model_path)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234402)[0m     signatures)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234402)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234402)[0m     f.close()
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234402)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234402)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234402)[0m , filename = '/tmp/thalvari/4565628/automl_save_da8s1y8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9e16dbfa0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234402)[0m Exception in thread Thread-1:
[2m[36m(pid=234402)[0m Traceback (most recent call last):
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234402)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234402)[0m     param_dset[:] = val
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234402)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234402)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234402)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234402)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234402)[0m , filename = '/tmp/thalvari/4565628/automl_save_da8s1y8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9e29dcb48, total write size = 968280, bytes this sub-write = 968280, bytes actually written = 18446744073709551615, offset = 983040)
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234402)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234402)[0m Traceback (most recent call last):
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234402)[0m     self._entrypoint()
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234402)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234402)[0m     output = train_func(config, reporter)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234402)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234402)[0m     config=config)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234402)[0m     model.save(model_path, config_path)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234402)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234402)[0m     self.model.save(model_path)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234402)[0m     signatures)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234402)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234402)[0m     f.close()
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234402)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234402)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234402)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234402)[0m , filename = '/tmp/thalvari/4565628/automl_save_da8s1y8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc9e16dbfa0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236185)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=236185)[0m 
[2m[36m(pid=236185)[0m Stack (most recent call first):
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234402)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234402)[0m Traceback (most recent call last):
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234402)[0m     self.run()
[2m[36m(pid=234402)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234402)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234402)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234435)[0m 2021-01-16 21:24:08,538	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234435)[0m Traceback (most recent call last):
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234435)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234435)[0m     param_dset[:] = val
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234435)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234435)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234435)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234435)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234435)[0m , filename = '/tmp/thalvari/4565628/automl_save_q8yyvflm/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd35aa34bfc, total write size = 539332, bytes this sub-write = 539332, bytes actually written = 18446744073709551615, offset = 2506752)
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234435)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234435)[0m Traceback (most recent call last):
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234435)[0m     self._entrypoint()
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234435)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234435)[0m     output = train_func(config, reporter)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234435)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234435)[0m     config=config)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234435)[0m     model.save(model_path, config_path)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234435)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234435)[0m     self.model.save(model_path)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234435)[0m     signatures)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234435)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234435)[0m     f.close()
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234435)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234435)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234435)[0m , filename = '/tmp/thalvari/4565628/automl_save_q8yyvflm/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd35a1de340, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234435)[0m Exception in thread Thread-1:
[2m[36m(pid=234435)[0m Traceback (most recent call last):
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234435)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234435)[0m     param_dset[:] = val
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234435)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234435)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234435)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234435)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234435)[0m , filename = '/tmp/thalvari/4565628/automl_save_q8yyvflm/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd35aa34bfc, total write size = 539332, bytes this sub-write = 539332, bytes actually written = 18446744073709551615, offset = 2506752)
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234435)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234435)[0m Traceback (most recent call last):
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234435)[0m     self._entrypoint()
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234435)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234435)[0m     output = train_func(config, reporter)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234435)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234435)[0m     config=config)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234435)[0m     model.save(model_path, config_path)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234435)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234435)[0m     self.model.save(model_path)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234435)[0m     signatures)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234435)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234435)[0m     f.close()
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234435)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234435)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234435)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:08 2021
[2m[36m(pid=234435)[0m , filename = '/tmp/thalvari/4565628/automl_save_q8yyvflm/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd35a1de340, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234435)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234435)[0m Traceback (most recent call last):
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234435)[0m     self.run()
[2m[36m(pid=234435)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234435)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234435)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234407)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234407)[0m Instructions for updating:
[2m[36m(pid=234407)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:09,330	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234419, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:09,333	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_23_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=78.263,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234410)[0m 2021-01-16 21:24:09,320	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234410)[0m Traceback (most recent call last):
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234410)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234410)[0m     param_dset[:] = val
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234410)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234410)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234410)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234410)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:09 2021
[2m[36m(pid=234410)[0m , filename = '/tmp/thalvari/4565628/automl_save_gaisw44i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9be2a3e72c, total write size = 876596, bytes this sub-write = 876596, bytes actually written = 18446744073709551615, offset = 2502656)
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234410)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234410)[0m Traceback (most recent call last):
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234410)[0m     self._entrypoint()
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234410)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234410)[0m     output = train_func(config, reporter)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234410)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234410)[0m     config=config)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234410)[0m     model.save(model_path, config_path)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234410)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234410)[0m     self.model.save(model_path)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234410)[0m     signatures)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234410)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234410)[0m     f.close()
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234410)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234410)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:09 2021
[2m[36m(pid=234410)[0m , filename = '/tmp/thalvari/4565628/automl_save_gaisw44i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9be1533800, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234410)[0m Exception in thread Thread-1:
[2m[36m(pid=234410)[0m Traceback (most recent call last):
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234410)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234410)[0m     param_dset[:] = val
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234410)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234410)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234410)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234410)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:09 2021
[2m[36m(pid=234410)[0m , filename = '/tmp/thalvari/4565628/automl_save_gaisw44i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9be2a3e72c, total write size = 876596, bytes this sub-write = 876596, bytes actually written = 18446744073709551615, offset = 2502656)
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234410)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234410)[0m Traceback (most recent call last):
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234410)[0m     self._entrypoint()
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234410)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234410)[0m     output = train_func(config, reporter)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234410)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234410)[0m     config=config)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234410)[0m     model.save(model_path, config_path)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234410)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234410)[0m     self.model.save(model_path)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234410)[0m     signatures)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234410)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234410)[0m     f.close()
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234410)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234410)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234410)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:09 2021
[2m[36m(pid=234410)[0m , filename = '/tmp/thalvari/4565628/automl_save_gaisw44i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9be1533800, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234410)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234410)[0m Traceback (most recent call last):
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234410)[0m     self.run()
[2m[36m(pid=234410)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234410)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234410)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234419)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234419)[0m 
[2m[36m(pid=234419)[0m Stack (most recent call first):
[2m[36m(pid=234407)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234407)[0m 2021-01-16 21:24:09.771670: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234407)[0m 2021-01-16 21:24:09.781204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234407)[0m 2021-01-16 21:24:09.785160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82890e6080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234407)[0m 2021-01-16 21:24:09.785202: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:24:09,993	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234435, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:09,996	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_28_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.117,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234435)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234435)[0m 
[2m[36m(pid=234435)[0m Stack (most recent call first):
2021-01-16 21:24:10,793	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234402, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:10,797	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234402)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234402)[0m 
[2m[36m(pid=234402)[0m Stack (most recent call first):
[2m[36m(pid=234405)[0m 2021-01-16 21:24:12,057	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234405)[0m Traceback (most recent call last):
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234405)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234405)[0m     param_dset[:] = val
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234405)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234405)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234405)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234405)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234405)[0m , filename = '/tmp/thalvari/4565628/automl_save_25rodo_a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efc5a8002dc, total write size = 30964, bytes this sub-write = 30964, bytes actually written = 18446744073709551615, offset = 2490368)
[2m[36m(pid=234405)[0m 
[2m[36m(pid=234405)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234405)[0m 
[2m[36m(pid=234405)[0m Traceback (most recent call last):
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234405)[0m     self._entrypoint()
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234405)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234405)[0m     output = train_func(config, reporter)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234405)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234405)[0m     config=config)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234405)[0m     model.save(model_path, config_path)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234405)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234405)[0m     self.model.save(model_path)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234405)[0m     signatures)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234405)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234405)[0m     f.close()
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234405)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234405)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234405)[0m , filename = '/tmp/thalvari/4565628/automl_save_25rodo_a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efc5959ac50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234405)[0m Exception in thread Thread-1:
[2m[36m(pid=234405)[0m Traceback (most recent call last):
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234405)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234405)[0m     param_dset[:] = val
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234405)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234405)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234405)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234405)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234405)[0m , filename = '/tmp/thalvari/4565628/automl_save_25rodo_a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efc5a8002dc, total write size = 30964, bytes this sub-write = 30964, bytes actually written = 18446744073709551615, offset = 2490368)
[2m[36m(pid=234405)[0m 
[2m[36m(pid=234405)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234405)[0m 
[2m[36m(pid=234405)[0m Traceback (most recent call last):
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234405)[0m     self._entrypoint()
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234405)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234405)[0m     output = train_func(config, reporter)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234405)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234405)[0m     config=config)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234405)[0m     model.save(model_path, config_path)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234405)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234405)[0m     self.model.save(model_path)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234405)[0m     signatures)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234405)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234405)[0m     f.close()
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234405)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234405)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234405)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234405)[0m , filename = '/tmp/thalvari/4565628/automl_save_25rodo_a/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efc5959ac50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234405)[0m 
[2m[36m(pid=234405)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234405)[0m 
[2m[36m(pid=234405)[0m Traceback (most recent call last):
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234405)[0m     self.run()
[2m[36m(pid=234405)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234405)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234405)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234405)[0m 
2021-01-16 21:24:12,100	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234410, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:12,104	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_24_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=78.687,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234410)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234410)[0m 
[2m[36m(pid=234410)[0m Stack (most recent call first):
[2m[36m(pid=236201)[0m 2021-01-16 21:24:12,610	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=236201)[0m Traceback (most recent call last):
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236201)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236201)[0m     param_dset[:] = val
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236201)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236201)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236201)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236201)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=236201)[0m , filename = '/tmp/thalvari/4565628/automl_save_2o545_zl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1c5a7b428c, total write size = 30964, bytes this sub-write = 30964, bytes actually written = 18446744073709551615, offset = 2486272)
[2m[36m(pid=236201)[0m 
[2m[36m(pid=236201)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236201)[0m 
[2m[36m(pid=236201)[0m Traceback (most recent call last):
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236201)[0m     self._entrypoint()
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236201)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236201)[0m     output = train_func(config, reporter)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236201)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236201)[0m     config=config)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236201)[0m     model.save(model_path, config_path)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236201)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236201)[0m     self.model.save(model_path)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236201)[0m     signatures)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236201)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236201)[0m     f.close()
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236201)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236201)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=236201)[0m , filename = '/tmp/thalvari/4565628/automl_save_2o545_zl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1c5a54f910, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236201)[0m Exception in thread Thread-1:
[2m[36m(pid=236201)[0m Traceback (most recent call last):
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236201)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236201)[0m     param_dset[:] = val
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236201)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236201)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236201)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236201)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=236201)[0m , filename = '/tmp/thalvari/4565628/automl_save_2o545_zl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1c5a7b428c, total write size = 30964, bytes this sub-write = 30964, bytes actually written = 18446744073709551615, offset = 2486272)
[2m[36m(pid=236201)[0m 
[2m[36m(pid=236201)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236201)[0m 
[2m[36m(pid=236201)[0m Traceback (most recent call last):
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236201)[0m     self._entrypoint()
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236201)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236201)[0m     output = train_func(config, reporter)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236201)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236201)[0m     config=config)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236201)[0m     model.save(model_path, config_path)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236201)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236201)[0m     self.model.save(model_path)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236201)[0m     signatures)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236201)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236201)[0m     f.close()
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236201)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236201)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236201)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=236201)[0m , filename = '/tmp/thalvari/4565628/automl_save_2o545_zl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1c5a54f910, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236201)[0m 
[2m[36m(pid=236201)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236201)[0m 
[2m[36m(pid=236201)[0m Traceback (most recent call last):
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=236201)[0m     self.run()
[2m[36m(pid=236201)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=236201)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=236201)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=236201)[0m 
[2m[36m(pid=234407)[0m 2021-01-16 21:24:12,919	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234407)[0m Traceback (most recent call last):
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234407)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234407)[0m     param_dset[:] = val
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234407)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234407)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234407)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234407)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234407)[0m , filename = '/tmp/thalvari/4565628/automl_save_ve4tan2b/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f828aa30f9c, total write size = 572100, bytes this sub-write = 572100, bytes actually written = 18446744073709551615, offset = 2473984)
[2m[36m(pid=234407)[0m 
[2m[36m(pid=234407)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234407)[0m 
[2m[36m(pid=234407)[0m Traceback (most recent call last):
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234407)[0m     self._entrypoint()
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234407)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234407)[0m     output = train_func(config, reporter)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234407)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234407)[0m     config=config)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234407)[0m     model.save(model_path, config_path)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234407)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234407)[0m     self.model.save(model_path)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234407)[0m     signatures)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234407)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234407)[0m     f.close()
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234407)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234407)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234407)[0m , filename = '/tmp/thalvari/4565628/automl_save_ve4tan2b/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f828a27acf0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234407)[0m Exception in thread Thread-1:
[2m[36m(pid=234407)[0m Traceback (most recent call last):
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234407)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234407)[0m     param_dset[:] = val
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234407)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234407)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234407)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234407)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234407)[0m , filename = '/tmp/thalvari/4565628/automl_save_ve4tan2b/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f828aa30f9c, total write size = 572100, bytes this sub-write = 572100, bytes actually written = 18446744073709551615, offset = 2473984)
[2m[36m(pid=234407)[0m 
[2m[36m(pid=234407)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234407)[0m 
[2m[36m(pid=234407)[0m Traceback (most recent call last):
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234407)[0m     self._entrypoint()
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234407)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234407)[0m     output = train_func(config, reporter)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234407)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234407)[0m     config=config)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234407)[0m     model.save(model_path, config_path)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234407)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234407)[0m     self.model.save(model_path)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234407)[0m     signatures)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234407)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234407)[0m     f.close()
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234407)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234407)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234407)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:12 2021
[2m[36m(pid=234407)[0m , filename = '/tmp/thalvari/4565628/automl_save_ve4tan2b/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f828a27acf0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234407)[0m 
[2m[36m(pid=234407)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234407)[0m 
[2m[36m(pid=234407)[0m Traceback (most recent call last):
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234407)[0m     self.run()
[2m[36m(pid=234407)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234407)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234407)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234407)[0m 
2021-01-16 21:24:13,121	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234405, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:13,124	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234421)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234421)[0m   agg_primitives: ['count']
[2m[36m(pid=234421)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234421)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234438)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234438)[0m   agg_primitives: ['count']
[2m[36m(pid=234438)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234438)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234405)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234405)[0m 
[2m[36m(pid=234405)[0m Stack (most recent call first):
[2m[36m(pid=234438)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 36 ({'TERMINATED': 13, 'ERROR': 13, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 7 not shown
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=78.687,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_24_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-52mfndd9ae/error_2021-01-16_21-24-12.txt
 - train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-16_21-23-53nx1725uz/error_2021-01-16_21-24-13.txt
 - train_func_28_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.117,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_28_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-58s23_i5zd/error_2021-01-16_21-24-09.txt
RUNNING trials:
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_34_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_35_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_36_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=234421)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234421)[0m Instructions for updating:
[2m[36m(pid=234421)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234421)[0m LSTM is selected.
[2m[36m(pid=234438)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234438)[0m Instructions for updating:
[2m[36m(pid=234438)[0m If using Keras pass *_constraint arguments to layers.
2021-01-16 21:24:13,724	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=236201, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:13,726	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_26_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=236201)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=236201)[0m 
[2m[36m(pid=236201)[0m Stack (most recent call first):
2021-01-16 21:24:14,157	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234407, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:14,159	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_29_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234438)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234438)[0m Instructions for updating:
[2m[36m(pid=234438)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234442)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234442)[0m   agg_primitives: ['count']
[2m[36m(pid=234442)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234442)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234421)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234421)[0m Instructions for updating:
[2m[36m(pid=234421)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234407)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234407)[0m 
[2m[36m(pid=234407)[0m Stack (most recent call first):
[2m[36m(pid=234442)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234442)[0m Instructions for updating:
[2m[36m(pid=234442)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234442)[0m LSTM is selected.
[2m[36m(pid=236190)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=236190)[0m   agg_primitives: ['count']
[2m[36m(pid=236190)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=236190)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234422)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234422)[0m   agg_primitives: ['count']
[2m[36m(pid=234422)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234422)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234438)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234438)[0m 2021-01-16 21:24:15.157358: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234438)[0m 2021-01-16 21:24:15.165381: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234438)[0m 2021-01-16 21:24:15.167638: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f599d0e6fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234438)[0m 2021-01-16 21:24:15.167668: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234421)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234421)[0m 2021-01-16 21:24:15.202085: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234421)[0m 2021-01-16 21:24:15.209810: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234421)[0m 2021-01-16 21:24:15.211998: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0de10e66c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234421)[0m 2021-01-16 21:24:15.212030: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234442)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234442)[0m Instructions for updating:
[2m[36m(pid=234442)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=236190)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=236190)[0m Instructions for updating:
[2m[36m(pid=236190)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=236190)[0m LSTM is selected.
[2m[36m(pid=234418)[0m 2021-01-16 21:24:15,407	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234418)[0m Traceback (most recent call last):
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234418)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234418)[0m     param_dset[:] = val
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234418)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234418)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234418)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234418)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:15 2021
[2m[36m(pid=234418)[0m , filename = '/tmp/thalvari/4565628/automl_save_15yakwft/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c86016b8c, total write size = 47348, bytes this sub-write = 47348, bytes actually written = 18446744073709551615, offset = 2465792)
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234418)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234418)[0m Traceback (most recent call last):
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234418)[0m     self._entrypoint()
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234418)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234418)[0m     output = train_func(config, reporter)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234418)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234418)[0m     config=config)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234418)[0m     model.save(model_path, config_path)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234418)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234418)[0m     self.model.save(model_path)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234418)[0m     signatures)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234418)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234418)[0m     f.close()
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234418)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234418)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:15 2021
[2m[36m(pid=234418)[0m , filename = '/tmp/thalvari/4565628/automl_save_15yakwft/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c85767110, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234418)[0m Exception in thread Thread-1:
[2m[36m(pid=234418)[0m Traceback (most recent call last):
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234418)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234418)[0m     param_dset[:] = val
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234418)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234418)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234418)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234418)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:15 2021
[2m[36m(pid=234418)[0m , filename = '/tmp/thalvari/4565628/automl_save_15yakwft/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c86016b8c, total write size = 47348, bytes this sub-write = 47348, bytes actually written = 18446744073709551615, offset = 2465792)
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234418)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234418)[0m Traceback (most recent call last):
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234418)[0m     self._entrypoint()
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234418)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234418)[0m     output = train_func(config, reporter)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234418)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234418)[0m     config=config)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234418)[0m     model.save(model_path, config_path)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234418)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234418)[0m     self.model.save(model_path)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234418)[0m     signatures)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234418)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234418)[0m     f.close()
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234418)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234418)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234418)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:15 2021
[2m[36m(pid=234418)[0m , filename = '/tmp/thalvari/4565628/automl_save_15yakwft/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c85767110, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234418)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234418)[0m Traceback (most recent call last):
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234418)[0m     self.run()
[2m[36m(pid=234418)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234418)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234418)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234403)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234403)[0m   agg_primitives: ['count']
[2m[36m(pid=234403)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234403)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234422)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234422)[0m Instructions for updating:
[2m[36m(pid=234422)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234422)[0m LSTM is selected.
[2m[36m(pid=236190)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=236190)[0m Instructions for updating:
[2m[36m(pid=236190)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234403)[0m LSTM is selected.
[2m[36m(pid=234403)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234403)[0m Instructions for updating:
[2m[36m(pid=234403)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234442)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234442)[0m 2021-01-16 21:24:16.167071: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234442)[0m 2021-01-16 21:24:16.174635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234442)[0m 2021-01-16 21:24:16.176696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4f10e5a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234442)[0m 2021-01-16 21:24:16.176717: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234422)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234422)[0m Instructions for updating:
[2m[36m(pid=234422)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:16,467	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234418, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:16,471	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234418)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234418)[0m 
[2m[36m(pid=234418)[0m Stack (most recent call first):
[2m[36m(pid=234403)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234403)[0m Instructions for updating:
[2m[36m(pid=234403)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234437)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234437)[0m   agg_primitives: ['count']
[2m[36m(pid=234437)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234437)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234425)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234425)[0m   agg_primitives: ['count']
[2m[36m(pid=234425)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234425)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=236190)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=236190)[0m 2021-01-16 21:24:16.862755: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=236190)[0m 2021-01-16 21:24:16.871745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=236190)[0m 2021-01-16 21:24:16.876562: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f50490e6620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=236190)[0m 2021-01-16 21:24:16.876598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234425)[0m LSTM is selected.
[2m[36m(pid=234437)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234437)[0m Instructions for updating:
[2m[36m(pid=234437)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234437)[0m LSTM is selected.
[2m[36m(pid=234422)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234422)[0m 2021-01-16 21:24:17.214359: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234422)[0m 2021-01-16 21:24:17.222999: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234422)[0m 2021-01-16 21:24:17.227860: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f02d50e8620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234422)[0m 2021-01-16 21:24:17.227899: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234425)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234425)[0m Instructions for updating:
[2m[36m(pid=234425)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234403)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234403)[0m 2021-01-16 21:24:17.669761: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234403)[0m 2021-01-16 21:24:17.678023: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234403)[0m 2021-01-16 21:24:17.684809: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f07f50e8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234403)[0m 2021-01-16 21:24:17.684870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234425)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234425)[0m Instructions for updating:
[2m[36m(pid=234425)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234437)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234437)[0m Instructions for updating:
[2m[36m(pid=234437)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234436)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234436)[0m   agg_primitives: ['count']
[2m[36m(pid=234436)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234436)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234421)[0m 2021-01-16 21:24:17,821	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234421)[0m Traceback (most recent call last):
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234421)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234421)[0m     param_dset[:] = val
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234421)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234421)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234421)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234421)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234421)[0m , filename = '/tmp/thalvari/4565628/automl_save_rjb9jtv4/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f0de287d348, total write size = 594584, bytes this sub-write = 594584, bytes actually written = 18446744073709551615, offset = 925696)
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234421)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234421)[0m Traceback (most recent call last):
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234421)[0m     self._entrypoint()
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234421)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234421)[0m     output = train_func(config, reporter)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234421)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234421)[0m     config=config)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234421)[0m     model.save(model_path, config_path)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234421)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234421)[0m     self.model.save(model_path)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234421)[0m     signatures)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234421)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234421)[0m     f.close()
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234421)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234421)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234421)[0m , filename = '/tmp/thalvari/4565628/automl_save_rjb9jtv4/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f0de1fe3ca0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234421)[0m Exception in thread Thread-1:
[2m[36m(pid=234421)[0m Traceback (most recent call last):
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234421)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234421)[0m     param_dset[:] = val
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234421)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234421)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234421)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234421)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234421)[0m , filename = '/tmp/thalvari/4565628/automl_save_rjb9jtv4/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f0de287d348, total write size = 594584, bytes this sub-write = 594584, bytes actually written = 18446744073709551615, offset = 925696)
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234421)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234421)[0m Traceback (most recent call last):
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234421)[0m     self._entrypoint()
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234421)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234421)[0m     output = train_func(config, reporter)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234421)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234421)[0m     config=config)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234421)[0m     model.save(model_path, config_path)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234421)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234421)[0m     self.model.save(model_path)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234421)[0m     signatures)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234421)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234421)[0m     f.close()
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234421)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234421)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234421)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234421)[0m , filename = '/tmp/thalvari/4565628/automl_save_rjb9jtv4/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f0de1fe3ca0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234438)[0m 2021-01-16 21:24:17,826	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234438)[0m Traceback (most recent call last):
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234438)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234438)[0m     param_dset[:] = val
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234438)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234438)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234438)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234438)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234438)[0m , filename = '/tmp/thalvari/4565628/automl_save_0t0vuctn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f599e8e852c, total write size = 588484, bytes this sub-write = 588484, bytes actually written = 18446744073709551615, offset = 2457600)
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234438)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234438)[0m Traceback (most recent call last):
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234438)[0m     self._entrypoint()
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234438)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234438)[0m     output = train_func(config, reporter)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234438)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234438)[0m     config=config)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234438)[0m     model.save(model_path, config_path)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234438)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234438)[0m     self.model.save(model_path)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234438)[0m     signatures)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234438)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234438)[0m     f.close()
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234438)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234438)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234438)[0m , filename = '/tmp/thalvari/4565628/automl_save_0t0vuctn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f599dd369e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234438)[0m Exception in thread Thread-1:
[2m[36m(pid=234438)[0m Traceback (most recent call last):
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234438)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234438)[0m     param_dset[:] = val
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234438)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234438)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234438)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234438)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234438)[0m , filename = '/tmp/thalvari/4565628/automl_save_0t0vuctn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f599e8e852c, total write size = 588484, bytes this sub-write = 588484, bytes actually written = 18446744073709551615, offset = 2457600)
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234438)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234438)[0m Traceback (most recent call last):
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234438)[0m     self._entrypoint()
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234438)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234438)[0m     output = train_func(config, reporter)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234438)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234438)[0m     config=config)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234438)[0m     model.save(model_path, config_path)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234438)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234438)[0m     self.model.save(model_path)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234438)[0m     signatures)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234438)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234438)[0m     f.close()
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234438)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234438)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234438)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:17 2021
[2m[36m(pid=234438)[0m , filename = '/tmp/thalvari/4565628/automl_save_0t0vuctn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f599dd369e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234421)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234421)[0m Traceback (most recent call last):
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234421)[0m     self.run()
[2m[36m(pid=234421)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234421)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234421)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234438)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234438)[0m Traceback (most recent call last):
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234438)[0m     self.run()
[2m[36m(pid=234438)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234438)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234438)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234436)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234436)[0m Instructions for updating:
[2m[36m(pid=234436)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234436)[0m LSTM is selected.
[2m[36m(pid=234437)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234437)[0m 2021-01-16 21:24:18.762706: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234437)[0m 2021-01-16 21:24:18.772366: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234437)[0m 2021-01-16 21:24:18.774150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea9d0e8900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234437)[0m 2021-01-16 21:24:18.774176: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234425)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234425)[0m 2021-01-16 21:24:18.797144: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234425)[0m 2021-01-16 21:24:18.806186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234425)[0m 2021-01-16 21:24:18.808088: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd490e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234425)[0m 2021-01-16 21:24:18.808115: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234436)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234436)[0m Instructions for updating:
[2m[36m(pid=234436)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234442)[0m 2021-01-16 21:24:18,868	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234442)[0m Traceback (most recent call last):
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234442)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234442)[0m     param_dset[:] = val
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234442)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234442)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234442)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234442)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:18 2021
[2m[36m(pid=234442)[0m , filename = '/tmp/thalvari/4565628/automl_save_fwe8h5ce/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f28d7d6c, total write size = 604868, bytes this sub-write = 604868, bytes actually written = 18446744073709551615, offset = 2441216)
[2m[36m(pid=234442)[0m 
[2m[36m(pid=234442)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234442)[0m 
[2m[36m(pid=234442)[0m Traceback (most recent call last):
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234442)[0m     self._entrypoint()
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234442)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234442)[0m     output = train_func(config, reporter)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234442)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234442)[0m     config=config)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234442)[0m     model.save(model_path, config_path)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234442)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234442)[0m     self.model.save(model_path)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234442)[0m     signatures)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234442)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234442)[0m     f.close()
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234442)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234442)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:18 2021
[2m[36m(pid=234442)[0m , filename = '/tmp/thalvari/4565628/automl_save_fwe8h5ce/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f23adc70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234442)[0m Exception in thread Thread-1:
[2m[36m(pid=234442)[0m Traceback (most recent call last):
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234442)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234442)[0m     param_dset[:] = val
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234442)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234442)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234442)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234442)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:18 2021
[2m[36m(pid=234442)[0m , filename = '/tmp/thalvari/4565628/automl_save_fwe8h5ce/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f28d7d6c, total write size = 604868, bytes this sub-write = 604868, bytes actually written = 18446744073709551615, offset = 2441216)
[2m[36m(pid=234442)[0m 
[2m[36m(pid=234442)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234442)[0m 
[2m[36m(pid=234442)[0m Traceback (most recent call last):
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234442)[0m     self._entrypoint()
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234442)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234442)[0m     output = train_func(config, reporter)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234442)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234442)[0m     config=config)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234442)[0m     model.save(model_path, config_path)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234442)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234442)[0m     self.model.save(model_path)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234442)[0m     signatures)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234442)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234442)[0m     f.close()
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234442)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234442)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234442)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:18 2021
[2m[36m(pid=234442)[0m , filename = '/tmp/thalvari/4565628/automl_save_fwe8h5ce/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe4f23adc70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234442)[0m 
[2m[36m(pid=234442)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234442)[0m 
[2m[36m(pid=234442)[0m Traceback (most recent call last):
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234442)[0m     self.run()
[2m[36m(pid=234442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234442)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234442)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234442)[0m 
2021-01-16 21:24:18,964	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234421, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:18,969	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_31_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.299,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 39 ({'TERMINATED': 13, 'ERROR': 17, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 11 not shown
 - train_func_28_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.117,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_28_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-23-58s23_i5zd/error_2021-01-16_21-24-09.txt
 - train_func_29_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_29_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-0205lnf39u/error_2021-01-16_21-24-14.txt
 - train_func_31_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.299,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_31_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-09uvvu0l34/error_2021-01-16_21-24-18.txt
RUNNING trials:
 - train_func_30_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_37_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_39_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=234421)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234421)[0m 
[2m[36m(pid=234421)[0m Stack (most recent call first):
2021-01-16 21:24:19,378	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234438, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:19,385	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_30_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234438)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234438)[0m 
[2m[36m(pid=234438)[0m Stack (most recent call first):
[2m[36m(pid=236190)[0m 2021-01-16 21:24:19,812	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=236190)[0m Traceback (most recent call last):
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236190)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236190)[0m     param_dset[:] = val
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236190)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236190)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236190)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236190)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:19 2021
[2m[36m(pid=236190)[0m , filename = '/tmp/thalvari/4565628/automl_save_xujux9hr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f504aa8412c, total write size = 613060, bytes this sub-write = 613060, bytes actually written = 18446744073709551615, offset = 2433024)
[2m[36m(pid=236190)[0m 
[2m[36m(pid=236190)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236190)[0m 
[2m[36m(pid=236190)[0m Traceback (most recent call last):
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236190)[0m     self._entrypoint()
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236190)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236190)[0m     output = train_func(config, reporter)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236190)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236190)[0m     config=config)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236190)[0m     model.save(model_path, config_path)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236190)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236190)[0m     self.model.save(model_path)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236190)[0m     signatures)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236190)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236190)[0m     f.close()
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236190)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236190)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:19 2021
[2m[36m(pid=236190)[0m , filename = '/tmp/thalvari/4565628/automl_save_xujux9hr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f504a925b30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236190)[0m Exception in thread Thread-1:
[2m[36m(pid=236190)[0m Traceback (most recent call last):
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=236190)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=236190)[0m     param_dset[:] = val
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=236190)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=236190)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=236190)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=236190)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:19 2021
[2m[36m(pid=236190)[0m , filename = '/tmp/thalvari/4565628/automl_save_xujux9hr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f504aa8412c, total write size = 613060, bytes this sub-write = 613060, bytes actually written = 18446744073709551615, offset = 2433024)
[2m[36m(pid=236190)[0m 
[2m[36m(pid=236190)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236190)[0m 
[2m[36m(pid=236190)[0m Traceback (most recent call last):
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=236190)[0m     self._entrypoint()
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=236190)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=236190)[0m     output = train_func(config, reporter)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=236190)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=236190)[0m     config=config)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=236190)[0m     model.save(model_path, config_path)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=236190)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=236190)[0m     self.model.save(model_path)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=236190)[0m     signatures)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=236190)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=236190)[0m     f.close()
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=236190)[0m     h5i.dec_ref(id_)
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=236190)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=236190)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:19 2021
[2m[36m(pid=236190)[0m , filename = '/tmp/thalvari/4565628/automl_save_xujux9hr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f504a925b30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=236190)[0m 
[2m[36m(pid=236190)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=236190)[0m 
[2m[36m(pid=236190)[0m Traceback (most recent call last):
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=236190)[0m     self.run()
[2m[36m(pid=236190)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=236190)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=236190)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=236190)[0m 
[2m[36m(pid=234436)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234436)[0m 2021-01-16 21:24:19.958517: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234436)[0m 2021-01-16 21:24:19.967888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234436)[0m 2021-01-16 21:24:19.970467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3c6d0e8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234436)[0m 2021-01-16 21:24:19.970502: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:24:20,166	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234442, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:20,168	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_32_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234422)[0m 2021-01-16 21:24:20,314	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234422)[0m Traceback (most recent call last):
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234422)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234422)[0m     param_dset[:] = val
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234422)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234422)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234422)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234422)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234422)[0m , filename = '/tmp/thalvari/4565628/automl_save_c1_kkl_p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f02d5f94b1c, total write size = 88308, bytes this sub-write = 88308, bytes actually written = 18446744073709551615, offset = 2428928)
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234422)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234422)[0m Traceback (most recent call last):
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234422)[0m     self._entrypoint()
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234422)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234422)[0m     output = train_func(config, reporter)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234422)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234422)[0m     config=config)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234422)[0m     model.save(model_path, config_path)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234422)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234422)[0m     self.model.save(model_path)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234422)[0m     signatures)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234422)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234422)[0m     f.close()
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234422)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234422)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234422)[0m , filename = '/tmp/thalvari/4565628/automl_save_c1_kkl_p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f02d5f0a830, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234422)[0m Exception in thread Thread-1:
[2m[36m(pid=234422)[0m Traceback (most recent call last):
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234422)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234422)[0m     param_dset[:] = val
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234422)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234422)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234422)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234422)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234422)[0m , filename = '/tmp/thalvari/4565628/automl_save_c1_kkl_p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f02d5f94b1c, total write size = 88308, bytes this sub-write = 88308, bytes actually written = 18446744073709551615, offset = 2428928)
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234422)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234422)[0m Traceback (most recent call last):
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234422)[0m     self._entrypoint()
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234422)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234422)[0m     output = train_func(config, reporter)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234422)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234422)[0m     config=config)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234422)[0m     model.save(model_path, config_path)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234422)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234422)[0m     self.model.save(model_path)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234422)[0m     signatures)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234422)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234422)[0m     f.close()
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234422)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234422)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234422)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234422)[0m , filename = '/tmp/thalvari/4565628/automl_save_c1_kkl_p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f02d5f0a830, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234422)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234422)[0m Traceback (most recent call last):
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234422)[0m     self.run()
[2m[36m(pid=234422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234422)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234422)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234442)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234442)[0m 
[2m[36m(pid=234442)[0m Stack (most recent call first):
[2m[36m(pid=234403)[0m 2021-01-16 21:24:20,866	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234403)[0m Traceback (most recent call last):
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234403)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234403)[0m     param_dset[:] = val
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234403)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234403)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234403)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234403)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234403)[0m , filename = '/tmp/thalvari/4565628/automl_save_uwdyupuv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07f61ac16c, total write size = 96500, bytes this sub-write = 96500, bytes actually written = 18446744073709551615, offset = 2420736)
[2m[36m(pid=234403)[0m 
[2m[36m(pid=234403)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234403)[0m 
[2m[36m(pid=234403)[0m Traceback (most recent call last):
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234403)[0m     self._entrypoint()
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234403)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234403)[0m     output = train_func(config, reporter)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234403)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234403)[0m     config=config)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234403)[0m     model.save(model_path, config_path)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234403)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234403)[0m     self.model.save(model_path)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234403)[0m     signatures)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234403)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234403)[0m     f.close()
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234403)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234403)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234403)[0m , filename = '/tmp/thalvari/4565628/automl_save_uwdyupuv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07f64cbb50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234403)[0m Exception in thread Thread-1:
[2m[36m(pid=234403)[0m Traceback (most recent call last):
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234403)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234403)[0m     param_dset[:] = val
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234403)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234403)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234403)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234403)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234403)[0m , filename = '/tmp/thalvari/4565628/automl_save_uwdyupuv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07f61ac16c, total write size = 96500, bytes this sub-write = 96500, bytes actually written = 18446744073709551615, offset = 2420736)
[2m[36m(pid=234403)[0m 
[2m[36m(pid=234403)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234403)[0m 
[2m[36m(pid=234403)[0m Traceback (most recent call last):
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234403)[0m     self._entrypoint()
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234403)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234403)[0m     output = train_func(config, reporter)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234403)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234403)[0m     config=config)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234403)[0m     model.save(model_path, config_path)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234403)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234403)[0m     self.model.save(model_path)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234403)[0m     signatures)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234403)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234403)[0m     f.close()
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234403)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234403)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234403)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:20 2021
[2m[36m(pid=234403)[0m , filename = '/tmp/thalvari/4565628/automl_save_uwdyupuv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07f64cbb50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234403)[0m 
[2m[36m(pid=234403)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234403)[0m 
[2m[36m(pid=234403)[0m Traceback (most recent call last):
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234403)[0m     self.run()
[2m[36m(pid=234403)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234403)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234403)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234403)[0m 
2021-01-16 21:24:20,996	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=236190, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:20,998	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_33_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=36.301,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=236190)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=236190)[0m 
[2m[36m(pid=236190)[0m Stack (most recent call first):
[2m[36m(pid=234441)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234441)[0m   agg_primitives: ['count']
[2m[36m(pid=234441)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234441)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:24:21,934	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234422, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:21,939	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_34_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234441)[0m LSTM is selected.
[2m[36m(pid=234441)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234441)[0m Instructions for updating:
[2m[36m(pid=234441)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234422)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234422)[0m 
[2m[36m(pid=234422)[0m Stack (most recent call first):
[2m[36m(pid=234437)[0m 2021-01-16 21:24:22,053	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234437)[0m Traceback (most recent call last):
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234437)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234437)[0m     param_dset[:] = val
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234437)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234437)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234437)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234437)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234437)[0m , filename = '/tmp/thalvari/4565628/automl_save_j33l82pn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fea9e99f71c, total write size = 112884, bytes this sub-write = 112884, bytes actually written = 18446744073709551615, offset = 2404352)
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234437)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234437)[0m Traceback (most recent call last):
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234437)[0m     self._entrypoint()
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234437)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234437)[0m     output = train_func(config, reporter)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234437)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234437)[0m     config=config)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234437)[0m     model.save(model_path, config_path)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234437)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234437)[0m     self.model.save(model_path)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234437)[0m     signatures)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234437)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234437)[0m     f.close()
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234437)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234437)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234437)[0m , filename = '/tmp/thalvari/4565628/automl_save_j33l82pn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fea9e271490, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234437)[0m Exception in thread Thread-1:
[2m[36m(pid=234437)[0m Traceback (most recent call last):
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234437)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234437)[0m     param_dset[:] = val
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234437)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234437)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234437)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234437)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234437)[0m , filename = '/tmp/thalvari/4565628/automl_save_j33l82pn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fea9e99f71c, total write size = 112884, bytes this sub-write = 112884, bytes actually written = 18446744073709551615, offset = 2404352)
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234437)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234437)[0m Traceback (most recent call last):
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234437)[0m     self._entrypoint()
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234437)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234437)[0m     output = train_func(config, reporter)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234437)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234437)[0m     config=config)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234437)[0m     model.save(model_path, config_path)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234437)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234437)[0m     self.model.save(model_path)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234437)[0m     signatures)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234437)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234437)[0m     f.close()
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234437)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234437)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234437)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234437)[0m , filename = '/tmp/thalvari/4565628/automl_save_j33l82pn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fea9e271490, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234437)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234437)[0m Traceback (most recent call last):
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234437)[0m     self.run()
[2m[36m(pid=234437)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234437)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234437)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234425)[0m 2021-01-16 21:24:22,258	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234425)[0m Traceback (most recent call last):
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234425)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234425)[0m     param_dset[:] = val
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234425)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234425)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234425)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234425)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234425)[0m , filename = '/tmp/thalvari/4565628/automl_save_qhtypori/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbd4a5acd7c, total write size = 112884, bytes this sub-write = 112884, bytes actually written = 18446744073709551615, offset = 2404352)
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234425)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234425)[0m Traceback (most recent call last):
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234425)[0m     self._entrypoint()
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234425)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234425)[0m     output = train_func(config, reporter)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234425)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234425)[0m     config=config)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234425)[0m     model.save(model_path, config_path)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234425)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234425)[0m     self.model.save(model_path)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234425)[0m     signatures)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234425)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234425)[0m     f.close()
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234425)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234425)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234425)[0m , filename = '/tmp/thalvari/4565628/automl_save_qhtypori/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbd4992a070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234425)[0m Exception in thread Thread-1:
[2m[36m(pid=234425)[0m Traceback (most recent call last):
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234425)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234425)[0m     param_dset[:] = val
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234425)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234425)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234425)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234425)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234425)[0m , filename = '/tmp/thalvari/4565628/automl_save_qhtypori/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbd4a5acd7c, total write size = 112884, bytes this sub-write = 112884, bytes actually written = 18446744073709551615, offset = 2404352)
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234425)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234425)[0m Traceback (most recent call last):
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234425)[0m     self._entrypoint()
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234425)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234425)[0m     output = train_func(config, reporter)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234425)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234425)[0m     config=config)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234425)[0m     model.save(model_path, config_path)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234425)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234425)[0m     self.model.save(model_path)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234425)[0m     signatures)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234425)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234425)[0m     f.close()
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234425)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234425)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234425)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234425)[0m , filename = '/tmp/thalvari/4565628/automl_save_qhtypori/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fbd4992a070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234425)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234425)[0m Traceback (most recent call last):
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234425)[0m     self.run()
[2m[36m(pid=234425)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234425)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234425)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234441)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234441)[0m Instructions for updating:
[2m[36m(pid=234441)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:22,693	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234403, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:22,696	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_35_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234403)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234403)[0m 
[2m[36m(pid=234403)[0m Stack (most recent call first):
[2m[36m(pid=234436)[0m 2021-01-16 21:24:22,951	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234436)[0m Traceback (most recent call last):
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234436)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234436)[0m     param_dset[:] = val
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234436)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234436)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234436)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234436)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234436)[0m , filename = '/tmp/thalvari/4565628/automl_save_hm7evqe3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c6ea2bf8c, total write size = 121076, bytes this sub-write = 121076, bytes actually written = 18446744073709551615, offset = 2396160)
[2m[36m(pid=234436)[0m 
[2m[36m(pid=234436)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234436)[0m 
[2m[36m(pid=234436)[0m Traceback (most recent call last):
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234436)[0m     self._entrypoint()
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234436)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234436)[0m     output = train_func(config, reporter)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234436)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234436)[0m     config=config)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234436)[0m     model.save(model_path, config_path)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234436)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234436)[0m     self.model.save(model_path)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234436)[0m     signatures)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234436)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234436)[0m     f.close()
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234436)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234436)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234436)[0m , filename = '/tmp/thalvari/4565628/automl_save_hm7evqe3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c6e6250e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234436)[0m Exception in thread Thread-1:
[2m[36m(pid=234436)[0m Traceback (most recent call last):
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234436)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234436)[0m     param_dset[:] = val
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234436)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234436)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234436)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234436)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234436)[0m , filename = '/tmp/thalvari/4565628/automl_save_hm7evqe3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c6ea2bf8c, total write size = 121076, bytes this sub-write = 121076, bytes actually written = 18446744073709551615, offset = 2396160)
[2m[36m(pid=234436)[0m 
[2m[36m(pid=234436)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234436)[0m 
[2m[36m(pid=234436)[0m Traceback (most recent call last):
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234436)[0m     self._entrypoint()
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234436)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234436)[0m     output = train_func(config, reporter)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234436)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234436)[0m     config=config)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234436)[0m     model.save(model_path, config_path)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234436)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234436)[0m     self.model.save(model_path)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234436)[0m     signatures)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234436)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234436)[0m     f.close()
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234436)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234436)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234436)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:22 2021
[2m[36m(pid=234436)[0m , filename = '/tmp/thalvari/4565628/automl_save_hm7evqe3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3c6e6250e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234436)[0m 
[2m[36m(pid=234436)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234436)[0m 
[2m[36m(pid=234436)[0m Traceback (most recent call last):
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234436)[0m     self.run()
[2m[36m(pid=234436)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234436)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234436)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234436)[0m 
2021-01-16 21:24:23,248	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234437, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:23,250	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_37_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234404)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234404)[0m   agg_primitives: ['count']
[2m[36m(pid=234404)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234404)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234409)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234409)[0m   agg_primitives: ['count']
[2m[36m(pid=234409)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234409)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234437)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234437)[0m 
[2m[36m(pid=234437)[0m Stack (most recent call first):
[2m[36m(pid=234441)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234441)[0m 2021-01-16 21:24:23.653403: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234441)[0m 2021-01-16 21:24:23.661238: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234441)[0m 2021-01-16 21:24:23.663285: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f985d0e9230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234441)[0m 2021-01-16 21:24:23.663308: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:24:23,732	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234425, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:23,734	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_36_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234409)[0m LSTM is selected.
[2m[36m(pid=234425)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234425)[0m 
[2m[36m(pid=234425)[0m Stack (most recent call first):
[2m[36m(pid=234404)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234404)[0m Instructions for updating:
[2m[36m(pid=234404)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234404)[0m LSTM is selected.
[2m[36m(pid=234409)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234409)[0m Instructions for updating:
[2m[36m(pid=234409)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 47 ({'TERMINATED': 13, 'ERROR': 24, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 18 not shown
 - train_func_35_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_35_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-12zbh_di_r/error_2021-01-16_21-24-22.txt
 - train_func_36_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_36_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-139e4aupvk/error_2021-01-16_21-24-23.txt
 - train_func_37_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_37_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-144qdi8k1o/error_2021-01-16_21-24-23.txt
RUNNING trials:
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_39_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_40_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_45_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_46_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_47_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

2021-01-16 21:24:24,254	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234436, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:24,257	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_38_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234416)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234416)[0m   agg_primitives: ['count']
[2m[36m(pid=234416)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234416)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234436)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234436)[0m 
[2m[36m(pid=234436)[0m Stack (most recent call first):
[2m[36m(pid=234404)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234404)[0m Instructions for updating:
[2m[36m(pid=234404)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234409)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234409)[0m Instructions for updating:
[2m[36m(pid=234409)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234416)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234416)[0m Instructions for updating:
[2m[36m(pid=234416)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234416)[0m LSTM is selected.
[2m[36m(pid=234432)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234432)[0m   agg_primitives: ['count']
[2m[36m(pid=234432)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234432)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234404)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234404)[0m 2021-01-16 21:24:25.443969: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234404)[0m 2021-01-16 21:24:25.451812: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234404)[0m 2021-01-16 21:24:25.453646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5490e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234404)[0m 2021-01-16 21:24:25.453666: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234416)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234416)[0m Instructions for updating:
[2m[36m(pid=234416)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234409)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234409)[0m 2021-01-16 21:24:25.413181: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234409)[0m 2021-01-16 21:24:25.421498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234409)[0m 2021-01-16 21:24:25.424825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f476d0e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234409)[0m 2021-01-16 21:24:25.424871: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234432)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234432)[0m Instructions for updating:
[2m[36m(pid=234432)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234432)[0m LSTM is selected.
[2m[36m(pid=234413)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234413)[0m   agg_primitives: ['count']
[2m[36m(pid=234413)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234413)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234432)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234432)[0m Instructions for updating:
[2m[36m(pid=234432)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234427)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234427)[0m   agg_primitives: ['count']
[2m[36m(pid=234427)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234427)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234413)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234413)[0m Instructions for updating:
[2m[36m(pid=234413)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234413)[0m LSTM is selected.
[2m[36m(pid=234416)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234416)[0m 2021-01-16 21:24:26.415073: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234416)[0m 2021-01-16 21:24:26.422906: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234416)[0m 2021-01-16 21:24:26.425081: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4231103230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234416)[0m 2021-01-16 21:24:26.425109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234441)[0m 2021-01-16 21:24:26,531	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234441)[0m Traceback (most recent call last):
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234441)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234441)[0m     param_dset[:] = val
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234441)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234441)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234441)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234441)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:26 2021
[2m[36m(pid=234441)[0m , filename = '/tmp/thalvari/4565628/automl_save_kw1qymbr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f985e1c81ec, total write size = 129268, bytes this sub-write = 129268, bytes actually written = 18446744073709551615, offset = 2387968)
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234441)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234441)[0m Traceback (most recent call last):
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234441)[0m     self._entrypoint()
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234441)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234441)[0m     output = train_func(config, reporter)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234441)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234441)[0m     config=config)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234441)[0m     model.save(model_path, config_path)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234441)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234441)[0m     self.model.save(model_path)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234441)[0m     signatures)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234441)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234441)[0m     f.close()
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234441)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234441)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:26 2021
[2m[36m(pid=234441)[0m , filename = '/tmp/thalvari/4565628/automl_save_kw1qymbr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f985d451a40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234441)[0m Exception in thread Thread-1:
[2m[36m(pid=234441)[0m Traceback (most recent call last):
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234441)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234441)[0m     param_dset[:] = val
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234441)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234441)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234441)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234441)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:26 2021
[2m[36m(pid=234441)[0m , filename = '/tmp/thalvari/4565628/automl_save_kw1qymbr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f985e1c81ec, total write size = 129268, bytes this sub-write = 129268, bytes actually written = 18446744073709551615, offset = 2387968)
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234441)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234441)[0m Traceback (most recent call last):
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234441)[0m     self._entrypoint()
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234441)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234441)[0m     output = train_func(config, reporter)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234441)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234441)[0m     config=config)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234441)[0m     model.save(model_path, config_path)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234441)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234441)[0m     self.model.save(model_path)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234441)[0m     signatures)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234441)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234441)[0m     f.close()
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234441)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234441)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234441)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:26 2021
[2m[36m(pid=234441)[0m , filename = '/tmp/thalvari/4565628/automl_save_kw1qymbr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f985d451a40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234441)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234441)[0m Traceback (most recent call last):
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234441)[0m     self.run()
[2m[36m(pid=234441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234441)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234441)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234427)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234427)[0m Instructions for updating:
[2m[36m(pid=234427)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234427)[0m LSTM is selected.
[2m[36m(pid=234408)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234408)[0m   agg_primitives: ['count']
[2m[36m(pid=234408)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234408)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234413)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234413)[0m Instructions for updating:
[2m[36m(pid=234413)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234432)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234432)[0m 2021-01-16 21:24:27.075852: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234432)[0m 2021-01-16 21:24:27.083427: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234432)[0m 2021-01-16 21:24:27.085487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7d79103230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234432)[0m 2021-01-16 21:24:27.085509: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234412)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234412)[0m   agg_primitives: ['count']
[2m[36m(pid=234412)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234412)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234423)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234423)[0m   agg_primitives: ['count']
[2m[36m(pid=234423)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234423)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234408)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234408)[0m Instructions for updating:
[2m[36m(pid=234408)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234408)[0m LSTM is selected.
[2m[36m(pid=234427)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234427)[0m Instructions for updating:
[2m[36m(pid=234427)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:27,572	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234441, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:27,578	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_39_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234441)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234441)[0m 
[2m[36m(pid=234441)[0m Stack (most recent call first):
[2m[36m(pid=234423)[0m LSTM is selected.
[2m[36m(pid=234423)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234423)[0m Instructions for updating:
[2m[36m(pid=234423)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234413)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234413)[0m 2021-01-16 21:24:27.855111: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234413)[0m 2021-01-16 21:24:27.864776: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234413)[0m 2021-01-16 21:24:27.869705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f677d0e8c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234413)[0m 2021-01-16 21:24:27.869743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234412)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234412)[0m Instructions for updating:
[2m[36m(pid=234412)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234412)[0m LSTM is selected.
[2m[36m(pid=234408)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234408)[0m Instructions for updating:
[2m[36m(pid=234408)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234409)[0m 2021-01-16 21:24:28,348	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234409)[0m Traceback (most recent call last):
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234409)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234409)[0m     param_dset[:] = val
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234409)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234409)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234409)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234409)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234409)[0m , filename = '/tmp/thalvari/4565628/automl_save_rhk2rqa2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f476dfccccc, total write size = 145652, bytes this sub-write = 145652, bytes actually written = 18446744073709551615, offset = 2371584)
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234409)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234409)[0m Traceback (most recent call last):
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234409)[0m     self._entrypoint()
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234409)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234409)[0m     output = train_func(config, reporter)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234409)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234409)[0m     config=config)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234409)[0m     model.save(model_path, config_path)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234409)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234409)[0m     self.model.save(model_path)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234409)[0m     signatures)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234409)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234409)[0m     f.close()
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234409)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234409)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234409)[0m , filename = '/tmp/thalvari/4565628/automl_save_rhk2rqa2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f476e6e38e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234409)[0m Exception in thread Thread-1:
[2m[36m(pid=234409)[0m Traceback (most recent call last):
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234409)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234409)[0m     param_dset[:] = val
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234409)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234409)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234409)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234409)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234409)[0m , filename = '/tmp/thalvari/4565628/automl_save_rhk2rqa2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f476dfccccc, total write size = 145652, bytes this sub-write = 145652, bytes actually written = 18446744073709551615, offset = 2371584)
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234409)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234409)[0m Traceback (most recent call last):
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234409)[0m     self._entrypoint()
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234409)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234409)[0m     output = train_func(config, reporter)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234409)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234409)[0m     config=config)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234409)[0m     model.save(model_path, config_path)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234409)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234409)[0m     self.model.save(model_path)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234409)[0m     signatures)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234409)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234409)[0m     f.close()
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234409)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234409)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234409)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234409)[0m , filename = '/tmp/thalvari/4565628/automl_save_rhk2rqa2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f476e6e38e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234409)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234409)[0m Traceback (most recent call last):
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234409)[0m     self.run()
[2m[36m(pid=234409)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234409)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234409)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234423)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234423)[0m Instructions for updating:
[2m[36m(pid=234423)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234427)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234427)[0m 2021-01-16 21:24:28.405553: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234427)[0m 2021-01-16 21:24:28.413304: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234427)[0m 2021-01-16 21:24:28.416782: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eff450ceee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234427)[0m 2021-01-16 21:24:28.416828: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234412)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234412)[0m Instructions for updating:
[2m[36m(pid=234412)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234404)[0m 2021-01-16 21:24:28,566	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234404)[0m Traceback (most recent call last):
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234404)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234404)[0m     param_dset[:] = val
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234404)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234404)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234404)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234404)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234404)[0m , filename = '/tmp/thalvari/4565628/automl_save_wn5lxg48/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa54a6e9ccc, total write size = 145652, bytes this sub-write = 145652, bytes actually written = 18446744073709551615, offset = 2371584)
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234404)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234404)[0m Traceback (most recent call last):
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234404)[0m     self._entrypoint()
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234404)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234404)[0m     output = train_func(config, reporter)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234404)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234404)[0m     config=config)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234404)[0m     model.save(model_path, config_path)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234404)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234404)[0m     self.model.save(model_path)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234404)[0m     signatures)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234404)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234404)[0m     f.close()
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234404)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234404)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234404)[0m , filename = '/tmp/thalvari/4565628/automl_save_wn5lxg48/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa54a04c4d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234404)[0m Exception in thread Thread-1:
[2m[36m(pid=234404)[0m Traceback (most recent call last):
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234404)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234404)[0m     param_dset[:] = val
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234404)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234404)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234404)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234404)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234404)[0m , filename = '/tmp/thalvari/4565628/automl_save_wn5lxg48/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa54a6e9ccc, total write size = 145652, bytes this sub-write = 145652, bytes actually written = 18446744073709551615, offset = 2371584)
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234404)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234404)[0m Traceback (most recent call last):
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234404)[0m     self._entrypoint()
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234404)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234404)[0m     output = train_func(config, reporter)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234404)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234404)[0m     config=config)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234404)[0m     model.save(model_path, config_path)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234404)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234404)[0m     self.model.save(model_path)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234404)[0m     signatures)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234404)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234404)[0m     f.close()
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234404)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234404)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234404)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:28 2021
[2m[36m(pid=234404)[0m , filename = '/tmp/thalvari/4565628/automl_save_wn5lxg48/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fa54a04c4d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234404)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234404)[0m Traceback (most recent call last):
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234404)[0m     self.run()
[2m[36m(pid=234404)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234404)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234404)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234408)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234408)[0m 2021-01-16 21:24:28.893803: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234408)[0m 2021-01-16 21:24:28.902946: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234408)[0m 2021-01-16 21:24:28.905912: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f18ed102ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234408)[0m 2021-01-16 21:24:28.905950: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:24:29,407	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234409, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:29,410	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_41_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 49 ({'TERMINATED': 13, 'ERROR': 27, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 21 not shown
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_38_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-1404n6ey2d/error_2021-01-16_21-24-24.txt
 - train_func_39_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_39_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-17jf2nuq6a/error_2021-01-16_21-24-27.txt
 - train_func_41_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_41_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-20a0scn90a/error_2021-01-16_21-24-29.txt
RUNNING trials:
 - train_func_40_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_42_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_43_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_47_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_49_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=234423)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234423)[0m 2021-01-16 21:24:29.421487: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234423)[0m 2021-01-16 21:24:29.430043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234423)[0m 2021-01-16 21:24:29.432533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f172d0e8a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234423)[0m 2021-01-16 21:24:29.432564: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234412)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234412)[0m 2021-01-16 21:24:29.494340: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234412)[0m 2021-01-16 21:24:29.507006: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234412)[0m 2021-01-16 21:24:29.509129: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5a51103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234412)[0m 2021-01-16 21:24:29.509150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234416)[0m 2021-01-16 21:24:29,475	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234416)[0m Traceback (most recent call last):
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234416)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234416)[0m     param_dset[:] = val
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234416)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234416)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234416)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234416)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:29 2021
[2m[36m(pid=234416)[0m , filename = '/tmp/thalvari/4565628/automl_save_a1jqbwuj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4232711cac, total write size = 162036, bytes this sub-write = 162036, bytes actually written = 18446744073709551615, offset = 2359296)
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234416)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234416)[0m Traceback (most recent call last):
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234416)[0m     self._entrypoint()
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234416)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234416)[0m     output = train_func(config, reporter)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234416)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234416)[0m     config=config)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234416)[0m     model.save(model_path, config_path)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234416)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234416)[0m     self.model.save(model_path)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234416)[0m     signatures)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234416)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234416)[0m     f.close()
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234416)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234416)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:29 2021
[2m[36m(pid=234416)[0m , filename = '/tmp/thalvari/4565628/automl_save_a1jqbwuj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4231438dd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234416)[0m Exception in thread Thread-1:
[2m[36m(pid=234416)[0m Traceback (most recent call last):
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234416)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234416)[0m     param_dset[:] = val
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234416)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234416)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234416)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234416)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:29 2021
[2m[36m(pid=234416)[0m , filename = '/tmp/thalvari/4565628/automl_save_a1jqbwuj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4232711cac, total write size = 162036, bytes this sub-write = 162036, bytes actually written = 18446744073709551615, offset = 2359296)
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234416)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234416)[0m Traceback (most recent call last):
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234416)[0m     self._entrypoint()
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234416)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234416)[0m     output = train_func(config, reporter)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234416)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234416)[0m     config=config)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234416)[0m     model.save(model_path, config_path)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234416)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234416)[0m     self.model.save(model_path)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234416)[0m     signatures)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234416)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234416)[0m     f.close()
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234416)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234416)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234416)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:29 2021
[2m[36m(pid=234416)[0m , filename = '/tmp/thalvari/4565628/automl_save_a1jqbwuj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4231438dd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234416)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234416)[0m Traceback (most recent call last):
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234416)[0m     self.run()
[2m[36m(pid=234416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234416)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234416)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234409)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234409)[0m 
[2m[36m(pid=234409)[0m Stack (most recent call first):
2021-01-16 21:24:30,126	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234404, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:30,131	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_40_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234432)[0m 2021-01-16 21:24:30,265	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234432)[0m Traceback (most recent call last):
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234432)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234432)[0m     param_dset[:] = val
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234432)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234432)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234432)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234432)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:30 2021
[2m[36m(pid=234432)[0m , filename = '/tmp/thalvari/4565628/automl_save_k1_lv_e5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d7a83443c, total write size = 170228, bytes this sub-write = 170228, bytes actually written = 18446744073709551615, offset = 2351104)
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234432)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234432)[0m Traceback (most recent call last):
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234432)[0m     self._entrypoint()
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234432)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234432)[0m     output = train_func(config, reporter)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234432)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234432)[0m     config=config)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234432)[0m     model.save(model_path, config_path)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234432)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234432)[0m     self.model.save(model_path)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234432)[0m     signatures)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234432)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234432)[0m     f.close()
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234432)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234432)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:30 2021
[2m[36m(pid=234432)[0m , filename = '/tmp/thalvari/4565628/automl_save_k1_lv_e5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d7a438970, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234432)[0m Exception in thread Thread-1:
[2m[36m(pid=234432)[0m Traceback (most recent call last):
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234432)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234432)[0m     param_dset[:] = val
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234432)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234432)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234432)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234432)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:30 2021
[2m[36m(pid=234432)[0m , filename = '/tmp/thalvari/4565628/automl_save_k1_lv_e5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d7a83443c, total write size = 170228, bytes this sub-write = 170228, bytes actually written = 18446744073709551615, offset = 2351104)
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234432)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234432)[0m Traceback (most recent call last):
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234432)[0m     self._entrypoint()
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234432)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234432)[0m     output = train_func(config, reporter)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234432)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234432)[0m     config=config)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234432)[0m     model.save(model_path, config_path)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234432)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234432)[0m     self.model.save(model_path)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234432)[0m     signatures)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234432)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234432)[0m     f.close()
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234432)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234432)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234432)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:30 2021
[2m[36m(pid=234432)[0m , filename = '/tmp/thalvari/4565628/automl_save_k1_lv_e5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d7a438970, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234432)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234432)[0m Traceback (most recent call last):
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234432)[0m     self.run()
[2m[36m(pid=234432)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234432)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234432)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234404)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234404)[0m 
[2m[36m(pid=234404)[0m Stack (most recent call first):
2021-01-16 21:24:30,861	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234416, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:30,865	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_42_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234413)[0m 2021-01-16 21:24:31,077	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234413)[0m Traceback (most recent call last):
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234413)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234413)[0m     param_dset[:] = val
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234413)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234413)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234413)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234413)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:31 2021
[2m[36m(pid=234413)[0m , filename = '/tmp/thalvari/4565628/automl_save_o4khtwxj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f677e936c9c, total write size = 170228, bytes this sub-write = 170228, bytes actually written = 18446744073709551615, offset = 2347008)
[2m[36m(pid=234413)[0m 
[2m[36m(pid=234413)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234413)[0m 
[2m[36m(pid=234413)[0m Traceback (most recent call last):
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234413)[0m     self._entrypoint()
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234413)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234413)[0m     output = train_func(config, reporter)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234413)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234413)[0m     config=config)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234413)[0m     model.save(model_path, config_path)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234413)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234413)[0m     self.model.save(model_path)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234413)[0m     signatures)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234413)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234413)[0m     f.close()
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234413)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234413)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:31 2021
[2m[36m(pid=234413)[0m , filename = '/tmp/thalvari/4565628/automl_save_o4khtwxj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f677d65ff40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234413)[0m Exception in thread Thread-1:
[2m[36m(pid=234413)[0m Traceback (most recent call last):
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234413)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234413)[0m     param_dset[:] = val
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234413)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234413)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234413)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234413)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:31 2021
[2m[36m(pid=234413)[0m , filename = '/tmp/thalvari/4565628/automl_save_o4khtwxj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f677e936c9c, total write size = 170228, bytes this sub-write = 170228, bytes actually written = 18446744073709551615, offset = 2347008)
[2m[36m(pid=234413)[0m 
[2m[36m(pid=234413)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234413)[0m 
[2m[36m(pid=234413)[0m Traceback (most recent call last):
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234413)[0m     self._entrypoint()
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234413)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234413)[0m     output = train_func(config, reporter)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234413)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234413)[0m     config=config)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234413)[0m     model.save(model_path, config_path)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234413)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234413)[0m     self.model.save(model_path)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234413)[0m     signatures)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234413)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234413)[0m     f.close()
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234413)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234413)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234413)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:31 2021
[2m[36m(pid=234413)[0m , filename = '/tmp/thalvari/4565628/automl_save_o4khtwxj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f677d65ff40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234416)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234416)[0m 
[2m[36m(pid=234416)[0m Stack (most recent call first):
[2m[36m(pid=234413)[0m 
[2m[36m(pid=234413)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234413)[0m 
[2m[36m(pid=234413)[0m Traceback (most recent call last):
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234413)[0m     self.run()
[2m[36m(pid=234413)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234413)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234413)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234413)[0m 
2021-01-16 21:24:31,460	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234432, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:31,463	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_43_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234432)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234432)[0m 
[2m[36m(pid=234432)[0m Stack (most recent call first):
[2m[36m(pid=234427)[0m 2021-01-16 21:24:32,013	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234427)[0m Traceback (most recent call last):
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234427)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234427)[0m     param_dset[:] = val
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234427)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234427)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234427)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234427)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234427)[0m , filename = '/tmp/thalvari/4565628/automl_save_r1ty5dhc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eff46a032dc, total write size = 178420, bytes this sub-write = 178420, bytes actually written = 18446744073709551615, offset = 2334720)
[2m[36m(pid=234427)[0m 
[2m[36m(pid=234427)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234427)[0m 
[2m[36m(pid=234427)[0m Traceback (most recent call last):
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234427)[0m     self._entrypoint()
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234427)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234427)[0m     output = train_func(config, reporter)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234427)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234427)[0m     config=config)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234427)[0m     model.save(model_path, config_path)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234427)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234427)[0m     self.model.save(model_path)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234427)[0m     signatures)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234427)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234427)[0m     f.close()
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234427)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234427)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234427)[0m , filename = '/tmp/thalvari/4565628/automl_save_r1ty5dhc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eff4599b410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234427)[0m Exception in thread Thread-1:
[2m[36m(pid=234427)[0m Traceback (most recent call last):
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234427)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234427)[0m     param_dset[:] = val
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234427)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234427)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234427)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234427)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234427)[0m , filename = '/tmp/thalvari/4565628/automl_save_r1ty5dhc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eff46a032dc, total write size = 178420, bytes this sub-write = 178420, bytes actually written = 18446744073709551615, offset = 2334720)
[2m[36m(pid=234427)[0m 
[2m[36m(pid=234427)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234427)[0m 
[2m[36m(pid=234427)[0m Traceback (most recent call last):
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234427)[0m     self._entrypoint()
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234427)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234427)[0m     output = train_func(config, reporter)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234427)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234427)[0m     config=config)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234427)[0m     model.save(model_path, config_path)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234427)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234427)[0m     self.model.save(model_path)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234427)[0m     signatures)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234427)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234427)[0m     f.close()
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234427)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234427)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234427)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234427)[0m , filename = '/tmp/thalvari/4565628/automl_save_r1ty5dhc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eff4599b410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234427)[0m 
[2m[36m(pid=234427)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234427)[0m 
[2m[36m(pid=234427)[0m Traceback (most recent call last):
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234427)[0m     self.run()
[2m[36m(pid=234427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234427)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234427)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234427)[0m 
2021-01-16 21:24:32,241	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234413, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:32,246	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_44_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234408)[0m 2021-01-16 21:24:32,504	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234408)[0m Traceback (most recent call last):
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234408)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234408)[0m     param_dset[:] = val
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234408)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234408)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234408)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234408)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234408)[0m , filename = '/tmp/thalvari/4565628/automl_save_xv06tb6z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18ee9af13c, total write size = 194804, bytes this sub-write = 194804, bytes actually written = 18446744073709551615, offset = 2326528)
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234408)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234408)[0m Traceback (most recent call last):
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234408)[0m     self._entrypoint()
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234408)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234408)[0m     output = train_func(config, reporter)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234408)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234408)[0m     config=config)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234408)[0m     model.save(model_path, config_path)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234408)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234408)[0m     self.model.save(model_path)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234408)[0m     signatures)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234408)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234408)[0m     f.close()
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234408)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234408)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234408)[0m , filename = '/tmp/thalvari/4565628/automl_save_xv06tb6z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18ed75aeb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234408)[0m Exception in thread Thread-1:
[2m[36m(pid=234408)[0m Traceback (most recent call last):
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234408)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234408)[0m     param_dset[:] = val
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234408)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234408)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234408)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234408)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234408)[0m , filename = '/tmp/thalvari/4565628/automl_save_xv06tb6z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18ee9af13c, total write size = 194804, bytes this sub-write = 194804, bytes actually written = 18446744073709551615, offset = 2326528)
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234408)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234408)[0m Traceback (most recent call last):
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234408)[0m     self._entrypoint()
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234408)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234408)[0m     output = train_func(config, reporter)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234408)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234408)[0m     config=config)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234408)[0m     model.save(model_path, config_path)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234408)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234408)[0m     self.model.save(model_path)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234408)[0m     signatures)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234408)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234408)[0m     f.close()
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234408)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234408)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234408)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234408)[0m , filename = '/tmp/thalvari/4565628/automl_save_xv06tb6z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18ed75aeb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234408)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234408)[0m Traceback (most recent call last):
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234408)[0m     self.run()
[2m[36m(pid=234408)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234408)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234408)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234413)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234413)[0m 
[2m[36m(pid=234413)[0m Stack (most recent call first):
[2m[36m(pid=234428)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234428)[0m   agg_primitives: ['count']
[2m[36m(pid=234428)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234428)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234423)[0m 2021-01-16 21:24:32,854	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234423)[0m Traceback (most recent call last):
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234423)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234423)[0m     param_dset[:] = val
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234423)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234423)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234423)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234423)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234423)[0m , filename = '/tmp/thalvari/4565628/automl_save_266yoxuf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f172d56e248, total write size = 235608, bytes this sub-write = 235608, bytes actually written = 18446744073709551615, offset = 315392)
[2m[36m(pid=234423)[0m 
[2m[36m(pid=234423)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234423)[0m 
[2m[36m(pid=234423)[0m Traceback (most recent call last):
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234423)[0m     self._entrypoint()
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234423)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234423)[0m     output = train_func(config, reporter)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234423)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234423)[0m     config=config)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234423)[0m     model.save(model_path, config_path)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234423)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234423)[0m     self.model.save(model_path)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234423)[0m     signatures)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234423)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234423)[0m     f.close()
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234423)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234423)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234423)[0m , filename = '/tmp/thalvari/4565628/automl_save_266yoxuf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f172d65fc50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234423)[0m Exception in thread Thread-1:
[2m[36m(pid=234423)[0m Traceback (most recent call last):
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=234423)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=234423)[0m     param_dset[:] = val
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234423)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234423)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234423)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234423)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234423)[0m , filename = '/tmp/thalvari/4565628/automl_save_266yoxuf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f172d56e248, total write size = 235608, bytes this sub-write = 235608, bytes actually written = 18446744073709551615, offset = 315392)
[2m[36m(pid=234423)[0m 
[2m[36m(pid=234423)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234423)[0m 
[2m[36m(pid=234423)[0m Traceback (most recent call last):
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234423)[0m     self._entrypoint()
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234423)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234423)[0m     output = train_func(config, reporter)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234423)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234423)[0m     config=config)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234423)[0m     model.save(model_path, config_path)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234423)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234423)[0m     self.model.save(model_path)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234423)[0m     signatures)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234423)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234423)[0m     f.close()
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234423)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234423)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234423)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234423)[0m , filename = '/tmp/thalvari/4565628/automl_save_266yoxuf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f172d65fc50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234423)[0m 
[2m[36m(pid=234423)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234423)[0m 
[2m[36m(pid=234423)[0m Traceback (most recent call last):
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234423)[0m     self.run()
[2m[36m(pid=234423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234423)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234423)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234423)[0m 
[2m[36m(pid=244990)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=244992)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=244993)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=244991)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=244990)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=244992)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=244993)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=244991)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234412)[0m 2021-01-16 21:24:32,951	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234412)[0m Traceback (most recent call last):
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234412)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234412)[0m     param_dset[:] = val
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234412)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234412)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234412)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234412)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234412)[0m , filename = '/tmp/thalvari/4565628/automl_save_veipd80k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5a529c9b8c, total write size = 243956, bytes this sub-write = 243956, bytes actually written = 18446744073709551615, offset = 2277376)
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234412)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234412)[0m Traceback (most recent call last):
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234412)[0m     self._entrypoint()
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234412)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234412)[0m     output = train_func(config, reporter)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234412)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234412)[0m     config=config)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234412)[0m     model.save(model_path, config_path)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234412)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234412)[0m     self.model.save(model_path)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234412)[0m     signatures)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234412)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234412)[0m     f.close()
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234412)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234412)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234412)[0m , filename = '/tmp/thalvari/4565628/automl_save_veipd80k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5a51b0df80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234412)[0m Exception in thread Thread-1:
[2m[36m(pid=234412)[0m Traceback (most recent call last):
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234412)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234412)[0m     param_dset[:] = val
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234412)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234412)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234412)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234412)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234412)[0m , filename = '/tmp/thalvari/4565628/automl_save_veipd80k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5a529c9b8c, total write size = 243956, bytes this sub-write = 243956, bytes actually written = 18446744073709551615, offset = 2277376)
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234412)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234412)[0m Traceback (most recent call last):
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234412)[0m     self._entrypoint()
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234412)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234412)[0m     output = train_func(config, reporter)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234412)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234412)[0m     config=config)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234412)[0m     model.save(model_path, config_path)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234412)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234412)[0m     self.model.save(model_path)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234412)[0m     signatures)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234412)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234412)[0m     f.close()
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234412)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234412)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234412)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:32 2021
[2m[36m(pid=234412)[0m , filename = '/tmp/thalvari/4565628/automl_save_veipd80k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5a51b0df80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234412)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234412)[0m Traceback (most recent call last):
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234412)[0m     self.run()
[2m[36m(pid=234412)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234412)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234412)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234428)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234428)[0m Instructions for updating:
[2m[36m(pid=234428)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234428)[0m LSTM is selected.
[2m[36m(pid=245161)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245163)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245163)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245157)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245157)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245158)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245158)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245159)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245159)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245155)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245155)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245164)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245164)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245160)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245160)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245161)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-16 21:24:33,369	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234427, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:33,372	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_45_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234427)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234427)[0m 
[2m[36m(pid=234427)[0m Stack (most recent call first):
[2m[36m(pid=245498)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245498)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245496)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245496)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245494)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245494)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245497)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245497)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245500)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245500)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245499)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=245499)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=234428)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234428)[0m Instructions for updating:
[2m[36m(pid=234428)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:34,107	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234423, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:34,110	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_48_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234423)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234423)[0m 
[2m[36m(pid=234423)[0m Stack (most recent call first):
[2m[36m(pid=234414)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234414)[0m   agg_primitives: ['count']
[2m[36m(pid=234414)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234414)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234439)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=234439)[0m   agg_primitives: ['count']
[2m[36m(pid=234439)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=234439)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 56 ({'TERMINATED': 13, 'ERROR': 33, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 27 not shown
 - train_func_44_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_44_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-223owqjera/error_2021-01-16_21-24-32.txt
 - train_func_45_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_45_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-23j8i5ajxq/error_2021-01-16_21-24-33.txt
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_48_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-24z6t_a322/error_2021-01-16_21-24-34.txt
RUNNING trials:
 - train_func_46_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_47_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_49_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_54_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.75214,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_55_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_56_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

2021-01-16 21:24:35,073	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234408, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:35,076	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_46_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234428)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234428)[0m 2021-01-16 21:24:35.195623: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234428)[0m 2021-01-16 21:24:35.204273: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234428)[0m 2021-01-16 21:24:35.206546: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2369102ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234428)[0m 2021-01-16 21:24:35.206567: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234408)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234408)[0m 
[2m[36m(pid=234408)[0m Stack (most recent call first):
[2m[36m(pid=234414)[0m LSTM is selected.
[2m[36m(pid=234414)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234414)[0m Instructions for updating:
[2m[36m(pid=234414)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234439)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=234439)[0m Instructions for updating:
[2m[36m(pid=234439)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234439)[0m LSTM is selected.
2021-01-16 21:24:35,617	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234412, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:35,619	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_47_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234412)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234412)[0m 
[2m[36m(pid=234412)[0m Stack (most recent call first):
[2m[36m(pid=234414)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234414)[0m Instructions for updating:
[2m[36m(pid=234414)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234439)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=234439)[0m Instructions for updating:
[2m[36m(pid=234439)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=234439)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234439)[0m 2021-01-16 21:24:37.064393: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234439)[0m 2021-01-16 21:24:37.074829: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234439)[0m 2021-01-16 21:24:37.077769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9b190e9620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234439)[0m 2021-01-16 21:24:37.077827: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234414)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=234414)[0m 2021-01-16 21:24:37.088471: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=234414)[0m 2021-01-16 21:24:37.096555: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=234414)[0m 2021-01-16 21:24:37.099692: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efe19103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=234414)[0m 2021-01-16 21:24:37.099724: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=244992)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=244992)[0m   agg_primitives: ['count']
[2m[36m(pid=244992)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=244992)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245164)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245164)[0m   agg_primitives: ['count']
[2m[36m(pid=245164)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245164)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245499)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245499)[0m   agg_primitives: ['count']
[2m[36m(pid=245499)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245499)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245500)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245500)[0m   agg_primitives: ['count']
[2m[36m(pid=245500)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245500)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=244993)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=244993)[0m   agg_primitives: ['count']
[2m[36m(pid=244993)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=244993)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=234428)[0m 2021-01-16 21:24:37,831	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234428)[0m Traceback (most recent call last):
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234428)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234428)[0m     param_dset[:] = val
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234428)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234428)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234428)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234428)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:37 2021
[2m[36m(pid=234428)[0m , filename = '/tmp/thalvari/4565628/automl_save_vnmk681r/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f236a1f179c, total write size = 98548, bytes this sub-write = 98548, bytes actually written = 18446744073709551615, offset = 2154496)
[2m[36m(pid=234428)[0m 
[2m[36m(pid=234428)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234428)[0m 
[2m[36m(pid=234428)[0m Traceback (most recent call last):
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234428)[0m     self._entrypoint()
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234428)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234428)[0m     output = train_func(config, reporter)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234428)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234428)[0m     config=config)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234428)[0m     model.save(model_path, config_path)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234428)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234428)[0m     self.model.save(model_path)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234428)[0m     signatures)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234428)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234428)[0m     f.close()
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234428)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234428)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:37 2021
[2m[36m(pid=234428)[0m , filename = '/tmp/thalvari/4565628/automl_save_vnmk681r/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f236a453110, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234428)[0m Exception in thread Thread-1:
[2m[36m(pid=234428)[0m Traceback (most recent call last):
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234428)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234428)[0m     param_dset[:] = val
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234428)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234428)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234428)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234428)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:37 2021
[2m[36m(pid=234428)[0m , filename = '/tmp/thalvari/4565628/automl_save_vnmk681r/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f236a1f179c, total write size = 98548, bytes this sub-write = 98548, bytes actually written = 18446744073709551615, offset = 2154496)
[2m[36m(pid=234428)[0m 
[2m[36m(pid=234428)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234428)[0m 
[2m[36m(pid=234428)[0m Traceback (most recent call last):
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234428)[0m     self._entrypoint()
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234428)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234428)[0m     output = train_func(config, reporter)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234428)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234428)[0m     config=config)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234428)[0m     model.save(model_path, config_path)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234428)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234428)[0m     self.model.save(model_path)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234428)[0m     signatures)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234428)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234428)[0m     f.close()
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234428)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234428)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234428)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:37 2021
[2m[36m(pid=234428)[0m , filename = '/tmp/thalvari/4565628/automl_save_vnmk681r/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f236a453110, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234428)[0m 
[2m[36m(pid=234428)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234428)[0m 
[2m[36m(pid=234428)[0m Traceback (most recent call last):
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234428)[0m     self.run()
[2m[36m(pid=234428)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234428)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234428)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234428)[0m 
[2m[36m(pid=244992)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=244992)[0m Instructions for updating:
[2m[36m(pid=244992)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=244992)[0m LSTM is selected.
[2m[36m(pid=245164)[0m LSTM is selected.
[2m[36m(pid=245500)[0m LSTM is selected.
[2m[36m(pid=245499)[0m LSTM is selected.
[2m[36m(pid=244993)[0m LSTM is selected.
[2m[36m(pid=245164)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245164)[0m Instructions for updating:
[2m[36m(pid=245164)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245500)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245500)[0m Instructions for updating:
[2m[36m(pid=245500)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245499)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245499)[0m Instructions for updating:
[2m[36m(pid=245499)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=244993)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=244993)[0m Instructions for updating:
[2m[36m(pid=244993)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245498)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245498)[0m   agg_primitives: ['count']
[2m[36m(pid=245498)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245498)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=244992)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=244992)[0m Instructions for updating:
[2m[36m(pid=244992)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245164)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245164)[0m Instructions for updating:
[2m[36m(pid=245164)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245500)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245500)[0m Instructions for updating:
[2m[36m(pid=245500)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245499)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245499)[0m Instructions for updating:
[2m[36m(pid=245499)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=244993)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=244993)[0m Instructions for updating:
[2m[36m(pid=244993)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245498)[0m LSTM is selected.
2021-01-16 21:24:38,907	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234428, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:38,912	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_49_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245498)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245498)[0m Instructions for updating:
[2m[36m(pid=245498)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=234428)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234428)[0m 
[2m[36m(pid=234428)[0m Stack (most recent call first):
[2m[36m(pid=245496)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245496)[0m   agg_primitives: ['count']
[2m[36m(pid=245496)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245496)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245498)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245498)[0m Instructions for updating:
[2m[36m(pid=245498)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245164)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245164)[0m 2021-01-16 21:24:39.734693: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245164)[0m 2021-01-16 21:24:39.742223: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245164)[0m 2021-01-16 21:24:39.744264: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f620d102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245164)[0m 2021-01-16 21:24:39.744289: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245496)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245496)[0m Instructions for updating:
[2m[36m(pid=245496)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245496)[0m LSTM is selected.
[2m[36m(pid=245500)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245500)[0m 2021-01-16 21:24:39.745021: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245499)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245499)[0m 2021-01-16 21:24:39.728522: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245499)[0m 2021-01-16 21:24:39.738506: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245499)[0m 2021-01-16 21:24:39.740714: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f29e10e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245499)[0m 2021-01-16 21:24:39.740743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245500)[0m 2021-01-16 21:24:39.752886: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245500)[0m 2021-01-16 21:24:39.755161: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5bc90e86c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245500)[0m 2021-01-16 21:24:39.755192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=244992)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=244992)[0m 2021-01-16 21:24:39.844290: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=244992)[0m 2021-01-16 21:24:39.851894: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=244992)[0m 2021-01-16 21:24:39.853721: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4990e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=244992)[0m 2021-01-16 21:24:39.853740: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=244993)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=244993)[0m 2021-01-16 21:24:39.841435: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=244993)[0m 2021-01-16 21:24:39.849151: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=244993)[0m 2021-01-16 21:24:39.851330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb4250e8ae0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=244993)[0m 2021-01-16 21:24:39.851363: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=234414)[0m 2021-01-16 21:24:39,932	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234414)[0m Traceback (most recent call last):
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234414)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234414)[0m     param_dset[:] = val
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234414)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234414)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234414)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234414)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:39 2021
[2m[36m(pid=234414)[0m , filename = '/tmp/thalvari/4565628/automl_save_69dkpuku/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe19d2409c, total write size = 114932, bytes this sub-write = 114932, bytes actually written = 18446744073709551615, offset = 2138112)
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234414)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234414)[0m Traceback (most recent call last):
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234414)[0m     self._entrypoint()
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234414)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234414)[0m     output = train_func(config, reporter)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234414)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234414)[0m     config=config)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234414)[0m     model.save(model_path, config_path)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234414)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234414)[0m     self.model.save(model_path)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234414)[0m     signatures)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234414)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234414)[0m     f.close()
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234414)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234414)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:39 2021
[2m[36m(pid=234414)[0m , filename = '/tmp/thalvari/4565628/automl_save_69dkpuku/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe19b56080, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234414)[0m Exception in thread Thread-1:
[2m[36m(pid=234414)[0m Traceback (most recent call last):
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234414)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234414)[0m     param_dset[:] = val
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234414)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234414)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234414)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234414)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:39 2021
[2m[36m(pid=234414)[0m , filename = '/tmp/thalvari/4565628/automl_save_69dkpuku/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe19d2409c, total write size = 114932, bytes this sub-write = 114932, bytes actually written = 18446744073709551615, offset = 2138112)
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234414)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234414)[0m Traceback (most recent call last):
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234414)[0m     self._entrypoint()
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234414)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234414)[0m     output = train_func(config, reporter)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234414)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234414)[0m     config=config)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234414)[0m     model.save(model_path, config_path)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234414)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234414)[0m     self.model.save(model_path)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234414)[0m     signatures)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234414)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234414)[0m     f.close()
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234414)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234414)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234414)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:39 2021
[2m[36m(pid=234414)[0m , filename = '/tmp/thalvari/4565628/automl_save_69dkpuku/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe19b56080, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234414)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234414)[0m Traceback (most recent call last):
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234414)[0m     self.run()
[2m[36m(pid=234414)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234414)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234414)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234439)[0m 2021-01-16 21:24:40,190	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=234439)[0m Traceback (most recent call last):
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234439)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234439)[0m     param_dset[:] = val
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234439)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234439)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234439)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234439)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:40 2021
[2m[36m(pid=234439)[0m , filename = '/tmp/thalvari/4565628/automl_save_dx7t0j7f/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9b1a1b1dfc, total write size = 106740, bytes this sub-write = 106740, bytes actually written = 18446744073709551615, offset = 2142208)
[2m[36m(pid=234439)[0m 
[2m[36m(pid=234439)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234439)[0m 
[2m[36m(pid=234439)[0m Traceback (most recent call last):
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234439)[0m     self._entrypoint()
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234439)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234439)[0m     output = train_func(config, reporter)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234439)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234439)[0m     config=config)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234439)[0m     model.save(model_path, config_path)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234439)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234439)[0m     self.model.save(model_path)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234439)[0m     signatures)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234439)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234439)[0m     f.close()
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234439)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234439)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:40 2021
[2m[36m(pid=234439)[0m , filename = '/tmp/thalvari/4565628/automl_save_dx7t0j7f/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9b1a9ff1f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234439)[0m Exception in thread Thread-1:
[2m[36m(pid=234439)[0m Traceback (most recent call last):
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=234439)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=234439)[0m     param_dset[:] = val
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=234439)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=234439)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=234439)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=234439)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:40 2021
[2m[36m(pid=234439)[0m , filename = '/tmp/thalvari/4565628/automl_save_dx7t0j7f/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9b1a1b1dfc, total write size = 106740, bytes this sub-write = 106740, bytes actually written = 18446744073709551615, offset = 2142208)
[2m[36m(pid=234439)[0m 
[2m[36m(pid=234439)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234439)[0m 
[2m[36m(pid=234439)[0m Traceback (most recent call last):
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=234439)[0m     self._entrypoint()
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=234439)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=234439)[0m     output = train_func(config, reporter)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=234439)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=234439)[0m     config=config)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=234439)[0m     model.save(model_path, config_path)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=234439)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=234439)[0m     self.model.save(model_path)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=234439)[0m     signatures)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=234439)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=234439)[0m     f.close()
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=234439)[0m     h5i.dec_ref(id_)
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=234439)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=234439)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:40 2021
[2m[36m(pid=234439)[0m , filename = '/tmp/thalvari/4565628/automl_save_dx7t0j7f/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9b1a9ff1f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=234439)[0m 
[2m[36m(pid=234439)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=234439)[0m 
[2m[36m(pid=234439)[0m Traceback (most recent call last):
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=234439)[0m     self.run()
[2m[36m(pid=234439)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=234439)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=234439)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=234439)[0m 
[2m[36m(pid=245496)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245496)[0m Instructions for updating:
[2m[36m(pid=245496)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245498)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245498)[0m 2021-01-16 21:24:40.511875: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245498)[0m 2021-01-16 21:24:40.519599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245498)[0m 2021-01-16 21:24:40.521440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92910e9fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245498)[0m 2021-01-16 21:24:40.521461: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:24:41,054	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234414, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:41,058	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_51_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 59 ({'TERMINATED': 13, 'ERROR': 37, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 31 not shown
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_48_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-24z6t_a322/error_2021-01-16_21-24-34.txt
 - train_func_49_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_49_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-28fk7lm8u8/error_2021-01-16_21-24-38.txt
 - train_func_51_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_51_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-30whe2fgab/error_2021-01-16_21-24-41.txt
RUNNING trials:
 - train_func_50_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_53_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_57_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_58_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_59_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=234414)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234414)[0m 
[2m[36m(pid=234414)[0m Stack (most recent call first):
[2m[36m(pid=245496)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245496)[0m 2021-01-16 21:24:41.277412: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245496)[0m 2021-01-16 21:24:41.290192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245496)[0m 2021-01-16 21:24:41.303512: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb1ad0e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245496)[0m 2021-01-16 21:24:41.303562: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:24:41,792	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=234439, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:41,799	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_50_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=234439)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=234439)[0m 
[2m[36m(pid=234439)[0m Stack (most recent call first):
[2m[36m(pid=245500)[0m 2021-01-16 21:24:43,289	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245500)[0m Traceback (most recent call last):
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245500)[0m     self._entrypoint()
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245500)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245500)[0m     output = train_func(config, reporter)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245500)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245500)[0m     config=config)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245500)[0m     model.save(model_path, config_path)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245500)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245500)[0m     self.model.save(model_path)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245500)[0m     signatures)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245500)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245500)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245500)[0m     param_dset[:] = val
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245500)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245500)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245500)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245500)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245500)[0m , filename = '/tmp/thalvari/4565628/automl_save_kyrofebf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5bca7fcc70, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 819288)
[2m[36m(pid=245500)[0m Exception in thread Thread-1:
[2m[36m(pid=245500)[0m Traceback (most recent call last):
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245500)[0m     self._entrypoint()
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245500)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245500)[0m     output = train_func(config, reporter)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245500)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245500)[0m     config=config)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245500)[0m     model.save(model_path, config_path)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245500)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245500)[0m     self.model.save(model_path)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245500)[0m     signatures)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245500)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245500)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245500)[0m     param_dset[:] = val
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245500)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245500)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245500)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245500)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245500)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245500)[0m , filename = '/tmp/thalvari/4565628/automl_save_kyrofebf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5bca7fcc70, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 819288)
[2m[36m(pid=245500)[0m 
[2m[36m(pid=245500)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245500)[0m 
[2m[36m(pid=245500)[0m Traceback (most recent call last):
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245500)[0m     self.run()
[2m[36m(pid=245500)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245500)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245500)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245500)[0m 
[2m[36m(pid=245499)[0m 2021-01-16 21:24:43,289	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245499)[0m Traceback (most recent call last):
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245499)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245499)[0m     param_dset[:] = val
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245499)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245499)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245499)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245499)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245499)[0m , filename = '/tmp/thalvari/4565628/automl_save_o8vzek0h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f29e2884e08, total write size = 953944, bytes this sub-write = 953944, bytes actually written = 18446744073709551615, offset = 1003520)
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245499)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245499)[0m Traceback (most recent call last):
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245499)[0m     self._entrypoint()
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245499)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245499)[0m     output = train_func(config, reporter)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245499)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245499)[0m     config=config)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245499)[0m     model.save(model_path, config_path)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245499)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245499)[0m     self.model.save(model_path)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245499)[0m     signatures)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245499)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245499)[0m     f.close()
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245499)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245499)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245499)[0m , filename = '/tmp/thalvari/4565628/automl_save_o8vzek0h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f29e172a750, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245499)[0m Exception in thread Thread-1:
[2m[36m(pid=245499)[0m Traceback (most recent call last):
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245499)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245499)[0m     param_dset[:] = val
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245499)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245499)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245499)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245499)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245499)[0m , filename = '/tmp/thalvari/4565628/automl_save_o8vzek0h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f29e2884e08, total write size = 953944, bytes this sub-write = 953944, bytes actually written = 18446744073709551615, offset = 1003520)
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245499)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245499)[0m Traceback (most recent call last):
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245499)[0m     self._entrypoint()
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245499)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245499)[0m     output = train_func(config, reporter)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245499)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245499)[0m     config=config)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245499)[0m     model.save(model_path, config_path)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245499)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245499)[0m     self.model.save(model_path)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245499)[0m     signatures)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245499)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245499)[0m     f.close()
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245499)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245499)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245499)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245499)[0m , filename = '/tmp/thalvari/4565628/automl_save_o8vzek0h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f29e172a750, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245499)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245499)[0m Traceback (most recent call last):
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245499)[0m     self.run()
[2m[36m(pid=245499)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245499)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245499)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245164)[0m 2021-01-16 21:24:43,370	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245164)[0m Traceback (most recent call last):
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245164)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245164)[0m     param_dset[:] = val
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245164)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245164)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245164)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245164)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245164)[0m , filename = '/tmp/thalvari/4565628/automl_save_8zz2j4iq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f620e8ddf18, total write size = 140888, bytes this sub-write = 140888, bytes actually written = 18446744073709551615, offset = 1818624)
[2m[36m(pid=245164)[0m 
[2m[36m(pid=245164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245164)[0m 
[2m[36m(pid=245164)[0m Traceback (most recent call last):
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245164)[0m     self._entrypoint()
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245164)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245164)[0m     output = train_func(config, reporter)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245164)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245164)[0m     config=config)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245164)[0m     model.save(model_path, config_path)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245164)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245164)[0m     self.model.save(model_path)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245164)[0m     signatures)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245164)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245164)[0m     f.close()
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245164)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245164)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245164)[0m , filename = '/tmp/thalvari/4565628/automl_save_8zz2j4iq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f620e58f360, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245164)[0m Exception in thread Thread-1:
[2m[36m(pid=245164)[0m Traceback (most recent call last):
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245164)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245164)[0m     param_dset[:] = val
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245164)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245164)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245164)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245164)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245164)[0m , filename = '/tmp/thalvari/4565628/automl_save_8zz2j4iq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f620e8ddf18, total write size = 140888, bytes this sub-write = 140888, bytes actually written = 18446744073709551615, offset = 1818624)
[2m[36m(pid=245164)[0m 
[2m[36m(pid=245164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245164)[0m 
[2m[36m(pid=245164)[0m Traceback (most recent call last):
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245164)[0m     self._entrypoint()
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245164)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245164)[0m     output = train_func(config, reporter)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245164)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245164)[0m     config=config)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245164)[0m     model.save(model_path, config_path)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245164)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245164)[0m     self.model.save(model_path)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245164)[0m     signatures)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245164)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245164)[0m     f.close()
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245164)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245164)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245164)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245164)[0m , filename = '/tmp/thalvari/4565628/automl_save_8zz2j4iq/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f620e58f360, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245164)[0m 
[2m[36m(pid=245164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245164)[0m 
[2m[36m(pid=245164)[0m Traceback (most recent call last):
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245164)[0m     self.run()
[2m[36m(pid=245164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245164)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245164)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245164)[0m 
[2m[36m(pid=244992)[0m 2021-01-16 21:24:43,440	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=244992)[0m Traceback (most recent call last):
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=244992)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=244992)[0m     param_dset[:] = val
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244992)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244992)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244992)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244992)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244992)[0m , filename = '/tmp/thalvari/4565628/automl_save_8hj8lr11/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe49aa74c18, total write size = 671320, bytes this sub-write = 671320, bytes actually written = 18446744073709551615, offset = 1286144)
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244992)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244992)[0m Traceback (most recent call last):
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244992)[0m     self._entrypoint()
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244992)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244992)[0m     output = train_func(config, reporter)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244992)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244992)[0m     config=config)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244992)[0m     model.save(model_path, config_path)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244992)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244992)[0m     self.model.save(model_path)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244992)[0m     signatures)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244992)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244992)[0m     f.close()
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244992)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244992)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244992)[0m , filename = '/tmp/thalvari/4565628/automl_save_8hj8lr11/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe49a156fb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244992)[0m Exception in thread Thread-1:
[2m[36m(pid=244992)[0m Traceback (most recent call last):
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=244992)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=244992)[0m     param_dset[:] = val
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244992)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244992)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244992)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244992)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244992)[0m , filename = '/tmp/thalvari/4565628/automl_save_8hj8lr11/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe49aa74c18, total write size = 671320, bytes this sub-write = 671320, bytes actually written = 18446744073709551615, offset = 1286144)
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244992)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244992)[0m Traceback (most recent call last):
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244992)[0m     self._entrypoint()
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244992)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244992)[0m     output = train_func(config, reporter)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244992)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244992)[0m     config=config)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244992)[0m     model.save(model_path, config_path)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244992)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244992)[0m     self.model.save(model_path)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244992)[0m     signatures)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244992)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244992)[0m     f.close()
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244992)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244992)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244992)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244992)[0m , filename = '/tmp/thalvari/4565628/automl_save_8hj8lr11/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe49a156fb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244992)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244992)[0m Traceback (most recent call last):
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=244992)[0m     self.run()
[2m[36m(pid=244992)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=244992)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=244992)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244993)[0m 2021-01-16 21:24:43,499	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=244993)[0m Traceback (most recent call last):
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=244993)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=244993)[0m     param_dset[:] = val
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244993)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244993)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244993)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244993)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244993)[0m , filename = '/tmp/thalvari/4565628/automl_save_k2w_fu6m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb4266dc97c, total write size = 155892, bytes this sub-write = 155892, bytes actually written = 18446744073709551615, offset = 2093056)
[2m[36m(pid=244993)[0m 
[2m[36m(pid=244993)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244993)[0m 
[2m[36m(pid=244993)[0m Traceback (most recent call last):
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244993)[0m     self._entrypoint()
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244993)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244993)[0m     output = train_func(config, reporter)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244993)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244993)[0m     config=config)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244993)[0m     model.save(model_path, config_path)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244993)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244993)[0m     self.model.save(model_path)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244993)[0m     signatures)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244993)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244993)[0m     f.close()
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244993)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244993)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244993)[0m , filename = '/tmp/thalvari/4565628/automl_save_k2w_fu6m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb4263f9cc0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244993)[0m Exception in thread Thread-1:
[2m[36m(pid=244993)[0m Traceback (most recent call last):
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=244993)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=244993)[0m     param_dset[:] = val
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244993)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244993)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244993)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244993)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244993)[0m , filename = '/tmp/thalvari/4565628/automl_save_k2w_fu6m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb4266dc97c, total write size = 155892, bytes this sub-write = 155892, bytes actually written = 18446744073709551615, offset = 2093056)
[2m[36m(pid=244993)[0m 
[2m[36m(pid=244993)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244993)[0m 
[2m[36m(pid=244993)[0m Traceback (most recent call last):
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244993)[0m     self._entrypoint()
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244993)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244993)[0m     output = train_func(config, reporter)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244993)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244993)[0m     config=config)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244993)[0m     model.save(model_path, config_path)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244993)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244993)[0m     self.model.save(model_path)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244993)[0m     signatures)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244993)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244993)[0m     f.close()
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244993)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244993)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244993)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=244993)[0m , filename = '/tmp/thalvari/4565628/automl_save_k2w_fu6m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb4263f9cc0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244993)[0m 
[2m[36m(pid=244993)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244993)[0m 
[2m[36m(pid=244993)[0m Traceback (most recent call last):
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=244993)[0m     self.run()
[2m[36m(pid=244993)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=244993)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=244993)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=244993)[0m 
[2m[36m(pid=245498)[0m 2021-01-16 21:24:43,769	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245498)[0m Traceback (most recent call last):
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245498)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245498)[0m     param_dset[:] = val
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245498)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245498)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245498)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245498)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245498)[0m , filename = '/tmp/thalvari/4565628/automl_save_3h1njlpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9292022fdc, total write size = 155892, bytes this sub-write = 155892, bytes actually written = 18446744073709551615, offset = 2093056)
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245498)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245498)[0m Traceback (most recent call last):
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245498)[0m     self._entrypoint()
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245498)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245498)[0m     output = train_func(config, reporter)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245498)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245498)[0m     config=config)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245498)[0m     model.save(model_path, config_path)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245498)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245498)[0m     self.model.save(model_path)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245498)[0m     signatures)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245498)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245498)[0m     f.close()
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245498)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245498)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245498)[0m , filename = '/tmp/thalvari/4565628/automl_save_3h1njlpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9291fd9c90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245498)[0m Exception in thread Thread-1:
[2m[36m(pid=245498)[0m Traceback (most recent call last):
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245498)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245498)[0m     param_dset[:] = val
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245498)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245498)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245498)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245498)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245498)[0m , filename = '/tmp/thalvari/4565628/automl_save_3h1njlpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9292022fdc, total write size = 155892, bytes this sub-write = 155892, bytes actually written = 18446744073709551615, offset = 2093056)
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245498)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245498)[0m Traceback (most recent call last):
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245498)[0m     self._entrypoint()
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245498)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245498)[0m     output = train_func(config, reporter)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245498)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245498)[0m     config=config)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245498)[0m     model.save(model_path, config_path)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245498)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245498)[0m     self.model.save(model_path)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245498)[0m     signatures)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245498)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245498)[0m     f.close()
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245498)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245498)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245498)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:43 2021
[2m[36m(pid=245498)[0m , filename = '/tmp/thalvari/4565628/automl_save_3h1njlpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9291fd9c90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245498)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245498)[0m Traceback (most recent call last):
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245498)[0m     self.run()
[2m[36m(pid=245498)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245498)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245498)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245494)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245494)[0m   agg_primitives: ['count']
[2m[36m(pid=245494)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245494)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:24:44,337	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245499, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:44,342	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_56_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245499)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245499)[0m 
[2m[36m(pid=245499)[0m Stack (most recent call first):
[2m[36m(pid=245494)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245494)[0m Instructions for updating:
[2m[36m(pid=245494)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245494)[0m LSTM is selected.
[2m[36m(pid=245496)[0m 2021-01-16 21:24:44,687	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245496)[0m Traceback (most recent call last):
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245496)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245496)[0m     param_dset[:] = val
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245496)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245496)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245496)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245496)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:44 2021
[2m[36m(pid=245496)[0m , filename = '/tmp/thalvari/4565628/automl_save_0yodxa44/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb1ae93f69c, total write size = 168180, bytes this sub-write = 168180, bytes actually written = 18446744073709551615, offset = 2080768)
[2m[36m(pid=245496)[0m 
[2m[36m(pid=245496)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245496)[0m 
[2m[36m(pid=245496)[0m Traceback (most recent call last):
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245496)[0m     self._entrypoint()
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245496)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245496)[0m     output = train_func(config, reporter)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245496)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245496)[0m     config=config)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245496)[0m     model.save(model_path, config_path)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245496)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245496)[0m     self.model.save(model_path)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245496)[0m     signatures)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245496)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245496)[0m     f.close()
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245496)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245496)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:44 2021
[2m[36m(pid=245496)[0m , filename = '/tmp/thalvari/4565628/automl_save_0yodxa44/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb1ae58a090, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245496)[0m Exception in thread Thread-1:
[2m[36m(pid=245496)[0m Traceback (most recent call last):
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245496)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245496)[0m     param_dset[:] = val
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245496)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245496)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245496)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245496)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:44 2021
[2m[36m(pid=245496)[0m , filename = '/tmp/thalvari/4565628/automl_save_0yodxa44/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb1ae93f69c, total write size = 168180, bytes this sub-write = 168180, bytes actually written = 18446744073709551615, offset = 2080768)
[2m[36m(pid=245496)[0m 
[2m[36m(pid=245496)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245496)[0m 
[2m[36m(pid=245496)[0m Traceback (most recent call last):
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245496)[0m     self._entrypoint()
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245496)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245496)[0m     output = train_func(config, reporter)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245496)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245496)[0m     config=config)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245496)[0m     model.save(model_path, config_path)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245496)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245496)[0m     self.model.save(model_path)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245496)[0m     signatures)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245496)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245496)[0m     f.close()
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245496)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245496)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245496)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:44 2021
[2m[36m(pid=245496)[0m , filename = '/tmp/thalvari/4565628/automl_save_0yodxa44/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb1ae58a090, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245496)[0m 
[2m[36m(pid=245496)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245496)[0m 
[2m[36m(pid=245496)[0m Traceback (most recent call last):
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245496)[0m     self.run()
[2m[36m(pid=245496)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245496)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245496)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245496)[0m 
2021-01-16 21:24:45,164	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245498, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:45,166	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_57_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245494)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245494)[0m Instructions for updating:
[2m[36m(pid=245494)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245498)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245498)[0m 
[2m[36m(pid=245498)[0m Stack (most recent call first):
[2m[36m(pid=245160)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245160)[0m   agg_primitives: ['count']
[2m[36m(pid=245160)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245160)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245497)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245497)[0m   agg_primitives: ['count']
[2m[36m(pid=245497)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245497)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:24:45,699	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245500, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:45,701	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_55_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245160)[0m LSTM is selected.
[2m[36m(pid=245497)[0m LSTM is selected.
[2m[36m(pid=245160)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245160)[0m Instructions for updating:
[2m[36m(pid=245160)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245497)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245497)[0m Instructions for updating:
[2m[36m(pid=245497)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245494)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245494)[0m 2021-01-16 21:24:46.117449: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245494)[0m 2021-01-16 21:24:46.124968: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245494)[0m 2021-01-16 21:24:46.126999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a910e8e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245494)[0m 2021-01-16 21:24:46.127019: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 64 ({'TERMINATED': 13, 'ERROR': 41, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 35 not shown
 - train_func_55_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_55_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-345715xrpw/error_2021-01-16_21-24-45.txt
 - train_func_56_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_56_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-35i3toc41b/error_2021-01-16_21-24-44.txt
 - train_func_57_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_57_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-35qrl27826/error_2021-01-16_21-24-45.txt
RUNNING trials:
 - train_func_52_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_53_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_54_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.75214,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_62_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_63_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_64_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

2021-01-16 21:24:46,308	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245164, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:46,310	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_54_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.75214,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245164)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245164)[0m 
[2m[36m(pid=245164)[0m Stack (most recent call first):
[2m[36m(pid=245160)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245160)[0m Instructions for updating:
[2m[36m(pid=245160)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245497)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245497)[0m Instructions for updating:
[2m[36m(pid=245497)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:46,935	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245496, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:46,938	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_58_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245496)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245496)[0m 
[2m[36m(pid=245496)[0m Stack (most recent call first):
[2m[36m(pid=245497)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245497)[0m 2021-01-16 21:24:47.427015: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245497)[0m 2021-01-16 21:24:47.434653: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245497)[0m 2021-01-16 21:24:47.436634: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcbf50e9860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245497)[0m 2021-01-16 21:24:47.436653: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245160)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245160)[0m 2021-01-16 21:24:47.463339: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245160)[0m 2021-01-16 21:24:47.472150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245160)[0m 2021-01-16 21:24:47.474340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f024d103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245160)[0m 2021-01-16 21:24:47.474362: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:24:47,747	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=244993, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:47,750	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_52_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=244993)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=244993)[0m 
[2m[36m(pid=244993)[0m Stack (most recent call first):
2021-01-16 21:24:48,328	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=244992, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:48,331	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_53_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245161)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245161)[0m   agg_primitives: ['count']
[2m[36m(pid=245161)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245161)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245163)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245163)[0m   agg_primitives: ['count']
[2m[36m(pid=245163)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245163)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=244992)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=244992)[0m 
[2m[36m(pid=244992)[0m Stack (most recent call first):
[2m[36m(pid=245494)[0m 2021-01-16 21:24:48,704	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245494)[0m Traceback (most recent call last):
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245494)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245494)[0m     param_dset[:] = val
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245494)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245494)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245494)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245494)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:48 2021
[2m[36m(pid=245494)[0m , filename = '/tmp/thalvari/4565628/automl_save_u1cbv0_0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9a926eaffc, total write size = 176372, bytes this sub-write = 176372, bytes actually written = 18446744073709551615, offset = 2072576)
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245494)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245494)[0m Traceback (most recent call last):
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245494)[0m     self._entrypoint()
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245494)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245494)[0m     output = train_func(config, reporter)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245494)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245494)[0m     config=config)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245494)[0m     model.save(model_path, config_path)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245494)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245494)[0m     self.model.save(model_path)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245494)[0m     signatures)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245494)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245494)[0m     f.close()
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245494)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245494)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:48 2021
[2m[36m(pid=245494)[0m , filename = '/tmp/thalvari/4565628/automl_save_u1cbv0_0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9a91f6fdb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245494)[0m Exception in thread Thread-1:
[2m[36m(pid=245494)[0m Traceback (most recent call last):
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245494)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245494)[0m     param_dset[:] = val
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245494)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245494)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245494)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245494)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:48 2021
[2m[36m(pid=245494)[0m , filename = '/tmp/thalvari/4565628/automl_save_u1cbv0_0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9a926eaffc, total write size = 176372, bytes this sub-write = 176372, bytes actually written = 18446744073709551615, offset = 2072576)
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245494)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245494)[0m Traceback (most recent call last):
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245494)[0m     self._entrypoint()
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245494)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245494)[0m     output = train_func(config, reporter)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245494)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245494)[0m     config=config)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245494)[0m     model.save(model_path, config_path)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245494)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245494)[0m     self.model.save(model_path)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245494)[0m     signatures)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245494)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245494)[0m     f.close()
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245494)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245494)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245494)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:48 2021
[2m[36m(pid=245494)[0m , filename = '/tmp/thalvari/4565628/automl_save_u1cbv0_0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9a91f6fdb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245494)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245494)[0m Traceback (most recent call last):
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245494)[0m     self.run()
[2m[36m(pid=245494)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245494)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245494)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245161)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245161)[0m Instructions for updating:
[2m[36m(pid=245161)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245161)[0m LSTM is selected.
[2m[36m(pid=245163)[0m LSTM is selected.
[2m[36m(pid=245163)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245163)[0m Instructions for updating:
[2m[36m(pid=245163)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245161)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245161)[0m Instructions for updating:
[2m[36m(pid=245161)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245163)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245163)[0m Instructions for updating:
[2m[36m(pid=245163)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:49,723	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245494, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:49,728	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_59_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245157)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245157)[0m   agg_primitives: ['count']
[2m[36m(pid=245157)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245157)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245494)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245494)[0m 
[2m[36m(pid=245494)[0m Stack (most recent call first):
[2m[36m(pid=245157)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245157)[0m Instructions for updating:
[2m[36m(pid=245157)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245157)[0m LSTM is selected.
[2m[36m(pid=245160)[0m 2021-01-16 21:24:50,340	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245160)[0m Traceback (most recent call last):
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245160)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245160)[0m     param_dset[:] = val
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245160)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245160)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245160)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245160)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245160)[0m , filename = '/tmp/thalvari/4565628/automl_save_iaokj6mt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f024e822e08, total write size = 718424, bytes this sub-write = 718424, bytes actually written = 18446744073709551615, offset = 1241088)
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245160)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245160)[0m Traceback (most recent call last):
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245160)[0m     self._entrypoint()
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245160)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245160)[0m     output = train_func(config, reporter)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245160)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245160)[0m     config=config)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245160)[0m     model.save(model_path, config_path)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245160)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245160)[0m     self.model.save(model_path)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245160)[0m     signatures)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245160)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245160)[0m     f.close()
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245160)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245160)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245160)[0m , filename = '/tmp/thalvari/4565628/automl_save_iaokj6mt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f024e447ae0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245160)[0m Exception in thread Thread-1:
[2m[36m(pid=245160)[0m Traceback (most recent call last):
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245160)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245160)[0m     param_dset[:] = val
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245160)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245160)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245160)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245160)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245160)[0m , filename = '/tmp/thalvari/4565628/automl_save_iaokj6mt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f024e822e08, total write size = 718424, bytes this sub-write = 718424, bytes actually written = 18446744073709551615, offset = 1241088)
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245160)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245160)[0m Traceback (most recent call last):
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245160)[0m     self._entrypoint()
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245160)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245160)[0m     output = train_func(config, reporter)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245160)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245160)[0m     config=config)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245160)[0m     model.save(model_path, config_path)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245160)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245160)[0m     self.model.save(model_path)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245160)[0m     signatures)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245160)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245160)[0m     f.close()
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245160)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245160)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245160)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245160)[0m , filename = '/tmp/thalvari/4565628/automl_save_iaokj6mt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f024e447ae0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245160)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245160)[0m Traceback (most recent call last):
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245160)[0m     self.run()
[2m[36m(pid=245160)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245160)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245160)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245497)[0m 2021-01-16 21:24:50,379	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245497)[0m Traceback (most recent call last):
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245497)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245497)[0m     param_dset[:] = val
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245497)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245497)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245497)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245497)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245497)[0m , filename = '/tmp/thalvari/4565628/automl_save_a8gbor4d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbf6a1d0fc, total write size = 192756, bytes this sub-write = 192756, bytes actually written = 18446744073709551615, offset = 2056192)
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245497)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245497)[0m Traceback (most recent call last):
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245497)[0m     self._entrypoint()
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245497)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245497)[0m     output = train_func(config, reporter)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245497)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245497)[0m     config=config)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245497)[0m     model.save(model_path, config_path)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245497)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245497)[0m     self.model.save(model_path)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245497)[0m     signatures)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245497)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245497)[0m     f.close()
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245497)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245497)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245497)[0m , filename = '/tmp/thalvari/4565628/automl_save_a8gbor4d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbf5d3b0a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245497)[0m Exception in thread Thread-1:
[2m[36m(pid=245497)[0m Traceback (most recent call last):
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245497)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245497)[0m     param_dset[:] = val
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245497)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245497)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245497)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245497)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245497)[0m , filename = '/tmp/thalvari/4565628/automl_save_a8gbor4d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbf6a1d0fc, total write size = 192756, bytes this sub-write = 192756, bytes actually written = 18446744073709551615, offset = 2056192)
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245497)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245497)[0m Traceback (most recent call last):
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245497)[0m     self._entrypoint()
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245497)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245497)[0m     output = train_func(config, reporter)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245497)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245497)[0m     config=config)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245497)[0m     model.save(model_path, config_path)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245497)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245497)[0m     self.model.save(model_path)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245497)[0m     signatures)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245497)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245497)[0m     f.close()
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245497)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245497)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245497)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:50 2021
[2m[36m(pid=245497)[0m , filename = '/tmp/thalvari/4565628/automl_save_a8gbor4d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbf5d3b0a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245497)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245497)[0m Traceback (most recent call last):
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245497)[0m     self.run()
[2m[36m(pid=245497)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245497)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245497)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245161)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245161)[0m 2021-01-16 21:24:50.500143: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245161)[0m 2021-01-16 21:24:50.507761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245161)[0m 2021-01-16 21:24:50.509719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3139102900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245161)[0m 2021-01-16 21:24:50.509738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245163)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245163)[0m 2021-01-16 21:24:50.532639: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245163)[0m 2021-01-16 21:24:50.540384: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245163)[0m 2021-01-16 21:24:50.542222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83410e8300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245163)[0m 2021-01-16 21:24:50.542240: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245158)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245158)[0m   agg_primitives: ['count']
[2m[36m(pid=245158)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245158)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245157)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245157)[0m Instructions for updating:
[2m[36m(pid=245157)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245158)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245158)[0m Instructions for updating:
[2m[36m(pid=245158)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245158)[0m LSTM is selected.
[2m[36m(pid=245159)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245159)[0m   agg_primitives: ['count']
[2m[36m(pid=245159)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245159)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=245155)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=245155)[0m   agg_primitives: ['count']
[2m[36m(pid=245155)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=245155)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=244990)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=244990)[0m   agg_primitives: ['count']
[2m[36m(pid=244990)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=244990)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:24:51,459	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245497, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:51,462	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_60_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 69 ({'TERMINATED': 13, 'ERROR': 47, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 41 not shown
 - train_func_58_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_58_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-36m5fc28qa/error_2021-01-16_21-24-46.txt
 - train_func_59_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_59_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-39kr28usvs/error_2021-01-16_21-24-49.txt
 - train_func_60_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_60_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-41kutsyc1c/error_2021-01-16_21-24-51.txt
RUNNING trials:
 - train_func_61_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_62_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_63_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_67_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_68_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_69_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=245159)[0m LSTM is selected.
[2m[36m(pid=245159)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245159)[0m Instructions for updating:
[2m[36m(pid=245159)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245497)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245497)[0m 
[2m[36m(pid=245497)[0m Stack (most recent call first):
[2m[36m(pid=245157)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245157)[0m 2021-01-16 21:24:51.727090: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245157)[0m 2021-01-16 21:24:51.736275: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245157)[0m 2021-01-16 21:24:51.739758: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0590e8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245157)[0m 2021-01-16 21:24:51.739791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245158)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245158)[0m Instructions for updating:
[2m[36m(pid=245158)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245155)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=245155)[0m Instructions for updating:
[2m[36m(pid=245155)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245155)[0m LSTM is selected.
[2m[36m(pid=244990)[0m LSTM is selected.
[2m[36m(pid=244990)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=244990)[0m Instructions for updating:
[2m[36m(pid=244990)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=245159)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245159)[0m Instructions for updating:
[2m[36m(pid=245159)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245155)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=245155)[0m Instructions for updating:
[2m[36m(pid=245155)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:52,425	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245160, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:52,429	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_61_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=244990)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=244990)[0m Instructions for updating:
[2m[36m(pid=244990)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=245160)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245160)[0m 
[2m[36m(pid=245160)[0m Stack (most recent call first):
[2m[36m(pid=245158)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245158)[0m 2021-01-16 21:24:52.943672: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245158)[0m 2021-01-16 21:24:52.952439: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245158)[0m 2021-01-16 21:24:52.954999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe01d0e9900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245158)[0m 2021-01-16 21:24:52.955033: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245163)[0m 2021-01-16 21:24:53,274	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245163)[0m Traceback (most recent call last):
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245163)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245163)[0m     param_dset[:] = val
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245163)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245163)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245163)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245163)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245163)[0m , filename = '/tmp/thalvari/4565628/automl_save_wnnwjmwn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f834285d658, total write size = 732760, bytes this sub-write = 732760, bytes actually written = 18446744073709551615, offset = 1224704)
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245163)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245163)[0m Traceback (most recent call last):
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245163)[0m     self._entrypoint()
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245163)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245163)[0m     output = train_func(config, reporter)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245163)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245163)[0m     config=config)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245163)[0m     model.save(model_path, config_path)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245163)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245163)[0m     self.model.save(model_path)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245163)[0m     signatures)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245163)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245163)[0m     f.close()
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245163)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245163)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245163)[0m , filename = '/tmp/thalvari/4565628/automl_save_wnnwjmwn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f834259bde0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245163)[0m Exception in thread Thread-1:
[2m[36m(pid=245163)[0m Traceback (most recent call last):
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245163)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245163)[0m     param_dset[:] = val
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245163)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245163)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245163)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245163)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245163)[0m , filename = '/tmp/thalvari/4565628/automl_save_wnnwjmwn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f834285d658, total write size = 732760, bytes this sub-write = 732760, bytes actually written = 18446744073709551615, offset = 1224704)
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245163)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245163)[0m Traceback (most recent call last):
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245163)[0m     self._entrypoint()
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245163)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245163)[0m     output = train_func(config, reporter)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245163)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245163)[0m     config=config)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245163)[0m     model.save(model_path, config_path)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245163)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245163)[0m     self.model.save(model_path)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245163)[0m     signatures)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245163)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245163)[0m     f.close()
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245163)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245163)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245163)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245163)[0m , filename = '/tmp/thalvari/4565628/automl_save_wnnwjmwn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f834259bde0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245163)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245163)[0m Traceback (most recent call last):
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245163)[0m     self.run()
[2m[36m(pid=245163)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245163)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245163)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245161)[0m 2021-01-16 21:24:53,332	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245161)[0m Traceback (most recent call last):
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245161)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245161)[0m     param_dset[:] = val
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245161)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245161)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245161)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245161)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245161)[0m , filename = '/tmp/thalvari/4565628/automl_save_7h52y3xn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f313a8281fc, total write size = 217332, bytes this sub-write = 217332, bytes actually written = 18446744073709551615, offset = 2035712)
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245161)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245161)[0m Traceback (most recent call last):
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245161)[0m     self._entrypoint()
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245161)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245161)[0m     output = train_func(config, reporter)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245161)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245161)[0m     config=config)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245161)[0m     model.save(model_path, config_path)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245161)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245161)[0m     self.model.save(model_path)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245161)[0m     signatures)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245161)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245161)[0m     f.close()
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245161)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245161)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245161)[0m , filename = '/tmp/thalvari/4565628/automl_save_7h52y3xn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f313a2ca890, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245161)[0m Exception in thread Thread-1:
[2m[36m(pid=245161)[0m Traceback (most recent call last):
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=245161)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=245161)[0m     param_dset[:] = val
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245161)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245161)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245161)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245161)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245161)[0m , filename = '/tmp/thalvari/4565628/automl_save_7h52y3xn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f313a8281fc, total write size = 217332, bytes this sub-write = 217332, bytes actually written = 18446744073709551615, offset = 2035712)
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245161)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245161)[0m Traceback (most recent call last):
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245161)[0m     self._entrypoint()
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245161)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245161)[0m     output = train_func(config, reporter)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245161)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245161)[0m     config=config)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245161)[0m     model.save(model_path, config_path)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245161)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245161)[0m     self.model.save(model_path)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245161)[0m     signatures)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245161)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245161)[0m     f.close()
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245161)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245161)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245161)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:53 2021
[2m[36m(pid=245161)[0m , filename = '/tmp/thalvari/4565628/automl_save_7h52y3xn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f313a2ca890, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245159)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245159)[0m 2021-01-16 21:24:53.315488: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245159)[0m 2021-01-16 21:24:53.324447: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245159)[0m 2021-01-16 21:24:53.329078: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7c950e9620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245159)[0m 2021-01-16 21:24:53.329118: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245161)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245161)[0m Traceback (most recent call last):
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245161)[0m     self.run()
[2m[36m(pid=245161)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245161)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245161)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245155)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=245155)[0m 2021-01-16 21:24:53.466948: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=245155)[0m 2021-01-16 21:24:53.476084: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=245155)[0m 2021-01-16 21:24:53.477946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc6710e9530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=245155)[0m 2021-01-16 21:24:53.477970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=244990)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=244990)[0m 2021-01-16 21:24:53.554132: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=244990)[0m 2021-01-16 21:24:53.563463: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=244990)[0m 2021-01-16 21:24:53.567607: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6e90e9620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=244990)[0m 2021-01-16 21:24:53.567639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=248632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=248632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=248630)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=248630)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=248631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=248631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=244991)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=244991)[0m   agg_primitives: ['count']
[2m[36m(pid=244991)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=244991)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=249004)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=249004)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-16 21:24:54,387	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245161, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:54,390	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_62_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=249247)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=249247)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=249258)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=249222)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=249251)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=249251)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=249218)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=249218)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=249222)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=249258)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=245161)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245161)[0m 
[2m[36m(pid=245161)[0m Stack (most recent call first):
[2m[36m(pid=249235)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=249235)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=244991)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=244991)[0m Instructions for updating:
[2m[36m(pid=244991)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=244991)[0m LSTM is selected.
[2m[36m(pid=245157)[0m 2021-01-16 21:24:54,731	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245157)[0m Traceback (most recent call last):
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245157)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245157)[0m     param_dset[:] = val
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245157)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245157)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245157)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245157)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:54 2021
[2m[36m(pid=245157)[0m , filename = '/tmp/thalvari/4565628/automl_save_iuj67pw7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa05a904cd8, total write size = 11864, bytes this sub-write = 11864, bytes actually written = 18446744073709551615, offset = 1945600)
[2m[36m(pid=245157)[0m 
[2m[36m(pid=245157)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245157)[0m 
[2m[36m(pid=245157)[0m Traceback (most recent call last):
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245157)[0m     self._entrypoint()
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245157)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245157)[0m     output = train_func(config, reporter)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245157)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245157)[0m     config=config)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245157)[0m     model.save(model_path, config_path)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245157)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245157)[0m     self.model.save(model_path)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245157)[0m     signatures)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245157)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245157)[0m     f.close()
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245157)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245157)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:54 2021
[2m[36m(pid=245157)[0m , filename = '/tmp/thalvari/4565628/automl_save_iuj67pw7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa059da4b10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245157)[0m Exception in thread Thread-1:
[2m[36m(pid=245157)[0m Traceback (most recent call last):
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245157)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245157)[0m     param_dset[:] = val
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245157)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245157)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245157)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245157)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:54 2021
[2m[36m(pid=245157)[0m , filename = '/tmp/thalvari/4565628/automl_save_iuj67pw7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa05a904cd8, total write size = 11864, bytes this sub-write = 11864, bytes actually written = 18446744073709551615, offset = 1945600)
[2m[36m(pid=245157)[0m 
[2m[36m(pid=245157)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245157)[0m 
[2m[36m(pid=245157)[0m Traceback (most recent call last):
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245157)[0m     self._entrypoint()
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245157)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245157)[0m     output = train_func(config, reporter)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245157)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245157)[0m     config=config)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245157)[0m     model.save(model_path, config_path)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245157)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245157)[0m     self.model.save(model_path)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245157)[0m     signatures)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245157)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245157)[0m     f.close()
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245157)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245157)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245157)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:54 2021
[2m[36m(pid=245157)[0m , filename = '/tmp/thalvari/4565628/automl_save_iuj67pw7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa059da4b10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245157)[0m 
[2m[36m(pid=245157)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245157)[0m 
[2m[36m(pid=245157)[0m Traceback (most recent call last):
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245157)[0m     self.run()
[2m[36m(pid=245157)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245157)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245157)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245157)[0m 
2021-01-16 21:24:55,118	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245163, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:55,122	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_63_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245163)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245163)[0m 
[2m[36m(pid=245163)[0m Stack (most recent call first):
[2m[36m(pid=244991)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=244991)[0m Instructions for updating:
[2m[36m(pid=244991)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:24:55,935	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245157, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:55,944	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_64_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245157)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245157)[0m 
[2m[36m(pid=245157)[0m Stack (most recent call first):
[2m[36m(pid=245158)[0m 2021-01-16 21:24:56,410	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245158)[0m Traceback (most recent call last):
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245158)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245158)[0m     param_dset[:] = val
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245158)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245158)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245158)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245158)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245158)[0m , filename = '/tmp/thalvari/4565628/automl_save_hhnyzttf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe01e920ba8, total write size = 20056, bytes this sub-write = 20056, bytes actually written = 18446744073709551615, offset = 1937408)
[2m[36m(pid=245158)[0m 
[2m[36m(pid=245158)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245158)[0m 
[2m[36m(pid=245158)[0m Traceback (most recent call last):
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245158)[0m     self._entrypoint()
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245158)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245158)[0m     output = train_func(config, reporter)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245158)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245158)[0m     config=config)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245158)[0m     model.save(model_path, config_path)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245158)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245158)[0m     self.model.save(model_path)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245158)[0m     signatures)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245158)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245158)[0m     f.close()
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245158)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245158)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245158)[0m , filename = '/tmp/thalvari/4565628/automl_save_hhnyzttf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe01e5b4c10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245158)[0m Exception in thread Thread-1:
[2m[36m(pid=245158)[0m Traceback (most recent call last):
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245158)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245158)[0m     param_dset[:] = val
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245158)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245158)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245158)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245158)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245158)[0m , filename = '/tmp/thalvari/4565628/automl_save_hhnyzttf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe01e920ba8, total write size = 20056, bytes this sub-write = 20056, bytes actually written = 18446744073709551615, offset = 1937408)
[2m[36m(pid=245158)[0m 
[2m[36m(pid=245158)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245158)[0m 
[2m[36m(pid=245158)[0m Traceback (most recent call last):
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245158)[0m     self._entrypoint()
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245158)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245158)[0m     output = train_func(config, reporter)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245158)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245158)[0m     config=config)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245158)[0m     model.save(model_path, config_path)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245158)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245158)[0m     self.model.save(model_path)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245158)[0m     signatures)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245158)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245158)[0m     f.close()
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245158)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245158)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245158)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245158)[0m , filename = '/tmp/thalvari/4565628/automl_save_hhnyzttf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe01e5b4c10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245158)[0m 
[2m[36m(pid=245158)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245158)[0m 
[2m[36m(pid=245158)[0m Traceback (most recent call last):
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245158)[0m     self.run()
[2m[36m(pid=245158)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245158)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245158)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245158)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 74 ({'TERMINATED': 13, 'ERROR': 51, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 45 not shown
 - train_func_62_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_62_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-45nwcv8029/error_2021-01-16_21-24-54.txt
 - train_func_63_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_63_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-45sn6rzcrq/error_2021-01-16_21-24-55.txt
 - train_func_64_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_64_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-46w9z_7tqm/error_2021-01-16_21-24-55.txt
RUNNING trials:
 - train_func_65_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.48478,dropout_2=0.28283,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_66_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_67_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_72_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_73_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.27184,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_74_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.31692,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=244991)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=244991)[0m 2021-01-16 21:24:56.792809: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=244991)[0m 2021-01-16 21:24:56.804455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=244991)[0m 2021-01-16 21:24:56.807753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e8d0e8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=244991)[0m 2021-01-16 21:24:56.807803: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=245159)[0m 2021-01-16 21:24:56,962	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245159)[0m Traceback (most recent call last):
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245159)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245159)[0m     param_dset[:] = val
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245159)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245159)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245159)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245159)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245159)[0m , filename = '/tmp/thalvari/4565628/automl_save_c88cfw5s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c9695d308, total write size = 28248, bytes this sub-write = 28248, bytes actually written = 18446744073709551615, offset = 1929216)
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245159)[0m Traceback (most recent call last):
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245159)[0m     self._entrypoint()
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245159)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245159)[0m     output = train_func(config, reporter)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245159)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245159)[0m     config=config)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245159)[0m     model.save(model_path, config_path)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245159)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245159)[0m     self.model.save(model_path)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245159)[0m     signatures)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245159)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245159)[0m     f.close()
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245159)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245159)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245159)[0m , filename = '/tmp/thalvari/4565628/automl_save_c88cfw5s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c965b9860, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245159)[0m Exception in thread Thread-1:
[2m[36m(pid=245159)[0m Traceback (most recent call last):
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245159)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245159)[0m     param_dset[:] = val
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245159)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245159)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245159)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245159)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245159)[0m , filename = '/tmp/thalvari/4565628/automl_save_c88cfw5s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c9695d308, total write size = 28248, bytes this sub-write = 28248, bytes actually written = 18446744073709551615, offset = 1929216)
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245159)[0m Traceback (most recent call last):
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245159)[0m     self._entrypoint()
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245159)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245159)[0m     output = train_func(config, reporter)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245159)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245159)[0m     config=config)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245159)[0m     model.save(model_path, config_path)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245159)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245159)[0m     self.model.save(model_path)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245159)[0m     signatures)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245159)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245159)[0m     f.close()
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245159)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245159)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245159)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:56 2021
[2m[36m(pid=245159)[0m , filename = '/tmp/thalvari/4565628/automl_save_c88cfw5s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c965b9860, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245159)[0m Traceback (most recent call last):
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245159)[0m     self.run()
[2m[36m(pid=245159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245159)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245159)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245155)[0m 2021-01-16 21:24:57,316	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=245155)[0m Traceback (most recent call last):
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245155)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245155)[0m     param_dset[:] = val
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245155)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245155)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245155)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245155)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=245155)[0m , filename = '/tmp/thalvari/4565628/automl_save_9w1px55k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc6729595e8, total write size = 44632, bytes this sub-write = 44632, bytes actually written = 18446744073709551615, offset = 1912832)
[2m[36m(pid=245155)[0m 
[2m[36m(pid=245155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245155)[0m 
[2m[36m(pid=245155)[0m Traceback (most recent call last):
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245155)[0m     self._entrypoint()
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245155)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245155)[0m     output = train_func(config, reporter)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245155)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245155)[0m     config=config)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245155)[0m     model.save(model_path, config_path)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245155)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245155)[0m     self.model.save(model_path)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245155)[0m     signatures)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245155)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245155)[0m     f.close()
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245155)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245155)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=245155)[0m , filename = '/tmp/thalvari/4565628/automl_save_9w1px55k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc671924bf0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245155)[0m Exception in thread Thread-1:
[2m[36m(pid=245155)[0m Traceback (most recent call last):
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=245155)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=245155)[0m     param_dset[:] = val
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=245155)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=245155)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=245155)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=245155)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=245155)[0m , filename = '/tmp/thalvari/4565628/automl_save_9w1px55k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc6729595e8, total write size = 44632, bytes this sub-write = 44632, bytes actually written = 18446744073709551615, offset = 1912832)
[2m[36m(pid=245155)[0m 
[2m[36m(pid=245155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245155)[0m 
[2m[36m(pid=245155)[0m Traceback (most recent call last):
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=245155)[0m     self._entrypoint()
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=245155)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=245155)[0m     output = train_func(config, reporter)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=245155)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=245155)[0m     config=config)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=245155)[0m     model.save(model_path, config_path)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=245155)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=245155)[0m     self.model.save(model_path)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=245155)[0m     signatures)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=245155)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=245155)[0m     f.close()
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=245155)[0m     h5i.dec_ref(id_)
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=245155)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=245155)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=245155)[0m , filename = '/tmp/thalvari/4565628/automl_save_9w1px55k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc671924bf0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=245155)[0m 
[2m[36m(pid=245155)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=245155)[0m 
[2m[36m(pid=245155)[0m Traceback (most recent call last):
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=245155)[0m     self.run()
[2m[36m(pid=245155)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=245155)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=245155)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=245155)[0m 
[2m[36m(pid=244990)[0m 2021-01-16 21:24:57,428	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=244990)[0m Traceback (most recent call last):
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=244990)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=244990)[0m     param_dset[:] = val
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244990)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244990)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244990)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244990)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=244990)[0m , filename = '/tmp/thalvari/4565628/automl_save_j8cir9xp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6ea98da78, total write size = 44632, bytes this sub-write = 44632, bytes actually written = 18446744073709551615, offset = 1912832)
[2m[36m(pid=244990)[0m 
[2m[36m(pid=244990)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244990)[0m 
[2m[36m(pid=244990)[0m Traceback (most recent call last):
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244990)[0m     self._entrypoint()
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244990)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244990)[0m     output = train_func(config, reporter)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244990)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244990)[0m     config=config)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244990)[0m     model.save(model_path, config_path)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244990)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244990)[0m     self.model.save(model_path)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244990)[0m     signatures)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244990)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244990)[0m     f.close()
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244990)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244990)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=244990)[0m , filename = '/tmp/thalvari/4565628/automl_save_j8cir9xp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6e940bff0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244990)[0m Exception in thread Thread-1:
[2m[36m(pid=244990)[0m Traceback (most recent call last):
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=244990)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=244990)[0m     param_dset[:] = val
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244990)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244990)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244990)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244990)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=244990)[0m , filename = '/tmp/thalvari/4565628/automl_save_j8cir9xp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6ea98da78, total write size = 44632, bytes this sub-write = 44632, bytes actually written = 18446744073709551615, offset = 1912832)
[2m[36m(pid=244990)[0m 
[2m[36m(pid=244990)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244990)[0m 
[2m[36m(pid=244990)[0m Traceback (most recent call last):
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244990)[0m     self._entrypoint()
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244990)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244990)[0m     output = train_func(config, reporter)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244990)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244990)[0m     config=config)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244990)[0m     model.save(model_path, config_path)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244990)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244990)[0m     self.model.save(model_path)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244990)[0m     signatures)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244990)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244990)[0m     f.close()
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244990)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244990)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244990)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:57 2021
[2m[36m(pid=244990)[0m , filename = '/tmp/thalvari/4565628/automl_save_j8cir9xp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6e940bff0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244990)[0m 
[2m[36m(pid=244990)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244990)[0m 
[2m[36m(pid=244990)[0m Traceback (most recent call last):
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=244990)[0m     self.run()
[2m[36m(pid=244990)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=244990)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=244990)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=244990)[0m 
2021-01-16 21:24:57,465	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245158, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:57,468	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_65_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.48478,dropout_2=0.28283,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245158)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245158)[0m 
[2m[36m(pid=245158)[0m Stack (most recent call first):
2021-01-16 21:24:57,997	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245159, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:57,999	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_66_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245159)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245159)[0m 
[2m[36m(pid=245159)[0m Stack (most recent call first):
2021-01-16 21:24:58,452	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=245155, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:58,454	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_67_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=245155)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=245155)[0m 
[2m[36m(pid=245155)[0m Stack (most recent call first):
2021-01-16 21:24:59,008	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=244990, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:24:59,010	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_68_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=244990)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=244990)[0m 
[2m[36m(pid=244990)[0m Stack (most recent call first):
[2m[36m(pid=248631)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=248631)[0m   agg_primitives: ['count']
[2m[36m(pid=248631)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=248631)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=249235)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=249235)[0m   agg_primitives: ['count']
[2m[36m(pid=249235)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=249235)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=249251)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=249251)[0m   agg_primitives: ['count']
[2m[36m(pid=249251)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=249251)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=249218)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=249218)[0m   agg_primitives: ['count']
[2m[36m(pid=249218)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=249218)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=248632)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=248632)[0m   agg_primitives: ['count']
[2m[36m(pid=248632)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=248632)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=244991)[0m 2021-01-16 21:24:59,565	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=244991)[0m Traceback (most recent call last):
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=244991)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=244991)[0m     param_dset[:] = val
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244991)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244991)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244991)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244991)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:59 2021
[2m[36m(pid=244991)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lq0du36/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e8e957458, total write size = 52824, bytes this sub-write = 52824, bytes actually written = 18446744073709551615, offset = 1904640)
[2m[36m(pid=244991)[0m 
[2m[36m(pid=244991)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244991)[0m 
[2m[36m(pid=244991)[0m Traceback (most recent call last):
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244991)[0m     self._entrypoint()
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244991)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244991)[0m     output = train_func(config, reporter)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244991)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244991)[0m     config=config)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244991)[0m     model.save(model_path, config_path)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244991)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244991)[0m     self.model.save(model_path)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244991)[0m     signatures)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244991)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244991)[0m     f.close()
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244991)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244991)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:59 2021
[2m[36m(pid=244991)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lq0du36/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e8e290150, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244991)[0m Exception in thread Thread-1:
[2m[36m(pid=244991)[0m Traceback (most recent call last):
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=244991)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=244991)[0m     param_dset[:] = val
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=244991)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=244991)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=244991)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=244991)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:24:59 2021
[2m[36m(pid=244991)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lq0du36/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e8e957458, total write size = 52824, bytes this sub-write = 52824, bytes actually written = 18446744073709551615, offset = 1904640)
[2m[36m(pid=244991)[0m 
[2m[36m(pid=244991)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244991)[0m 
[2m[36m(pid=244991)[0m Traceback (most recent call last):
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=244991)[0m     self._entrypoint()
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=244991)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=244991)[0m     output = train_func(config, reporter)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=244991)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=244991)[0m     config=config)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=244991)[0m     model.save(model_path, config_path)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=244991)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=244991)[0m     self.model.save(model_path)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=244991)[0m     signatures)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=244991)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=244991)[0m     f.close()
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=244991)[0m     h5i.dec_ref(id_)
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=244991)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=244991)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:24:59 2021
[2m[36m(pid=244991)[0m , filename = '/tmp/thalvari/4565628/automl_save_1lq0du36/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e8e290150, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=244991)[0m 
[2m[36m(pid=244991)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=244991)[0m 
[2m[36m(pid=244991)[0m Traceback (most recent call last):
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=244991)[0m     self.run()
[2m[36m(pid=244991)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=244991)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=244991)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=244991)[0m 
[2m[36m(pid=248631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=248631)[0m Instructions for updating:
[2m[36m(pid=248631)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=248631)[0m LSTM is selected.
[2m[36m(pid=249235)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=249235)[0m Instructions for updating:
[2m[36m(pid=249235)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=249235)[0m LSTM is selected.
[2m[36m(pid=249251)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=249251)[0m Instructions for updating:
[2m[36m(pid=249251)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=249251)[0m LSTM is selected.
[2m[36m(pid=249218)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=249218)[0m Instructions for updating:
[2m[36m(pid=249218)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=249218)[0m LSTM is selected.
[2m[36m(pid=248632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=248632)[0m Instructions for updating:
[2m[36m(pid=248632)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=248632)[0m LSTM is selected.
[2m[36m(pid=248631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=248631)[0m Instructions for updating:
[2m[36m(pid=248631)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=249235)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=249235)[0m Instructions for updating:
[2m[36m(pid=249235)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=249251)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=249251)[0m Instructions for updating:
[2m[36m(pid=249251)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=249218)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=249218)[0m Instructions for updating:
[2m[36m(pid=249218)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=248632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=248632)[0m Instructions for updating:
[2m[36m(pid=248632)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:25:00,607	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=244991, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:00,610	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_69_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=244991)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=244991)[0m 
[2m[36m(pid=244991)[0m Stack (most recent call first):
[2m[36m(pid=249222)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=249222)[0m   agg_primitives: ['count']
[2m[36m(pid=249222)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=249222)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=249258)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=249258)[0m   agg_primitives: ['count']
[2m[36m(pid=249258)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=249258)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=249235)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=249235)[0m 2021-01-16 21:25:01.353300: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=249235)[0m 2021-01-16 21:25:01.361015: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=249235)[0m 2021-01-16 21:25:01.363285: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85010e8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=249235)[0m 2021-01-16 21:25:01.363310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=248631)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=248631)[0m 2021-01-16 21:25:01.399203: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=248631)[0m 2021-01-16 21:25:01.406601: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=248631)[0m 2021-01-16 21:25:01.408597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f70310e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=248631)[0m 2021-01-16 21:25:01.408618: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=249251)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=249251)[0m 2021-01-16 21:25:01.464964: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=249218)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=249218)[0m 2021-01-16 21:25:01.466734: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=249247)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=249247)[0m   agg_primitives: ['count']
[2m[36m(pid=249247)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=249247)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=248632)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=248632)[0m 2021-01-16 21:25:01.489580: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=248632)[0m 2021-01-16 21:25:01.496889: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=248632)[0m 2021-01-16 21:25:01.498643: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7face90e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=248632)[0m 2021-01-16 21:25:01.498666: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=249251)[0m 2021-01-16 21:25:01.473271: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=249251)[0m 2021-01-16 21:25:01.475578: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe46d0e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=249251)[0m 2021-01-16 21:25:01.475602: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=249218)[0m 2021-01-16 21:25:01.474322: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=249218)[0m 2021-01-16 21:25:01.476528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ae5103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=249218)[0m 2021-01-16 21:25:01.476552: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=249258)[0m LSTM is selected.
[2m[36m(pid=249222)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=249222)[0m Instructions for updating:
[2m[36m(pid=249222)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=249222)[0m LSTM is selected.
[2m[36m(pid=249258)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=249258)[0m Instructions for updating:
[2m[36m(pid=249258)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=249247)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=249247)[0m Instructions for updating:
[2m[36m(pid=249247)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=249247)[0m LSTM is selected.
[2m[36m(pid=249222)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=249222)[0m Instructions for updating:
[2m[36m(pid=249222)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=249258)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=249258)[0m Instructions for updating:
[2m[36m(pid=249258)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=249247)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=249247)[0m Instructions for updating:
[2m[36m(pid=249247)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=249004)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=249004)[0m   agg_primitives: ['count']
[2m[36m(pid=249004)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=249004)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=249258)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=249258)[0m 2021-01-16 21:25:03.107175: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=249258)[0m 2021-01-16 21:25:03.122865: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=249004)[0m LSTM is selected.
[2m[36m(pid=249258)[0m 2021-01-16 21:25:03.143037: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb090e96c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=249258)[0m 2021-01-16 21:25:03.143076: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=249222)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=249222)[0m 2021-01-16 21:25:03.192985: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=249004)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=249004)[0m Instructions for updating:
[2m[36m(pid=249004)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=249222)[0m 2021-01-16 21:25:03.207532: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=249222)[0m 2021-01-16 21:25:03.212704: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fab190e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=249222)[0m 2021-01-16 21:25:03.212748: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=249247)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=249247)[0m 2021-01-16 21:25:03.606692: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=249247)[0m 2021-01-16 21:25:03.619930: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=249247)[0m 2021-01-16 21:25:03.648166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4190e9220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=249247)[0m 2021-01-16 21:25:03.648215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=249004)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=249004)[0m Instructions for updating:
[2m[36m(pid=249004)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=248631)[0m 2021-01-16 21:25:04,721	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=248631)[0m Traceback (most recent call last):
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=248631)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=248631)[0m     param_dset[:] = val
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=248631)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=248631)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=248631)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=248631)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248631)[0m , filename = '/tmp/thalvari/4565628/automl_save_brsc2ci2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f70328d8988, total write size = 93784, bytes this sub-write = 93784, bytes actually written = 18446744073709551615, offset = 1863680)
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248631)[0m Traceback (most recent call last):
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=248631)[0m     self._entrypoint()
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=248631)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=248631)[0m     output = train_func(config, reporter)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=248631)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=248631)[0m     config=config)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=248631)[0m     model.save(model_path, config_path)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=248631)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=248631)[0m     self.model.save(model_path)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=248631)[0m     signatures)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=248631)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=248631)[0m     f.close()
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=248631)[0m     h5i.dec_ref(id_)
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=248631)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248631)[0m , filename = '/tmp/thalvari/4565628/automl_save_brsc2ci2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f703160e770, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=248631)[0m Exception in thread Thread-1:
[2m[36m(pid=248631)[0m Traceback (most recent call last):
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=248631)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=248631)[0m     param_dset[:] = val
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=248631)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=248631)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=248631)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=248631)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248631)[0m , filename = '/tmp/thalvari/4565628/automl_save_brsc2ci2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f70328d8988, total write size = 93784, bytes this sub-write = 93784, bytes actually written = 18446744073709551615, offset = 1863680)
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248631)[0m Traceback (most recent call last):
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=248631)[0m     self._entrypoint()
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=248631)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=248631)[0m     output = train_func(config, reporter)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=248631)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=248631)[0m     config=config)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=248631)[0m     model.save(model_path, config_path)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=248631)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=248631)[0m     self.model.save(model_path)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=248631)[0m     signatures)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=248631)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=248631)[0m     f.close()
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=248631)[0m     h5i.dec_ref(id_)
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248631)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=248631)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248631)[0m , filename = '/tmp/thalvari/4565628/automl_save_brsc2ci2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f703160e770, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248631)[0m Traceback (most recent call last):
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=248631)[0m     self.run()
[2m[36m(pid=248631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=248631)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=248631)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248632)[0m 2021-01-16 21:25:04,832	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=248632)[0m Traceback (most recent call last):
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=248632)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=248632)[0m     param_dset[:] = val
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=248632)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=248632)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=248632)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=248632)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248632)[0m , filename = '/tmp/thalvari/4565628/automl_save_i_bez4my/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7faceaa41698, total write size = 896600, bytes this sub-write = 896600, bytes actually written = 18446744073709551615, offset = 1060864)
[2m[36m(pid=248632)[0m 
[2m[36m(pid=248632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248632)[0m 
[2m[36m(pid=248632)[0m Traceback (most recent call last):
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=248632)[0m     self._entrypoint()
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=248632)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=248632)[0m     output = train_func(config, reporter)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=248632)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=248632)[0m     config=config)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=248632)[0m     model.save(model_path, config_path)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=248632)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=248632)[0m     self.model.save(model_path)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=248632)[0m     signatures)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=248632)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=248632)[0m     f.close()
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=248632)[0m     h5i.dec_ref(id_)
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=248632)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248632)[0m , filename = '/tmp/thalvari/4565628/automl_save_i_bez4my/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7face9ad7150, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=248632)[0m Exception in thread Thread-1:
[2m[36m(pid=248632)[0m Traceback (most recent call last):
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=248632)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=248632)[0m     param_dset[:] = val
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=248632)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=248632)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=248632)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=248632)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248632)[0m , filename = '/tmp/thalvari/4565628/automl_save_i_bez4my/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7faceaa41698, total write size = 896600, bytes this sub-write = 896600, bytes actually written = 18446744073709551615, offset = 1060864)
[2m[36m(pid=248632)[0m 
[2m[36m(pid=248632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248632)[0m 
[2m[36m(pid=248632)[0m Traceback (most recent call last):
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=248632)[0m     self._entrypoint()
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=248632)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=248632)[0m     output = train_func(config, reporter)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=248632)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=248632)[0m     config=config)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=248632)[0m     model.save(model_path, config_path)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=248632)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=248632)[0m     self.model.save(model_path)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=248632)[0m     signatures)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=248632)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=248632)[0m     f.close()
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=248632)[0m     h5i.dec_ref(id_)
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248632)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=248632)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=248632)[0m , filename = '/tmp/thalvari/4565628/automl_save_i_bez4my/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7face9ad7150, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249251)[0m 2021-01-16 21:25:04,836	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=249251)[0m Traceback (most recent call last):
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249251)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249251)[0m     param_dset[:] = val
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249251)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249251)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249251)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249251)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249251)[0m , filename = '/tmp/thalvari/4565628/automl_save_2te83pka/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe46e9555d8, total write size = 85592, bytes this sub-write = 85592, bytes actually written = 18446744073709551615, offset = 1871872)
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249251)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249251)[0m Traceback (most recent call last):
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249251)[0m     self._entrypoint()
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249251)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249251)[0m     output = train_func(config, reporter)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249251)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249251)[0m     config=config)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249251)[0m     model.save(model_path, config_path)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249251)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249251)[0m     self.model.save(model_path)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249251)[0m     signatures)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249251)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249251)[0m     f.close()
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249251)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249251)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249251)[0m , filename = '/tmp/thalvari/4565628/automl_save_2te83pka/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe46e5820f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249251)[0m Exception in thread Thread-1:
[2m[36m(pid=249251)[0m Traceback (most recent call last):
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249251)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249251)[0m     param_dset[:] = val
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249251)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249251)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249251)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249251)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249251)[0m , filename = '/tmp/thalvari/4565628/automl_save_2te83pka/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe46e9555d8, total write size = 85592, bytes this sub-write = 85592, bytes actually written = 18446744073709551615, offset = 1871872)
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249251)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249251)[0m Traceback (most recent call last):
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249251)[0m     self._entrypoint()
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249251)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249251)[0m     output = train_func(config, reporter)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249251)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249251)[0m     config=config)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249251)[0m     model.save(model_path, config_path)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249251)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249251)[0m     self.model.save(model_path)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249251)[0m     signatures)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249251)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249251)[0m     f.close()
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249251)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249251)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249251)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249251)[0m , filename = '/tmp/thalvari/4565628/automl_save_2te83pka/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe46e5820f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249218)[0m 2021-01-16 21:25:04,822	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=249218)[0m Traceback (most recent call last):
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249218)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249218)[0m     param_dset[:] = val
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249218)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249218)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249218)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249218)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249218)[0m , filename = '/tmp/thalvari/4565628/automl_save_xsjpj8s4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ae5db36e8, total write size = 45144, bytes this sub-write = 45144, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249218)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249218)[0m Traceback (most recent call last):
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249218)[0m     self._entrypoint()
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249218)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249218)[0m     output = train_func(config, reporter)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249218)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249218)[0m     config=config)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249218)[0m     model.save(model_path, config_path)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249218)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249218)[0m     self.model.save(model_path)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249218)[0m     signatures)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249218)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249218)[0m     f.close()
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249218)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249218)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249218)[0m , filename = '/tmp/thalvari/4565628/automl_save_xsjpj8s4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ae67d2250, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249218)[0m Exception in thread Thread-1:
[2m[36m(pid=249218)[0m Traceback (most recent call last):
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249218)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249218)[0m     param_dset[:] = val
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249218)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249218)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249218)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249218)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249218)[0m , filename = '/tmp/thalvari/4565628/automl_save_xsjpj8s4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ae5db36e8, total write size = 45144, bytes this sub-write = 45144, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249218)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249218)[0m Traceback (most recent call last):
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249218)[0m     self._entrypoint()
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249218)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249218)[0m     output = train_func(config, reporter)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249218)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249218)[0m     config=config)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249218)[0m     model.save(model_path, config_path)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249218)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249218)[0m     self.model.save(model_path)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249218)[0m     signatures)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249218)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249218)[0m     f.close()
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249218)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249218)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249218)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249218)[0m , filename = '/tmp/thalvari/4565628/automl_save_xsjpj8s4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ae67d2250, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249235)[0m 2021-01-16 21:25:04,829	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=249235)[0m Traceback (most recent call last):
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249235)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249235)[0m     param_dset[:] = val
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249235)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249235)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249235)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249235)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249235)[0m , filename = '/tmp/thalvari/4565628/automl_save_xxgvuarx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f8502335a48, total write size = 43096, bytes this sub-write = 43096, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249235)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249235)[0m Traceback (most recent call last):
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249235)[0m     self._entrypoint()
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249235)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249235)[0m     output = train_func(config, reporter)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249235)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249235)[0m     config=config)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249235)[0m     model.save(model_path, config_path)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249235)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249235)[0m     self.model.save(model_path)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249235)[0m     signatures)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249235)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249235)[0m     f.close()
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249235)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249235)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249235)[0m , filename = '/tmp/thalvari/4565628/automl_save_xxgvuarx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f8502359830, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249235)[0m Exception in thread Thread-1:
[2m[36m(pid=249235)[0m Traceback (most recent call last):
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249235)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249235)[0m     param_dset[:] = val
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249235)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249235)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249235)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249235)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249235)[0m , filename = '/tmp/thalvari/4565628/automl_save_xxgvuarx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f8502335a48, total write size = 43096, bytes this sub-write = 43096, bytes actually written = 18446744073709551615, offset = 241664)
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249235)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249235)[0m Traceback (most recent call last):
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249235)[0m     self._entrypoint()
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249235)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249235)[0m     output = train_func(config, reporter)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249235)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249235)[0m     config=config)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249235)[0m     model.save(model_path, config_path)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249235)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249235)[0m     self.model.save(model_path)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249235)[0m     signatures)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249235)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249235)[0m     f.close()
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249235)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249235)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249235)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:04 2021
[2m[36m(pid=249235)[0m , filename = '/tmp/thalvari/4565628/automl_save_xxgvuarx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f8502359830, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=248632)[0m 
[2m[36m(pid=248632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248632)[0m 
[2m[36m(pid=248632)[0m Traceback (most recent call last):
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=248632)[0m     self.run()
[2m[36m(pid=248632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=248632)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=248632)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=248632)[0m 
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249251)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249251)[0m Traceback (most recent call last):
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=249251)[0m     self.run()
[2m[36m(pid=249251)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=249251)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=249251)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249218)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249218)[0m Traceback (most recent call last):
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=249218)[0m     self.run()
[2m[36m(pid=249218)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=249218)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=249218)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249235)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249235)[0m Traceback (most recent call last):
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=249235)[0m     self.run()
[2m[36m(pid=249235)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=249235)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=249235)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249004)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=249004)[0m 2021-01-16 21:25:04.880683: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=249004)[0m 2021-01-16 21:25:04.889099: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=249004)[0m 2021-01-16 21:25:04.891386: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85690e8900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=249004)[0m 2021-01-16 21:25:04.891421: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=248630)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=248630)[0m   agg_primitives: ['count']
[2m[36m(pid=248630)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=248630)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:25:05,822	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=248631, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:05,826	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_71_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 20.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 79 ({'TERMINATED': 13, 'ERROR': 57, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 51 not shown
 - train_func_68_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_68_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-48yehp0k5_/error_2021-01-16_21-24-59.txt
 - train_func_69_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_69_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-50p9w6jkm1/error_2021-01-16_21-25-00.txt
 - train_func_71_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_71_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-537_m3t44f/error_2021-01-16_21-25-05.txt
RUNNING trials:
 - train_func_70_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.49129,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_72_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_73_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.27184,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_77_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_78_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_79_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=248630)[0m LSTM is selected.
[2m[36m(pid=248630)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=248630)[0m Instructions for updating:
[2m[36m(pid=248630)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=248631)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=248631)[0m 
[2m[36m(pid=248631)[0m Stack (most recent call first):
2021-01-16 21:25:06,417	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=249235, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:06,422	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_72_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=248630)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=248630)[0m Instructions for updating:
[2m[36m(pid=248630)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=249258)[0m 2021-01-16 21:25:06,591	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=249258)[0m Traceback (most recent call last):
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249258)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249258)[0m     param_dset[:] = val
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249258)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249258)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249258)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249258)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249258)[0m , filename = '/tmp/thalvari/4565628/automl_save_saywk38s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb0a8fca68, total write size = 110168, bytes this sub-write = 110168, bytes actually written = 18446744073709551615, offset = 1847296)
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249258)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249258)[0m Traceback (most recent call last):
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249258)[0m     self._entrypoint()
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249258)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249258)[0m     output = train_func(config, reporter)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249258)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249258)[0m     config=config)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249258)[0m     model.save(model_path, config_path)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249258)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249258)[0m     self.model.save(model_path)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249258)[0m     signatures)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249258)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249258)[0m     f.close()
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249258)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249258)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249258)[0m , filename = '/tmp/thalvari/4565628/automl_save_saywk38s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb09c1ba10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249258)[0m Exception in thread Thread-1:
[2m[36m(pid=249258)[0m Traceback (most recent call last):
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249258)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249258)[0m     param_dset[:] = val
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249258)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249258)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249258)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249258)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249258)[0m , filename = '/tmp/thalvari/4565628/automl_save_saywk38s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb0a8fca68, total write size = 110168, bytes this sub-write = 110168, bytes actually written = 18446744073709551615, offset = 1847296)
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249258)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249258)[0m Traceback (most recent call last):
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249258)[0m     self._entrypoint()
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249258)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249258)[0m     output = train_func(config, reporter)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249258)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249258)[0m     config=config)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249258)[0m     model.save(model_path, config_path)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249258)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249258)[0m     self.model.save(model_path)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249258)[0m     signatures)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249258)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249258)[0m     f.close()
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249258)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249258)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249258)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249258)[0m , filename = '/tmp/thalvari/4565628/automl_save_saywk38s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcb09c1ba10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249235)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=249235)[0m 
[2m[36m(pid=249235)[0m Stack (most recent call first):
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249258)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249258)[0m Traceback (most recent call last):
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=249258)[0m     self.run()
[2m[36m(pid=249258)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=249258)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=249258)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249222)[0m 2021-01-16 21:25:06,844	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=249222)[0m Traceback (most recent call last):
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249222)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249222)[0m     param_dset[:] = val
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249222)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249222)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249222)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249222)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249222)[0m , filename = '/tmp/thalvari/4565628/automl_save_b176yw9i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fab1aaf8788, total write size = 118360, bytes this sub-write = 118360, bytes actually written = 18446744073709551615, offset = 1839104)
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249222)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249222)[0m Traceback (most recent call last):
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249222)[0m     self._entrypoint()
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249222)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249222)[0m     output = train_func(config, reporter)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249222)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249222)[0m     config=config)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249222)[0m     model.save(model_path, config_path)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249222)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249222)[0m     self.model.save(model_path)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249222)[0m     signatures)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249222)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249222)[0m     f.close()
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249222)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249222)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249222)[0m , filename = '/tmp/thalvari/4565628/automl_save_b176yw9i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fab1a2916d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249222)[0m Exception in thread Thread-1:
[2m[36m(pid=249222)[0m Traceback (most recent call last):
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249222)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249222)[0m     param_dset[:] = val
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249222)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249222)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249222)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249222)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249222)[0m , filename = '/tmp/thalvari/4565628/automl_save_b176yw9i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fab1aaf8788, total write size = 118360, bytes this sub-write = 118360, bytes actually written = 18446744073709551615, offset = 1839104)
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249222)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249222)[0m Traceback (most recent call last):
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249222)[0m     self._entrypoint()
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249222)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249222)[0m     output = train_func(config, reporter)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249222)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249222)[0m     config=config)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249222)[0m     model.save(model_path, config_path)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249222)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249222)[0m     self.model.save(model_path)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249222)[0m     signatures)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249222)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249222)[0m     f.close()
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249222)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249222)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249222)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249222)[0m , filename = '/tmp/thalvari/4565628/automl_save_b176yw9i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fab1a2916d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249222)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249222)[0m Traceback (most recent call last):
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=249222)[0m     self.run()
[2m[36m(pid=249222)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=249222)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=249222)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249247)[0m 2021-01-16 21:25:07,001	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=249247)[0m Traceback (most recent call last):
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249247)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249247)[0m     param_dset[:] = val
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249247)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249247)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249247)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249247)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249247)[0m , filename = '/tmp/thalvari/4565628/automl_save_j3ly7yq2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe41a95fed8, total write size = 118360, bytes this sub-write = 118360, bytes actually written = 18446744073709551615, offset = 1839104)
[2m[36m(pid=249247)[0m 
[2m[36m(pid=249247)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249247)[0m 
[2m[36m(pid=249247)[0m Traceback (most recent call last):
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249247)[0m     self._entrypoint()
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249247)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249247)[0m     output = train_func(config, reporter)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249247)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249247)[0m     config=config)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249247)[0m     model.save(model_path, config_path)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249247)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249247)[0m     self.model.save(model_path)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249247)[0m     signatures)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249247)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249247)[0m     f.close()
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249247)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249247)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:07 2021
[2m[36m(pid=249247)[0m , filename = '/tmp/thalvari/4565628/automl_save_j3ly7yq2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe41a723530, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249247)[0m Exception in thread Thread-1:
[2m[36m(pid=249247)[0m Traceback (most recent call last):
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249247)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249247)[0m     param_dset[:] = val
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249247)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249247)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249247)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249247)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:06 2021
[2m[36m(pid=249247)[0m , filename = '/tmp/thalvari/4565628/automl_save_j3ly7yq2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe41a95fed8, total write size = 118360, bytes this sub-write = 118360, bytes actually written = 18446744073709551615, offset = 1839104)
[2m[36m(pid=249247)[0m 
[2m[36m(pid=249247)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249247)[0m 
[2m[36m(pid=249247)[0m Traceback (most recent call last):
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249247)[0m     self._entrypoint()
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249247)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249247)[0m     output = train_func(config, reporter)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249247)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249247)[0m     config=config)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249247)[0m     model.save(model_path, config_path)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249247)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249247)[0m     self.model.save(model_path)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249247)[0m     signatures)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249247)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249247)[0m     f.close()
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249247)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249247)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249247)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:07 2021
[2m[36m(pid=249247)[0m , filename = '/tmp/thalvari/4565628/automl_save_j3ly7yq2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe41a723530, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249247)[0m 
[2m[36m(pid=249247)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249247)[0m 
[2m[36m(pid=249247)[0m Traceback (most recent call last):
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=249247)[0m     self.run()
[2m[36m(pid=249247)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=249247)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=249247)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=249247)[0m 
2021-01-16 21:25:07,158	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=248632, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:07,161	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_70_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.49129,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=248632)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=248632)[0m 
[2m[36m(pid=248632)[0m Stack (most recent call first):
[2m[36m(pid=251484)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251484)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251483)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251483)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251479)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251479)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=248630)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=248630)[0m 2021-01-16 21:25:07.856636: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=248630)[0m 2021-01-16 21:25:07.864463: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=248630)[0m 2021-01-16 21:25:07.866664: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6605103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=248630)[0m 2021-01-16 21:25:07.866693: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:25:08,002	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=249258, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:08,004	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_76_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=249004)[0m 2021-01-16 21:25:07,987	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=249004)[0m Traceback (most recent call last):
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249004)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249004)[0m     param_dset[:] = val
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249004)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249004)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249004)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249004)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:07 2021
[2m[36m(pid=249004)[0m , filename = '/tmp/thalvari/4565628/automl_save_w0rfbnjt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f856a928048, total write size = 159320, bytes this sub-write = 159320, bytes actually written = 18446744073709551615, offset = 1798144)
[2m[36m(pid=249004)[0m 
[2m[36m(pid=249004)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249004)[0m 
[2m[36m(pid=249004)[0m Traceback (most recent call last):
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249004)[0m     self._entrypoint()
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249004)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249004)[0m     output = train_func(config, reporter)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249004)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249004)[0m     config=config)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249004)[0m     model.save(model_path, config_path)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249004)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249004)[0m     self.model.save(model_path)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249004)[0m     signatures)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249004)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249004)[0m     f.close()
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249004)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249004)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:07 2021
[2m[36m(pid=249004)[0m , filename = '/tmp/thalvari/4565628/automl_save_w0rfbnjt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f856a155a30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249004)[0m Exception in thread Thread-1:
[2m[36m(pid=249004)[0m Traceback (most recent call last):
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=249004)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=249004)[0m     param_dset[:] = val
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=249004)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=249004)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=249004)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=249004)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:07 2021
[2m[36m(pid=249004)[0m , filename = '/tmp/thalvari/4565628/automl_save_w0rfbnjt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f856a928048, total write size = 159320, bytes this sub-write = 159320, bytes actually written = 18446744073709551615, offset = 1798144)
[2m[36m(pid=249004)[0m 
[2m[36m(pid=249004)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249004)[0m 
[2m[36m(pid=249004)[0m Traceback (most recent call last):
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=249004)[0m     self._entrypoint()
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=249004)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=249004)[0m     output = train_func(config, reporter)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=249004)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=249004)[0m     config=config)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=249004)[0m     model.save(model_path, config_path)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=249004)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=249004)[0m     self.model.save(model_path)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=249004)[0m     signatures)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=249004)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=249004)[0m     f.close()
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=249004)[0m     h5i.dec_ref(id_)
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=249004)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=249004)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:07 2021
[2m[36m(pid=249004)[0m , filename = '/tmp/thalvari/4565628/automl_save_w0rfbnjt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f856a155a30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=249004)[0m 
[2m[36m(pid=249004)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=249004)[0m 
[2m[36m(pid=249004)[0m Traceback (most recent call last):
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=249004)[0m     self.run()
[2m[36m(pid=249004)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=249004)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=249004)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=249004)[0m 
[2m[36m(pid=251609)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251609)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=249258)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=249258)[0m 
[2m[36m(pid=249258)[0m Stack (most recent call first):
[2m[36m(pid=251608)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251610)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251608)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251610)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251607)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251607)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251611)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251611)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251818)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251818)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251819)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251819)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251812)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251812)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251817)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251817)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251816)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251816)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251814)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251814)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251820)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=251820)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-16 21:25:08,709	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=249218, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:08,712	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_74_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.31692,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=249218)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=249218)[0m 
[2m[36m(pid=249218)[0m Stack (most recent call first):
2021-01-16 21:25:09,830	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=249251, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:09,834	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_73_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.27184,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=249251)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=249251)[0m 
[2m[36m(pid=249251)[0m Stack (most recent call first):
2021-01-16 21:25:10,446	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=249247, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:10,449	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_77_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=249247)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=249247)[0m 
[2m[36m(pid=249247)[0m Stack (most recent call first):
[2m[36m(pid=248630)[0m 2021-01-16 21:25:10,816	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=248630)[0m Traceback (most recent call last):
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=248630)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=248630)[0m     param_dset[:] = val
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=248630)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=248630)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=248630)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=248630)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:10 2021
[2m[36m(pid=248630)[0m , filename = '/tmp/thalvari/4565628/automl_save_6tejipw0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f66068f8978, total write size = 259672, bytes this sub-write = 259672, bytes actually written = 18446744073709551615, offset = 1699840)
[2m[36m(pid=248630)[0m 
[2m[36m(pid=248630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248630)[0m 
[2m[36m(pid=248630)[0m Traceback (most recent call last):
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=248630)[0m     self._entrypoint()
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=248630)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=248630)[0m     output = train_func(config, reporter)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=248630)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=248630)[0m     config=config)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=248630)[0m     model.save(model_path, config_path)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=248630)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=248630)[0m     self.model.save(model_path)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=248630)[0m     signatures)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=248630)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=248630)[0m     f.close()
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=248630)[0m     h5i.dec_ref(id_)
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=248630)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:10 2021
[2m[36m(pid=248630)[0m , filename = '/tmp/thalvari/4565628/automl_save_6tejipw0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f660661c2d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=248630)[0m Exception in thread Thread-1:
[2m[36m(pid=248630)[0m Traceback (most recent call last):
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=248630)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=248630)[0m     param_dset[:] = val
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=248630)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=248630)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=248630)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=248630)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:10 2021
[2m[36m(pid=248630)[0m , filename = '/tmp/thalvari/4565628/automl_save_6tejipw0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f66068f8978, total write size = 259672, bytes this sub-write = 259672, bytes actually written = 18446744073709551615, offset = 1699840)
[2m[36m(pid=248630)[0m 
[2m[36m(pid=248630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248630)[0m 
[2m[36m(pid=248630)[0m Traceback (most recent call last):
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=248630)[0m     self._entrypoint()
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=248630)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=248630)[0m     output = train_func(config, reporter)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=248630)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=248630)[0m     config=config)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=248630)[0m     model.save(model_path, config_path)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=248630)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=248630)[0m     self.model.save(model_path)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=248630)[0m     signatures)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=248630)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=248630)[0m     f.close()
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=248630)[0m     h5i.dec_ref(id_)
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=248630)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=248630)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:10 2021
[2m[36m(pid=248630)[0m , filename = '/tmp/thalvari/4565628/automl_save_6tejipw0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f660661c2d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=248630)[0m 
[2m[36m(pid=248630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=248630)[0m 
[2m[36m(pid=248630)[0m Traceback (most recent call last):
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=248630)[0m     self.run()
[2m[36m(pid=248630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=248630)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=248630)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=248630)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 86 ({'TERMINATED': 13, 'ERROR': 63, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 57 not shown
 - train_func_74_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.31692,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_74_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-56_age6ny5/error_2021-01-16_21-25-08.txt
 - train_func_76_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_76_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-580s8lsvon/error_2021-01-16_21-25-08.txt
 - train_func_77_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_77_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-58hm0x2m4s/error_2021-01-16_21-25-10.txt
RUNNING trials:
 - train_func_75_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_78_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_79_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_84_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_85_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

2021-01-16 21:25:11,079	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=249004, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:11,081	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_78_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=249004)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=249004)[0m 
[2m[36m(pid=249004)[0m Stack (most recent call first):
2021-01-16 21:25:11,669	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=249222, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:11,671	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_75_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=249222)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=249222)[0m 
[2m[36m(pid=249222)[0m Stack (most recent call first):
2021-01-16 21:25:12,132	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=248630, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:12,136	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_79_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=248630)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=248630)[0m 
[2m[36m(pid=248630)[0m Stack (most recent call first):
[2m[36m(pid=251483)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251483)[0m   agg_primitives: ['count']
[2m[36m(pid=251483)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251483)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251479)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251479)[0m   agg_primitives: ['count']
[2m[36m(pid=251479)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251479)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251820)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251820)[0m   agg_primitives: ['count']
[2m[36m(pid=251820)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251820)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251814)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251814)[0m   agg_primitives: ['count']
[2m[36m(pid=251814)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251814)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251484)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251484)[0m   agg_primitives: ['count']
[2m[36m(pid=251484)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251484)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251818)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251818)[0m   agg_primitives: ['count']
[2m[36m(pid=251818)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251818)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251483)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251483)[0m Instructions for updating:
[2m[36m(pid=251483)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251483)[0m LSTM is selected.
[2m[36m(pid=251479)[0m LSTM is selected.
[2m[36m(pid=251820)[0m LSTM is selected.
[2m[36m(pid=251484)[0m LSTM is selected.
[2m[36m(pid=251479)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251479)[0m Instructions for updating:
[2m[36m(pid=251479)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251814)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251814)[0m Instructions for updating:
[2m[36m(pid=251814)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251814)[0m LSTM is selected.
[2m[36m(pid=251820)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251820)[0m Instructions for updating:
[2m[36m(pid=251820)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251484)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251484)[0m Instructions for updating:
[2m[36m(pid=251484)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251818)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251818)[0m Instructions for updating:
[2m[36m(pid=251818)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251818)[0m LSTM is selected.
[2m[36m(pid=251483)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251483)[0m Instructions for updating:
[2m[36m(pid=251483)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251479)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251479)[0m Instructions for updating:
[2m[36m(pid=251479)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251814)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251814)[0m Instructions for updating:
[2m[36m(pid=251814)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251820)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251820)[0m Instructions for updating:
[2m[36m(pid=251820)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251484)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251484)[0m Instructions for updating:
[2m[36m(pid=251484)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251819)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251819)[0m   agg_primitives: ['count']
[2m[36m(pid=251819)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251819)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251818)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251818)[0m Instructions for updating:
[2m[36m(pid=251818)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251819)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251819)[0m Instructions for updating:
[2m[36m(pid=251819)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251819)[0m LSTM is selected.
[2m[36m(pid=251812)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251812)[0m   agg_primitives: ['count']
[2m[36m(pid=251812)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251812)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251483)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251483)[0m 2021-01-16 21:25:14.666216: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251483)[0m 2021-01-16 21:25:14.673943: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251483)[0m 2021-01-16 21:25:14.675994: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3690e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251483)[0m 2021-01-16 21:25:14.676017: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251479)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251479)[0m 2021-01-16 21:25:14.670270: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251479)[0m 2021-01-16 21:25:14.678042: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251817)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251817)[0m   agg_primitives: ['count']
[2m[36m(pid=251817)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251817)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251479)[0m 2021-01-16 21:25:14.679828: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4bfd0e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251479)[0m 2021-01-16 21:25:14.679857: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251814)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251814)[0m 2021-01-16 21:25:14.695876: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251814)[0m 2021-01-16 21:25:14.703430: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251814)[0m 2021-01-16 21:25:14.705218: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3ee10e8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251814)[0m 2021-01-16 21:25:14.705239: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251820)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251820)[0m 2021-01-16 21:25:14.745309: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251820)[0m 2021-01-16 21:25:14.752931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251820)[0m 2021-01-16 21:25:14.754793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f56cd0e9a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251820)[0m 2021-01-16 21:25:14.754814: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251484)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251484)[0m 2021-01-16 21:25:14.841006: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251484)[0m 2021-01-16 21:25:14.848599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251484)[0m 2021-01-16 21:25:14.850621: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb17d0e8c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251484)[0m 2021-01-16 21:25:14.850643: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251819)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251819)[0m Instructions for updating:
[2m[36m(pid=251819)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251812)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251812)[0m Instructions for updating:
[2m[36m(pid=251812)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251812)[0m LSTM is selected.
[2m[36m(pid=251818)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251818)[0m 2021-01-16 21:25:15.096313: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251818)[0m 2021-01-16 21:25:15.103606: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251818)[0m 2021-01-16 21:25:15.105567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc4b10e8900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251818)[0m 2021-01-16 21:25:15.105588: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251611)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251611)[0m   agg_primitives: ['count']
[2m[36m(pid=251611)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251611)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251817)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251817)[0m Instructions for updating:
[2m[36m(pid=251817)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251817)[0m LSTM is selected.
[2m[36m(pid=251812)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251812)[0m Instructions for updating:
[2m[36m(pid=251812)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251611)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251611)[0m Instructions for updating:
[2m[36m(pid=251611)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251611)[0m LSTM is selected.
[2m[36m(pid=251817)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251817)[0m Instructions for updating:
[2m[36m(pid=251817)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251819)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251819)[0m 2021-01-16 21:25:15.866227: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251819)[0m 2021-01-16 21:25:15.873871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251819)[0m 2021-01-16 21:25:15.875997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f41f90e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251819)[0m 2021-01-16 21:25:15.876020: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251611)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251611)[0m Instructions for updating:
[2m[36m(pid=251611)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251812)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251812)[0m 2021-01-16 21:25:16.613020: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251812)[0m 2021-01-16 21:25:16.642751: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251812)[0m 2021-01-16 21:25:16.648700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5975103220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251812)[0m 2021-01-16 21:25:16.648752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251817)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251817)[0m 2021-01-16 21:25:16.782011: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251817)[0m 2021-01-16 21:25:16.817379: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251817)[0m 2021-01-16 21:25:16.825743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa9dd0e8860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251817)[0m 2021-01-16 21:25:16.825807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251611)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251611)[0m 2021-01-16 21:25:17.461621: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251611)[0m 2021-01-16 21:25:17.492383: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251611)[0m 2021-01-16 21:25:17.503208: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fde210e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251611)[0m 2021-01-16 21:25:17.503281: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251814)[0m 2021-01-16 21:25:18,219	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251814)[0m Traceback (most recent call last):
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251814)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251814)[0m     param_dset[:] = val
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251814)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251814)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251814)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251814)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251814)[0m , filename = '/tmp/thalvari/4565628/automl_save_04o55f93/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3ee28a4a68, total write size = 577112, bytes this sub-write = 577112, bytes actually written = 18446744073709551615, offset = 1380352)
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251814)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251814)[0m Traceback (most recent call last):
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251814)[0m     self._entrypoint()
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251814)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251814)[0m     output = train_func(config, reporter)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251814)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251814)[0m     config=config)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251814)[0m     model.save(model_path, config_path)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251814)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251814)[0m     self.model.save(model_path)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251814)[0m     signatures)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251814)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251814)[0m     f.close()
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251814)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251814)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251814)[0m , filename = '/tmp/thalvari/4565628/automl_save_04o55f93/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3ee1481450, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251814)[0m Exception in thread Thread-1:
[2m[36m(pid=251814)[0m Traceback (most recent call last):
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251814)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251814)[0m     param_dset[:] = val
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251814)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251814)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251814)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251814)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251814)[0m , filename = '/tmp/thalvari/4565628/automl_save_04o55f93/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3ee28a4a68, total write size = 577112, bytes this sub-write = 577112, bytes actually written = 18446744073709551615, offset = 1380352)
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251814)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251814)[0m Traceback (most recent call last):
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251814)[0m     self._entrypoint()
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251814)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251814)[0m     output = train_func(config, reporter)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251814)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251814)[0m     config=config)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251814)[0m     model.save(model_path, config_path)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251814)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251814)[0m     self.model.save(model_path)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251814)[0m     signatures)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251814)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251814)[0m     f.close()
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251814)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251814)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251814)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251814)[0m , filename = '/tmp/thalvari/4565628/automl_save_04o55f93/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3ee1481450, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251814)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251814)[0m Traceback (most recent call last):
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251814)[0m     self.run()
[2m[36m(pid=251814)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251814)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251814)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251479)[0m 2021-01-16 21:25:18,293	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251479)[0m Traceback (most recent call last):
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251479)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251479)[0m     param_dset[:] = val
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251479)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251479)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251479)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251479)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251479)[0m , filename = '/tmp/thalvari/4565628/automl_save_g179v9be/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4bfe91d888, total write size = 298584, bytes this sub-write = 298584, bytes actually written = 18446744073709551615, offset = 1658880)
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251479)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251479)[0m Traceback (most recent call last):
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251479)[0m     self._entrypoint()
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251479)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251479)[0m     output = train_func(config, reporter)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251479)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251479)[0m     config=config)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251479)[0m     model.save(model_path, config_path)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251479)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251479)[0m     self.model.save(model_path)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251479)[0m     signatures)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251479)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251479)[0m     f.close()
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251479)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251479)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251479)[0m , filename = '/tmp/thalvari/4565628/automl_save_g179v9be/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4bfd7e4220, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251479)[0m Exception in thread Thread-1:
[2m[36m(pid=251479)[0m Traceback (most recent call last):
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251479)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251479)[0m     param_dset[:] = val
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251479)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251479)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251479)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251479)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251479)[0m , filename = '/tmp/thalvari/4565628/automl_save_g179v9be/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4bfe91d888, total write size = 298584, bytes this sub-write = 298584, bytes actually written = 18446744073709551615, offset = 1658880)
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251479)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251479)[0m Traceback (most recent call last):
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251479)[0m     self._entrypoint()
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251479)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251479)[0m     output = train_func(config, reporter)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251479)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251479)[0m     config=config)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251479)[0m     model.save(model_path, config_path)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251479)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251479)[0m     self.model.save(model_path)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251479)[0m     signatures)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251479)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251479)[0m     f.close()
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251479)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251479)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251479)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251479)[0m , filename = '/tmp/thalvari/4565628/automl_save_g179v9be/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4bfd7e4220, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251479)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251479)[0m Traceback (most recent call last):
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251479)[0m     self.run()
[2m[36m(pid=251479)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251479)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251479)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251484)[0m 2021-01-16 21:25:18,400	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251484)[0m Traceback (most recent call last):
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251484)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251484)[0m     param_dset[:] = val
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251484)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251484)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251484)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251484)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251484)[0m , filename = '/tmp/thalvari/4565628/automl_save_6t09jwz_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fb17df2cbb8, total write size = 254040, bytes this sub-write = 254040, bytes actually written = 18446744073709551615, offset = 561152)
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251484)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251484)[0m Traceback (most recent call last):
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251484)[0m     self._entrypoint()
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251484)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251484)[0m     output = train_func(config, reporter)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251484)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251484)[0m     config=config)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251484)[0m     model.save(model_path, config_path)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251484)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251484)[0m     self.model.save(model_path)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251484)[0m     signatures)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251484)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251484)[0m     f.close()
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251484)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251484)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251484)[0m , filename = '/tmp/thalvari/4565628/automl_save_6t09jwz_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fb17d39f9d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251484)[0m Exception in thread Thread-1:
[2m[36m(pid=251484)[0m Traceback (most recent call last):
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251484)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251484)[0m     param_dset[:] = val
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251484)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251484)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251484)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251484)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251484)[0m , filename = '/tmp/thalvari/4565628/automl_save_6t09jwz_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fb17df2cbb8, total write size = 254040, bytes this sub-write = 254040, bytes actually written = 18446744073709551615, offset = 561152)
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251484)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251484)[0m Traceback (most recent call last):
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251484)[0m     self._entrypoint()
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251484)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251484)[0m     output = train_func(config, reporter)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251484)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251484)[0m     config=config)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251484)[0m     model.save(model_path, config_path)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251484)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251484)[0m     self.model.save(model_path)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251484)[0m     signatures)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251484)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251484)[0m     f.close()
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251484)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251484)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251484)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251484)[0m , filename = '/tmp/thalvari/4565628/automl_save_6t09jwz_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fb17d39f9d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251484)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251484)[0m Traceback (most recent call last):
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251484)[0m     self.run()
[2m[36m(pid=251484)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251484)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251484)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251483)[0m 2021-01-16 21:25:18,455	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251483)[0m Traceback (most recent call last):
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251483)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251483)[0m     param_dset[:] = val
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251483)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251483)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251483)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251483)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251483)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ba1rc4v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd36a8cc0c8, total write size = 306776, bytes this sub-write = 306776, bytes actually written = 18446744073709551615, offset = 1650688)
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251483)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251483)[0m Traceback (most recent call last):
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251483)[0m     self._entrypoint()
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251483)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251483)[0m     output = train_func(config, reporter)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251483)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251483)[0m     config=config)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251483)[0m     model.save(model_path, config_path)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251483)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251483)[0m     self.model.save(model_path)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251483)[0m     signatures)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251483)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251483)[0m     f.close()
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251483)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251483)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251483)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ba1rc4v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd369662910, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251483)[0m Exception in thread Thread-1:
[2m[36m(pid=251483)[0m Traceback (most recent call last):
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251483)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251483)[0m     param_dset[:] = val
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251483)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251483)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251483)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251483)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251483)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ba1rc4v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd36a8cc0c8, total write size = 306776, bytes this sub-write = 306776, bytes actually written = 18446744073709551615, offset = 1650688)
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251483)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251483)[0m Traceback (most recent call last):
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251483)[0m     self._entrypoint()
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251483)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251483)[0m     output = train_func(config, reporter)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251483)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251483)[0m     config=config)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251483)[0m     model.save(model_path, config_path)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251483)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251483)[0m     self.model.save(model_path)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251483)[0m     signatures)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251483)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251483)[0m     f.close()
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251483)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251483)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251483)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251483)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ba1rc4v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd369662910, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251820)[0m 2021-01-16 21:25:18,438	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251820)[0m Traceback (most recent call last):
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251820)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251820)[0m     param_dset[:] = val
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251820)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251820)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251820)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251820)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251820)[0m , filename = '/tmp/thalvari/4565628/automl_save_ihtllefd/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f56cea117a8, total write size = 1117784, bytes this sub-write = 1117784, bytes actually written = 18446744073709551615, offset = 839680)
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251820)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251820)[0m Traceback (most recent call last):
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251820)[0m     self._entrypoint()
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251820)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251820)[0m     output = train_func(config, reporter)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251820)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251820)[0m     config=config)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251820)[0m     model.save(model_path, config_path)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251820)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251820)[0m     self.model.save(model_path)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251820)[0m     signatures)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251820)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251820)[0m     f.close()
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251820)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251820)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251820)[0m , filename = '/tmp/thalvari/4565628/automl_save_ihtllefd/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f56ce2d56a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251820)[0m Exception in thread Thread-1:
[2m[36m(pid=251820)[0m Traceback (most recent call last):
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251820)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251820)[0m     param_dset[:] = val
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251820)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251820)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251820)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251820)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251820)[0m , filename = '/tmp/thalvari/4565628/automl_save_ihtllefd/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f56cea117a8, total write size = 1117784, bytes this sub-write = 1117784, bytes actually written = 18446744073709551615, offset = 839680)
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251820)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251820)[0m Traceback (most recent call last):
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251820)[0m     self._entrypoint()
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251820)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251820)[0m     output = train_func(config, reporter)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251820)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251820)[0m     config=config)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251820)[0m     model.save(model_path, config_path)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251820)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251820)[0m     self.model.save(model_path)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251820)[0m     signatures)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251820)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251820)[0m     f.close()
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251820)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251820)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251820)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251820)[0m , filename = '/tmp/thalvari/4565628/automl_save_ihtllefd/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f56ce2d56a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251483)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251483)[0m Traceback (most recent call last):
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251483)[0m     self.run()
[2m[36m(pid=251483)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251483)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251483)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251820)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251820)[0m Traceback (most recent call last):
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251820)[0m     self.run()
[2m[36m(pid=251820)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251820)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251820)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251818)[0m 2021-01-16 21:25:18,623	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251818)[0m Traceback (most recent call last):
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251818)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251818)[0m     param_dset[:] = val
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251818)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251818)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251818)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251818)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251818)[0m , filename = '/tmp/thalvari/4565628/automl_save_85viyyz5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc4b285e818, total write size = 306776, bytes this sub-write = 306776, bytes actually written = 18446744073709551615, offset = 1650688)
[2m[36m(pid=251818)[0m 
[2m[36m(pid=251818)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251818)[0m 
[2m[36m(pid=251818)[0m Traceback (most recent call last):
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251818)[0m     self._entrypoint()
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251818)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251818)[0m     output = train_func(config, reporter)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251818)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251818)[0m     config=config)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251818)[0m     model.save(model_path, config_path)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251818)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251818)[0m     self.model.save(model_path)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251818)[0m     signatures)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251818)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251818)[0m     f.close()
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251818)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251818)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251818)[0m , filename = '/tmp/thalvari/4565628/automl_save_85viyyz5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc4b21d2960, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251818)[0m Exception in thread Thread-1:
[2m[36m(pid=251818)[0m Traceback (most recent call last):
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251818)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251818)[0m     param_dset[:] = val
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251818)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251818)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251818)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251818)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251818)[0m , filename = '/tmp/thalvari/4565628/automl_save_85viyyz5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc4b285e818, total write size = 306776, bytes this sub-write = 306776, bytes actually written = 18446744073709551615, offset = 1650688)
[2m[36m(pid=251818)[0m 
[2m[36m(pid=251818)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251818)[0m 
[2m[36m(pid=251818)[0m Traceback (most recent call last):
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251818)[0m     self._entrypoint()
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251818)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251818)[0m     output = train_func(config, reporter)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251818)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251818)[0m     config=config)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251818)[0m     model.save(model_path, config_path)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251818)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251818)[0m     self.model.save(model_path)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251818)[0m     signatures)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251818)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251818)[0m     f.close()
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251818)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251818)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251818)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:18 2021
[2m[36m(pid=251818)[0m , filename = '/tmp/thalvari/4565628/automl_save_85viyyz5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc4b21d2960, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251818)[0m 
[2m[36m(pid=251818)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251818)[0m 
[2m[36m(pid=251818)[0m Traceback (most recent call last):
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251818)[0m     self.run()
[2m[36m(pid=251818)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251818)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251818)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251818)[0m 
2021-01-16 21:25:19,315	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251814, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:19,321	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_83_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 21.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 89 ({'TERMINATED': 13, 'ERROR': 67, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 61 not shown
 - train_func_78_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_78_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-24-59oubjrotg/error_2021-01-16_21-25-11.txt
 - train_func_79_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_79_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-01j4sfytua/error_2021-01-16_21-25-12.txt
 - train_func_83_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_83_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-082k4no497/error_2021-01-16_21-25-19.txt
RUNNING trials:
 - train_func_80_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_81_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_82_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_87_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.72725,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0048356,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_88_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_89_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=251814)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251814)[0m 
[2m[36m(pid=251814)[0m Stack (most recent call first):
[2m[36m(pid=251819)[0m 2021-01-16 21:25:19,640	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251819)[0m Traceback (most recent call last):
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251819)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251819)[0m     param_dset[:] = val
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251819)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251819)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251819)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251819)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:19 2021
[2m[36m(pid=251819)[0m , filename = '/tmp/thalvari/4565628/automl_save_zrf1xg3y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41fa8f48f8, total write size = 314968, bytes this sub-write = 314968, bytes actually written = 18446744073709551615, offset = 1642496)
[2m[36m(pid=251819)[0m 
[2m[36m(pid=251819)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251819)[0m 
[2m[36m(pid=251819)[0m Traceback (most recent call last):
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251819)[0m     self._entrypoint()
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251819)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251819)[0m     output = train_func(config, reporter)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251819)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251819)[0m     config=config)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251819)[0m     model.save(model_path, config_path)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251819)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251819)[0m     self.model.save(model_path)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251819)[0m     signatures)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251819)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251819)[0m     f.close()
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251819)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251819)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:19 2021
[2m[36m(pid=251819)[0m , filename = '/tmp/thalvari/4565628/automl_save_zrf1xg3y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41fa0a2b90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251819)[0m Exception in thread Thread-1:
[2m[36m(pid=251819)[0m Traceback (most recent call last):
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251819)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251819)[0m     param_dset[:] = val
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251819)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251819)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251819)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251819)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:19 2021
[2m[36m(pid=251819)[0m , filename = '/tmp/thalvari/4565628/automl_save_zrf1xg3y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41fa8f48f8, total write size = 314968, bytes this sub-write = 314968, bytes actually written = 18446744073709551615, offset = 1642496)
[2m[36m(pid=251819)[0m 
[2m[36m(pid=251819)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251819)[0m 
[2m[36m(pid=251819)[0m Traceback (most recent call last):
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251819)[0m     self._entrypoint()
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251819)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251819)[0m     output = train_func(config, reporter)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251819)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251819)[0m     config=config)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251819)[0m     model.save(model_path, config_path)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251819)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251819)[0m     self.model.save(model_path)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251819)[0m     signatures)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251819)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251819)[0m     f.close()
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251819)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251819)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251819)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:19 2021
[2m[36m(pid=251819)[0m , filename = '/tmp/thalvari/4565628/automl_save_zrf1xg3y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41fa0a2b90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251819)[0m 
[2m[36m(pid=251819)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251819)[0m 
[2m[36m(pid=251819)[0m Traceback (most recent call last):
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251819)[0m     self.run()
[2m[36m(pid=251819)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251819)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251819)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251819)[0m 
2021-01-16 21:25:19,874	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251483, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:19,878	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_81_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251483)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251483)[0m 
[2m[36m(pid=251483)[0m Stack (most recent call first):
[2m[36m(pid=251812)[0m 2021-01-16 21:25:20,163	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251812)[0m Traceback (most recent call last):
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251812)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251812)[0m     param_dset[:] = val
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251812)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251812)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251812)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251812)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251812)[0m , filename = '/tmp/thalvari/4565628/automl_save_aj6enazd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f597671a2b8, total write size = 2136, bytes this sub-write = 2136, bytes actually written = 18446744073709551615, offset = 815104)
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251812)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251812)[0m Traceback (most recent call last):
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251812)[0m     self._entrypoint()
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251812)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251812)[0m     output = train_func(config, reporter)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251812)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251812)[0m     config=config)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251812)[0m     model.save(model_path, config_path)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251812)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251812)[0m     self.model.save(model_path)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251812)[0m     signatures)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251812)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251812)[0m     f.close()
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251812)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251812)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251812)[0m , filename = '/tmp/thalvari/4565628/automl_save_aj6enazd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f59757429b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251812)[0m Exception in thread Thread-1:
[2m[36m(pid=251812)[0m Traceback (most recent call last):
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251812)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251812)[0m     param_dset[:] = val
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251812)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251812)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251812)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251812)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251812)[0m , filename = '/tmp/thalvari/4565628/automl_save_aj6enazd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f597671a2b8, total write size = 2136, bytes this sub-write = 2136, bytes actually written = 18446744073709551615, offset = 815104)
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251812)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251812)[0m Traceback (most recent call last):
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251812)[0m     self._entrypoint()
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251812)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251812)[0m     output = train_func(config, reporter)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251812)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251812)[0m     config=config)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251812)[0m     model.save(model_path, config_path)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251812)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251812)[0m     self.model.save(model_path)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251812)[0m     signatures)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251812)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251812)[0m     f.close()
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251812)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251812)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251812)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251812)[0m , filename = '/tmp/thalvari/4565628/automl_save_aj6enazd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f59757429b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251812)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251812)[0m Traceback (most recent call last):
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251812)[0m     self.run()
[2m[36m(pid=251812)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251812)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251812)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251817)[0m 2021-01-16 21:25:20,198	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251817)[0m Traceback (most recent call last):
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251817)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251817)[0m     param_dset[:] = val
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251817)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251817)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251817)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251817)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251817)[0m , filename = '/tmp/thalvari/4565628/automl_save_hqk_qoln/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa9de862008, total write size = 331352, bytes this sub-write = 331352, bytes actually written = 18446744073709551615, offset = 1626112)
[2m[36m(pid=251817)[0m 
[2m[36m(pid=251817)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251817)[0m 
[2m[36m(pid=251817)[0m Traceback (most recent call last):
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251817)[0m     self._entrypoint()
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251817)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251817)[0m     output = train_func(config, reporter)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251817)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251817)[0m     config=config)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251817)[0m     model.save(model_path, config_path)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251817)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251817)[0m     self.model.save(model_path)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251817)[0m     signatures)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251817)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251817)[0m     f.close()
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251817)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251817)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251817)[0m , filename = '/tmp/thalvari/4565628/automl_save_hqk_qoln/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa9de514d80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251817)[0m Exception in thread Thread-1:
[2m[36m(pid=251817)[0m Traceback (most recent call last):
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251817)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251817)[0m     param_dset[:] = val
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251817)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251817)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251817)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251817)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251817)[0m , filename = '/tmp/thalvari/4565628/automl_save_hqk_qoln/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa9de862008, total write size = 331352, bytes this sub-write = 331352, bytes actually written = 18446744073709551615, offset = 1626112)
[2m[36m(pid=251817)[0m 
[2m[36m(pid=251817)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251817)[0m 
[2m[36m(pid=251817)[0m Traceback (most recent call last):
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251817)[0m     self._entrypoint()
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251817)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251817)[0m     output = train_func(config, reporter)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251817)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251817)[0m     config=config)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251817)[0m     model.save(model_path, config_path)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251817)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251817)[0m     self.model.save(model_path)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251817)[0m     signatures)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251817)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251817)[0m     f.close()
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251817)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251817)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251817)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251817)[0m , filename = '/tmp/thalvari/4565628/automl_save_hqk_qoln/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa9de514d80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251817)[0m 
[2m[36m(pid=251817)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251817)[0m 
[2m[36m(pid=251817)[0m Traceback (most recent call last):
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251817)[0m     self.run()
[2m[36m(pid=251817)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251817)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251817)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251817)[0m 
2021-01-16 21:25:20,473	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251479, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:20,476	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_80_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251479)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251479)[0m 
[2m[36m(pid=251479)[0m Stack (most recent call first):
[2m[36m(pid=251611)[0m 2021-01-16 21:25:20,849	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251611)[0m Traceback (most recent call last):
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251611)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251611)[0m     param_dset[:] = val
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251611)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251611)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251611)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251611)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251611)[0m , filename = '/tmp/thalvari/4565628/automl_save_nui52hhh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fde2287af58, total write size = 339544, bytes this sub-write = 339544, bytes actually written = 18446744073709551615, offset = 1617920)
[2m[36m(pid=251611)[0m 
[2m[36m(pid=251611)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251611)[0m 
[2m[36m(pid=251611)[0m Traceback (most recent call last):
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251611)[0m     self._entrypoint()
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251611)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251611)[0m     output = train_func(config, reporter)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251611)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251611)[0m     config=config)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251611)[0m     model.save(model_path, config_path)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251611)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251611)[0m     self.model.save(model_path)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251611)[0m     signatures)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251611)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251611)[0m     f.close()
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251611)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251611)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251611)[0m , filename = '/tmp/thalvari/4565628/automl_save_nui52hhh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fde215e9570, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251611)[0m Exception in thread Thread-1:
[2m[36m(pid=251611)[0m Traceback (most recent call last):
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251611)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251611)[0m     param_dset[:] = val
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251611)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251611)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251611)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251611)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251611)[0m , filename = '/tmp/thalvari/4565628/automl_save_nui52hhh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fde2287af58, total write size = 339544, bytes this sub-write = 339544, bytes actually written = 18446744073709551615, offset = 1617920)
[2m[36m(pid=251611)[0m 
[2m[36m(pid=251611)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251611)[0m 
[2m[36m(pid=251611)[0m Traceback (most recent call last):
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251611)[0m     self._entrypoint()
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251611)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251611)[0m     output = train_func(config, reporter)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251611)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251611)[0m     config=config)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251611)[0m     model.save(model_path, config_path)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251611)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251611)[0m     self.model.save(model_path)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251611)[0m     signatures)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251611)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251611)[0m     f.close()
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251611)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251611)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251611)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:20 2021
[2m[36m(pid=251611)[0m , filename = '/tmp/thalvari/4565628/automl_save_nui52hhh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fde215e9570, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251611)[0m 
[2m[36m(pid=251611)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251611)[0m 
[2m[36m(pid=251611)[0m Traceback (most recent call last):
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251611)[0m     self.run()
[2m[36m(pid=251611)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251611)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251611)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251611)[0m 
2021-01-16 21:25:21,193	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251820, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:21,196	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_84_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251820)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251820)[0m 
[2m[36m(pid=251820)[0m Stack (most recent call first):
2021-01-16 21:25:21,745	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251818, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:21,747	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_85_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251818)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251818)[0m 
[2m[36m(pid=251818)[0m Stack (most recent call first):
2021-01-16 21:25:22,499	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251819, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:22,502	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_86_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251819)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251819)[0m 
[2m[36m(pid=251819)[0m Stack (most recent call first):
[2m[36m(pid=251607)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251607)[0m   agg_primitives: ['count']
[2m[36m(pid=251607)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251607)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251610)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251610)[0m   agg_primitives: ['count']
[2m[36m(pid=251610)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251610)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:25:23,199	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251817, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:23,201	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_88_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251817)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251817)[0m 
[2m[36m(pid=251817)[0m Stack (most recent call first):
[2m[36m(pid=251607)[0m LSTM is selected.
[2m[36m(pid=251610)[0m LSTM is selected.
[2m[36m(pid=251607)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251607)[0m Instructions for updating:
[2m[36m(pid=251607)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251610)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251610)[0m Instructions for updating:
[2m[36m(pid=251610)[0m If using Keras pass *_constraint arguments to layers.
2021-01-16 21:25:23,846	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251611, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:23,848	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_89_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251607)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251607)[0m Instructions for updating:
[2m[36m(pid=251607)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251611)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251611)[0m 
[2m[36m(pid=251611)[0m Stack (most recent call first):
[2m[36m(pid=254215)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254213)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254213)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254214)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254214)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254215)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251610)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251610)[0m Instructions for updating:
[2m[36m(pid=251610)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251816)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251816)[0m   agg_primitives: ['count']
[2m[36m(pid=251816)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251816)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251608)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251608)[0m   agg_primitives: ['count']
[2m[36m(pid=251608)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251608)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254344)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254344)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254341)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254341)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254364)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254364)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254343)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254343)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254345)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254345)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254339)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254339)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254385)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254385)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254624)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251816)[0m LSTM is selected.
[2m[36m(pid=254624)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254622)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254622)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=251816)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251816)[0m Instructions for updating:
[2m[36m(pid=251816)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 97 ({'TERMINATED': 13, 'ERROR': 74, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 68 not shown
 - train_func_86_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_86_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-118jxt8dyt/error_2021-01-16_21-25-22.txt
 - train_func_88_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_88_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-12h178_8f8/error_2021-01-16_21-25-23.txt
 - train_func_89_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_89_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-12qshdz_sm/error_2021-01-16_21-25-23.txt
RUNNING trials:
 - train_func_82_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_87_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.72725,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0048356,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_90_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_95_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_96_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_97_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

2021-01-16 21:25:25,032	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251484, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:25,036	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_82_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251608)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251608)[0m Instructions for updating:
[2m[36m(pid=251608)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251608)[0m LSTM is selected.
[2m[36m(pid=251484)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251484)[0m 
[2m[36m(pid=251484)[0m Stack (most recent call first):
[2m[36m(pid=251607)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251607)[0m 2021-01-16 21:25:25.309932: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251607)[0m 2021-01-16 21:25:25.331233: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251607)[0m 2021-01-16 21:25:25.333354: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d610e8a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251607)[0m 2021-01-16 21:25:25.333388: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:25:25,548	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251812, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:25,551	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_87_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.72725,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0048356,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251816)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251816)[0m Instructions for updating:
[2m[36m(pid=251816)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251610)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251610)[0m 2021-01-16 21:25:25.584076: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251610)[0m 2021-01-16 21:25:25.592218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251610)[0m 2021-01-16 21:25:25.594276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3e810e8c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251610)[0m 2021-01-16 21:25:25.594300: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251812)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251812)[0m 
[2m[36m(pid=251812)[0m Stack (most recent call first):
[2m[36m(pid=251608)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251608)[0m Instructions for updating:
[2m[36m(pid=251608)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251609)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=251609)[0m   agg_primitives: ['count']
[2m[36m(pid=251609)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=251609)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251609)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=251609)[0m Instructions for updating:
[2m[36m(pid=251609)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251609)[0m LSTM is selected.
[2m[36m(pid=251816)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251816)[0m 2021-01-16 21:25:26.720833: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251816)[0m 2021-01-16 21:25:26.728330: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251816)[0m 2021-01-16 21:25:26.730083: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0369103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251816)[0m 2021-01-16 21:25:26.730103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251608)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251608)[0m 2021-01-16 21:25:26.860873: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251608)[0m 2021-01-16 21:25:26.868504: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251608)[0m 2021-01-16 21:25:26.871119: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f84b50e8a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251608)[0m 2021-01-16 21:25:26.871139: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251609)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=251609)[0m Instructions for updating:
[2m[36m(pid=251609)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251609)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=251609)[0m 2021-01-16 21:25:28.218154: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=251609)[0m 2021-01-16 21:25:28.229028: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=251609)[0m 2021-01-16 21:25:28.233928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5b650e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=251609)[0m 2021-01-16 21:25:28.233983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=251607)[0m 2021-01-16 21:25:28,469	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251607)[0m Traceback (most recent call last):
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251607)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251607)[0m     param_dset[:] = val
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251607)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251607)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251607)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251607)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251607)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ennh2p_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8d628f51d8, total write size = 470616, bytes this sub-write = 470616, bytes actually written = 18446744073709551615, offset = 1486848)
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251607)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251607)[0m Traceback (most recent call last):
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251607)[0m     self._entrypoint()
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251607)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251607)[0m     output = train_func(config, reporter)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251607)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251607)[0m     config=config)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251607)[0m     model.save(model_path, config_path)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251607)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251607)[0m     self.model.save(model_path)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251607)[0m     signatures)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251607)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251607)[0m     f.close()
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251607)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251607)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251607)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ennh2p_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8d61530a50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251607)[0m Exception in thread Thread-1:
[2m[36m(pid=251607)[0m Traceback (most recent call last):
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251607)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251607)[0m     param_dset[:] = val
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251607)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251607)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251607)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251607)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251607)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ennh2p_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8d628f51d8, total write size = 470616, bytes this sub-write = 470616, bytes actually written = 18446744073709551615, offset = 1486848)
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251607)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251607)[0m Traceback (most recent call last):
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251607)[0m     self._entrypoint()
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251607)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251607)[0m     output = train_func(config, reporter)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251607)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251607)[0m     config=config)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251607)[0m     model.save(model_path, config_path)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251607)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251607)[0m     self.model.save(model_path)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251607)[0m     signatures)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251607)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251607)[0m     f.close()
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251607)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251607)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251607)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251607)[0m , filename = '/tmp/thalvari/4565628/automl_save_1ennh2p_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8d61530a50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251607)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251607)[0m Traceback (most recent call last):
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251607)[0m     self.run()
[2m[36m(pid=251607)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251607)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251607)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251610)[0m 2021-01-16 21:25:28,765	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251610)[0m Traceback (most recent call last):
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251610)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251610)[0m     param_dset[:] = val
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251610)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251610)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251610)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251610)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251610)[0m , filename = '/tmp/thalvari/4565628/automl_save_gknimgct/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3e82894038, total write size = 470616, bytes this sub-write = 470616, bytes actually written = 18446744073709551615, offset = 1486848)
[2m[36m(pid=251610)[0m 
[2m[36m(pid=251610)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251610)[0m 
[2m[36m(pid=251610)[0m Traceback (most recent call last):
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251610)[0m     self._entrypoint()
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251610)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251610)[0m     output = train_func(config, reporter)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251610)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251610)[0m     config=config)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251610)[0m     model.save(model_path, config_path)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251610)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251610)[0m     self.model.save(model_path)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251610)[0m     signatures)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251610)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251610)[0m     f.close()
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251610)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251610)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251610)[0m , filename = '/tmp/thalvari/4565628/automl_save_gknimgct/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3e8252d140, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251610)[0m Exception in thread Thread-1:
[2m[36m(pid=251610)[0m Traceback (most recent call last):
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251610)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251610)[0m     param_dset[:] = val
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251610)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251610)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251610)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251610)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251610)[0m , filename = '/tmp/thalvari/4565628/automl_save_gknimgct/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3e82894038, total write size = 470616, bytes this sub-write = 470616, bytes actually written = 18446744073709551615, offset = 1486848)
[2m[36m(pid=251610)[0m 
[2m[36m(pid=251610)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251610)[0m 
[2m[36m(pid=251610)[0m Traceback (most recent call last):
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251610)[0m     self._entrypoint()
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251610)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251610)[0m     output = train_func(config, reporter)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251610)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251610)[0m     config=config)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251610)[0m     model.save(model_path, config_path)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251610)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251610)[0m     self.model.save(model_path)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251610)[0m     signatures)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251610)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251610)[0m     f.close()
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251610)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251610)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251610)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:28 2021
[2m[36m(pid=251610)[0m , filename = '/tmp/thalvari/4565628/automl_save_gknimgct/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3e8252d140, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251610)[0m 
[2m[36m(pid=251610)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251610)[0m 
[2m[36m(pid=251610)[0m Traceback (most recent call last):
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251610)[0m     self.run()
[2m[36m(pid=251610)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251610)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251610)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251610)[0m 
2021-01-16 21:25:29,648	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251607, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:29,651	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_91_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254625)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254625)[0m   agg_primitives: ['count']
[2m[36m(pid=254625)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254625)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254385)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254385)[0m   agg_primitives: ['count']
[2m[36m(pid=254385)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254385)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254627)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254627)[0m   agg_primitives: ['count']
[2m[36m(pid=254627)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254627)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254215)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254215)[0m   agg_primitives: ['count']
[2m[36m(pid=254215)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254215)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254213)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254213)[0m   agg_primitives: ['count']
[2m[36m(pid=254213)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254213)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=251607)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251607)[0m 
[2m[36m(pid=251607)[0m Stack (most recent call first):
[2m[36m(pid=251816)[0m 2021-01-16 21:25:29,734	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251816)[0m Traceback (most recent call last):
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251816)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251816)[0m     param_dset[:] = val
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251816)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251816)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251816)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251816)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251816)[0m , filename = '/tmp/thalvari/4565628/automl_save_sv_pqga_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f036a910d48, total write size = 489048, bytes this sub-write = 489048, bytes actually written = 18446744073709551615, offset = 1470464)
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251816)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251816)[0m Traceback (most recent call last):
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251816)[0m     self._entrypoint()
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251816)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251816)[0m     output = train_func(config, reporter)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251816)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251816)[0m     config=config)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251816)[0m     model.save(model_path, config_path)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251816)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251816)[0m     self.model.save(model_path)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251816)[0m     signatures)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251816)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251816)[0m     f.close()
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251816)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251816)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251816)[0m , filename = '/tmp/thalvari/4565628/automl_save_sv_pqga_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0369944400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251816)[0m Exception in thread Thread-1:
[2m[36m(pid=251816)[0m Traceback (most recent call last):
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251816)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251816)[0m     param_dset[:] = val
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251816)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251816)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251816)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251816)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251816)[0m , filename = '/tmp/thalvari/4565628/automl_save_sv_pqga_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f036a910d48, total write size = 489048, bytes this sub-write = 489048, bytes actually written = 18446744073709551615, offset = 1470464)
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251816)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251816)[0m Traceback (most recent call last):
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251816)[0m     self._entrypoint()
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251816)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251816)[0m     output = train_func(config, reporter)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251816)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251816)[0m     config=config)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251816)[0m     model.save(model_path, config_path)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251816)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251816)[0m     self.model.save(model_path)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251816)[0m     signatures)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251816)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251816)[0m     f.close()
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251816)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251816)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251816)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251816)[0m , filename = '/tmp/thalvari/4565628/automl_save_sv_pqga_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0369944400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251816)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251816)[0m Traceback (most recent call last):
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251816)[0m     self.run()
[2m[36m(pid=251816)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251816)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251816)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251608)[0m 2021-01-16 21:25:29,814	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251608)[0m Traceback (most recent call last):
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251608)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251608)[0m     param_dset[:] = val
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251608)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251608)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251608)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251608)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251608)[0m , filename = '/tmp/thalvari/4565628/automl_save_lyrfd6ju/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f84b68c5188, total write size = 487000, bytes this sub-write = 487000, bytes actually written = 18446744073709551615, offset = 1470464)
[2m[36m(pid=251608)[0m 
[2m[36m(pid=251608)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251608)[0m 
[2m[36m(pid=251608)[0m Traceback (most recent call last):
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251608)[0m     self._entrypoint()
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251608)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251608)[0m     output = train_func(config, reporter)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251608)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251608)[0m     config=config)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251608)[0m     model.save(model_path, config_path)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251608)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251608)[0m     self.model.save(model_path)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251608)[0m     signatures)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251608)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251608)[0m     f.close()
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251608)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251608)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251608)[0m , filename = '/tmp/thalvari/4565628/automl_save_lyrfd6ju/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f84b55ebf80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251608)[0m Exception in thread Thread-1:
[2m[36m(pid=251608)[0m Traceback (most recent call last):
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251608)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251608)[0m     param_dset[:] = val
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251608)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251608)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251608)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251608)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251608)[0m , filename = '/tmp/thalvari/4565628/automl_save_lyrfd6ju/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f84b68c5188, total write size = 487000, bytes this sub-write = 487000, bytes actually written = 18446744073709551615, offset = 1470464)
[2m[36m(pid=251608)[0m 
[2m[36m(pid=251608)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251608)[0m 
[2m[36m(pid=251608)[0m Traceback (most recent call last):
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251608)[0m     self._entrypoint()
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251608)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251608)[0m     output = train_func(config, reporter)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251608)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251608)[0m     config=config)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251608)[0m     model.save(model_path, config_path)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251608)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251608)[0m     self.model.save(model_path)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251608)[0m     signatures)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251608)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251608)[0m     f.close()
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251608)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251608)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251608)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:29 2021
[2m[36m(pid=251608)[0m , filename = '/tmp/thalvari/4565628/automl_save_lyrfd6ju/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f84b55ebf80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251608)[0m 
[2m[36m(pid=251608)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251608)[0m 
[2m[36m(pid=251608)[0m Traceback (most recent call last):
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251608)[0m     self.run()
[2m[36m(pid=251608)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251608)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251608)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251608)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 100 ({'TERMINATED': 13, 'ERROR': 77, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 71 not shown
 - train_func_88_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_88_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-12h178_8f8/error_2021-01-16_21-25-23.txt
 - train_func_89_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_89_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-12qshdz_sm/error_2021-01-16_21-25-23.txt
 - train_func_91_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_91_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-20kxx48v_x/error_2021-01-16_21-25-29.txt
RUNNING trials:
 - train_func_90_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_92_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_93_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_98_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_99_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_100_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=254625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254625)[0m Instructions for updating:
[2m[36m(pid=254625)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254625)[0m LSTM is selected.
[2m[36m(pid=254385)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254385)[0m Instructions for updating:
[2m[36m(pid=254385)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254385)[0m LSTM is selected.
[2m[36m(pid=254627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254627)[0m Instructions for updating:
[2m[36m(pid=254627)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254627)[0m LSTM is selected.
2021-01-16 21:25:30,248	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251610, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:30,250	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_90_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254215)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254215)[0m Instructions for updating:
[2m[36m(pid=254215)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254215)[0m LSTM is selected.
[2m[36m(pid=254213)[0m LSTM is selected.
[2m[36m(pid=254213)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254213)[0m Instructions for updating:
[2m[36m(pid=254213)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=251610)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251610)[0m 
[2m[36m(pid=251610)[0m Stack (most recent call first):
[2m[36m(pid=254625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254625)[0m Instructions for updating:
[2m[36m(pid=254625)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254627)[0m Instructions for updating:
[2m[36m(pid=254627)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254215)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254215)[0m Instructions for updating:
[2m[36m(pid=254215)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254385)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254385)[0m Instructions for updating:
[2m[36m(pid=254385)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:25:30,892	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251608, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:30,896	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_93_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254213)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254213)[0m Instructions for updating:
[2m[36m(pid=254213)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=251608)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251608)[0m 
[2m[36m(pid=251608)[0m Stack (most recent call first):
[2m[36m(pid=251609)[0m 2021-01-16 21:25:31,388	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=251609)[0m Traceback (most recent call last):
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251609)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251609)[0m     param_dset[:] = val
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251609)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251609)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251609)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251609)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:31 2021
[2m[36m(pid=251609)[0m , filename = '/tmp/thalvari/4565628/automl_save_fbde88y_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b66aa91d8, total write size = 495192, bytes this sub-write = 495192, bytes actually written = 18446744073709551615, offset = 1462272)
[2m[36m(pid=251609)[0m 
[2m[36m(pid=251609)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251609)[0m 
[2m[36m(pid=251609)[0m Traceback (most recent call last):
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251609)[0m     self._entrypoint()
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251609)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251609)[0m     output = train_func(config, reporter)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251609)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251609)[0m     config=config)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251609)[0m     model.save(model_path, config_path)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251609)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251609)[0m     self.model.save(model_path)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251609)[0m     signatures)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251609)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251609)[0m     f.close()
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251609)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251609)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:31 2021
[2m[36m(pid=251609)[0m , filename = '/tmp/thalvari/4565628/automl_save_fbde88y_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b6617eb70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251609)[0m Exception in thread Thread-1:
[2m[36m(pid=251609)[0m Traceback (most recent call last):
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=251609)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=251609)[0m     param_dset[:] = val
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=251609)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=251609)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=251609)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=251609)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:31 2021
[2m[36m(pid=251609)[0m , filename = '/tmp/thalvari/4565628/automl_save_fbde88y_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b66aa91d8, total write size = 495192, bytes this sub-write = 495192, bytes actually written = 18446744073709551615, offset = 1462272)
[2m[36m(pid=251609)[0m 
[2m[36m(pid=251609)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251609)[0m 
[2m[36m(pid=251609)[0m Traceback (most recent call last):
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=251609)[0m     self._entrypoint()
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=251609)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=251609)[0m     output = train_func(config, reporter)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=251609)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=251609)[0m     config=config)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=251609)[0m     model.save(model_path, config_path)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=251609)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=251609)[0m     self.model.save(model_path)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=251609)[0m     signatures)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=251609)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=251609)[0m     f.close()
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=251609)[0m     h5i.dec_ref(id_)
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=251609)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=251609)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:31 2021
[2m[36m(pid=251609)[0m , filename = '/tmp/thalvari/4565628/automl_save_fbde88y_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5b6617eb70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=251609)[0m 
[2m[36m(pid=251609)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=251609)[0m 
[2m[36m(pid=251609)[0m Traceback (most recent call last):
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=251609)[0m     self.run()
[2m[36m(pid=251609)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=251609)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=251609)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=251609)[0m 
2021-01-16 21:25:31,516	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251816, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:31,518	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_92_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251816)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251816)[0m 
[2m[36m(pid=251816)[0m Stack (most recent call first):
[2m[36m(pid=254385)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254385)[0m 2021-01-16 21:25:31.746948: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254385)[0m 2021-01-16 21:25:31.754596: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254385)[0m 2021-01-16 21:25:31.756754: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9cd90e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254385)[0m 2021-01-16 21:25:31.756779: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254625)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254625)[0m 2021-01-16 21:25:31.817039: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254625)[0m 2021-01-16 21:25:31.824786: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254625)[0m 2021-01-16 21:25:31.826822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2e10e8860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254625)[0m 2021-01-16 21:25:31.826853: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254215)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254215)[0m 2021-01-16 21:25:31.812627: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254215)[0m 2021-01-16 21:25:31.820705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254215)[0m 2021-01-16 21:25:31.822579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f824d1039c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254215)[0m 2021-01-16 21:25:31.822600: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254627)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254627)[0m 2021-01-16 21:25:31.826409: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254627)[0m 2021-01-16 21:25:31.834097: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254627)[0m 2021-01-16 21:25:31.836169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eefe10e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254627)[0m 2021-01-16 21:25:31.836197: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254213)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254213)[0m 2021-01-16 21:25:31.910473: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254213)[0m 2021-01-16 21:25:31.918168: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254213)[0m 2021-01-16 21:25:31.920332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f89ed103900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254213)[0m 2021-01-16 21:25:31.920364: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:25:32,433	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=251609, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:32,436	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_94_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.49595,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=251609)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=251609)[0m 
[2m[36m(pid=251609)[0m Stack (most recent call first):
[2m[36m(pid=254364)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254364)[0m   agg_primitives: ['count']
[2m[36m(pid=254364)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254364)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254345)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254345)[0m   agg_primitives: ['count']
[2m[36m(pid=254345)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254345)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254364)[0m LSTM is selected.
[2m[36m(pid=254345)[0m LSTM is selected.
[2m[36m(pid=254364)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254364)[0m Instructions for updating:
[2m[36m(pid=254364)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254345)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254345)[0m Instructions for updating:
[2m[36m(pid=254345)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254345)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254345)[0m Instructions for updating:
[2m[36m(pid=254345)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254364)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254364)[0m Instructions for updating:
[2m[36m(pid=254364)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254625)[0m Traceback (most recent call last):
[2m[36m(pid=254625)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254625)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254625)[0m , filename = '/tmp/thalvari/4565628/automl_save_a6_1kqqc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa2e256bfb8, total write size = 10240, bytes this sub-write = 10240, bytes actually written = 18446744073709551615, offset = 10328)
[2m[36m(pid=254625)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=254625)[0m Traceback (most recent call last):
[2m[36m(pid=254625)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254625)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254625)[0m , filename = '/tmp/thalvari/4565628/automl_save_a6_1kqqc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa2e256bfb8, total write size = 10240, bytes this sub-write = 10240, bytes actually written = 18446744073709551615, offset = 10328)
[2m[36m(pid=254215)[0m Traceback (most recent call last):
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254215)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254215)[0m , filename = '/tmp/thalvari/4565628/automl_save_v2kgcvho/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f824d62e910, total write size = 88, bytes this sub-write = 88, bytes actually written = 18446744073709551615, offset = 819200)
[2m[36m(pid=254215)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=254215)[0m Traceback (most recent call last):
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254215)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254215)[0m , filename = '/tmp/thalvari/4565628/automl_save_v2kgcvho/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f824d62e910, total write size = 88, bytes this sub-write = 88, bytes actually written = 18446744073709551615, offset = 819200)
[2m[36m(pid=254625)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254625)[0m 
[2m[36m(pid=254625)[0m Stack (most recent call first):
[2m[36m(pid=254625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 439 in close
[2m[36m(pid=254625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114 in save_model_to_hdf5
[2m[36m(pid=254625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109 in save_model
[2m[36m(pid=254625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171 in save
[2m[36m(pid=254625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163 in save
[2m[36m(pid=254625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122 in save
[2m[36m(pid=254625)[0m   File "/projappl/project_2003107/anaconda3/envs/
[2m[36m(pid=254215)[0m 2021-01-16 21:25:35,124	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254215)[0m Traceback (most recent call last):
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254215)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254215)[0m     param_dset[:] = val
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254215)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254215)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254215)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254215)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254215)[0m , filename = '/tmp/thalvari/4565628/automl_save_v2kgcvho/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f824e82f0b8, total write size = 1066584, bytes this sub-write = 1066584, bytes actually written = 18446744073709551615, offset = 892928)
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254215)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254215)[0m Traceback (most recent call last):
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254215)[0m     self._entrypoint()
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254215)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254215)[0m     output = train_func(config, reporter)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254215)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254215)[0m     config=config)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254215)[0m     model.save(model_path, config_path)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254215)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254215)[0m     self.model.save(model_path)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254215)[0m     signatures)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254215)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254215)[0m     f.close()
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254215)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254215)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254215)[0m , filename = '/tmp/thalvari/4565628/automl_save_v2kgcvho/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f824e16c410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254215)[0m Exception in thread Thread-1:
[2m[36m(pid=254215)[0m Traceback (most recent call last):
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254215)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254215)[0m     param_dset[:] = val
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254215)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254215)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254215)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254215)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254215)[0m , filename = '/tmp/thalvari/4565628/automl_save_v2kgcvho/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f824e82f0b8, total write size = 1066584, bytes this sub-write = 1066584, bytes actually written = 18446744073709551615, offset = 892928)
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254215)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254215)[0m Traceback (most recent call last):
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254215)[0m     self._entrypoint()
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254215)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254215)[0m     output = train_func(config, reporter)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254215)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254215)[0m     config=config)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254215)[0m     model.save(model_path, config_path)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254215)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254215)[0m     self.model.save(model_path)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254215)[0m     signatures)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254215)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254215)[0m     f.close()
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254215)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254215)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254215)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254215)[0m , filename = '/tmp/thalvari/4565628/automl_save_v2kgcvho/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f824e16c410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254385)[0m 2021-01-16 21:25:35,122	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254385)[0m Traceback (most recent call last):
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254385)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254385)[0m     param_dset[:] = val
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254385)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254385)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254385)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254385)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254385)[0m , filename = '/tmp/thalvari/4565628/automl_save_ztopsn5n/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cd9f118f8, total write size = 211032, bytes this sub-write = 211032, bytes actually written = 18446744073709551615, offset = 339968)
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254385)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254385)[0m Traceback (most recent call last):
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254385)[0m     self._entrypoint()
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254385)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254385)[0m     output = train_func(config, reporter)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254385)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254385)[0m     config=config)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254385)[0m     model.save(model_path, config_path)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254385)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254385)[0m     self.model.save(model_path)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254385)[0m     signatures)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254385)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254385)[0m     f.close()
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254385)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254385)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254385)[0m , filename = '/tmp/thalvari/4565628/automl_save_ztopsn5n/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cda97c520, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254385)[0m Exception in thread Thread-1:
[2m[36m(pid=254385)[0m Traceback (most recent call last):
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254385)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254385)[0m     param_dset[:] = val
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254385)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254385)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254385)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254385)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254385)[0m , filename = '/tmp/thalvari/4565628/automl_save_ztopsn5n/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cd9f118f8, total write size = 211032, bytes this sub-write = 211032, bytes actually written = 18446744073709551615, offset = 339968)
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254385)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254385)[0m Traceback (most recent call last):
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254385)[0m     self._entrypoint()
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254385)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254385)[0m     output = train_func(config, reporter)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254385)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254385)[0m     config=config)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254385)[0m     model.save(model_path, config_path)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254385)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254385)[0m     self.model.save(model_path)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254385)[0m     signatures)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254385)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254385)[0m     f.close()
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254385)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254385)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254385)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254385)[0m , filename = '/tmp/thalvari/4565628/automl_save_ztopsn5n/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cda97c520, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254627)[0m 2021-01-16 21:25:35,167	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254627)[0m Traceback (most recent call last):
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254627)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254627)[0m     param_dset[:] = val
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254627)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254627)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254627)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254627)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254627)[0m , filename = '/tmp/thalvari/4565628/automl_save_yio2qmoe/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7eefe27cdf40, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 819288)
[2m[36m(pid=254627)[0m 
[2m[36m(pid=254627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254627)[0m 
[2m[36m(pid=254627)[0m Traceback (most recent call last):
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254627)[0m     self._entrypoint()
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254627)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254627)[0m     output = train_func(config, reporter)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254627)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254627)[0m     config=config)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254627)[0m     model.save(model_path, config_path)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254627)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254627)[0m     self.model.save(model_path)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254627)[0m     signatures)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254627)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254627)[0m     f.close()
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254627)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254627)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254627)[0m , filename = '/tmp/thalvari/4565628/automl_save_yio2qmoe/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7eefe1772740, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254627)[0m Exception in thread Thread-1:
[2m[36m(pid=254627)[0m Traceback (most recent call last):
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254627)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254627)[0m     param_dset[:] = val
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254627)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254627)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254627)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254627)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254627)[0m , filename = '/tmp/thalvari/4565628/automl_save_yio2qmoe/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7eefe27cdf40, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 819288)
[2m[36m(pid=254627)[0m 
[2m[36m(pid=254627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254627)[0m 
[2m[36m(pid=254627)[0m Traceback (most recent call last):
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254627)[0m     self._entrypoint()
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254627)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254627)[0m     output = train_func(config, reporter)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254627)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254627)[0m     config=config)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254627)[0m     model.save(model_path, config_path)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254627)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254627)[0m     self.model.save(model_path)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254627)[0m     signatures)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254627)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254627)[0m     f.close()
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254627)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254627)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254627)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254627)[0m , filename = '/tmp/thalvari/4565628/automl_save_yio2qmoe/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7eefe1772740, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254215)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254215)[0m Traceback (most recent call last):
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254215)[0m     self.run()
[2m[36m(pid=254215)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254215)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254215)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254385)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254385)[0m Traceback (most recent call last):
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254385)[0m     self.run()
[2m[36m(pid=254385)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254385)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254385)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254627)[0m 
[2m[36m(pid=254627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254627)[0m 
[2m[36m(pid=254627)[0m Traceback (most recent call last):
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254627)[0m     self.run()
[2m[36m(pid=254627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254627)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254627)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254627)[0m 
2021-01-16 21:25:35,266	ERROR worker.py:1672 -- A worker died or was killed while executing task a9273c450d8d1e1a99532381a89ad5fa.
2021-01-16 21:25:35,267	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2021-01-16 21:25:35,269	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_97_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 104 ({'TERMINATED': 13, 'ERROR': 82, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 76 not shown
 - train_func_93_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_93_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-21ha9aetdz/error_2021-01-16_21-25-30.txt
 - train_func_94_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.49595,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_94_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-22la53xnke/error_2021-01-16_21-25-32.txt
 - train_func_97_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_97_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-24dcu1kkvz/error_2021-01-16_21-25-35.txt
RUNNING trials:
 - train_func_95_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_96_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_98_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_102_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.45471,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_103_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_104_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=254213)[0m Traceback (most recent call last):
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254213)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254213)[0m , filename = '/tmp/thalvari/4565628/automl_save_5x4q8d6d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f89ed8fca30, total write size = 88, bytes this sub-write = 88, bytes actually written = 18446744073709551615, offset = 819200)
[2m[36m(pid=254213)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=254213)[0m Traceback (most recent call last):
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254213)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254213)[0m , filename = '/tmp/thalvari/4565628/automl_save_5x4q8d6d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f89ed8fca30, total write size = 88, bytes this sub-write = 88, bytes actually written = 18446744073709551615, offset = 819200)
[2m[36m(pid=254213)[0m 2021-01-16 21:25:35,374	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254213)[0m Traceback (most recent call last):
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254213)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254213)[0m     param_dset[:] = val
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254213)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254213)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254213)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254213)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254213)[0m , filename = '/tmp/thalvari/4565628/automl_save_5x4q8d6d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f89eea21710, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 821336)
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254213)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254213)[0m Traceback (most recent call last):
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254213)[0m     self._entrypoint()
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254213)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254213)[0m     output = train_func(config, reporter)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254213)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254213)[0m     config=config)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254213)[0m     model.save(model_path, config_path)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254213)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254213)[0m     self.model.save(model_path)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254213)[0m     signatures)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254213)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254213)[0m     f.close()
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254213)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254213)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254213)[0m , filename = '/tmp/thalvari/4565628/automl_save_5x4q8d6d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f89ee06c170, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254213)[0m Exception in thread Thread-1:
[2m[36m(pid=254213)[0m Traceback (most recent call last):
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254213)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254213)[0m     param_dset[:] = val
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254213)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254213)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254213)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254213)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254213)[0m , filename = '/tmp/thalvari/4565628/automl_save_5x4q8d6d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f89eea21710, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 821336)
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254213)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254213)[0m Traceback (most recent call last):
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254213)[0m     self._entrypoint()
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254213)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254213)[0m     output = train_func(config, reporter)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254213)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254213)[0m     config=config)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254213)[0m     model.save(model_path, config_path)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254213)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254213)[0m     self.model.save(model_path)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254213)[0m     signatures)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254213)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254213)[0m     f.close()
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254213)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254213)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254213)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:35 2021
[2m[36m(pid=254213)[0m , filename = '/tmp/thalvari/4565628/automl_save_5x4q8d6d/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f89ee06c170, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254213)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254213)[0m Traceback (most recent call last):
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254213)[0m     self.run()
[2m[36m(pid=254213)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254213)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254213)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254622)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254622)[0m   agg_primitives: ['count']
[2m[36m(pid=254622)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254622)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254345)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254345)[0m 2021-01-16 21:25:35.616672: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254345)[0m 2021-01-16 21:25:35.624172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254345)[0m 2021-01-16 21:25:35.626293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3d690e8a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254345)[0m 2021-01-16 21:25:35.626319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254364)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254364)[0m 2021-01-16 21:25:35.722427: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254364)[0m 2021-01-16 21:25:35.729849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254364)[0m 2021-01-16 21:25:35.731877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd5250e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254364)[0m 2021-01-16 21:25:35.731897: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254339)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254339)[0m   agg_primitives: ['count']
[2m[36m(pid=254339)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254339)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254622)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254622)[0m Instructions for updating:
[2m[36m(pid=254622)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254622)[0m LSTM is selected.
2021-01-16 21:25:36,314	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254385, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:36,316	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_99_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254339)[0m LSTM is selected.
[2m[36m(pid=254339)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254339)[0m Instructions for updating:
[2m[36m(pid=254339)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254385)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254385)[0m 
[2m[36m(pid=254385)[0m Stack (most recent call first):
[2m[36m(pid=254622)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254622)[0m Instructions for updating:
[2m[36m(pid=254622)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254339)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254339)[0m Instructions for updating:
[2m[36m(pid=254339)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:25:37,060	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254627, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:37,065	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_98_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254344)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254344)[0m   agg_primitives: ['count']
[2m[36m(pid=254344)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254344)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254627)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254627)[0m 
[2m[36m(pid=254627)[0m Stack (most recent call first):
[2m[36m(pid=254344)[0m LSTM is selected.
2021-01-16 21:25:37,606	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254215, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:37,608	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_96_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254344)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254344)[0m Instructions for updating:
[2m[36m(pid=254344)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254622)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254622)[0m 2021-01-16 21:25:37.769217: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254622)[0m 2021-01-16 21:25:37.781302: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254622)[0m 2021-01-16 21:25:37.785698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7fb50e9530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254622)[0m 2021-01-16 21:25:37.785738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254215)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254215)[0m 
[2m[36m(pid=254215)[0m Stack (most recent call first):
[2m[36m(pid=254339)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254339)[0m 2021-01-16 21:25:38.062817: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254339)[0m 2021-01-16 21:25:38.073289: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254339)[0m 2021-01-16 21:25:38.076891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2c75103a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254339)[0m 2021-01-16 21:25:38.076941: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:25:38,236	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254213, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:38,239	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_95_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254344)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254344)[0m Instructions for updating:
[2m[36m(pid=254344)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254213)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254213)[0m 
[2m[36m(pid=254213)[0m Stack (most recent call first):
[2m[36m(pid=254345)[0m 2021-01-16 21:25:38,529	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254345)[0m Traceback (most recent call last):
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254345)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254345)[0m     param_dset[:] = val
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254345)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254345)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254345)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254345)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254345)[0m , filename = '/tmp/thalvari/4565628/automl_save__0luj3gz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f3d6a03d488, total write size = 8280, bytes this sub-write = 8280, bytes actually written = 18446744073709551615, offset = 806912)
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254345)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254345)[0m Traceback (most recent call last):
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254345)[0m     self._entrypoint()
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254345)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254345)[0m     output = train_func(config, reporter)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254345)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254345)[0m     config=config)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254345)[0m     model.save(model_path, config_path)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254345)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254345)[0m     self.model.save(model_path)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254345)[0m     signatures)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254345)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254345)[0m     f.close()
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254345)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254345)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254345)[0m , filename = '/tmp/thalvari/4565628/automl_save__0luj3gz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f3d69d44120, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254345)[0m Exception in thread Thread-1:
[2m[36m(pid=254345)[0m Traceback (most recent call last):
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254345)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254345)[0m     param_dset[:] = val
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254345)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254345)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254345)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254345)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254345)[0m , filename = '/tmp/thalvari/4565628/automl_save__0luj3gz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f3d6a03d488, total write size = 8280, bytes this sub-write = 8280, bytes actually written = 18446744073709551615, offset = 806912)
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254345)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254345)[0m Traceback (most recent call last):
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254345)[0m     self._entrypoint()
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254345)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254345)[0m     output = train_func(config, reporter)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254345)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254345)[0m     config=config)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254345)[0m     model.save(model_path, config_path)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254345)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254345)[0m     self.model.save(model_path)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254345)[0m     signatures)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254345)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254345)[0m     f.close()
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254345)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254345)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254345)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254345)[0m , filename = '/tmp/thalvari/4565628/automl_save__0luj3gz/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f3d69d44120, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254345)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254345)[0m Traceback (most recent call last):
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254345)[0m     self.run()
[2m[36m(pid=254345)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254345)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254345)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254364)[0m 2021-01-16 21:25:38,852	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254364)[0m Traceback (most recent call last):
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254364)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254364)[0m     param_dset[:] = val
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254364)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254364)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254364)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254364)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254364)[0m , filename = '/tmp/thalvari/4565628/automl_save_8fv3wpa4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd5264e5a58, total write size = 16472, bytes this sub-write = 16472, bytes actually written = 18446744073709551615, offset = 798720)
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254364)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254364)[0m Traceback (most recent call last):
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254364)[0m     self._entrypoint()
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254364)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254364)[0m     output = train_func(config, reporter)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254364)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254364)[0m     config=config)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254364)[0m     model.save(model_path, config_path)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254364)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254364)[0m     self.model.save(model_path)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254364)[0m     signatures)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254364)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254364)[0m     f.close()
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254364)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254364)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254364)[0m , filename = '/tmp/thalvari/4565628/automl_save_8fv3wpa4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd526268b60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254364)[0m Exception in thread Thread-1:
[2m[36m(pid=254364)[0m Traceback (most recent call last):
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254364)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254364)[0m     param_dset[:] = val
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254364)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254364)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254364)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254364)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254364)[0m , filename = '/tmp/thalvari/4565628/automl_save_8fv3wpa4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd5264e5a58, total write size = 16472, bytes this sub-write = 16472, bytes actually written = 18446744073709551615, offset = 798720)
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254364)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254364)[0m Traceback (most recent call last):
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254364)[0m     self._entrypoint()
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254364)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254364)[0m     output = train_func(config, reporter)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254364)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254364)[0m     config=config)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254364)[0m     model.save(model_path, config_path)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254364)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254364)[0m     self.model.save(model_path)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254364)[0m     signatures)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254364)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254364)[0m     f.close()
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254364)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254364)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254364)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:38 2021
[2m[36m(pid=254364)[0m , filename = '/tmp/thalvari/4565628/automl_save_8fv3wpa4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd526268b60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254364)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254364)[0m Traceback (most recent call last):
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254364)[0m     self.run()
[2m[36m(pid=254364)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254364)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254364)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254344)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254344)[0m 2021-01-16 21:25:39.381858: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254344)[0m 2021-01-16 21:25:39.393199: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254344)[0m 2021-01-16 21:25:39.396766: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb810e8c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254344)[0m 2021-01-16 21:25:39.396798: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254624)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254624)[0m   agg_primitives: ['count']
[2m[36m(pid=254624)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254624)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:25:39,688	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254345, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:39,691	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_101_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254345)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254345)[0m 
[2m[36m(pid=254345)[0m Stack (most recent call first):
[2m[36m(pid=257272)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=257232)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=257272)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=257232)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254624)[0m LSTM is selected.
[2m[36m(pid=254624)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254624)[0m Instructions for updating:
[2m[36m(pid=254624)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 110 ({'TERMINATED': 13, 'ERROR': 87, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 81 not shown
 - train_func_98_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_98_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-25iuv96sel/error_2021-01-16_21-25-37.txt
 - train_func_99_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_99_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime_2021-01-16_21-25-267e034s89/error_2021-01-16_21-25-36.txt
 - train_func_101_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_101_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetim_2021-01-16_21-25-3002g_4iv7/error_2021-01-16_21-25-39.txt
RUNNING trials:
 - train_func_100_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_102_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.45471,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_103_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_108_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_109_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_110_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.46018,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

2021-01-16 21:25:40,750	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254364, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:40,753	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_100_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254624)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254624)[0m Instructions for updating:
[2m[36m(pid=254624)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=257441)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=257443)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=257442)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=254364)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254364)[0m 
[2m[36m(pid=254364)[0m Stack (most recent call first):
[2m[36m(pid=254339)[0m 2021-01-16 21:25:40,911	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254339)[0m Traceback (most recent call last):
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254339)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254339)[0m     param_dset[:] = val
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254339)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254339)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254339)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254339)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254339)[0m , filename = '/tmp/thalvari/4565628/automl_save_hw6s99qj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2c761d2478, total write size = 84056, bytes this sub-write = 84056, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254339)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254339)[0m Traceback (most recent call last):
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254339)[0m     self._entrypoint()
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254339)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254339)[0m     output = train_func(config, reporter)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254339)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254339)[0m     config=config)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254339)[0m     model.save(model_path, config_path)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254339)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254339)[0m     self.model.save(model_path)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254339)[0m     signatures)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254339)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254339)[0m     f.close()
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254339)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254339)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254339)[0m , filename = '/tmp/thalvari/4565628/automl_save_hw6s99qj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2c76260230, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=257441)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=257443)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=257442)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254341)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254341)[0m   agg_primitives: ['count']
[2m[36m(pid=254341)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254341)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=254339)[0m Exception in thread Thread-1:
[2m[36m(pid=254339)[0m Traceback (most recent call last):
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254339)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254339)[0m     param_dset[:] = val
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254339)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254339)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254339)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254339)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254339)[0m , filename = '/tmp/thalvari/4565628/automl_save_hw6s99qj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2c761d2478, total write size = 84056, bytes this sub-write = 84056, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254339)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254339)[0m Traceback (most recent call last):
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254339)[0m     self._entrypoint()
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254339)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254339)[0m     output = train_func(config, reporter)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254339)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254339)[0m     config=config)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254339)[0m     model.save(model_path, config_path)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254339)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254339)[0m     self.model.save(model_path)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254339)[0m     signatures)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254339)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254339)[0m     f.close()
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254339)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254339)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254339)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254339)[0m , filename = '/tmp/thalvari/4565628/automl_save_hw6s99qj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2c76260230, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254339)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254339)[0m Traceback (most recent call last):
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254339)[0m     self.run()
[2m[36m(pid=254339)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254339)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254339)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254622)[0m 2021-01-16 21:25:40,966	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254622)[0m Traceback (most recent call last):
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254622)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254622)[0m     param_dset[:] = val
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254622)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254622)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254622)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254622)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254622)[0m , filename = '/tmp/thalvari/4565628/automl_save_vrc35ega/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fb558a9d8, total write size = 82008, bytes this sub-write = 82008, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254622)[0m Traceback (most recent call last):
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254622)[0m     self._entrypoint()
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254622)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254622)[0m     output = train_func(config, reporter)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254622)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254622)[0m     config=config)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254622)[0m     model.save(model_path, config_path)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254622)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254622)[0m     self.model.save(model_path)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254622)[0m     signatures)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254622)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254622)[0m     f.close()
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254622)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254622)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254622)[0m , filename = '/tmp/thalvari/4565628/automl_save_vrc35ega/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fb55d2bd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254622)[0m Exception in thread Thread-1:
[2m[36m(pid=254622)[0m Traceback (most recent call last):
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254622)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254622)[0m     param_dset[:] = val
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254622)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254622)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254622)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254622)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254622)[0m , filename = '/tmp/thalvari/4565628/automl_save_vrc35ega/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fb558a9d8, total write size = 82008, bytes this sub-write = 82008, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254622)[0m Traceback (most recent call last):
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254622)[0m     self._entrypoint()
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254622)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254622)[0m     output = train_func(config, reporter)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254622)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254622)[0m     config=config)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254622)[0m     model.save(model_path, config_path)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254622)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254622)[0m     self.model.save(model_path)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254622)[0m     signatures)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254622)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254622)[0m     f.close()
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254622)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254622)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254622)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:40 2021
[2m[36m(pid=254622)[0m , filename = '/tmp/thalvari/4565628/automl_save_vrc35ega/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fb55d2bd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254343)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254343)[0m   agg_primitives: ['count']
[2m[36m(pid=254343)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254343)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=257563)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=257563)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254622)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254622)[0m Traceback (most recent call last):
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254622)[0m     self.run()
[2m[36m(pid=254622)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254622)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254622)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254341)[0m LSTM is selected.
[2m[36m(pid=254341)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254341)[0m Instructions for updating:
[2m[36m(pid=254341)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254343)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254343)[0m Instructions for updating:
[2m[36m(pid=254343)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254343)[0m LSTM is selected.
[2m[36m(pid=254214)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=254214)[0m   agg_primitives: ['count']
[2m[36m(pid=254214)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=254214)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:25:42,026	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254622, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:42,030	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_102_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.45471,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254624)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254624)[0m 2021-01-16 21:25:42.105383: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254624)[0m 2021-01-16 21:25:42.113679: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254624)[0m 2021-01-16 21:25:42.116227: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3105102fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254624)[0m 2021-01-16 21:25:42.116251: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254622)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254622)[0m 
[2m[36m(pid=254622)[0m Stack (most recent call first):
[2m[36m(pid=254341)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254341)[0m Instructions for updating:
[2m[36m(pid=254341)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254343)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254343)[0m Instructions for updating:
[2m[36m(pid=254343)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254344)[0m 2021-01-16 21:25:42,462	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254344)[0m Traceback (most recent call last):
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254344)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254344)[0m     param_dset[:] = val
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254344)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254344)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254344)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254344)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:42 2021
[2m[36m(pid=254344)[0m , filename = '/tmp/thalvari/4565628/automl_save_b19z74dy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb824ae258, total write size = 90200, bytes this sub-write = 90200, bytes actually written = 18446744073709551615, offset = 724992)
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254344)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254344)[0m Traceback (most recent call last):
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254344)[0m     self._entrypoint()
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254344)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254344)[0m     output = train_func(config, reporter)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254344)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254344)[0m     config=config)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254344)[0m     model.save(model_path, config_path)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254344)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254344)[0m     self.model.save(model_path)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254344)[0m     signatures)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254344)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254344)[0m     f.close()
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254344)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254344)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:42 2021
[2m[36m(pid=254344)[0m , filename = '/tmp/thalvari/4565628/automl_save_b19z74dy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb824060b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254344)[0m Exception in thread Thread-1:
[2m[36m(pid=254344)[0m Traceback (most recent call last):
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254344)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254344)[0m     param_dset[:] = val
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254344)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254344)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254344)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254344)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:42 2021
[2m[36m(pid=254344)[0m , filename = '/tmp/thalvari/4565628/automl_save_b19z74dy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb824ae258, total write size = 90200, bytes this sub-write = 90200, bytes actually written = 18446744073709551615, offset = 724992)
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254344)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254344)[0m Traceback (most recent call last):
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254344)[0m     self._entrypoint()
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254344)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254344)[0m     output = train_func(config, reporter)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254344)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254344)[0m     config=config)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254344)[0m     model.save(model_path, config_path)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254344)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254344)[0m     self.model.save(model_path)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254344)[0m     signatures)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254344)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254344)[0m     f.close()
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254344)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254344)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254344)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:42 2021
[2m[36m(pid=254344)[0m , filename = '/tmp/thalvari/4565628/automl_save_b19z74dy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdb824060b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254344)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254344)[0m Traceback (most recent call last):
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254344)[0m     self.run()
[2m[36m(pid=254344)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254344)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254344)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254214)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=254214)[0m Instructions for updating:
[2m[36m(pid=254214)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=254214)[0m LSTM is selected.
2021-01-16 21:25:42,696	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254339, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:42,698	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_103_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254339)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254339)[0m 
[2m[36m(pid=254339)[0m Stack (most recent call first):
[2m[36m(pid=254214)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=254214)[0m Instructions for updating:
[2m[36m(pid=254214)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254341)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254341)[0m 2021-01-16 21:25:43.222607: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254341)[0m 2021-01-16 21:25:43.230499: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254341)[0m 2021-01-16 21:25:43.232507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f84e50cf900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254341)[0m 2021-01-16 21:25:43.232528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254343)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254343)[0m 2021-01-16 21:25:43.337155: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254343)[0m 2021-01-16 21:25:43.344625: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254343)[0m 2021-01-16 21:25:43.346456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5d890e9530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254343)[0m 2021-01-16 21:25:43.346476: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:25:43,503	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254344, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:43,505	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_104_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254344)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254344)[0m 
[2m[36m(pid=254344)[0m Stack (most recent call first):
[2m[36m(pid=254214)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=254214)[0m 2021-01-16 21:25:44.036273: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=254214)[0m 2021-01-16 21:25:44.044888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=254214)[0m 2021-01-16 21:25:44.047036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbdfd0e8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=254214)[0m 2021-01-16 21:25:44.047060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=254624)[0m 2021-01-16 21:25:44,690	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254624)[0m Traceback (most recent call last):
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254624)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254624)[0m     param_dset[:] = val
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254624)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254624)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254624)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254624)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:44 2021
[2m[36m(pid=254624)[0m , filename = '/tmp/thalvari/4565628/automl_save_6w8s_7ul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3106050ec8, total write size = 100440, bytes this sub-write = 100440, bytes actually written = 18446744073709551615, offset = 716800)
[2m[36m(pid=254624)[0m 
[2m[36m(pid=254624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254624)[0m 
[2m[36m(pid=254624)[0m Traceback (most recent call last):
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254624)[0m     self._entrypoint()
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254624)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254624)[0m     output = train_func(config, reporter)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254624)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254624)[0m     config=config)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254624)[0m     model.save(model_path, config_path)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254624)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254624)[0m     self.model.save(model_path)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254624)[0m     signatures)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254624)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254624)[0m     f.close()
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254624)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254624)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:44 2021
[2m[36m(pid=254624)[0m , filename = '/tmp/thalvari/4565628/automl_save_6w8s_7ul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3105ff0b70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254624)[0m Exception in thread Thread-1:
[2m[36m(pid=254624)[0m Traceback (most recent call last):
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254624)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254624)[0m     param_dset[:] = val
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254624)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254624)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254624)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254624)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:44 2021
[2m[36m(pid=254624)[0m , filename = '/tmp/thalvari/4565628/automl_save_6w8s_7ul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3106050ec8, total write size = 100440, bytes this sub-write = 100440, bytes actually written = 18446744073709551615, offset = 716800)
[2m[36m(pid=254624)[0m 
[2m[36m(pid=254624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254624)[0m 
[2m[36m(pid=254624)[0m Traceback (most recent call last):
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254624)[0m     self._entrypoint()
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254624)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254624)[0m     output = train_func(config, reporter)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254624)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254624)[0m     config=config)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=254624)[0m     model.save(model_path, config_path)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=254624)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=254624)[0m     self.model.save(model_path)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=254624)[0m     signatures)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=254624)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=254624)[0m     f.close()
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=254624)[0m     h5i.dec_ref(id_)
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254624)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=254624)[0m RuntimeError: Problems closing file (file write failed: time = Sat Jan 16 21:25:44 2021
[2m[36m(pid=254624)[0m , filename = '/tmp/thalvari/4565628/automl_save_6w8s_7ul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3105ff0b70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=254624)[0m 
[2m[36m(pid=254624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254624)[0m 
[2m[36m(pid=254624)[0m Traceback (most recent call last):
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=254624)[0m     self.run()
[2m[36m(pid=254624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=254624)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=254624)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=254624)[0m 
[2m[36m(pid=257232)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=257232)[0m   agg_primitives: ['count']
[2m[36m(pid=257232)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=257232)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=257563)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=257563)[0m   agg_primitives: ['count']
[2m[36m(pid=257563)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=257563)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=257442)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=257442)[0m   agg_primitives: ['count']
[2m[36m(pid=257442)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=257442)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=257272)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=257272)[0m   agg_primitives: ['count']
[2m[36m(pid=257272)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=257272)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=257563)[0m LSTM is selected.
[2m[36m(pid=257232)[0m LSTM is selected.
[2m[36m(pid=257563)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=257563)[0m Instructions for updating:
[2m[36m(pid=257563)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=257442)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=257442)[0m Instructions for updating:
[2m[36m(pid=257442)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=257442)[0m LSTM is selected.
[2m[36m(pid=257272)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=257272)[0m Instructions for updating:
[2m[36m(pid=257272)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=257272)[0m LSTM is selected.
[2m[36m(pid=257232)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=257232)[0m Instructions for updating:
[2m[36m(pid=257232)[0m If using Keras pass *_constraint arguments to layers.
2021-01-16 21:25:45,800	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254624, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:45,803	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_105_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 114 ({'TERMINATED': 13, 'ERROR': 92, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 86 not shown
 - train_func_103_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_103_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetim_2021-01-16_21-25-32y9o9x4jn/error_2021-01-16_21-25-42.txt
 - train_func_104_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_104_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetim_2021-01-16_21-25-33aqc_6fqq/error_2021-01-16_21-25-43.txt
 - train_func_105_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_105_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetim_2021-01-16_21-25-35m1n42_ad/error_2021-01-16_21-25-45.txt
RUNNING trials:
 - train_func_106_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_107_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_108_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_112_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_113_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_114_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

[2m[36m(pid=254624)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254624)[0m 
[2m[36m(pid=254624)[0m Stack (most recent call first):
[2m[36m(pid=257442)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=257442)[0m Instructions for updating:
[2m[36m(pid=257442)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=257272)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=257272)[0m Instructions for updating:
[2m[36m(pid=257272)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=257232)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=257232)[0m Instructions for updating:
[2m[36m(pid=257232)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=254341)[0m 2021-01-16 21:25:46,319	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254341)[0m Traceback (most recent call last):
[2m[36m(pid=254341)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=254341)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
2021-01-16 21:25:46,499	ERROR worker.py:1672 -- A worker died or was killed while executing task d1e3f908ac77c809ed181394793ac471.
[2m[36m(pid=254341)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=254341)[0m     param_dset[:] = val
[2m[36m(pid=254341)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254341)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254341)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=254341)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=254341)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254341)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=254341)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=254341)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=254341)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=254341)[0m OSError: Can't write data (file write failed: time = Sat Jan 16 21:25:46 2021
[2m[36m(pid=254341)[0m , filename = '/tmp/thalvari/4565628/automl_save_3g4_8sm3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f84e69b3c58, total write size = 127064, bytes this sub-write = 127064, bytes actually written = 18446744073709551615, offset = 421888)
[2m[36m(pid=254341)[0m 
[2m[36m(pid=254341)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254341)[0m 
[2m[36m(pid=254341)[0m Traceback (most recent call last):
[2m[36m(pid=254341)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254341)[0m     self._entrypoint()
[2m[36m(pid=254341)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254341)[0m     return self._trainable_func(config, self._status_reporter
[2m[36m(pid=254343)[0m Traceback (most recent call last):
[2m[36m(pid=254343)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254343)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:46 2021
[2m[36m(pid=254343)[0m , filename = '/tmp/thalvari/4565628/automl_save_zd10e1fq/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5d8a03e9d0, total write size = 88, bytes this sub-write = 88, bytes actually written = 18446744073709551615, offset = 286720)
[2m[36m(pid=254343)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=254343)[0m Traceback (most recent call last):
[2m[36m(pid=254343)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=254343)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sat Jan 16 21:25:46 2021
[2m[36m(pid=254343)[0m , filename = '/tmp/thalvari/4565628/automl_save_zd10e1fq/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5d8a03e9d0, total write size = 88, bytes this sub-write = 88, bytes actually written = 18446744073709551615, offset = 286720)
[2m[36m(pid=254343)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=254343)[0m 
[2m[36m(pid=254343)[0m Stack (most recent call first):
[2m[36m(pid=254343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 439 in close
[2m[36m(pid=254343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114 in save_model_to_hdf5
[2m[36m(pid=254343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109 in save_model
[2m[36m(pid=254343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171 in save
[2m[36m(pid=254343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163 in save
[2m[36m(pid=254343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122 in save
[2m[36m(pid=254343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-
[2m[36m(pid=257563)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=257563)[0m Instructions for updating:
[2m[36m(pid=257563)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-16 21:25:46,546	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2021-01-16 21:25:46,548	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_107_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=254214)[0m 2021-01-16 21:25:46,697	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=254214)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=254214)[0m 
[2m[36m(pid=254214)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254214)[0m 
[2m[36m(pid=254214)[0m Traceback (most recent call last):
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=254214)[0m     self._entrypoint()
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=254214)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=254214)[0m     output = train_func(config, reporter)
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=254214)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=254214)[0m     config=config)
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=254214)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=254214)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=254214)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=254214)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=254214)[0m Exception in thread Thread-1:
[2m[36m(pid=254214)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=254214)[0m 
[2m[36m(pid=254214)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=254214)[0m 
[2m[36m(pid=254214)[0m Traceback (most recent call last):
[2m[36m(pid=254214)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=257442)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=257442)[0m 2021-01-16 21:25:47.214318: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=257272)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=257272)[0m 2021-01-16 21:25:47.261296: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=257272)[0m 2021-01-16 21:25:47.270507: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=257272)[0m 2021-01-16 21:25:47.274575: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2bad0e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=257272)[0m 2021-01-16 21:25:47.274598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=257442)[0m 2021-01-16 21:25:47.261944: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=257442)[0m 2021-01-16 21:25:47.265594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcdf10e8900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=257442)[0m 2021-01-16 21:25:47.265616: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=257563)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=257563)[0m 2021-01-16 21:25:47.320143: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=257563)[0m 2021-01-16 21:25:47.328502: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=257441)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=257441)[0m   agg_primitives: ['count']
[2m[36m(pid=257441)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=257441)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-16 21:25:47,371	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254341, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:47,384	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_106_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=257563)[0m 2021-01-16 21:25:47.377738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feaad0e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=257563)[0m 2021-01-16 21:25:47.377770: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=257443)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=257443)[0m   agg_primitives: ['count']
[2m[36m(pid=257443)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=257443)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=257232)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=257232)[0m 2021-01-16 21:25:47.448276: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=257232)[0m 2021-01-16 21:25:47.471873: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=257232)[0m 2021-01-16 21:25:47.474542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbbed0e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=257232)[0m 2021-01-16 21:25:47.474565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-16 21:25:47,966	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=254214, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:47,969	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_108_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=257441)[0m LSTM is selected.
[2m[36m(pid=257441)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=257441)[0m Instructions for updating:
[2m[36m(pid=257441)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=257443)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=257443)[0m Instructions for updating:
[2m[36m(pid=257443)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=257443)[0m LSTM is selected.
[2m[36m(pid=257441)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=257441)[0m Instructions for updating:
[2m[36m(pid=257441)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=257443)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=257443)[0m Instructions for updating:
[2m[36m(pid=257443)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=257441)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=257441)[0m 2021-01-16 21:25:49.778023: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=257441)[0m 2021-01-16 21:25:49.790322: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=257441)[0m 2021-01-16 21:25:49.799797: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7b01103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=257441)[0m 2021-01-16 21:25:49.799855: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=257443)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=257443)[0m 2021-01-16 21:25:49.845185: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=257443)[0m 2021-01-16 21:25:49.863037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=257443)[0m 2021-01-16 21:25:49.868754: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98910e9620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=257443)[0m 2021-01-16 21:25:49.868810: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=257272)[0m 2021-01-16 21:25:50,580	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=257272)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257272)[0m 
[2m[36m(pid=257272)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257272)[0m 
[2m[36m(pid=257272)[0m Traceback (most recent call last):
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=257272)[0m     self._entrypoint()
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=257272)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=257272)[0m     output = train_func(config, reporter)
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=257272)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=257272)[0m     config=config)
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=257272)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=257272)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=257272)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=257272)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257272)[0m Exception in thread Thread-1:
[2m[36m(pid=257272)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257272)[0m 
[2m[36m(pid=257272)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257272)[0m 
[2m[36m(pid=257272)[0m Traceback (most recent call last):
[2m[36m(pid=257272)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=257563)[0m 2021-01-16 21:25:50,572	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=257563)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257563)[0m 
[2m[36m(pid=257563)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257563)[0m 
[2m[36m(pid=257563)[0m Traceback (most recent call last):
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=257563)[0m     self._entrypoint()
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=257563)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=257563)[0m     output = train_func(config, reporter)
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=257563)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=257563)[0m     config=config)
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=257563)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=257563)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=257563)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=257563)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257563)[0m Exception in thread Thread-1:
[2m[36m(pid=257563)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257563)[0m 
[2m[36m(pid=257563)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257563)[0m 
[2m[36m(pid=257563)[0m Traceback (most recent call last):
[2m[36m(pid=257563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=257442)[0m 2021-01-16 21:25:50,563	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=257442)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257442)[0m 
[2m[36m(pid=257442)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257442)[0m 
[2m[36m(pid=257442)[0m Traceback (most recent call last):
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=257442)[0m     self._entrypoint()
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=257442)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=257442)[0m     output = train_func(config, reporter)
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=257442)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=257442)[0m     config=config)
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=257442)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=257442)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=257442)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=257442)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257442)[0m Exception in thread Thread-1:
[2m[36m(pid=257442)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257442)[0m 
[2m[36m(pid=257442)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257442)[0m 
[2m[36m(pid=257442)[0m Traceback (most recent call last):
[2m[36m(pid=257442)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=257232)[0m 2021-01-16 21:25:50,822	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=257232)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257232)[0m 
[2m[36m(pid=257232)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257232)[0m 
[2m[36m(pid=257232)[0m Traceback (most recent call last):
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=257232)[0m     self._entrypoint()
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=257232)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=257232)[0m     output = train_func(config, reporter)
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=257232)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=257232)[0m     config=config)
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=257232)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=257232)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=257232)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=257232)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257232)[0m Exception in thread Thread-1:
[2m[36m(pid=257232)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257232)[0m 
[2m[36m(pid=257232)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257232)[0m 
[2m[36m(pid=257232)[0m Traceback (most recent call last):
[2m[36m(pid=257232)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
2021-01-16 21:25:51,716	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=257272, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:51,719	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_110_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.46018,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_1xd7p0gv/automl
Number of trials: 118 ({'TERMINATED': 13, 'ERROR': 96, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-16_21-23-174cylbgqr/error_2021-01-16_21-23-31.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-16_21-23-172_o5sl01/error_2021-01-16_21-23-31.txt
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE_2021-01-16_21-23-17nrd8ya4y/error_2021-01-16_21-23-31.txt
  ... 90 not shown
 - train_func_107_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_107_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetim_2021-01-16_21-25-37ormvkry8/error_2021-01-16_21-25-46.txt
 - train_func_108_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_108_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetim_2021-01-16_21-25-38mv0_08i3/error_2021-01-16_21-25-47.txt
 - train_func_110_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.46018,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_1xd7p0gv/automl/train_func_110_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetim_2021-01-16_21-25-40751xk06r/error_2021-01-16_21-25-51.txt
RUNNING trials:
 - train_func_109_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_111_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_112_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_116_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.38551,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_117_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_118_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234434], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234431], 37 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234424], 11 s, 5 iter
  ... 7 not shown
 - train_func_14_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236199], 13 s, 5 iter
 - train_func_15_batch_size_log=8.5703,bayes_feature_DAY(datetime)=0.73452,bayes_feature_HOUR(datetime)=0.32816,bayes_feature_IS_AWAKE(datetime)=0.52125,bayes_feature_IS_BUSY_HOURS(datetime)=0.46976,bayes_feature_IS_WEEKEND(datetime)=0.67052,bayes_feature_MONTH(datetime)=0.73558,bayes_feature_WEEKDAY(datetime)=0.44887,dropout_1=0.25582,dropout_2=0.26897,epochs=5,lr=0.003671,lstm_1_units_float=27.008,lstm_2_units_float=42.37,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=236208], 11 s, 5 iter
 - train_func_18_batch_size_log=7.9737,bayes_feature_DAY(datetime)=0.65103,bayes_feature_HOUR(datetime)=0.59299,bayes_feature_IS_AWAKE(datetime)=0.95592,bayes_feature_IS_BUSY_HOURS(datetime)=0.82965,bayes_feature_IS_WEEKEND(datetime)=0.84328,bayes_feature_MONTH(datetime)=0.39168,bayes_feature_WEEKDAY(datetime)=0.96729,dropout_1=0.23917,dropout_2=0.23695,epochs=5,lr=0.0018261,lstm_1_units_float=8.4257,lstm_2_units_float=88.082,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=234429], 13 s, 5 iter

2021-01-16 21:25:52,688	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=257563, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:52,693	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_111_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=257441)[0m 2021-01-16 21:25:52,922	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=257441)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257441)[0m 
[2m[36m(pid=257441)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257441)[0m 
[2m[36m(pid=257441)[0m Traceback (most recent call last):
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=257441)[0m     self._entrypoint()
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=257441)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=257441)[0m     output = train_func(config, reporter)
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=257441)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=257441)[0m     config=config)
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=257441)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=257441)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=257441)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=257441)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257441)[0m Exception in thread Thread-1:
[2m[36m(pid=257441)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257441)[0m 
[2m[36m(pid=257441)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257441)[0m 
[2m[36m(pid=257441)[0m Traceback (most recent call last):
[2m[36m(pid=257441)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=257443)[0m 2021-01-16 21:25:53,062	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=257443)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257443)[0m 
[2m[36m(pid=257443)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257443)[0m 
[2m[36m(pid=257443)[0m Traceback (most recent call last):
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=257443)[0m     self._entrypoint()
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=257443)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=257443)[0m     output = train_func(config, reporter)
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=257443)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=257443)[0m     config=config)
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=257443)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=257443)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=257443)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=257443)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257443)[0m Exception in thread Thread-1:
[2m[36m(pid=257443)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=257443)[0m 
[2m[36m(pid=257443)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=257443)[0m 
[2m[36m(pid=257443)[0m Traceback (most recent call last):
[2m[36m(pid=257443)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
2021-01-16 21:25:53,406	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=257232, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:53,408	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_109_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:25:54,134	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=257442, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:54,137	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_112_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:25:54,946	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=257441, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:54,949	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_113_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-16 21:25:55,450	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=257443, host=r02c19.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-16 21:25:55,453	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_114_batch_size_log=10.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-17 00:40:03,736	ERROR worker.py:1672 -- The reporter on node r02c19.bullx failed with the following error:
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/6234/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 176, in run
    self.perform_iteration()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 165, in perform_iteration
    stats = self.get_all_stats()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 156, in get_all_stats
    "workers": self.get_workers(),
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in get_workers
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in <listcomp>
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/__init__.py", line 634, in name
    name = self._proc.name()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1610, in name
    name = self._parse_stat_file()['name']
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=6234)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 218, in <module>
    reporter.run()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 178, in run
    traceback.print_exc()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 105, in print_exception
    print(line, file=file, end="")
OSError: [Errno 28] No space left on device

