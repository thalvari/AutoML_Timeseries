Running on local machine
Parent Run ID: AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233

Current status: DatasetFeaturization. Beginning to featurize the dataset.
Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.
Heuristic parameters: Target_Lag = '[0]', Target_Rolling_Window = '0', Max_Horizon = '24'.
WARNING - Converting non-string tag to string: (forecasting_target_lags: [0])
WARNING - Converting non-string tag to string: (forecasting_target_rolling_window_size: 0)
WARNING - Converting non-string tag to string: (forecasting_max_horizon: 24)
Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.
Current status: DatasetFeaturization. Beginning to featurize the CV split.
Current status: DatasetFeaturizationCompleted. Completed featurizing the CV split.

****************************************************************************************************
DATA GUARDRAILS: 

TYPE:         Frequency detection
STATUS:       PASSED
DESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.
              

****************************************************************************************************

TYPE:         Missing feature values imputation
STATUS:       PASSED
DESCRIPTION:  No feature missing values were detected in the training data.
              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization

****************************************************************************************************

TYPE:         Memory Issues Detection
STATUS:       PASSED
DESCRIPTION:  The selected horizon, lag and rolling window values were analyzed, and no potential memory issues were detected.
              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration

****************************************************************************************************
Current status: ModelSelection. Beginning model selection.

****************************************************************************************************
ITERATION: The iteration being evaluated.
PIPELINE: A summary description of the pipeline being evaluated.
DURATION: Time taken for the current iteration.
METRIC: The result of computing score on the fitted pipeline.
BEST: The best observed score thus far.
****************************************************************************************************

 ITERATION   PIPELINE                                       DURATION      METRIC      BEST
         0   MaxAbsScaler DecisionTree                      0:00:31       0.1326    0.1326
         1   RobustScaler ElasticNet                        0:00:25       0.1457    0.1326
         2   RobustScaler ElasticNet                        0:00:24       0.1434    0.1326
         3   RobustScaler ElasticNet                        0:00:23       0.1452    0.1326
         4   RobustScaler ElasticNet                        0:00:24       0.1414    0.1326
         5   WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233_5/outputs/pipeline_graph.json?sv=2019-02-02&sr=b&sig=BWKMTCZ4JpsoRgSi7QP5vQ3wVRIXBeatyOCrW4JZiPU%3D&st=2020-08-26T01%3A24%3A28Z&se=2020-08-27T01%3A34%3A28Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
MinMaxScaler DecisionTree                      0:03:15       0.1442    0.1326
         6   StandardScalerWrapper ElasticNet               0:00:27       0.1431    0.1326
         7   StandardScalerWrapper DecisionTree             0:00:27       0.1520    0.1326
         8   RobustScaler DecisionTree                      0:00:42       0.1536    0.1326
         9   StandardScalerWrapper DecisionTree             0:00:31       0.1489    0.1326
        10   MaxAbsScaler SGD                               0:00:26       0.1827    0.1326
        11   StandardScalerWrapper DecisionTree             0:00:27       0.1336    0.1326
        12   WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233_12/outputs/pipeline_graph.json?sv=2019-02-02&sr=b&sig=D%2BofCeCq4cUdd9ce4zk4Q5JoL1xTfd4GycRw2llZSgc%3D&st=2020-08-26T01%3A30%3A45Z&se=2020-08-27T01%3A40%3A45Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233_12/outputs/conda_env_v_1_0_0.yml?sv=2019-02-02&sr=b&sig=RZBaLphEdzwIZSksQQ89%2BJeeRLrxqFFYbzwDqqrb56k%3D&st=2020-08-26T01%3A30%3A45Z&se=2020-08-27T01%3A40%3A45Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233_12/outputs/model.pkl?sv=2019-02-02&sr=b&sig=aGjzQlPT0dVlU6N2%2BZHnJyhzkdwwjMqngQvKEmACW6k%3D&st=2020-08-26T01%3A30%3A45Z&se=2020-08-27T01%3A40%3A45Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
MinMaxScaler DecisionTree                      0:03:05       0.1436    0.1326
        13   MinMaxScaler SGD                               0:00:25       0.1491    0.1326
        14   RobustScaler DecisionTree                      0:00:25       0.1233    0.1233
        15   MinMaxScaler DecisionTree                      0:00:24       0.1837    0.1233
        16   StandardScalerWrapper DecisionTree             0:00:26       0.1455    0.1233
        17   StandardScalerWrapper SGD                      0:00:25       0.6072    0.1233
        18   RobustScaler ElasticNet                        0:00:24       0.1409    0.1233
        19   MinMaxScaler DecisionTree                      0:00:24       0.1336    0.1233
        20   WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233_20/outputs/model.pkl?sv=2019-02-02&sr=b&sig=biGcDfCbnwE6SEJSm52HwV%2BmRJn9nPXiEBEOQ9kV%2FrA%3D&st=2020-08-26T01%3A37%3A18Z&se=2020-08-27T01%3A47%3A18Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233_20/outputs/pipeline_graph.json?sv=2019-02-02&sr=b&sig=BnCd3a1A2xDZRqfQ3I72oU84zKROp8%2FGOqUpdEtUuvA%3D&st=2020-08-26T01%3A37%3A18Z&se=2020-08-27T01%3A47%3A18Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
MinMaxScaler ExtremeRandomTrees                0:03:11       0.1306    0.1233
        21   WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /azureml/ExperimentRun/dcid.AutoML_92f10ff2-ea14-49cd-9672-945b42c7f233_21/outputs/pipeline_graph.json?sv=2019-02-02&sr=b&sig=%2FyWCq3a1oH5x80vExLfly%2B4wPM%2BtHw3CL5s60%2FS%2BccE%3D&st=2020-08-26T01%3A40%3A13Z&se=2020-08-27T01%3A50%3A13Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30
MinMaxScaler ExtremeRandomTrees                0:00:53       0.1280    0.1233
        22   MinMaxScaler RandomForest                      0:00:38       0.1240    0.1233
        23   StandardScalerWrapper RandomForest             0:00:37       0.1337    0.1233
        24   StandardScalerWrapper ExtremeRandomTrees       0:00:48       0.1267    0.1233
        25   MaxAbsScaler DecisionTree                      0:00:25       0.1264    0.1233
        26   StandardScalerWrapper RandomForest             0:00:40       0.1295    0.1233
        27   RobustScaler ExtremeRandomTrees                0:00:40       0.1237    0.1233
        28   RobustScaler ExtremeRandomTrees                0:01:28       0.1311    0.1233
        29   StandardScalerWrapper ExtremeRandomTrees       0:00:38       0.1310    0.1233
        30   VotingEnsemble                                 0:02:28       0.1135    0.1135
Stopping criteria reached at iteration 31. Ending experiment.
****************************************************************************************************
Current status: BestRunExplainModel. Best run model explanations started
Current status: ModelExplanationDataSetSetup. Model explanations data setup completed
Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations
Current status: EngineeredFeatureExplanations. Computation of engineered features started
Current status: EngineeredFeatureExplanations. Computation of engineered features completed
Current status: BestRunExplainModel. Best run model explanations completed
****************************************************************************************************
[('timeseriestransformer', TimeSeriesTransformer(featurization_config=None,
           pipeline_type=<TimeSeriesPipelineType.FULL: 1>)), ('prefittedsoftvotingregressor', PreFittedSoftVotingRegressor(estimators=[('14', Pipeline(memory=None,
     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=[25, 75], with_centering=False,
       with_scaling=False)), ('decisiontreeregressor', DecisionTreeRegressor(criterion='friedman_mse', max_depth=None,
           max_features=None, max_leaf_n...ate=None, shuffle=True, tol=1e-05,
       validation_fraction=0.1, verbose=0, warm_start=False))]))],
               flatten_transform=None,
               weights=[0.4666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]))]
